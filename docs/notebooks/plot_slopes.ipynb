{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Slopes\n",
    "\n",
    "Bambi's sub-package `interpret` features a set of functions to help interpret complex regression models. The sub-package is inspired by the R package [marginaleffects](https://marginaleffects.com/chapters/predictions.html#conditional-predictions). In this notebook we will discuss two functions `slopes` and `plot_slopes`. These two functions allow the modeler to easier interpret slopes, either by a inspecting a summary output or plotting them.\n",
    "\n",
    "Below, it is described why estimating the slope of the prediction function is useful in interpreting generalized linear models (GLMs), how this methodology is implemented in Bambi, and how to use `slopes` and `plot_slopes`. It is assumed that the reader is familiar with the basics of GLMs. If not, refer to the Bambi [Basic Building Blocks](https://bambinos.github.io/bambi/notebooks/how_bambi_works.html#Link-functions) example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of Regression Coefficients\n",
    "\n",
    "Assuming we have fit a linear regression model of the form\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_k x_k + \\epsilon$$\n",
    "\n",
    "the \"safest\" interpretation of the regression coefficients $\\beta$ is as a comparison between two groups of items that differ by $1$ in the relevant predictor variable $x_i$ while being identical in all the other predictors. Formally, the predicted difference between two items $i$ and $j$ that differ by an amount $n$ on predictor $k$, but are identical on all other predictors, the predicted difference is $y_i - y_j$ is $\\beta_kx$, on average.\n",
    "\n",
    "However, once we move away from a regression model with a Gaussian response, the identity function, and no interaction terms, the interpretation of the coefficients are not as straightforward. For example, in a logistic regression model, the coefficients are on a different scale and are measured in logits (log odds), not probabilities or percentage points. Thus, you cannot interpret the coefficents as a \"one unit increase in $x_k$ is associated with an $n$ percentage point decrease in $y$\". First, the logits must be converted to the probability scale. Secondly, a one unit change in $x_k$ may produce a larger or smaller change in the outcome, depending upon how far away from zero the logits are. \n",
    "\n",
    "`slopes` and `plot_slopes`, by default, computes quantities of interest on the response scale for GLMs. For example, for a logistic regression model, this is the probability scale, and for a Poisson regression model, this is the count scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting interaction effects\n",
    "\n",
    "Specifying interactions in a regression model is a way of allowing parameters to be conditional on certain aspects of the data. By contrast, for a model with no interactions, the parameters are **not** conditional and thus, the value of one parameter is not dependent on the value of another covariate. However, once interactions exist, multiple parameters are always in play at the same time. Additionally, interactions can be specified for either categorical, continuous, or both types of covariates. Thus, making the interpretation of the parameters more difficult.\n",
    "\n",
    "With GLMs, every covariate essentially interacts with itself because of the link function. To demonstrate parameters interacting with themselves, consider the mean of a Gaussian linear model with an identity link function\n",
    "\n",
    "$$\\mu = \\alpha + \\beta x$$\n",
    "\n",
    "where the rate of change in $\\mu$ with respect to $x$ is just $\\beta$, i.e., the rate of change is constant no matter what the value of $x$ is. But when we consider GLMs with link functions used to map outputs to exponential family distribution parameters, calculating the derivative of the mean output $\\mu$ with respect to the predictor is not as straightforward as in the Gaussian linear model. For example, computing the rate of change in a binomial probability $p$ with respect to $x$\n",
    "\n",
    "$$p = \\frac{exp(\\alpha + \\beta x)}{1 + exp(\\alpha + \\beta x)}$$\n",
    "\n",
    "And taking the derivative of $p$ with respect to $x$ yields\n",
    "\n",
    "$$\\frac{\\partial p}{\\partial x} = \\frac{\\beta}{2(1 + cosh(\\alpha + \\beta x))}$$\n",
    "\n",
    "Since $x$ appears in the derivative, the impact of a change in $x$ depends upon $x$, i.e., an interaction with itself even though no interaction term was specified in the model.Thus, visualizing the rate of change in the mean response with respect to a covariate $x$ becomes a useful tool in interpreting GLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Predictive Slopes\n",
    "\n",
    "Here, we adopt the notation from Chapter 14.4 of [Regression and Other Stories](https://avehtari.github.io/ROS-Examples/) to first describe average predictive differences which is essential to computing `slopes`, and then secondly, average predictive slopes. Assume we have fit a Bambi model predicting an outcome $Y$ based on inputs $X$ and parameters $\\theta$. Consider the following scalar inputs:\n",
    "\n",
    "$$w: \\text{the input of interest}$$\n",
    "$$c: \\text{all the other inputs}$$\n",
    "$$X = (w, c)$$\n",
    "\n",
    "In contrast to `comparisons`, for `slopes` we are interested in comparing $w^{\\text{value}}$ to $w^{\\text{value}+\\epsilon}$ (perhaps age = 60 and 60.0001 respectively) with all other inputs $c$ held constant. The _predictive difference_ in the outcome changing **only** $w$ is:\n",
    "\n",
    "$$\\text{average predictive difference} = \\mathbb{E}(y|w^{\\text{value}+\\epsilon}, c, \\theta) - \\mathbb{E}(y|w^{\\text{value}}, c, \\theta)$$\n",
    "\n",
    "Selecting $w$ and $w^{\\text{value}+\\epsilon}$ and averaging over all other inputs $c$ in the data gives you a new \"hypothetical\" dataset and corresponds to counting all pairs of transitions of $(w^\\text{value})$ to $(w^{\\text{value}+\\epsilon})$, i.e., differences in $w$ with $c$ held constant. The difference between these two terms is the average predictive difference.\n",
    "\n",
    "However, to obtain the slope estimate, we need to take the above formula and divide by $\\epsilon$ to obtain the _average predictive slope_:\n",
    "\n",
    "$$\\text{average predictive slope} = \\frac{\\mathbb{E}(y|w^{\\text{value}+\\epsilon}, c, \\theta) - \\mathbb{E}(y|w^{\\text{value}}, c, \\theta)}{\\epsilon}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Slopes\n",
    "\n",
    "The objective of `slopes` and `plot_slopes` is to compute the rate of change (slope) in the mean of the response $y$ with respect to a small change $\\epsilon$ in the predictor $x$ conditional on other covariates $c$ specified in the model. $w$ is specified by the user and the original value is either provided by the user, else a default value (the mean) is computed by Bambi. The values for the other covariates $c$ specified in the model can be determined under the following three scenarios:\n",
    "\n",
    "1. user provided values \n",
    "2. a grid of equally spaced and central values\n",
    "3. empirical distribution (original data used to fit the model)\n",
    "\n",
    "In the case of (1) and (2) above, Bambi assembles all pairwise combinations (transitions) of $w$ and $c$ into a new \"hypothetical\" dataset. In (3), Bambi uses the original $c$, and adds a small amount $\\epsilon$ to each unit of observation's $w$. In each scenario, predictions are made on the data using the fitted model. Once the predictions are made, comparisons are computed using the posterior samples by taking the difference in the predicted outcome for each pair of transitions and dividing by $\\epsilon$. The average of these slopes is the average predictive slopes.\n",
    "\n",
    "For variables $w$ with a string or categorical data type, use the `comparisons` function as `slopes` expects a numeric data type to approximate the derivative via finite-differences. Please refer to the [comparisons](https://bambinos.github.io/bambi/notebooks/plot_comparisons.html) documentation for more details.\n",
    "\n",
    "Below, we present several examples showing how to use Bambi to perform these computations for us, and to return either a summary dataframe, or a visualization of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import arviz as az\nimport numpy as np\nimport pandas as pd\nimport warnings\n\nimport bambi as bmb\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "To demonstrate `slopes` and `plot_slopes`, we will use the [well switching dataset](https://vincentarelbundock.github.io/Rdatasets/doc/carData/Wells.html) to model the probability a household in Bangladesh switches water wells. The data are for an area of Arahazar Upazila, Bangladesh. The researchers labelled each well with its level of arsenic and an indication of whether the well was “safe” or “unsafe”. Those using unsafe wells were encouraged to switch. After several years, it was determined whether each household using an unsafe well had changed its well. The data contains $3020$ observations on the following five variables:\n",
    "\n",
    "- `switch`: a factor with levels `no` and `yes` indicating whether the household switched to a new well\n",
    "- `arsenic`: the level of arsenic in the old well (measured in micrograms per liter)\n",
    "- `dist`: the distance to the nearest safe well (measured in meters)\n",
    "- `assoc`: a factor with levels `no` and `yes` indicating whether the household is a member of an arsenic education group\n",
    "- `educ`: years of education of the household head\n",
    "\n",
    "First, a logistic regression model with no interactions is fit to the data. Subsequently, to demonstrate the benefits of `plot_slopes` in interpreting interactions, we will fit a logistic regression model with an interaction term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rownames</th>\n",
       "      <th>switch</th>\n",
       "      <th>arsenic</th>\n",
       "      <th>distance</th>\n",
       "      <th>education</th>\n",
       "      <th>association</th>\n",
       "      <th>dist100</th>\n",
       "      <th>educ4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16.826</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.16826</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.71</td>\n",
       "      <td>47.322</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.47322</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>2.07</td>\n",
       "      <td>20.967</td>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "      <td>0.20967</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.15</td>\n",
       "      <td>21.486</td>\n",
       "      <td>12</td>\n",
       "      <td>no</td>\n",
       "      <td>0.21486</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.10</td>\n",
       "      <td>40.874</td>\n",
       "      <td>14</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.40874</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rownames switch  arsenic  distance  education association  dist100  educ4\n",
       "0         1    yes     2.36    16.826          0          no  0.16826    0.0\n",
       "1         2    yes     0.71    47.322          0          no  0.47322    0.0\n",
       "2         3     no     2.07    20.967         10          no  0.20967    2.5\n",
       "3         4    yes     1.15    21.486         12          no  0.21486    3.0\n",
       "4         5    yes     1.10    40.874         14         yes  0.40874    3.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Wells.csv\")\n",
    "data[\"switch\"] = pd.Categorical(data[\"switch\"])\n",
    "data[\"dist100\"] = data[\"distance\"] / 100\n",
    "data[\"educ4\"] = data[\"education\"] / 4\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modeling the probability that switch==no\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, dist100, arsenic, educ4]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/hslu-n0006897/projects/bambi/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/hslu-n0006897/projects/bambi/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n"
     ]
    }
   ],
   "source": [
    "well_model = bmb.Model(\n",
    "    \"switch ~ dist100 + arsenic + educ4\",\n",
    "    data,\n",
    "    family=\"bernoulli\"\n",
    ")\n",
    "\n",
    "well_idata = well_model.fit(\n",
    "    draws=1000, \n",
    "    target_accept=0.95, \n",
    "    random_seed=1234, \n",
    "    chains=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User provided values\n",
    "\n",
    "First, an example of scenario 1 (user provided values) is given below. In both `plot_slopes` and `slopes`, $w$ and $c$ are represented by `wrt` (with respect to) and `conditional`, respectively. The modeler has the ability to pass their own values for `wrt` and `conditional` by using a dictionary where the key-value pairs are the covariate and value(s) of interest.\n",
    "\n",
    "For example, if we wanted to compute the slope of the probability of switching wells for a typical `arsenic` value of $1.3$ conditional on a range of `dist` and `educ` values, we would pass the following dictionary in the code block below. By default, for $w$, Bambi compares $w^\\text{value}$ to $w^{\\text{value} + \\epsilon}$ where $\\epsilon =$ `1e-4`. However, the value for $\\epsilon$ can be changed by passing a value to the argument `eps`. \n",
    "\n",
    "Thus, in this example, $w^\\text{value} = 1.3$ and $w^{\\text{value} + \\epsilon} = 1.3001$. The user is not limited to passing a list for the values. A `np.array` can also be used. Furthermore, Bambi by default, maps the order of the dict keys to the main, group, and panel of the matplotlib figure. Below, since `dist100` is the first key, this is used for the x-axis, and `educ4` is used for the group (color). If a third key was passed, it would be used for the panel (facet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "plot = bmb.interpret.plot_slopes(\n    well_model,\n    well_idata,\n    wrt={\"arsenic\": 1.3},\n    conditional={\"dist100\": [0.20, 0.50, 0.80], \"educ4\": [1.00, 1.20, 2.00]},\n)\n# fig.axes[0].set_ylabel(\"Slope of Well Switching Probability\");"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows that, for example, conditional on `dist100` $= 0.2$ and `educ4` $= 1.0$ a unit increase in `arsenic` is associated with households being $11$% less likely to switch wells. Notice that even though we fit a logistic regression model where the coefficients are on the log-odds scale, the `slopes` function returns the slope on the probability scale. Thus, we can interpret the y-axis (slope) as the expected change in the probability of switching wells for a unit increase in `arsenic` conditional on the specified covariates.\n",
    "\n",
    "`slopes` can be called directly to view a summary dataframe that includes the term name, estimate type (discussed in detail in the _interpreting coefficients as an elasticity_ section), values $w$ used to compute the estimate, the specified conditional covariates $c$, and the expected slope of the outcome with the uncertainty interval (by default the $94$% highest density interval is computed)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "`slopes` returns a `Result` named tuple with two fields: `summary` and `draws`. The `summary` field is a pandas DataFrame containing the point estimates (posterior mean) and credible intervals for each row of the slope grid. The `draws` field is an `arviz.InferenceData` object containing the full posterior samples used to compute the summary. The `summary` is useful for quick inspection and tabular reporting, while `draws` gives access to the complete posterior distribution for custom analyses or visualizations beyond the default summary statistics.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "result = bmb.interpret.slopes(\n    well_model,\n    well_idata,\n    wrt={\"arsenic\": 1.5},\n    conditional={\n        \"dist100\": [0.20, 0.50, 0.80],\n        \"educ4\": [1.00, 1.20, 2.00]\n    }\n)\n\nresult.summary"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all covariates used to fit the model were also specified to compute the slopes, no default value is used for unspecified covariates. A default value is computed for the unspecified covariates because in order to peform predictions, Bambi is expecting a value for each covariate used to fit the model. Additionally, with GLM models, average predictive slopes are conditional in the sense that the estimate depends on the values of **all** the covariates in the model. Thus, for unspecified covariates, `slopes` and `plot_slopes` computes a default value (mean or mode based on the data type of the covariate). Each row in the summary dataframe is read as \"the slope (or rate of change) of the probability of switching wells with respect to a small change in $w$ conditional on $c$ is $y$\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional slopes\n",
    "\n",
    "As stated in the _interpreting interaction effects_ section, interpreting coefficients of multiple interaction terms can be difficult and cumbersome. Thus, `plot_slopes` provides an effective way to visualize the conditional slopes of the interaction effects. Below, we will use the same well switching dataset, but with interaction terms. Specifically, one interaction is added between `dist100` and `educ4`, and another between `arsenic` and `educ4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modeling the probability that switch==no\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, dist100, arsenic, educ4, dist100:educ4, arsenic:educ4]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/hslu-n0006897/projects/bambi/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/hslu-n0006897/projects/bambi/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 500 tune and 500 draw iterations (2_000 + 2_000 draws total) took 2 seconds.\n"
     ]
    }
   ],
   "source": [
    "well_model_interact = bmb.Model(\n",
    "    \"switch ~ dist100 + arsenic + educ4 + dist100:educ4 + arsenic:educ4\",\n",
    "    data=data,\n",
    "    family=\"bernoulli\"\n",
    ")\n",
    "\n",
    "well_idata_interact = well_model_interact.fit(\n",
    "    draws=500, \n",
    "    tune=500,\n",
    "    target_accept=0.95, \n",
    "    random_seed=1234, \n",
    "    chains=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist100</th>\n",
       "      <td>1.317</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.977</td>\n",
       "      <td>1.623</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1103.0</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arsenic</th>\n",
       "      <td>-0.402</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.517</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>919.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educ4</th>\n",
       "      <td>0.095</td>\n",
       "      <td>0.078</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist100:educ4</th>\n",
       "      <td>-0.328</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.528</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arsenic:educ4</th>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>932.0</td>\n",
       "      <td>897.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "Intercept     -0.089  0.121  -0.304    0.151      0.003    0.002    1260.0   \n",
       "dist100        1.317  0.174   0.977    1.623      0.005    0.004    1103.0   \n",
       "arsenic       -0.402  0.061  -0.517   -0.295      0.002    0.001     919.0   \n",
       "educ4          0.095  0.078  -0.050    0.235      0.002    0.002    1075.0   \n",
       "dist100:educ4 -0.328  0.107  -0.528   -0.124      0.003    0.002    1102.0   \n",
       "arsenic:educ4 -0.076  0.043  -0.156    0.004      0.001    0.001     932.0   \n",
       "\n",
       "               ess_tail  r_hat  \n",
       "Intercept        1151.0    1.0  \n",
       "dist100          1217.0    1.0  \n",
       "arsenic          1021.0    1.0  \n",
       "educ4            1137.0    1.0  \n",
       "dist100:educ4    1074.0    1.0  \n",
       "arsenic:educ4     897.0    1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary of coefficients\n",
    "az.summary(well_idata_interact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients of the linear model are shown in the table above. The interaction coefficents indicate the slope varies in a continuous fashion with the continuous variable.\n",
    "\n",
    "A negative value for `arsenic:dist100` indicates that the \"effect\" of arsenic on the outcome is less negative as distance from the well increases. Similarly, a negative value for `arsenic:educ4` indicates that the \"effect\" of arsenic on the outcome is more negative as education increases. Remember, these coefficients are still on the logit scale. Furthermore, as more variables and interaction terms are added to the model, interpreting these coefficients becomes more difficult. \n",
    "\n",
    "Thus, lets use `plot_slopes` to visually see how the slope changes with respect to `arsenic` conditional on `dist100` and `educ4` changing. Notice in the code block below how parameters are passed to the `subplot_kwargs` and `fig_kwargs` arguments. At times, it can be useful to pass specific `group` and `panel` arguments to aid in the interpretation of the plot. Therefore, `subplot_kwargs` allows the user to manipulate the plotting by passing a dictionary where the keys are `{\"main\": ..., \"group\": ..., \"panel\": ...}` and the values are the names of the covariates to be plotted. `fig_kwargs` are figure level key word arguments such as a theme dictionary (dictionary of matplotlib rc parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "plot = bmb.interpret.plot_slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    conditional={\n        \"dist100\": np.linspace(0, 4, 50),\n        \"educ4\": np.arange(0, 5, 1)\n    },\n    subplot_kwargs={\"main\": \"dist100\", \"group\": \"educ4\", \"panel\": \"educ4\"},\n    fig_kwargs={\"theme\": {\"figure.figsize\": (16, 6)}},\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With interaction terms now defined, it can be seen how the slope of the outcome with respect to `arsenic` differ depending on the value of `educ4`. Especially in the case of `educ4` $= 4.25$, the slope is more \"constant\", but with greater uncertainty. Lets compare this with the model that does not include any interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "plot = bmb.interpret.plot_slopes(\n    well_model,\n    well_idata,\n    wrt=\"arsenic\",\n    conditional={\n        \"dist100\": np.linspace(0, 4, 50),\n        \"educ4\": np.arange(0, 5, 1)\n    },\n    subplot_kwargs={\"main\": \"dist100\", \"group\": \"educ4\", \"panel\": \"educ4\"},\n    fig_kwargs={\"theme\": {\"figure.figsize\": (16, 6)}},\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the non-interaction model, conditional on a range of values for `educ4` and `dist100`, the slopes of the outcome are nearly identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit level slopes\n",
    "\n",
    "Evaluating average predictive slopes at central values for the conditional covariates $c$ can be problematic when the inputs have a large variance since no single central value (mean, median, etc.) is representative of the covariate. This is especially true when $c$ exhibits bi or multimodality. Thus, it may be desireable to use the empirical distribution of $c$ to compute the predictive slopes, and then average over a specific or set of covariates to obtain average slopes. To achieve unit level slopes, do not pass a parameter into `conditional` and or specify `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "unit_level = bmb.interpret.slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    conditional=None\n)\n\n# empirical distribution\nprint(unit_level.summary.shape[0] == well_model_interact.data.shape[0])\nunit_level.summary.head(10)"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rownames</th>\n",
       "      <th>switch</th>\n",
       "      <th>arsenic</th>\n",
       "      <th>distance</th>\n",
       "      <th>education</th>\n",
       "      <th>association</th>\n",
       "      <th>dist100</th>\n",
       "      <th>educ4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16.826</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.16826</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.71</td>\n",
       "      <td>47.322</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.47322</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>2.07</td>\n",
       "      <td>20.967</td>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "      <td>0.20967</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.15</td>\n",
       "      <td>21.486</td>\n",
       "      <td>12</td>\n",
       "      <td>no</td>\n",
       "      <td>0.21486</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.10</td>\n",
       "      <td>40.874</td>\n",
       "      <td>14</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.40874</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.90</td>\n",
       "      <td>69.518</td>\n",
       "      <td>9</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.69518</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.97</td>\n",
       "      <td>80.711</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.80711</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.24</td>\n",
       "      <td>55.146</td>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "      <td>0.55146</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.28</td>\n",
       "      <td>52.647</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.52647</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.52</td>\n",
       "      <td>75.072</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.75072</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rownames switch  arsenic  distance  education association  dist100  educ4\n",
       "0         1    yes     2.36    16.826          0          no  0.16826   0.00\n",
       "1         2    yes     0.71    47.322          0          no  0.47322   0.00\n",
       "2         3     no     2.07    20.967         10          no  0.20967   2.50\n",
       "3         4    yes     1.15    21.486         12          no  0.21486   3.00\n",
       "4         5    yes     1.10    40.874         14         yes  0.40874   3.50\n",
       "5         6    yes     3.90    69.518          9         yes  0.69518   2.25\n",
       "6         7    yes     2.97    80.711          4         yes  0.80711   1.00\n",
       "7         8    yes     3.24    55.146         10          no  0.55146   2.50\n",
       "8         9    yes     3.28    52.647          0         yes  0.52647   0.00\n",
       "9        10    yes     2.52    75.072          0         yes  0.75072   0.00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "well_model_interact.data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, `unit_level` is the slopes summary dataframe and `well_model_interact.data` is the empirical data used to fit the model. Notice how the values for $c$ are identical in both dataframes. However, for $w$, the values are the original $w$ value plus $\\epsilon$. Thus, the `estimate` value represents the instantaneous rate of change for that unit of observation. However, these unit level slopes are difficult to interpret since each row may have a different slope estimate. Therefore, it is useful to average over (marginalize) the estimates to summarize the unit level predictive slopes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marginalizing over covariates\n",
    "\n",
    "Since the empirical distrubution is used for computing the average predictive slopes, the same number of rows ($3020$) is returned as the data used to fit the model. To average over a covariate, use the `average_by` argument. If `all` is passed, then `slopes` averages over **all** covariates. Else, if a single or list of covariates are passed, then `slopes` averages by the covariates passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "result = bmb.interpret.slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    conditional=None,\n    average_by=\"all\"\n)\n\nresult.summary"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block above is equivalent to taking the mean of the `estimate` and uncertainty columns. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estimate      -0.114508\n",
       "lower_3.0%    -0.139836\n",
       "upper_97.0%   -0.091411\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_level.summary[[\"estimate\", \"lower_3.0%\", \"upper_97.0%\"]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average by subgroups\n",
    "\n",
    "Averaging over all covariates may not be desired, and you would rather average by a group or specific covariate. To perform averaging by subgroups, users can pass a single or list of covariates to `average_by` to average over specific covariates. For example, if we wanted to average by `educ4`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# average by educ4\nresult = bmb.interpret.slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    conditional=None,\n    average_by=\"educ4\"\n)\n\nresult.summary"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# average by both educ4 and dist100\nresult = bmb.interpret.slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    conditional=None,\n    average_by=[\"educ4\", \"dist100\"]\n)\n\nresult.summary"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is still possible to use `plot_slopes` when passing an argument to `average_by`. In the plot below, the empirical distribution is used to compute unit level slopes with respect to `arsenic` and then averaged over `educ4` to obtain the average predictive slopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "plot = bmb.interpret.plot_slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    conditional=None,\n    average_by=\"educ4\"\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting coefficients as an elasticity\n",
    "\n",
    "In some fields, such as economics, it is useful to interpret the results of a regression model in terms of an elasticity (a percent change in $x$ is associated with a percent change in $y$) or semi-elasticity (a unit change in $x$ is associated with a percent change in $y$, or vice versa). Typically, this is achieved by fitting a model where either the outcome and or the covariates are log-transformed. However, since the log transformation is performed by the modeler, to compute elasticities for `slopes` and `plot_slopes`, Bambi \"post-processes\" the predictions to compute the elasticities. Below, it is shown the possible elasticity arguments and how they are computed for `slopes` and `plot_slopes`:\n",
    "\n",
    "- `eyex`: a percentage point increase in $x_1$ is associated with an $n$ percentage point increase in $y$\n",
    "\n",
    "$$\\frac{\\partial \\hat{y}}{\\partial x_1} * \\frac{x_1}{\\hat{y}}$$\n",
    "\n",
    "- `eydx`: a unit increase in $x_1$ is associated with an $n$ percentage point increase in $y$\n",
    "\n",
    "$$\\frac{\\partial \\hat{y}}{\\partial x_1} * \\frac{1}{\\hat{y}}$$\n",
    "\n",
    "- `dyex`: a percentage point increase in $x_1$ is associated with an $n$ unit increase in $y$\n",
    "\n",
    "$$\\frac{\\partial \\hat{y}}{\\partial x_1} * x_1$$\n",
    "\n",
    "Below, each code cell shows the same model, and `wrt` and `conditional` argument, but with a different elasticity (`slope`) argument. By default, `dydx` (a derivative with no post-processing) is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "result = bmb.interpret.slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    slope=\"eyex\",\n    conditional=None,\n    average_by=\"all\"\n)\n\nresult.summary"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>estimate_type</th>\n",
       "      <th>value</th>\n",
       "      <th>estimate</th>\n",
       "      <th>lower_3.0%</th>\n",
       "      <th>upper_97.0%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arsenic</td>\n",
       "      <td>eydx</td>\n",
       "      <td>1.65693</td>\n",
       "      <td>-0.291375</td>\n",
       "      <td>-0.360657</td>\n",
       "      <td>-0.226389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      term estimate_type    value  estimate  lower_3.0%  upper_97.0%\n",
       "0  arsenic          eydx  1.65693 -0.291375   -0.360657    -0.226389"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = bmb.interpret.slopes(\n",
    "    well_model_interact,\n",
    "    well_idata_interact,\n",
    "    wrt=\"arsenic\",\n",
    "    slope=\"eydx\",\n",
    "    conditional=None,\n",
    "    average_by=\"all\"\n",
    ")\n",
    "\n",
    "result.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "result = bmb.interpret.slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    slope=\"dyex\",\n    conditional=None,\n    average_by=\"all\"\n)\n\nresult.summary"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`slope` is also an argument for `plot_slopes`. Below, we visualize the elasticity with respect to `arsenic` conditional on a range of `dist100` and `educ4` values (notice this is the same plot as in the _conditional slopes_ section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "plot = bmb.interpret.plot_slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    conditional={\n        \"dist100\": np.linspace(0, 4, 50),\n        \"educ4\": np.arange(0, 5, 1)\n    },\n    slope=\"eyex\",\n    subplot_kwargs={\"main\": \"dist100\", \"group\": \"educ4\", \"panel\": \"educ4\"},\n    fig_kwargs={\"theme\": {\"figure.figsize\": (16, 6)}}\n)"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'watermark'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mload_ext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwatermark\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mwatermark\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m-n -u -v -iv -w\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bambi/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:2511\u001b[39m, in \u001b[36mInteractiveShell.run_line_magic\u001b[39m\u001b[34m(self, magic_name, line, _stack_depth)\u001b[39m\n\u001b[32m   2509\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mlocal_ns\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.get_local_scope(stack_depth)\n\u001b[32m   2510\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m-> \u001b[39m\u001b[32m2511\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2513\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2514\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2515\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2516\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bambi/.venv/lib/python3.13/site-packages/IPython/core/magics/extension.py:33\u001b[39m, in \u001b[36mExtensionMagics.load_ext\u001b[39m\u001b[34m(self, module_str)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module_str:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UsageError(\u001b[33m'\u001b[39m\u001b[33mMissing module name.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshell\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextension_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res == \u001b[33m'\u001b[39m\u001b[33malready loaded\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     36\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m extension is already loaded. To reload it, use:\u001b[39m\u001b[33m\"\u001b[39m % module_str)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bambi/.venv/lib/python3.13/site-packages/IPython/core/extensions.py:62\u001b[39m, in \u001b[36mExtensionManager.load_extension\u001b[39m\u001b[34m(self, module_str)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load an IPython extension by its module name.\u001b[39;00m\n\u001b[32m     56\u001b[39m \n\u001b[32m     57\u001b[39m \u001b[33;03mReturns the string \"already loaded\" if the extension is already loaded,\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[33;03m\"no load function\" if the module doesn't have a load_ipython_extension\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[33;03mfunction, or None if it succeeded.\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01min\u001b[39;00m BUILTINS_EXTS:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bambi/.venv/lib/python3.13/site-packages/IPython/core/extensions.py:77\u001b[39m, in \u001b[36mExtensionManager._load_extension\u001b[39m\u001b[34m(self, module_str)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.shell.builtin_trap:\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys.modules:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m         mod = \u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     mod = sys.modules[module_str]\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_load_ipython_extension(mod):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.0-macos-aarch64-none/lib/python3.13/importlib/__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     86\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1324\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'watermark'"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}