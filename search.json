[
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Bambi is dedicated to providing a harassment-free community for everyone, regardless of gender, sexual orientation, gender identity, and expression, disability, physical appearance, body size, race, or religion. We do not tolerate harassment of community members in any form.\nHowever, it is not uncommon to suffer or witness abusive behaviors online. If you have experienced or witnessed any behaviour that violates our Code of Conduct, we encourage you to report it through the form below.\nWhen reporting an incident, please provide as much detail as possible, including:\n\nThe approximate date, time and location of the incident (please be as specific as possible).\nAny identifying information of the individual whose behavior is being reported (e.g. name, nickname, screen name, physical description).\nA description of the behavior, your account of what happened, and any available supporting records (e.g. email, GitHub issue url, screenshots, etc.).\nIf reporting harassing language, please be specific about the words used.\nA description of the circumstances/context surrounding the incident.\nIs the incident ongoing, and/or is this part of an ongoing pattern of behavior by this individual?\nDid anyone else observe the incident? If possible, please provide names and contact info of anyone else who witnessed or was involved in this incident.\nAny other information you believe we should have about what happened or that you’d like us to know.\n\nAll the information be kept confidential. If you wish to remain anonymous, your information will not be shared beyond the person receiving the initial report.\nWe take every report of Code of Conduct violations very seriously and will handle each one with care and confidentiality. If you’re unsure whether certain behavior is a violation, or if you need help with the reporting process, don’t hesitate to reach out to us. We are here to help and support you.\n\n    \n    \n    \n  \n    \n    \n      \n    \n  \n\n\nForm adapted from the JAXGP Contact Form and the NumFOCUS Reporting Form."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BAyesian Model-Building Interface in Python",
    "section": "",
    "text": "Bambi is a high-level Bayesian model-building interface written in Python. It works with the PyMC probabilistic programming framework and is designed to make it extremely easy to fit Bayesian mixed-effects models common in biology, social sciences and other disciplines."
  },
  {
    "objectID": "index.html#dependencies",
    "href": "index.html#dependencies",
    "title": "BAyesian Model-Building Interface in Python",
    "section": "Dependencies",
    "text": "Dependencies\nBambi is tested on Python 3.10+ and depends on ArviZ, formulae, NumPy, pandas and PyMC (see pyproject.toml for version information)."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "BAyesian Model-Building Interface in Python",
    "section": "Installation",
    "text": "Installation\nBambi is available from the Python Package Index at https://pypi.org/project/bambi, alternatively it can be installed using Conda.\n\nPyPI\nThe latest release of Bambi can be installed using pip:\npip install bambi\nAlternatively, if you want the bleeding edge version of the package, you can install from GitHub:\npip install git+https://github.com/bambinos/bambi.git\n\n\nConda\nIf you use Conda, you can also install the latest release of Bambi with the following command:\nconda install -c conda-forge bambi"
  },
  {
    "objectID": "index.html#examples",
    "href": "index.html#examples",
    "title": "BAyesian Model-Building Interface in Python",
    "section": "Examples",
    "text": "Examples\nIn the following two examples we assume the following basic setup\nimport arviz as az\nimport bambi as bmb\nimport numpy as np\nimport pandas as pd\n\nLinear regression\nA simple fixed effects model is shown in the example below.\n# Read in a dataset from the package content\ndata = bmb.load_data(\"sleepstudy\")\n\n# See first rows\ndata.head()\n \n# Initialize the fixed effects only model\nmodel = bmb.Model('Reaction ~ Days', data)\n\n# Get model description\nprint(model)\n\n# Fit the model using 1000 on each chain\nresults = model.fit(draws=1000)\n\n# Key summary and diagnostic info on the model parameters\naz.summary(results)\n\n# Use ArviZ to plot the results\naz.plot_trace(results)\n   Reaction  Days  Subject\n0  249.5600     0      308\n1  258.7047     1      308\n2  250.8006     2      308\n3  321.4398     3      308\n4  356.8519     4      308\n       Formula: Reaction ~ Days\n        Family: gaussian\n          Link: mu = identity\n  Observations: 180\n        Priors:\n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 298.5079, sigma: 261.0092)\n            Days ~ Normal(mu: 0.0, sigma: 48.8915)\n\n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 56.1721)\n                   mean     sd   hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat\nIntercept       251.552  6.658  238.513  263.417      0.083    0.059    6491.0    2933.0    1.0\nDays             10.437  1.243    8.179   12.793      0.015    0.011    6674.0    3242.0    1.0\nReaction_sigma   47.949  2.550   43.363   52.704      0.035    0.025    5614.0    2974.0    1.0\nFirst, we create and build a Bambi Model. Then, the method model.fit() tells the sampler to start running and it returns an InferenceData object, which can be passed to several ArviZ functions such as az.summary() to get a summary of the parameters distribution and sample diagnostics or az.plot_trace() to visualize them.\n\n\nLogistic regression\nIn this example we will use a simulated dataset created as shown below.\ndata = pd.DataFrame({\n    \"g\": np.random.choice([\"Yes\", \"No\"], size=50),\n    \"x1\": np.random.normal(size=50),\n    \"x2\": np.random.normal(size=50)\n})\nHere we just add the family argument set to \"bernoulli\" to tell Bambi we are modelling a binary response. By default, it uses a logit link. We can also use some syntax sugar to specify which event we want to model. We just say g['Yes'] and Bambi will understand we want to model the probability of a \"Yes\" response. But this notation is not mandatory. If we use \"g ~ x1 + x2\", Bambi will pick one of the events to model and will inform us which one it picked.\nmodel = bmb.Model(\"g['Yes'] ~ x1 + x2\", data, family=\"bernoulli\")\nfitted = model.fit()\nAfter this, we can evaluate the model as before.\n\n\nMore\nFor a more in-depth introduction to Bambi see our Quickstart and check the notebooks in the Examples webpage."
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "BAyesian Model-Building Interface in Python",
    "section": "Citation",
    "text": "Citation\nIf you use Bambi and want to cite it please use\n@article{\n    Capretto2022,\n    title={Bambi: A Simple Interface for Fitting Bayesian Linear Models in Python},\n    volume={103},\n    url={https://www.jstatsoft.org/index.php/jss/article/view/v103i15},\n    doi={10.18637/jss.v103.i15},\n    number={15},\n    journal={Journal of Statistical Software},\n    author={Capretto, Tomás and Piho, Camen and Kumar, Ravin and Westfall, Jacob and Yarkoni, Tal and Martin, Osvaldo A},\n    year={2022},\n    pages={1–29}\n}"
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "BAyesian Model-Building Interface in Python",
    "section": "Contributing",
    "text": "Contributing\nWe welcome contributions from interested individuals or groups! For information about contributing to Bambi, check out our instructions, policies, and guidelines here."
  },
  {
    "objectID": "index.html#contributors",
    "href": "index.html#contributors",
    "title": "BAyesian Model-Building Interface in Python",
    "section": "Contributors",
    "text": "Contributors\nSee the GitHub contributor page."
  },
  {
    "objectID": "changelog.html",
    "href": "changelog.html",
    "title": "Changelog",
    "section": "",
    "text": "Add default priors for binomial and bernoulli families with logit link (#830)\nAdd horseshoe prior (#836)\nHandle multivariate responses with HSGP (#856)\n\n\n\n\n\nChange the JAX random number generator key for 32 bit systems (#833)\nChange rename to replace in pre-render.py (#843)\nFix out of sample prediction for multivariate families. It would not work for tables where the number of rows was different from the one used to fit the model (#847)\nCheck variables before trying to access them in posterior predictive sampling (#851)\nPass kwargs to nutpie + create env.yml file (#855)\n\n\n\n\n\nFix typos and incomplete doc strings (#765)\nClarify elpd differences interepretation (#825)\nFix the contributing readme link (#837)\nAdd example using offset (#842)\nFix model formula in negative binomial notebook (#859)\nFix formatting in t-test examples (#861)\nFix issue 812 Broken link (#862)\nUpdate repository documentation files (#865)\n\n\n\n\n\n\n\n\n\n\n\nAdd configuration facilities to Bambi (#745)\nInterpet submodule now outputs informative messages when computing default values (#745)\nBambi supports weighted responses (#761)\nBambi supports constrained responses (#764)\nImplement compute_log_likelihood() method to compute the log likelihood on a model (#769)\nAdd a class InferenceMethods that allows users to access the available inference methods and kwargs (#795)\n\n\n\n\n\nFix bug in predictions with models using HSGP (#780)\nFix get_model_covariates() utility function (#801)\nUpgrade PyMC dependency to &gt;= 5.13 (#803)\nUse pm.compute_deterministics() to compute deterministics when bayeux based samplers are used (#803)\nWrap all the parameters of the response distribution (the likelihood) with a pm.Deterministic (#804)\nKeep bayeux-ml as the single direct JAX-related dependency (#804)\nThe response component only holds response information about the response, not about predictors of the parent parameter (#804)\nResolve import error associated with bayeux (#822)\n\n\n\n\n\nOur Code of Conduct now includes how to send a report (#783)\nAdd polynomial regression example (#809)\nAdd Contact form to our webpage (#816)\n\n\n\n\n\nf\"{response_name}_obs\" has been replaced by \"__obs__\" as the dimension name for the observation index (#804)\nf\"{response_name}_{parameter_name}\" is no longer the name for the name of parameters of the likelihood. Now Bambi uses \"{parameter_name}\" (#804)\nkind in Model.predict() now use \"response_params\" and \"response\" instead of \"mean\" and \"pps\" (#804)\ninclude_mean has been replaced by include_response_params in Model.fit() (#804)\n\n\n\n\n\nThis is the first version of Bambi that is released with a Governance structure. Added in #709.\n\n\n\nBambi now supports censored responses (#697)\nImplement \"exponential\" and \"weibull\" families (#697)\nAdd \"kidney\" dataset (#697)\nAdd interpret submodule (#684, #695, #699, #701, #732, #736)\n\nImplements comparisons, predictions, slopes, plot_comparisons, plot_predictions, and plot_slopes\n\nSupport censored families\n\n\n\n\n\nBump quartodoc version to 0.6.1 (#720)\nReplace univariate_ordered with ordered (#724)\nAdd missing docstring for center_predictors (#726)\nFix bugs in plot_comparison (#731)\n\n\n\n\n\nAdd docstrings to utility functions (#696)\nMigrate documentation to Quarto (#712)\nAdd case study for MRP (#716)\nAdd example about ordinal regression (#719)\nAdd example about zero inflated models (#725)\nAdd example about predictions for new groups (#734)\n\n\n\n\n\nDrop official suport for Python 3.8 (#720)\nChange plots submodule name to interpret (#705)\n\n\n\n\n\n\n\n\nImplement new families \"ordinal\" and \"sratio\" for modeling of ordinal responses (#678)\nAllow families to implement a custom create_extra_pps_coord() (#688)\nAllow predictions on new groups (#693)\n\n\n\n\n\nRobustify how Bambi handles dims (#682)\nFix links in FAQ (#686)\nUpdate additional dependencies install command (#689)\nUpdate predict pps docstring (#690)\nAdd warning for aliases athat aren’t used (#691)\n\n\n\n\n\nAdd families to the Getting Started guide (#683)\n\n\n\n\n\n\n\n\n\n\n\nAdd support for Gaussian Processes via the HSGP approximation (#632)\nAdd new families: \"zero_inflated_poisson\", \"zero_inflated_binomial\", and \"zero_inflated_negativebinomial\" (#654)\nAdd new families: \"beta_binomial\" and \"dirichlet_multinomial\" (#659)\nAllow plot_cap() to show predictions at the observation level (#668)\nAdd new families: \"hurdle_gamma\", \"hurdle_lognormal\", \"hurdle_negativebinomial\", and \"hurdle_poisson\" (#676)\n\n\n\n\n\nModify how HSGP is built in PyMC when there are groups (#661)\nModify how Bambi is imported in the tests (#662)\nPrevent underscores from being removed in dim names (#664)\nBump sphix dependency to a version greater than 7 (#672)\n\n\n\n\n\nDocument how to use custom priors (#656)\nFix name of arviz traceplot function in the docs (#666)\nAdd example that shows how plot_cap() works (#670)\n\n\n\n\n\n\n\n\n\n\n\nRefactored the codebase to support distributional models (#607)\nAdded a default method to handle posterior predictive sampling for custom families (#625)\nplot_cap() gains a new argument target that allows to plot different parameters of the response distribution (#627)\n\n\n\n\n\nMoved the tests directory to the root of the repository (#607)\nDon’t pass dims to the response of the likelihood distribution anymore (#629)\nRemove requirements.txt and replace with pyproject.toml config file to distribute the package (#631)\n\n\n\n\n\nUpdate examples to work with the new internals (#607)\nFixed figure in the Sleepstudy example (#607)\nAdd example using distributional models (#641)\n\n\n\n\n\nRemoved versioned documentation webpage (#616)\nRemoved correlated priors for group-specific terms (#607)\nDictionary with tuple keys are not allowed for priors anymore (#607)\n\n\n\n\n\n\n\n\nUpdate to PyMC &gt;= 5, which means we use PyTensor instead of Aesara now (#613, #614)\n\n\n\n\n\n\n\n\nImplement censored() (#581)\nAdd Formula class (#585)\nAdd common numpy transforms to extra_namespace (#589)\nAdd AsymmetricLaplace family for Quantile Regression (#591)\nAdd ‘transforms’ argument to plot_cap() (#594)\nAdd panel covariates to plot_cap() and make it more flexible (#596)\n\n\n\n\n\nReimplemented predictions to make better usage of xarray data structures (#573)\nKeep 0 dimensional parameters as 0 dimensional instead of 1 dimensional (#575)\nRefactor terms for modularity and extensibility (#582)\nRemove seed argument from model.initial_point() (#592)\nAdd build check function on prior predictive and plot prior (#605)\n\n\n\n\n\nAdd quantile regression example (#608)\n\n\n\n\n\nRemove automatic_priors argument from Model (#603)\nRemove string option for data input in Model (#604)\n\n\n\n\n\n\n\n\nAdd support for jax sampling via numpyro and blackjax samplers (#526)\nAdd Laplace family (#524)\nImprove Laplace computation and integration (#555 and #563)\n\n\n\n\n\nEnsure order variable is preserved when ploting priors (#529)\nTreat offset accordingly (#534)\nRefactor tests to share data generation code (#531)\n\n\n\n\n\nUpdate documentation following good inferencedata practices (#537)\nAdd logos to repo and docs (#542)\n\n\n\n\n\nDeprecate method argument in favor of inference_method (#554)\n\n\n\n\n\n\n\n\nBambi now uses PyMC 4.0 as it’s backend. Most if not all your previous model should run the same, without the need of any change.\nAdd Plot Conditional Adjusted Predictions plot_cap (#517)\n\n\n\n\n\nGroup specific terms now work with numeric of multiple columns (#516)\n\n\n\n\n\n\n\n\nAdd VonMises (\"vonmises\") built-in family (#453)\nModel.predict() gains a new argument include_group_specific to determine if group-specific effects are considered when making predictions (#470)\nAdd Multinomial (\"multinomial\") built-in family (#490)\n\n\n\n\n\nAdd posterior predictive sampling method to “categorical” family (#458)\nRequire Python &gt;= 3.7.2 to fix NoReturn type bug in Python (#463)\nFixed the wrong builtin link given by link=\"inverse\" was wrong. It returned the same result as link=\"cloglog\" (#472)\nReplaced plain dictionaries with namedtuples when same dictionary structure was repeated many times (#472)\nThe function check_full_rank() in utils.py now checks the array is 2 dimensional (#472)\nRemoved _extract_family_prior() from bambi/families as it was unnecesary (#472)\nRemoved bambi/families/utils.py as it was unnecesary (#472)\nRemoved external links and unused datasets (#483)\nReplaced \"_coord_group_factor\" with \"__factor_dim\" and \"_coord_group_expr\" with \"__expr_dim\" in dimension/coord names (#499)\nFixed a bug related to modifying the types of the columns in the original data frame (#502)\n\n\n\n\n\nAdd circular regression example (#465)\nAdd Categorical regression example (#457)\nAdd Beta regression example (#442)\nAdd Radon Example (#440)\nFix typos and clear up writing in some docs (#462)\nDocumented the module bambi/defaults (#472)\nImproved documentation and made it more consistent (#472)\nCleaned Strack RRR example (#479)\n\n\n\n\n\nRemoved old default priors (#474)\nRemoved draws parameter from Model.predict() method (#504)\n\n\n\n\n\n\n\n\nFixed bug related to the shape of 2 level categorical group-specific effects (#441)\n\n\n\n\n\n\n\n\nAdd “categorical” built-in family (#426)\nAdd include_mean argument to the method Model.fit() (#434)\nAdd .set_alias() method to Model (#435)\n\n\n\n\n\nCodebase for the PyMC backend has been refactored (#408)\nFix examples that averaged posterior values across chains (#429)\nFix issue #427 with automatic priors for the intercept term (#430)\n\n\n\n\n\nAdd StudentT regression example, thanks to @tjburch (#414)\nAdd B-Spline regression example with cherry blossoms dataset (#416)\nAdd hirarchical linear regression example with sleepstudy dataset (#424)\n\n\n\n\n\n\nUse formulae 0.2.0 (#411)\n\n\n\n\n\n\n\nChange default priors for the ‘t’ family (#403)\n\n\n\n\n\nAdd installation instructions with conda (#406)\nCorrected a typo: pary_id -&gt; party_id (#402)\nAdd donation information (#409)\n\n\n\n\n\n\n\n\nDocumentation for all versions is built from scratch when there’s a release. This ensures older versions link to the current stable release. (#396)\nAdd new axis to prior predictive samples to represent 1 chain in the InferenceData object we return (#397)\nMove Family, Likelihood and Link to the families submodule and improved some docstrings (#399)\n\n\n\n\n\nAdd example with hierarchical binomial model (#398)\n\n\n\n\n\n\n\n\nAdd alternative default priors (#360)\nAdd StudentT family (#367)\nAdd Beta family (#368)\nImplement both in-sample and out-of-sample model predictions (#372)\nAdd function to load datasets (#375)\nAdd option to specify potentials (#379)\nAdd Binomial family (#386)\n\n\n\n\n\nAutomatic switch initialization method from “jitter-adapt_diag” to “adapt_diag” when sampling fails (#383)\nPredictors are internally centered when there is an intercept. This generally results in improved sampling efficiency (#385)\nImprove documentation and error message in Model.graph() (#390)\n\n\n\n\n\nAdd Negative Binomial family example notebook (#346)\nFixed typos and improved many notebooks (#374, #377, #382)\n\n\n\n\n\n\n\n\nIt is possible to specify priors for parameters in the response distribution (#335)\nAdd probit and cloglog link functions (#340)\n\n\n\n\n\nInformative message when default priors fail because of perfect separation. Model can be fit with custom priors (#330)\nBreaking changes to the API. All the information related to the model goes in Model() instantiation now (#333)\nFix gamma family (#337)\nNon-default links are properly passed to statsmodels (#337)\nFix Wald family (#340)\nFix Negative binomial family (#340)\nAdd informative message when link function is not available for a given family (#340)\nUpdate formulae version to 0.0.10 (#348)\n\n\n\n\n\nNotebooks are updated to the new API (#336)\nAdd badges, update introduction and minor style changes in webpage (#344)\nAdd example using Gamma and Wald families (#345)\nWebpage theme has been updated to PyData theme (#347)\nAdd model evaluation to logistic regression example (#350)\n\n\n\n\n\n\n\n\nAdd option to save a figure from model.graph() by passing the name of a file. Figure format and resolution can also be set (#317)\nObjects of class Prior, Family and Model have nicer print methods (#326)\n\n\n\n\n\nAdd negative binomial family to config file, which was missing (#324)\nAdd test to check model compilation with families available (#327)\nUpdate formulae to version 0.0.9 (#329)\n\n\n\n\n\nFix gamma docstring (#328)\n\n\n\n\n\n\n\n\nUse formulae to parse model formulas (#299)\nAdd model representation (#300)\n\n\n\n\n\nRemove deprecation warning related to pm.sample returning idata (#295)\n\n\n\n\n\nAdd citation to Bambi preprint (#290)\nRemove reference to pystan (#292)\n\n\n\n\n\n\n\n\nAdd posterior predictive sampling (#250)\nAdd prior predictive sampling (#244)\nAdd gamma, negativebinomial and wald families (#207)\n\n\n\n\n\nUse pm.sample_prior_predictive function to sample and plot from prior (#238)\nFix FutureWarning: Support for multi-dimensional indexing (#242)\nUse last version of black (#245)\nfix broken link increase Python version (#227)\nAdd black style check on lint (#220)\nSome linting while re-reading library (#219)\nRemove future warning when converting the trace to InferenceData (#213)\nInclude missing files for sdist (#204)\nFixed if-else comparison that prevented HalfTStudent prior from being used (#205)\nSidestep plotting flat priors in plot_priors() (#258)\nGLM.fit_constrained in automatic priors now uses start_params = None (#265)\nCategorical Term within Model now have Term.categorical equal to True(#269)\nUse logging instead of warnings (#270)\nOmits ploting group-level effects and offset variables (#276)\nLogistic regression works with no explicit index (#277)\nAdd argument to optionally keep offsets in InferenceData (#288)\nAdd argument to optionally keep group level effects and offsets variables in plot_prior (#288)\n\n\n\n\n\nUpdate example notebooks (#232)\nadd missing notebooks (#229)\nFix notebooks (#222)\nClean docs (#200)\nAdded notebook using Bambi and ArviZ for model comparison (#267)\nUse same color palette in all notebooks (#282)\nFix divergences in examples (two divergences remaining in Strack RRR example) (#282)\n\n\n\n\n\nDrop support python 3.6 (#218)\nRemove stan backend and replace sd with sigma (#205)\nDeprecate samples argument in favor of draws (#247)\n\n\n\n\n\n\n\n\nAdd laplace approximation (#184) (only for educational use, do not use for real problems)\nUse arviz (#182, #178, #166, #159)\n\n\n\n\n\nUpdate requirements (#191)\nChange default sd prior and update docs (#189)\nAdd f-strings and support python 3.6+ (#188)\nFix parallel sampling (#186)\nLint code (#175, #173, #171, #167)\nMove coverage configuration to setup.cfg (#168)\nAdd long description to setup.py; light linting on setup.py (#162)\nBlack list external/ and tests/from pylint\n\n\n\n\n\nAdd missing example (#194)\nUpdate docs and fix typos (#185, #181)\nAdd missing items to readme and code of conduct (#180)\nSimplify readme (#179)\nUnify docstring style and remove not used code (#169)\n\n\n\n\n\nDeprecate Stan backend (#183)\n\n\n\n\n\n\n\n\nUse a callable as link function (#147)\n\n\n\n\n\nUpdate to Python 3, black and some pylint (#158)\nFix test warnings (#144)\nReorder requirements; Add matplotlib to requirements.txt (#143)\nReorder imports; Only import necessary submodules from statsmodels (#142)\nUpdate travis config (#135)\n\n\n\n\n\nAdd contributing guide (#146)\nUpdate notebooks (#140)\n\n\n\n\n\nLast version to support Python 2.7\n\n\n\n\n\n\nMinor release for bugfixes and minor improvements. Changes include:\nBug that was causing an incorrect link function to be used in the PyMC3 backend when fitting logistic models.\nFixed handling of missing values in categorical variables.\nFixed bug in set_priors() when passing numerical values for scale.\nImproved internal handling of custom priors.\nPreliminary Sphinx docs (WIP; thanks to @ejolly).\n\n\n\n\nThis is a major release that introduces several new features, significant API changes, and a large number of bug fixes and minor improvements. Notable changes include:\n\nSupport for Stan as the sampling back-end (in addition to PyMC3), via the PyStan package.\nDropped support for the add_term API; all model specification is now done via formulas.\nExpanded support for arbitrary random effects specifications; any formula now supported by patsy can be passed in as the left-hand side of a random effects specification (e.g., previously, ‘(a*b)|c’ would not have worked).\nCompletely refactored Results classes that no longer depend on PyMC3, providing a completely generic representation of sampler results, independent of any back-end.\nRefactored plotting and summary methods implemented on the abstract MCMCResults classes rather than at the back-end level.\nMuch better compilation and sampling performance for models that include random effects with many levels. In many cases, performance should now be comparable to the most efficient native implementations of the models in the respective back-ends.\nAll random effects priors now use the “non-centered” parameterization by default, significantly reducing bias for some models.\nImproved naming conventions that are more consistent with other packages (e.g., random effects now include the ‘|’ operator in term names).\nRefactored Term class, including a separate subclass for RandomTerms, and a number of other associated changes to the internal object model.\nUpdated documentation and notebooks, including two new notebooks featuring well-developed examples (datasets included).\nImproved handling of NA values in continuous columns.\nSupport for flat priors everywhere (by setting auto_scale=False).\nNumerous bug fixes and minor improvements\n\n\n\n\n\nWeakly informative default priors now work the same for all response families & link functions\nMinor bug fixes/tweaks\n\n\n\n\n\nFixes referencing of Theano ops after PyMC3 namespace clean-up\nAdded example Jupyter notebooks\nImproved handling of priors\nImproved prior plots and result summaries\nImproved access to MCMC trace results\nAdd handling for datasets with NaN values\nAdded travis-ci and coveralls support\nMinor bug fixes/tweaks\n\n\n\n\nFirst official release."
  },
  {
    "objectID": "changelog.html#section",
    "href": "changelog.html#section",
    "title": "Changelog",
    "section": "",
    "text": "Add default priors for binomial and bernoulli families with logit link (#830)\nAdd horseshoe prior (#836)\nHandle multivariate responses with HSGP (#856)\n\n\n\n\n\nChange the JAX random number generator key for 32 bit systems (#833)\nChange rename to replace in pre-render.py (#843)\nFix out of sample prediction for multivariate families. It would not work for tables where the number of rows was different from the one used to fit the model (#847)\nCheck variables before trying to access them in posterior predictive sampling (#851)\nPass kwargs to nutpie + create env.yml file (#855)\n\n\n\n\n\nFix typos and incomplete doc strings (#765)\nClarify elpd differences interepretation (#825)\nFix the contributing readme link (#837)\nAdd example using offset (#842)\nFix model formula in negative binomial notebook (#859)\nFix formatting in t-test examples (#861)\nFix issue 812 Broken link (#862)\nUpdate repository documentation files (#865)"
  },
  {
    "objectID": "changelog.html#section-1",
    "href": "changelog.html#section-1",
    "title": "Changelog",
    "section": "",
    "text": "Add configuration facilities to Bambi (#745)\nInterpet submodule now outputs informative messages when computing default values (#745)\nBambi supports weighted responses (#761)\nBambi supports constrained responses (#764)\nImplement compute_log_likelihood() method to compute the log likelihood on a model (#769)\nAdd a class InferenceMethods that allows users to access the available inference methods and kwargs (#795)\n\n\n\n\n\nFix bug in predictions with models using HSGP (#780)\nFix get_model_covariates() utility function (#801)\nUpgrade PyMC dependency to &gt;= 5.13 (#803)\nUse pm.compute_deterministics() to compute deterministics when bayeux based samplers are used (#803)\nWrap all the parameters of the response distribution (the likelihood) with a pm.Deterministic (#804)\nKeep bayeux-ml as the single direct JAX-related dependency (#804)\nThe response component only holds response information about the response, not about predictors of the parent parameter (#804)\nResolve import error associated with bayeux (#822)\n\n\n\n\n\nOur Code of Conduct now includes how to send a report (#783)\nAdd polynomial regression example (#809)\nAdd Contact form to our webpage (#816)\n\n\n\n\n\nf\"{response_name}_obs\" has been replaced by \"__obs__\" as the dimension name for the observation index (#804)\nf\"{response_name}_{parameter_name}\" is no longer the name for the name of parameters of the likelihood. Now Bambi uses \"{parameter_name}\" (#804)\nkind in Model.predict() now use \"response_params\" and \"response\" instead of \"mean\" and \"pps\" (#804)\ninclude_mean has been replaced by include_response_params in Model.fit() (#804)"
  },
  {
    "objectID": "changelog.html#section-2",
    "href": "changelog.html#section-2",
    "title": "Changelog",
    "section": "",
    "text": "This is the first version of Bambi that is released with a Governance structure. Added in #709.\n\n\n\nBambi now supports censored responses (#697)\nImplement \"exponential\" and \"weibull\" families (#697)\nAdd \"kidney\" dataset (#697)\nAdd interpret submodule (#684, #695, #699, #701, #732, #736)\n\nImplements comparisons, predictions, slopes, plot_comparisons, plot_predictions, and plot_slopes\n\nSupport censored families\n\n\n\n\n\nBump quartodoc version to 0.6.1 (#720)\nReplace univariate_ordered with ordered (#724)\nAdd missing docstring for center_predictors (#726)\nFix bugs in plot_comparison (#731)\n\n\n\n\n\nAdd docstrings to utility functions (#696)\nMigrate documentation to Quarto (#712)\nAdd case study for MRP (#716)\nAdd example about ordinal regression (#719)\nAdd example about zero inflated models (#725)\nAdd example about predictions for new groups (#734)\n\n\n\n\n\nDrop official suport for Python 3.8 (#720)\nChange plots submodule name to interpret (#705)"
  },
  {
    "objectID": "changelog.html#section-3",
    "href": "changelog.html#section-3",
    "title": "Changelog",
    "section": "",
    "text": "Implement new families \"ordinal\" and \"sratio\" for modeling of ordinal responses (#678)\nAllow families to implement a custom create_extra_pps_coord() (#688)\nAllow predictions on new groups (#693)\n\n\n\n\n\nRobustify how Bambi handles dims (#682)\nFix links in FAQ (#686)\nUpdate additional dependencies install command (#689)\nUpdate predict pps docstring (#690)\nAdd warning for aliases athat aren’t used (#691)\n\n\n\n\n\nAdd families to the Getting Started guide (#683)"
  },
  {
    "objectID": "changelog.html#section-4",
    "href": "changelog.html#section-4",
    "title": "Changelog",
    "section": "",
    "text": "Add support for Gaussian Processes via the HSGP approximation (#632)\nAdd new families: \"zero_inflated_poisson\", \"zero_inflated_binomial\", and \"zero_inflated_negativebinomial\" (#654)\nAdd new families: \"beta_binomial\" and \"dirichlet_multinomial\" (#659)\nAllow plot_cap() to show predictions at the observation level (#668)\nAdd new families: \"hurdle_gamma\", \"hurdle_lognormal\", \"hurdle_negativebinomial\", and \"hurdle_poisson\" (#676)\n\n\n\n\n\nModify how HSGP is built in PyMC when there are groups (#661)\nModify how Bambi is imported in the tests (#662)\nPrevent underscores from being removed in dim names (#664)\nBump sphix dependency to a version greater than 7 (#672)\n\n\n\n\n\nDocument how to use custom priors (#656)\nFix name of arviz traceplot function in the docs (#666)\nAdd example that shows how plot_cap() works (#670)"
  },
  {
    "objectID": "changelog.html#section-5",
    "href": "changelog.html#section-5",
    "title": "Changelog",
    "section": "",
    "text": "Refactored the codebase to support distributional models (#607)\nAdded a default method to handle posterior predictive sampling for custom families (#625)\nplot_cap() gains a new argument target that allows to plot different parameters of the response distribution (#627)\n\n\n\n\n\nMoved the tests directory to the root of the repository (#607)\nDon’t pass dims to the response of the likelihood distribution anymore (#629)\nRemove requirements.txt and replace with pyproject.toml config file to distribute the package (#631)\n\n\n\n\n\nUpdate examples to work with the new internals (#607)\nFixed figure in the Sleepstudy example (#607)\nAdd example using distributional models (#641)\n\n\n\n\n\nRemoved versioned documentation webpage (#616)\nRemoved correlated priors for group-specific terms (#607)\nDictionary with tuple keys are not allowed for priors anymore (#607)"
  },
  {
    "objectID": "changelog.html#section-6",
    "href": "changelog.html#section-6",
    "title": "Changelog",
    "section": "",
    "text": "Update to PyMC &gt;= 5, which means we use PyTensor instead of Aesara now (#613, #614)"
  },
  {
    "objectID": "changelog.html#section-7",
    "href": "changelog.html#section-7",
    "title": "Changelog",
    "section": "",
    "text": "Implement censored() (#581)\nAdd Formula class (#585)\nAdd common numpy transforms to extra_namespace (#589)\nAdd AsymmetricLaplace family for Quantile Regression (#591)\nAdd ‘transforms’ argument to plot_cap() (#594)\nAdd panel covariates to plot_cap() and make it more flexible (#596)\n\n\n\n\n\nReimplemented predictions to make better usage of xarray data structures (#573)\nKeep 0 dimensional parameters as 0 dimensional instead of 1 dimensional (#575)\nRefactor terms for modularity and extensibility (#582)\nRemove seed argument from model.initial_point() (#592)\nAdd build check function on prior predictive and plot prior (#605)\n\n\n\n\n\nAdd quantile regression example (#608)\n\n\n\n\n\nRemove automatic_priors argument from Model (#603)\nRemove string option for data input in Model (#604)"
  },
  {
    "objectID": "changelog.html#section-8",
    "href": "changelog.html#section-8",
    "title": "Changelog",
    "section": "",
    "text": "Add support for jax sampling via numpyro and blackjax samplers (#526)\nAdd Laplace family (#524)\nImprove Laplace computation and integration (#555 and #563)\n\n\n\n\n\nEnsure order variable is preserved when ploting priors (#529)\nTreat offset accordingly (#534)\nRefactor tests to share data generation code (#531)\n\n\n\n\n\nUpdate documentation following good inferencedata practices (#537)\nAdd logos to repo and docs (#542)\n\n\n\n\n\nDeprecate method argument in favor of inference_method (#554)"
  },
  {
    "objectID": "changelog.html#section-9",
    "href": "changelog.html#section-9",
    "title": "Changelog",
    "section": "",
    "text": "Bambi now uses PyMC 4.0 as it’s backend. Most if not all your previous model should run the same, without the need of any change.\nAdd Plot Conditional Adjusted Predictions plot_cap (#517)\n\n\n\n\n\nGroup specific terms now work with numeric of multiple columns (#516)"
  },
  {
    "objectID": "changelog.html#section-10",
    "href": "changelog.html#section-10",
    "title": "Changelog",
    "section": "",
    "text": "Add VonMises (\"vonmises\") built-in family (#453)\nModel.predict() gains a new argument include_group_specific to determine if group-specific effects are considered when making predictions (#470)\nAdd Multinomial (\"multinomial\") built-in family (#490)\n\n\n\n\n\nAdd posterior predictive sampling method to “categorical” family (#458)\nRequire Python &gt;= 3.7.2 to fix NoReturn type bug in Python (#463)\nFixed the wrong builtin link given by link=\"inverse\" was wrong. It returned the same result as link=\"cloglog\" (#472)\nReplaced plain dictionaries with namedtuples when same dictionary structure was repeated many times (#472)\nThe function check_full_rank() in utils.py now checks the array is 2 dimensional (#472)\nRemoved _extract_family_prior() from bambi/families as it was unnecesary (#472)\nRemoved bambi/families/utils.py as it was unnecesary (#472)\nRemoved external links and unused datasets (#483)\nReplaced \"_coord_group_factor\" with \"__factor_dim\" and \"_coord_group_expr\" with \"__expr_dim\" in dimension/coord names (#499)\nFixed a bug related to modifying the types of the columns in the original data frame (#502)\n\n\n\n\n\nAdd circular regression example (#465)\nAdd Categorical regression example (#457)\nAdd Beta regression example (#442)\nAdd Radon Example (#440)\nFix typos and clear up writing in some docs (#462)\nDocumented the module bambi/defaults (#472)\nImproved documentation and made it more consistent (#472)\nCleaned Strack RRR example (#479)\n\n\n\n\n\nRemoved old default priors (#474)\nRemoved draws parameter from Model.predict() method (#504)"
  },
  {
    "objectID": "changelog.html#section-11",
    "href": "changelog.html#section-11",
    "title": "Changelog",
    "section": "",
    "text": "Fixed bug related to the shape of 2 level categorical group-specific effects (#441)"
  },
  {
    "objectID": "changelog.html#section-12",
    "href": "changelog.html#section-12",
    "title": "Changelog",
    "section": "",
    "text": "Add “categorical” built-in family (#426)\nAdd include_mean argument to the method Model.fit() (#434)\nAdd .set_alias() method to Model (#435)\n\n\n\n\n\nCodebase for the PyMC backend has been refactored (#408)\nFix examples that averaged posterior values across chains (#429)\nFix issue #427 with automatic priors for the intercept term (#430)\n\n\n\n\n\nAdd StudentT regression example, thanks to @tjburch (#414)\nAdd B-Spline regression example with cherry blossoms dataset (#416)\nAdd hirarchical linear regression example with sleepstudy dataset (#424)"
  },
  {
    "objectID": "changelog.html#section-13",
    "href": "changelog.html#section-13",
    "title": "Changelog",
    "section": "",
    "text": "Use formulae 0.2.0 (#411)"
  },
  {
    "objectID": "changelog.html#section-14",
    "href": "changelog.html#section-14",
    "title": "Changelog",
    "section": "",
    "text": "Change default priors for the ‘t’ family (#403)\n\n\n\n\n\nAdd installation instructions with conda (#406)\nCorrected a typo: pary_id -&gt; party_id (#402)\nAdd donation information (#409)"
  },
  {
    "objectID": "changelog.html#section-15",
    "href": "changelog.html#section-15",
    "title": "Changelog",
    "section": "",
    "text": "Documentation for all versions is built from scratch when there’s a release. This ensures older versions link to the current stable release. (#396)\nAdd new axis to prior predictive samples to represent 1 chain in the InferenceData object we return (#397)\nMove Family, Likelihood and Link to the families submodule and improved some docstrings (#399)\n\n\n\n\n\nAdd example with hierarchical binomial model (#398)"
  },
  {
    "objectID": "changelog.html#section-16",
    "href": "changelog.html#section-16",
    "title": "Changelog",
    "section": "",
    "text": "Add alternative default priors (#360)\nAdd StudentT family (#367)\nAdd Beta family (#368)\nImplement both in-sample and out-of-sample model predictions (#372)\nAdd function to load datasets (#375)\nAdd option to specify potentials (#379)\nAdd Binomial family (#386)\n\n\n\n\n\nAutomatic switch initialization method from “jitter-adapt_diag” to “adapt_diag” when sampling fails (#383)\nPredictors are internally centered when there is an intercept. This generally results in improved sampling efficiency (#385)\nImprove documentation and error message in Model.graph() (#390)\n\n\n\n\n\nAdd Negative Binomial family example notebook (#346)\nFixed typos and improved many notebooks (#374, #377, #382)"
  },
  {
    "objectID": "changelog.html#section-17",
    "href": "changelog.html#section-17",
    "title": "Changelog",
    "section": "",
    "text": "It is possible to specify priors for parameters in the response distribution (#335)\nAdd probit and cloglog link functions (#340)\n\n\n\n\n\nInformative message when default priors fail because of perfect separation. Model can be fit with custom priors (#330)\nBreaking changes to the API. All the information related to the model goes in Model() instantiation now (#333)\nFix gamma family (#337)\nNon-default links are properly passed to statsmodels (#337)\nFix Wald family (#340)\nFix Negative binomial family (#340)\nAdd informative message when link function is not available for a given family (#340)\nUpdate formulae version to 0.0.10 (#348)\n\n\n\n\n\nNotebooks are updated to the new API (#336)\nAdd badges, update introduction and minor style changes in webpage (#344)\nAdd example using Gamma and Wald families (#345)\nWebpage theme has been updated to PyData theme (#347)\nAdd model evaluation to logistic regression example (#350)"
  },
  {
    "objectID": "changelog.html#section-18",
    "href": "changelog.html#section-18",
    "title": "Changelog",
    "section": "",
    "text": "Add option to save a figure from model.graph() by passing the name of a file. Figure format and resolution can also be set (#317)\nObjects of class Prior, Family and Model have nicer print methods (#326)\n\n\n\n\n\nAdd negative binomial family to config file, which was missing (#324)\nAdd test to check model compilation with families available (#327)\nUpdate formulae to version 0.0.9 (#329)\n\n\n\n\n\nFix gamma docstring (#328)"
  },
  {
    "objectID": "changelog.html#section-19",
    "href": "changelog.html#section-19",
    "title": "Changelog",
    "section": "",
    "text": "Use formulae to parse model formulas (#299)\nAdd model representation (#300)\n\n\n\n\n\nRemove deprecation warning related to pm.sample returning idata (#295)\n\n\n\n\n\nAdd citation to Bambi preprint (#290)\nRemove reference to pystan (#292)"
  },
  {
    "objectID": "changelog.html#section-20",
    "href": "changelog.html#section-20",
    "title": "Changelog",
    "section": "",
    "text": "Add posterior predictive sampling (#250)\nAdd prior predictive sampling (#244)\nAdd gamma, negativebinomial and wald families (#207)\n\n\n\n\n\nUse pm.sample_prior_predictive function to sample and plot from prior (#238)\nFix FutureWarning: Support for multi-dimensional indexing (#242)\nUse last version of black (#245)\nfix broken link increase Python version (#227)\nAdd black style check on lint (#220)\nSome linting while re-reading library (#219)\nRemove future warning when converting the trace to InferenceData (#213)\nInclude missing files for sdist (#204)\nFixed if-else comparison that prevented HalfTStudent prior from being used (#205)\nSidestep plotting flat priors in plot_priors() (#258)\nGLM.fit_constrained in automatic priors now uses start_params = None (#265)\nCategorical Term within Model now have Term.categorical equal to True(#269)\nUse logging instead of warnings (#270)\nOmits ploting group-level effects and offset variables (#276)\nLogistic regression works with no explicit index (#277)\nAdd argument to optionally keep offsets in InferenceData (#288)\nAdd argument to optionally keep group level effects and offsets variables in plot_prior (#288)\n\n\n\n\n\nUpdate example notebooks (#232)\nadd missing notebooks (#229)\nFix notebooks (#222)\nClean docs (#200)\nAdded notebook using Bambi and ArviZ for model comparison (#267)\nUse same color palette in all notebooks (#282)\nFix divergences in examples (two divergences remaining in Strack RRR example) (#282)\n\n\n\n\n\nDrop support python 3.6 (#218)\nRemove stan backend and replace sd with sigma (#205)\nDeprecate samples argument in favor of draws (#247)"
  },
  {
    "objectID": "changelog.html#the-first-python-3-and-arviz-bambino",
    "href": "changelog.html#the-first-python-3-and-arviz-bambino",
    "title": "Changelog",
    "section": "",
    "text": "Add laplace approximation (#184) (only for educational use, do not use for real problems)\nUse arviz (#182, #178, #166, #159)\n\n\n\n\n\nUpdate requirements (#191)\nChange default sd prior and update docs (#189)\nAdd f-strings and support python 3.6+ (#188)\nFix parallel sampling (#186)\nLint code (#175, #173, #171, #167)\nMove coverage configuration to setup.cfg (#168)\nAdd long description to setup.py; light linting on setup.py (#162)\nBlack list external/ and tests/from pylint\n\n\n\n\n\nAdd missing example (#194)\nUpdate docs and fix typos (#185, #181)\nAdd missing items to readme and code of conduct (#180)\nSimplify readme (#179)\nUnify docstring style and remove not used code (#169)\n\n\n\n\n\nDeprecate Stan backend (#183)"
  },
  {
    "objectID": "changelog.html#the-last-legacy-python-bambino",
    "href": "changelog.html#the-last-legacy-python-bambino",
    "title": "Changelog",
    "section": "",
    "text": "Use a callable as link function (#147)\n\n\n\n\n\nUpdate to Python 3, black and some pylint (#158)\nFix test warnings (#144)\nReorder requirements; Add matplotlib to requirements.txt (#143)\nReorder imports; Only import necessary submodules from statsmodels (#142)\nUpdate travis config (#135)\n\n\n\n\n\nAdd contributing guide (#146)\nUpdate notebooks (#140)\n\n\n\n\n\nLast version to support Python 2.7"
  },
  {
    "objectID": "changelog.html#december-11",
    "href": "changelog.html#december-11",
    "title": "Changelog",
    "section": "",
    "text": "Minor release for bugfixes and minor improvements. Changes include:\nBug that was causing an incorrect link function to be used in the PyMC3 backend when fitting logistic models.\nFixed handling of missing values in categorical variables.\nFixed bug in set_priors() when passing numerical values for scale.\nImproved internal handling of custom priors.\nPreliminary Sphinx docs (WIP; thanks to @ejolly)."
  },
  {
    "objectID": "changelog.html#march-31",
    "href": "changelog.html#march-31",
    "title": "Changelog",
    "section": "",
    "text": "This is a major release that introduces several new features, significant API changes, and a large number of bug fixes and minor improvements. Notable changes include:\n\nSupport for Stan as the sampling back-end (in addition to PyMC3), via the PyStan package.\nDropped support for the add_term API; all model specification is now done via formulas.\nExpanded support for arbitrary random effects specifications; any formula now supported by patsy can be passed in as the left-hand side of a random effects specification (e.g., previously, ‘(a*b)|c’ would not have worked).\nCompletely refactored Results classes that no longer depend on PyMC3, providing a completely generic representation of sampler results, independent of any back-end.\nRefactored plotting and summary methods implemented on the abstract MCMCResults classes rather than at the back-end level.\nMuch better compilation and sampling performance for models that include random effects with many levels. In many cases, performance should now be comparable to the most efficient native implementations of the models in the respective back-ends.\nAll random effects priors now use the “non-centered” parameterization by default, significantly reducing bias for some models.\nImproved naming conventions that are more consistent with other packages (e.g., random effects now include the ‘|’ operator in term names).\nRefactored Term class, including a separate subclass for RandomTerms, and a number of other associated changes to the internal object model.\nUpdated documentation and notebooks, including two new notebooks featuring well-developed examples (datasets included).\nImproved handling of NA values in continuous columns.\nSupport for flat priors everywhere (by setting auto_scale=False).\nNumerous bug fixes and minor improvements"
  },
  {
    "objectID": "changelog.html#january-17",
    "href": "changelog.html#january-17",
    "title": "Changelog",
    "section": "",
    "text": "Weakly informative default priors now work the same for all response families & link functions\nMinor bug fixes/tweaks"
  },
  {
    "objectID": "changelog.html#october-11",
    "href": "changelog.html#october-11",
    "title": "Changelog",
    "section": "",
    "text": "Fixes referencing of Theano ops after PyMC3 namespace clean-up\nAdded example Jupyter notebooks\nImproved handling of priors\nImproved prior plots and result summaries\nImproved access to MCMC trace results\nAdd handling for datasets with NaN values\nAdded travis-ci and coveralls support\nMinor bug fixes/tweaks"
  },
  {
    "objectID": "changelog.html#september-4",
    "href": "changelog.html#september-4",
    "title": "Changelog",
    "section": "",
    "text": "First official release."
  },
  {
    "objectID": "api/interpret.slopes.html",
    "href": "api/interpret.slopes.html",
    "title": "interpret.slopes",
    "section": "",
    "text": "interpret.slopes(model, idata, wrt, conditional=None, average_by=None, eps=0.0001, slope='dydx', use_hdi=True, prob=None, transforms=None, sample_new_groups=False)\nCompute Conditional Adjusted Slopes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\nbambi.Model\nThe model for which we want to plot the predictions.\nrequired\n\n\nidata\narviz.InferenceData\nThe InferenceData object that contains the samples from the posterior distribution of the model.\nrequired\n\n\nwrt\n(str, dict)\nThe slope of the regression with respect to (wrt) this predictor will be computed.\nrequired\n\n\nconditional\n(str, list, dict)\nThe covariates we would like to condition on. If dict, keys are the covariate names and values are the values to condition on.\nNone\n\n\naverage_by\nUnion[str, list, bool, None]\nThe covariates we would like to average by. The passed covariate(s) will marginalize over the other covariates in the model. If True, it averages over all covariates in the model to obtain the average estimate. Defaults to None.\nNone\n\n\neps\nfloat\nTo compute the slope, ‘wrt’ is evaluated at wrt +/- ‘eps’. The rate of change is then computed as the difference between the two values divided by ‘eps’. Defaults to 1e-4.\n0.0001\n\n\nslope\nstr\nThe type of slope to compute. Defaults to ‘dydx’. ‘dydx’ represents a unit increase in ‘wrt’ is associated with an n-unit change in the response. ‘eyex’ represents a percentage increase in ‘wrt’ is associated with an n-percent change in the response. ‘eydx’ represents a unit increase in ‘wrt’ is associated with an n-percent change in the response. ‘dyex’ represents a percent change in ‘wrt’ is associated with a unit increase in the response.\n'dydx'\n\n\nuse_hdi\nbool\nWhether to compute the highest density interval (defaults to True) or the quantiles.\nTrue\n\n\nprob\nfloat\nThe probability for the credibility intervals. Must be between 0 and 1. Defaults to 0.94. Changing the global variable az.rcParams[\"stats.hdi_prob\"] affects this default.\nNone\n\n\ntransforms\ndict\nTransformations that are applied to each of the variables being plotted. The keys are the name of the variables, and the values are functions to be applied. Defaults to None.\nNone\n\n\nsample_new_groups\nbool\nIf the model contains group-level effects, and data is passed for unseen groups, whether to sample from the new groups. Defaults to False.\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nA dataframe with the comparison values, highest density interval, wrt name, contrast value, and conditional values.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nIf length of wrt is greater than 1. If conditional is None and wrt is passed more than 2 values. If conditional is None and default wrt has more than 2 unique values. If conditional is a list and the length is greater than 3. If slope is not ‘dydx’, ‘dyex’, ‘eyex’, or ‘eydx’. If prob is not &gt; 0 and &lt; 1.",
    "crumbs": [
      "API Reference",
      "Interpretations",
      "interpret.slopes"
    ]
  },
  {
    "objectID": "api/interpret.slopes.html#parameters",
    "href": "api/interpret.slopes.html#parameters",
    "title": "interpret.slopes",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nmodel\nbambi.Model\nThe model for which we want to plot the predictions.\nrequired\n\n\nidata\narviz.InferenceData\nThe InferenceData object that contains the samples from the posterior distribution of the model.\nrequired\n\n\nwrt\n(str, dict)\nThe slope of the regression with respect to (wrt) this predictor will be computed.\nrequired\n\n\nconditional\n(str, list, dict)\nThe covariates we would like to condition on. If dict, keys are the covariate names and values are the values to condition on.\nNone\n\n\naverage_by\nUnion[str, list, bool, None]\nThe covariates we would like to average by. The passed covariate(s) will marginalize over the other covariates in the model. If True, it averages over all covariates in the model to obtain the average estimate. Defaults to None.\nNone\n\n\neps\nfloat\nTo compute the slope, ‘wrt’ is evaluated at wrt +/- ‘eps’. The rate of change is then computed as the difference between the two values divided by ‘eps’. Defaults to 1e-4.\n0.0001\n\n\nslope\nstr\nThe type of slope to compute. Defaults to ‘dydx’. ‘dydx’ represents a unit increase in ‘wrt’ is associated with an n-unit change in the response. ‘eyex’ represents a percentage increase in ‘wrt’ is associated with an n-percent change in the response. ‘eydx’ represents a unit increase in ‘wrt’ is associated with an n-percent change in the response. ‘dyex’ represents a percent change in ‘wrt’ is associated with a unit increase in the response.\n'dydx'\n\n\nuse_hdi\nbool\nWhether to compute the highest density interval (defaults to True) or the quantiles.\nTrue\n\n\nprob\nfloat\nThe probability for the credibility intervals. Must be between 0 and 1. Defaults to 0.94. Changing the global variable az.rcParams[\"stats.hdi_prob\"] affects this default.\nNone\n\n\ntransforms\ndict\nTransformations that are applied to each of the variables being plotted. The keys are the name of the variables, and the values are functions to be applied. Defaults to None.\nNone\n\n\nsample_new_groups\nbool\nIf the model contains group-level effects, and data is passed for unseen groups, whether to sample from the new groups. Defaults to False.\nFalse",
    "crumbs": [
      "API Reference",
      "Interpretations",
      "interpret.slopes"
    ]
  },
  {
    "objectID": "api/interpret.slopes.html#returns",
    "href": "api/interpret.slopes.html#returns",
    "title": "interpret.slopes",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\npandas.DataFrame\nA dataframe with the comparison values, highest density interval, wrt name, contrast value, and conditional values.",
    "crumbs": [
      "API Reference",
      "Interpretations",
      "interpret.slopes"
    ]
  },
  {
    "objectID": "api/interpret.slopes.html#raises",
    "href": "api/interpret.slopes.html#raises",
    "title": "interpret.slopes",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nValueError\nIf length of wrt is greater than 1. If conditional is None and wrt is passed more than 2 values. If conditional is None and default wrt has more than 2 unique values. If conditional is a list and the length is greater than 3. If slope is not ‘dydx’, ‘dyex’, ‘eyex’, or ‘eydx’. If prob is not &gt; 0 and &lt; 1.",
    "crumbs": [
      "API Reference",
      "Interpretations",
      "interpret.slopes"
    ]
  },
  {
    "objectID": "api/interpret.plot_slopes.html",
    "href": "api/interpret.plot_slopes.html",
    "title": "interpret.plot_slopes",
    "section": "",
    "text": "interpret.plot_slopes(model, idata, wrt, conditional=None, average_by=None, eps=0.0001, slope='dydx', sample_new_groups=False, use_hdi=True, prob=None, transforms=None, legend=True, ax=None, fig_kwargs=None, subplot_kwargs=None)\nPlot Conditional Adjusted Slopes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\nbambi.Model\nThe model for which we want to plot the predictions.\nrequired\n\n\nidata\narviz.InferenceData\nThe InferenceData object that contains the samples from the posterior distribution of the model.\nrequired\n\n\nwrt\n(str, dict)\nThe slope of the regression with respect to (wrt) this predictor will be computed. If ‘wrt’ is numeric, the derivative is computed, else if string or categorical, ‘comparisons’ is called to compute difference in group means.\nrequired\n\n\nconditional\n(str, dict, list)\nThe covariates we would like to condition on. If dict, keys are the covariate names and values are the values to condition on.\nNone\n\n\naverage_by\nUnion[str, list]\nThe covariates we would like to average by. The passed covariate(s) will marginalize over the other covariates in the model. If True, it averages over all covariates in the model to obtain the average estimate. Defaults to None.\nNone\n\n\neps\nfloat\nTo compute the slope, ‘wrt’ is evaluated at wrt +/- ‘eps’. The rate of change is then computed as the difference between the two values divided by ‘eps’. Defaults to 1e-4.\n0.0001\n\n\nslope\nstr\nThe type of slope to compute. Defaults to ‘dydx’. ‘dydx’ represents a unit increase in ‘wrt’ is associated with an n-unit change in the response. ‘eyex’ represents a percentage increase in ‘wrt’ is associated with an n-percent change in the response. ‘eydx’ represents a unit increase in ‘wrt’ is associated with an n-percent change in the response. ‘dyex’ represents a percent change in ‘wrt’ is associated with a unit increase in the response.\n'dydx'\n\n\nsample_new_groups\nbool\nIf the model contains group-level effects, and data is passed for unseen groups, whether to sample from the new groups. Defaults to False.\nFalse\n\n\nuse_hdi\nbool\nWhether to compute the highest density interval (defaults to True) or the quantiles.\nTrue\n\n\nprob\nfloat\nThe probability for the credibility intervals. Must be between 0 and 1. Defaults to 0.94. Changing the global variable az.rcParam[\"stats.hdi_prob\"] affects this default.\nNone\n\n\ntransforms\ndict\nTransformations that are applied to each of the variables being plotted. The keys are the name of the variables, and the values are functions to be applied. Defaults to None.\nNone\n\n\nlegend\nbool\nWhether to automatically include a legend in the plot. Defaults to True.\nTrue\n\n\nax\nmatplotlib.axes._subplots.AxesSubplot\nA matplotlib axes object or a sequence of them. If None, this function instantiates a new axes object. Defaults to None.\nNone\n\n\nfig_kwargs\noptional\nKeyword arguments passed to the matplotlib figure function as a dict. For example, fig_kwargs=dict(figsize=(11, 8)), sharey=True would make the figure 11 inches wide by 8 inches high and would share the y-axis values.\nNone\n\n\nsubplot_kwargs\noptional\nKeyword arguments used to determine the covariates used for the horizontal, group, and panel axes. For example, subplot_kwargs=dict(main=\"x\", group=\"y\", panel=\"z\") would plot the horizontal axis as x, the color (hue) as y, and the panel axis as z.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n(matplotlib.figure.Figure, matplotlib.axes._subplots.AxesSubplot)\nA tuple with the figure and the axes.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nIf the number of wrt values is greater than 2 and average_by is None. If conditional and average_by are both None. If length of conditional is greater than 3 and average_by is None. If average_by is True. If slope is not one of (‘dydx’, ‘dyex’, ‘eyex’, ‘eydx’). If main covariate is not numeric or categoric.",
    "crumbs": [
      "API Reference",
      "Plots",
      "interpret.plot_slopes"
    ]
  },
  {
    "objectID": "api/interpret.plot_slopes.html#parameters",
    "href": "api/interpret.plot_slopes.html#parameters",
    "title": "interpret.plot_slopes",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nmodel\nbambi.Model\nThe model for which we want to plot the predictions.\nrequired\n\n\nidata\narviz.InferenceData\nThe InferenceData object that contains the samples from the posterior distribution of the model.\nrequired\n\n\nwrt\n(str, dict)\nThe slope of the regression with respect to (wrt) this predictor will be computed. If ‘wrt’ is numeric, the derivative is computed, else if string or categorical, ‘comparisons’ is called to compute difference in group means.\nrequired\n\n\nconditional\n(str, dict, list)\nThe covariates we would like to condition on. If dict, keys are the covariate names and values are the values to condition on.\nNone\n\n\naverage_by\nUnion[str, list]\nThe covariates we would like to average by. The passed covariate(s) will marginalize over the other covariates in the model. If True, it averages over all covariates in the model to obtain the average estimate. Defaults to None.\nNone\n\n\neps\nfloat\nTo compute the slope, ‘wrt’ is evaluated at wrt +/- ‘eps’. The rate of change is then computed as the difference between the two values divided by ‘eps’. Defaults to 1e-4.\n0.0001\n\n\nslope\nstr\nThe type of slope to compute. Defaults to ‘dydx’. ‘dydx’ represents a unit increase in ‘wrt’ is associated with an n-unit change in the response. ‘eyex’ represents a percentage increase in ‘wrt’ is associated with an n-percent change in the response. ‘eydx’ represents a unit increase in ‘wrt’ is associated with an n-percent change in the response. ‘dyex’ represents a percent change in ‘wrt’ is associated with a unit increase in the response.\n'dydx'\n\n\nsample_new_groups\nbool\nIf the model contains group-level effects, and data is passed for unseen groups, whether to sample from the new groups. Defaults to False.\nFalse\n\n\nuse_hdi\nbool\nWhether to compute the highest density interval (defaults to True) or the quantiles.\nTrue\n\n\nprob\nfloat\nThe probability for the credibility intervals. Must be between 0 and 1. Defaults to 0.94. Changing the global variable az.rcParam[\"stats.hdi_prob\"] affects this default.\nNone\n\n\ntransforms\ndict\nTransformations that are applied to each of the variables being plotted. The keys are the name of the variables, and the values are functions to be applied. Defaults to None.\nNone\n\n\nlegend\nbool\nWhether to automatically include a legend in the plot. Defaults to True.\nTrue\n\n\nax\nmatplotlib.axes._subplots.AxesSubplot\nA matplotlib axes object or a sequence of them. If None, this function instantiates a new axes object. Defaults to None.\nNone\n\n\nfig_kwargs\noptional\nKeyword arguments passed to the matplotlib figure function as a dict. For example, fig_kwargs=dict(figsize=(11, 8)), sharey=True would make the figure 11 inches wide by 8 inches high and would share the y-axis values.\nNone\n\n\nsubplot_kwargs\noptional\nKeyword arguments used to determine the covariates used for the horizontal, group, and panel axes. For example, subplot_kwargs=dict(main=\"x\", group=\"y\", panel=\"z\") would plot the horizontal axis as x, the color (hue) as y, and the panel axis as z.\nNone",
    "crumbs": [
      "API Reference",
      "Plots",
      "interpret.plot_slopes"
    ]
  },
  {
    "objectID": "api/interpret.plot_slopes.html#returns",
    "href": "api/interpret.plot_slopes.html#returns",
    "title": "interpret.plot_slopes",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\n(matplotlib.figure.Figure, matplotlib.axes._subplots.AxesSubplot)\nA tuple with the figure and the axes.",
    "crumbs": [
      "API Reference",
      "Plots",
      "interpret.plot_slopes"
    ]
  },
  {
    "objectID": "api/interpret.plot_slopes.html#raises",
    "href": "api/interpret.plot_slopes.html#raises",
    "title": "interpret.plot_slopes",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nValueError\nIf the number of wrt values is greater than 2 and average_by is None. If conditional and average_by are both None. If length of conditional is greater than 3 and average_by is None. If average_by is True. If slope is not one of (‘dydx’, ‘dyex’, ‘eyex’, ‘eydx’). If main covariate is not numeric or categoric.",
    "crumbs": [
      "API Reference",
      "Plots",
      "interpret.plot_slopes"
    ]
  },
  {
    "objectID": "api/interpret.plot_comparisons.html",
    "href": "api/interpret.plot_comparisons.html",
    "title": "interpret.plot_comparisons",
    "section": "",
    "text": "interpret.plot_comparisons(model, idata, contrast, conditional=None, average_by=None, comparison_type='diff', sample_new_groups=False, use_hdi=True, prob=None, legend=True, transforms=None, ax=None, fig_kwargs=None, subplot_kwargs=None)\nPlot Conditional Adjusted Comparisons\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\nbambi.Model\nThe model for which we want to plot the predictions.\nrequired\n\n\nidata\narviz.InferenceData\nThe InferenceData object that contains the samples from the posterior distribution of the model.\nrequired\n\n\ncontrast\n(str, dict, list)\nThe predictor name whose contrast we would like to compare.\nrequired\n\n\nconditional\n(str, dict, list)\nThe covariates we would like to condition on. If dict, keys are the covariate names and values are the values to condition on.\nNone\n\n\naverage_by\nUnion[str, list, None]\nThe covariates we would like to average by. The passed covariate(s) will marginalize over the other covariates in the model. Defaults to None.\nNone\n\n\ncomparison_type\nstr\nThe type of comparison to plot. Defaults to ‘diff’.\n'diff'\n\n\nsample_new_groups\nbool\nIf the model contains group-level effects, and data is passed for unseen groups, whether to sample from the new groups. Defaults to False.\nFalse\n\n\nuse_hdi\nbool\nWhether to compute the highest density interval (defaults to True) or the quantiles.\nTrue\n\n\nprob\nfloat\nThe probability for the credibility intervals. Must be between 0 and 1. Defaults to 0.94. Changing the global variable az.rcParam[\"stats.hdi_prob\"] affects this default.\nNone\n\n\nlegend\nbool\nWhether to automatically include a legend in the plot. Defaults to True.\nTrue\n\n\ntransforms\ndict\nTransformations that are applied to each of the variables being plotted. The keys are the name of the variables, and the values are functions to be applied. Defaults to None.\nNone\n\n\nax\nmatplotlib.axes._subplots.AxesSubplot\nA matplotlib axes object or a sequence of them. If None, this function instantiates a new axes object. Defaults to None.\nNone\n\n\nfig_kwargs\noptional\nKeyword arguments passed to the matplotlib figure function as a dict. For example, fig_kwargs=dict(figsize=(11, 8)), sharey=True would make the figure 11 inches wide by 8 inches high and would share the y-axis values.\nNone\n\n\nsubplot_kwargs\noptional\nKeyword arguments used to determine the covariates used for the horizontal, group, and panel axes. For example, subplot_kwargs=dict(main=\"x\", group=\"y\", panel=\"z\") would plot the horizontal axis as x, the color (hue) as y, and the panel axis as z.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n(matplotlib.figure.Figure, matplotlib.axes._subplots.AxesSubplot)\nA tuple with the figure and the axes.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nIf the number of contrast levels is greater than 2 and average_by is None. If conditional and average_by are both None. If length of conditional is greater than 3 and average_by is None. If average_by is True. If main covariate is not numeric or categoric.",
    "crumbs": [
      "API Reference",
      "Plots",
      "interpret.plot_comparisons"
    ]
  },
  {
    "objectID": "api/interpret.plot_comparisons.html#parameters",
    "href": "api/interpret.plot_comparisons.html#parameters",
    "title": "interpret.plot_comparisons",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nmodel\nbambi.Model\nThe model for which we want to plot the predictions.\nrequired\n\n\nidata\narviz.InferenceData\nThe InferenceData object that contains the samples from the posterior distribution of the model.\nrequired\n\n\ncontrast\n(str, dict, list)\nThe predictor name whose contrast we would like to compare.\nrequired\n\n\nconditional\n(str, dict, list)\nThe covariates we would like to condition on. If dict, keys are the covariate names and values are the values to condition on.\nNone\n\n\naverage_by\nUnion[str, list, None]\nThe covariates we would like to average by. The passed covariate(s) will marginalize over the other covariates in the model. Defaults to None.\nNone\n\n\ncomparison_type\nstr\nThe type of comparison to plot. Defaults to ‘diff’.\n'diff'\n\n\nsample_new_groups\nbool\nIf the model contains group-level effects, and data is passed for unseen groups, whether to sample from the new groups. Defaults to False.\nFalse\n\n\nuse_hdi\nbool\nWhether to compute the highest density interval (defaults to True) or the quantiles.\nTrue\n\n\nprob\nfloat\nThe probability for the credibility intervals. Must be between 0 and 1. Defaults to 0.94. Changing the global variable az.rcParam[\"stats.hdi_prob\"] affects this default.\nNone\n\n\nlegend\nbool\nWhether to automatically include a legend in the plot. Defaults to True.\nTrue\n\n\ntransforms\ndict\nTransformations that are applied to each of the variables being plotted. The keys are the name of the variables, and the values are functions to be applied. Defaults to None.\nNone\n\n\nax\nmatplotlib.axes._subplots.AxesSubplot\nA matplotlib axes object or a sequence of them. If None, this function instantiates a new axes object. Defaults to None.\nNone\n\n\nfig_kwargs\noptional\nKeyword arguments passed to the matplotlib figure function as a dict. For example, fig_kwargs=dict(figsize=(11, 8)), sharey=True would make the figure 11 inches wide by 8 inches high and would share the y-axis values.\nNone\n\n\nsubplot_kwargs\noptional\nKeyword arguments used to determine the covariates used for the horizontal, group, and panel axes. For example, subplot_kwargs=dict(main=\"x\", group=\"y\", panel=\"z\") would plot the horizontal axis as x, the color (hue) as y, and the panel axis as z.\nNone",
    "crumbs": [
      "API Reference",
      "Plots",
      "interpret.plot_comparisons"
    ]
  },
  {
    "objectID": "api/interpret.plot_comparisons.html#returns",
    "href": "api/interpret.plot_comparisons.html#returns",
    "title": "interpret.plot_comparisons",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\n(matplotlib.figure.Figure, matplotlib.axes._subplots.AxesSubplot)\nA tuple with the figure and the axes.",
    "crumbs": [
      "API Reference",
      "Plots",
      "interpret.plot_comparisons"
    ]
  },
  {
    "objectID": "api/interpret.plot_comparisons.html#raises",
    "href": "api/interpret.plot_comparisons.html#raises",
    "title": "interpret.plot_comparisons",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nValueError\nIf the number of contrast levels is greater than 2 and average_by is None. If conditional and average_by are both None. If length of conditional is greater than 3 and average_by is None. If average_by is True. If main covariate is not numeric or categoric.",
    "crumbs": [
      "API Reference",
      "Plots",
      "interpret.plot_comparisons"
    ]
  },
  {
    "objectID": "api/index.html",
    "href": "api/index.html",
    "title": "Function reference",
    "section": "",
    "text": "The basics\n\n\n\nModel\nSpecification of model class\n\n\nFormula\nModel formula\n\n\n\n\n\n\n\n\n\nPrior\nAbstract specification of a term prior\n\n\n\n\n\n\n\n\n\nFamily\nA specification of model family\n\n\nLikelihood\nRepresentation of a Likelihood function for a Bambi model\n\n\nLink\nRepresentation of a link function\n\n\n\n\n\n\n\n\n\ninterpret.plot_comparisons\nPlot Conditional Adjusted Comparisons\n\n\ninterpret.plot_predictions\nPlot Conditional Adjusted Predictions\n\n\ninterpret.plot_slopes\nPlot Conditional Adjusted Slopes\n\n\n\n\n\n\n\n\n\ninterpret.comparisons\nCompute Conditional Adjusted Comparisons\n\n\ninterpret.predictions\nCompute Conditional Adjusted Predictions\n\n\ninterpret.slopes\nCompute Conditional Adjusted Slopes\n\n\n\n\n\n\n\n\n\nclear_data_home\nDelete all the content of the data home cache.\n\n\nload_data\nLoad a dataset.",
    "crumbs": [
      "API Reference",
      "Function reference"
    ]
  },
  {
    "objectID": "api/index.html#model",
    "href": "api/index.html#model",
    "title": "Function reference",
    "section": "",
    "text": "The basics\n\n\n\nModel\nSpecification of model class\n\n\nFormula\nModel formula",
    "crumbs": [
      "API Reference",
      "Function reference"
    ]
  },
  {
    "objectID": "api/index.html#setting-up-priors",
    "href": "api/index.html#setting-up-priors",
    "title": "Function reference",
    "section": "",
    "text": "Prior\nAbstract specification of a term prior",
    "crumbs": [
      "API Reference",
      "Function reference"
    ]
  },
  {
    "objectID": "api/index.html#custom-families",
    "href": "api/index.html#custom-families",
    "title": "Function reference",
    "section": "",
    "text": "Family\nA specification of model family\n\n\nLikelihood\nRepresentation of a Likelihood function for a Bambi model\n\n\nLink\nRepresentation of a link function",
    "crumbs": [
      "API Reference",
      "Function reference"
    ]
  },
  {
    "objectID": "api/index.html#plots",
    "href": "api/index.html#plots",
    "title": "Function reference",
    "section": "",
    "text": "interpret.plot_comparisons\nPlot Conditional Adjusted Comparisons\n\n\ninterpret.plot_predictions\nPlot Conditional Adjusted Predictions\n\n\ninterpret.plot_slopes\nPlot Conditional Adjusted Slopes",
    "crumbs": [
      "API Reference",
      "Function reference"
    ]
  },
  {
    "objectID": "api/index.html#interpretations",
    "href": "api/index.html#interpretations",
    "title": "Function reference",
    "section": "",
    "text": "interpret.comparisons\nCompute Conditional Adjusted Comparisons\n\n\ninterpret.predictions\nCompute Conditional Adjusted Predictions\n\n\ninterpret.slopes\nCompute Conditional Adjusted Slopes",
    "crumbs": [
      "API Reference",
      "Function reference"
    ]
  },
  {
    "objectID": "api/index.html#data",
    "href": "api/index.html#data",
    "title": "Function reference",
    "section": "",
    "text": "clear_data_home\nDelete all the content of the data home cache.\n\n\nload_data\nLoad a dataset.",
    "crumbs": [
      "API Reference",
      "Function reference"
    ]
  },
  {
    "objectID": "api/Prior.html",
    "href": "api/Prior.html",
    "title": "Prior",
    "section": "",
    "text": "priors.Prior(self, name, auto_scale=True, dist=None, **kwargs)\nAbstract specification of a term prior\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nname\nstr\nName of prior distribution. Must be the name of a PyMC distribution (e.g., \"Normal\", \"Bernoulli\", etc.)\nrequired\n\n\nauto_scale\n\nWhether to adjust the parameters of the prior or use them as passed. Default to True.\nTrue\n\n\nkwargs\ndict\nOptional keywords specifying the parameters of the named distribution.\n{}\n\n\ndist\npymc.distributions.distribution.DistributionMeta or callable\nA callable that returns a valid PyMC distribution. The signature must contain name, dims, and shape, as well as its own keyworded arguments.\nNone\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nupdate\nUpdate the arguments of the prior with additional arguments\n\n\n\n\n\nPrior.update(self, **kwargs)\nUpdate the arguments of the prior with additional arguments\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nkwargs\ndict\nOptional keyword arguments to add to prior args.\n{}",
    "crumbs": [
      "API Reference",
      "Setting up priors",
      "Prior"
    ]
  },
  {
    "objectID": "api/Prior.html#parameters",
    "href": "api/Prior.html#parameters",
    "title": "Prior",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nname\nstr\nName of prior distribution. Must be the name of a PyMC distribution (e.g., \"Normal\", \"Bernoulli\", etc.)\nrequired\n\n\nauto_scale\n\nWhether to adjust the parameters of the prior or use them as passed. Default to True.\nTrue\n\n\nkwargs\ndict\nOptional keywords specifying the parameters of the named distribution.\n{}\n\n\ndist\npymc.distributions.distribution.DistributionMeta or callable\nA callable that returns a valid PyMC distribution. The signature must contain name, dims, and shape, as well as its own keyworded arguments.\nNone",
    "crumbs": [
      "API Reference",
      "Setting up priors",
      "Prior"
    ]
  },
  {
    "objectID": "api/Prior.html#methods",
    "href": "api/Prior.html#methods",
    "title": "Prior",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nupdate\nUpdate the arguments of the prior with additional arguments\n\n\n\n\n\nPrior.update(self, **kwargs)\nUpdate the arguments of the prior with additional arguments\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nkwargs\ndict\nOptional keyword arguments to add to prior args.\n{}",
    "crumbs": [
      "API Reference",
      "Setting up priors",
      "Prior"
    ]
  },
  {
    "objectID": "api/Link.html",
    "href": "api/Link.html",
    "title": "Link",
    "section": "",
    "text": "families.Link(self, name, link=None, linkinv=None, linkinv_backend=None)\nRepresentation of a link function\nThis object contains two main functions. One is the link function itself, the function that maps values in the response scale to the linear predictor, and the other is the inverse of the link function, that maps values of the linear predictor to the response scale.\nThe great majority of users will never interact with this class unless they want to create a custom Family with a custom Link. This is automatically handled for all the built-in families.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nname\nstr\nThe name of the link function. If it is a known name, it’s not necessary to pass any other arguments because functions are already defined internally. If not known, all of link, linkinv and linkinv_backend must be specified.\nrequired\n\n\nlink\nfunction\nA function that maps the response to the linear predictor. Known as the :math:g function in GLM jargon. Does not need to be specified when name is a known name.\nNone\n\n\nlinkinv\nfunction\nA function that maps the linear predictor to the response. Known as the :math:g^{-1} function in GLM jargon. Does not need to be specified when name is a known name.\nNone\n\n\nlinkinv_backend\nfunction\nSame than linkinv but must be something that works with PyMC backend (i.e. it must work with PyTensor tensors). Does not need to be specified when name is a known name.\nNone",
    "crumbs": [
      "API Reference",
      "Custom families",
      "Link"
    ]
  },
  {
    "objectID": "api/Link.html#parameters",
    "href": "api/Link.html#parameters",
    "title": "Link",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nname\nstr\nThe name of the link function. If it is a known name, it’s not necessary to pass any other arguments because functions are already defined internally. If not known, all of link, linkinv and linkinv_backend must be specified.\nrequired\n\n\nlink\nfunction\nA function that maps the response to the linear predictor. Known as the :math:g function in GLM jargon. Does not need to be specified when name is a known name.\nNone\n\n\nlinkinv\nfunction\nA function that maps the linear predictor to the response. Known as the :math:g^{-1} function in GLM jargon. Does not need to be specified when name is a known name.\nNone\n\n\nlinkinv_backend\nfunction\nSame than linkinv but must be something that works with PyMC backend (i.e. it must work with PyTensor tensors). Does not need to be specified when name is a known name.\nNone",
    "crumbs": [
      "API Reference",
      "Custom families",
      "Link"
    ]
  },
  {
    "objectID": "api/Formula.html",
    "href": "api/Formula.html",
    "title": "Formula",
    "section": "",
    "text": "Formula(self, formula, *additionals)\nModel formula\nAllows to describe a model with multiple formulas. The first formula describes the response variable and its predictors. The following formulas describe predictors for other parameters of the likelihood function, allowing distributional models.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nformula\nstr\nA model description written using the formula syntax from the formulae library.\nrequired\n\n\n*additionals\nstr\nAdditional formulas that describe model parameters rather than a response variable.\n()\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncheck_additional\nCheck if an additional formula matches the expected format\n\n\ncheck_additionals\nCheck if the additional formulas match the expected format\n\n\nget_all_formulas\nGet all the model formulas\n\n\n\n\n\nFormula.check_additional(self, additional)\nCheck if an additional formula matches the expected format\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nadditional\nstr\nA model formula that describes a model parameter.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nIf the formula does not contain a response term.\n\n\nValueError\nIf the response term is not a plain name.\n\n\n\n\n\n\n\nFormula.check_additionals(self, additionals)\nCheck if the additional formulas match the expected format\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nadditionals\nSequence[str]\nModel formulas that describe model parameters rather than a response variable.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSequence[str]\nIf all formulas match the required format, it return them.\n\n\n\n\n\n\n\nFormula.get_all_formulas(self)\nGet all the model formulas\n\n\n\n\n\nType\nDescription\n\n\n\n\nlist\nAll the formulas in the instance.",
    "crumbs": [
      "API Reference",
      "Model",
      "Formula"
    ]
  },
  {
    "objectID": "api/Formula.html#parameters",
    "href": "api/Formula.html#parameters",
    "title": "Formula",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nformula\nstr\nA model description written using the formula syntax from the formulae library.\nrequired\n\n\n*additionals\nstr\nAdditional formulas that describe model parameters rather than a response variable.\n()",
    "crumbs": [
      "API Reference",
      "Model",
      "Formula"
    ]
  },
  {
    "objectID": "api/Formula.html#methods",
    "href": "api/Formula.html#methods",
    "title": "Formula",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncheck_additional\nCheck if an additional formula matches the expected format\n\n\ncheck_additionals\nCheck if the additional formulas match the expected format\n\n\nget_all_formulas\nGet all the model formulas\n\n\n\n\n\nFormula.check_additional(self, additional)\nCheck if an additional formula matches the expected format\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nadditional\nstr\nA model formula that describes a model parameter.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nIf the formula does not contain a response term.\n\n\nValueError\nIf the response term is not a plain name.\n\n\n\n\n\n\n\nFormula.check_additionals(self, additionals)\nCheck if the additional formulas match the expected format\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nadditionals\nSequence[str]\nModel formulas that describe model parameters rather than a response variable.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSequence[str]\nIf all formulas match the required format, it return them.\n\n\n\n\n\n\n\nFormula.get_all_formulas(self)\nGet all the model formulas\n\n\n\n\n\nType\nDescription\n\n\n\n\nlist\nAll the formulas in the instance.",
    "crumbs": [
      "API Reference",
      "Model",
      "Formula"
    ]
  },
  {
    "objectID": "notebooks/zero_inflated_regression.html",
    "href": "notebooks/zero_inflated_regression.html",
    "title": "Zero inflated models",
    "section": "",
    "text": "import arviz as az\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\nimport numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nimport seaborn as sns\nimport warnings\n\nimport bambi as bmb\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nIn this notebook, we will describe zero inflated outcomes and why the data generating process behind these outcomes requires a special class of generalized linear models: zero-inflated Poisson (ZIP) and hurdle Poisson. Subsequently, we will describe and implement each model using a set of zero-inflated data from ecology. Along the way, we will also use the interpret sub-package to interpret the predictions and parameters of the models.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Zero inflated models"
    ]
  },
  {
    "objectID": "notebooks/zero_inflated_regression.html#zero-inflated-outcomes",
    "href": "notebooks/zero_inflated_regression.html#zero-inflated-outcomes",
    "title": "Zero inflated models",
    "section": "Zero inflated outcomes",
    "text": "Zero inflated outcomes\nSometimes, an observation is not generated from a single process, but from a mixture of processes. Whenever there is a mixture of processes generating an observation, a mixture model may be more appropriate. A mixture model uses more than one probability distribution to model the data. Count data are more susceptible to needing a mixture model as it is common to have a large number of zeros and values greater than zero. A zero means “nothing happened”, and this can be either because the rate of events is low, or because the process that generates the events was never “triggered”. For example, in health service utilization data (the number of times a patient used a service during a given time period), a large number of zeros represents patients with no utilization during the time period. However, some patients do use a service which is a result of some “triggered process”.\nThere are two popular classes of models for modeling zero-inflated data: (1) ZIP, and (2) hurdle Poisson. First, the ZIP model is described and how to implement it in Bambi is outlined. Subsequently, the hurdle Poisson model and how to implement it is outlined thereafter.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Zero inflated models"
    ]
  },
  {
    "objectID": "notebooks/zero_inflated_regression.html#zero-inflated-poisson",
    "href": "notebooks/zero_inflated_regression.html#zero-inflated-poisson",
    "title": "Zero inflated models",
    "section": "Zero inflated Poisson",
    "text": "Zero inflated Poisson\nTo model zero-inflated outcomes, the ZIP model uses a distribution that mixes two data generating processes. The first process generates zeros, and the second process uses a Poisson distribution to generate counts (of which some may be zero). The result of this mixture is a distribution that can be described as\n\\[P(Y=0) = (1 - \\psi) + \\psi e^{-\\mu}\\]\n\\[P(Y=y_i) = \\psi \\frac{e^{-\\mu} \\mu_{i}^y}{y_{i}!} \\ \\text{for} \\ y_i = 1, 2, 3,...,n\\]\nwhere \\(y_i\\) is the outcome, \\(\\mu\\) is the mean of the Poisson process where \\(\\mu \\ge 0\\), and \\(\\psi\\) is the probability of the Poisson process where \\(0 \\lt \\psi \\lt 1\\). To understand how these two processes are “mixed”, let’s simulate some data using the two process equations above (taken from the PyMC docs).\n\nx = np.arange(0, 22)\npsis = [0.7, 0.4]\nmus = [10, 4]\nplt.figure(figsize=(7, 3))\nfor psi, mu in zip(psis, mus):\n    pmf = stats.poisson.pmf(x, mu)\n    pmf[0] = (1 - psi) + pmf[0] # 1.) generate zeros\n    pmf[1:] =  psi * pmf[1:] # 2.) generate counts\n    pmf /= pmf.sum() # normalize to get probabilities\n    plt.plot(x, pmf, '-o', label='$\\\\psi$ = {}, $\\\\mu$ = {}'.format(psi, mu))\n\nplt.title(\"Zero Inflated Poisson Process\")\nplt.xlabel('x', fontsize=12)\nplt.ylabel('f(x)', fontsize=12)\nplt.legend(loc=1)\nplt.show()\n\n\n\n\n\n\n\n\nNotice how the blue line, corresponding to a higher \\(\\psi\\) and \\(\\mu\\), has a higher rate of counts and less zeros. Additionally, the inline comments above describe the first and second process generating the data.\n\nZIP regression model\nThe equations above only describe the ZIP distribution. However, predictors can be added to make this a regression model. Suppose we have a response variable \\(Y\\), which represents the number of events that occur during a time period, and \\(p\\) predictors \\(X_1, X_2, ..., X_p\\). We can model the parameters of the ZIP distribution as a linear combination of the predictors.\n\\[Y_i \\sim \\text{ZIPoisson}(\\mu_i, \\psi_i)\\]\n\\[g(\\mu_i) = \\beta_0 + \\beta_1 X_{1i}+,...,+\\beta_p X_{pi}\\]\n\\[h(\\psi_i) = \\alpha_0 + \\alpha_1 X_{1i}+,...,+\\alpha_p X_{pi}\\]\nwhere \\(g\\) and \\(h\\) are the link functions for each parameter. Bambi, by default, uses the log link for \\(g\\) and the logit link for \\(h\\). Notice how there are two linear models and two link functions: one for each parameter in the \\(\\text{ZIPoisson}\\). The parameters of the linear model differ, because any predictor such as \\(X\\) may be associated differently with each part of the mixture. Actually, you don’t even need to use the same predictors in both linear models—but this beyond the scope of this notebook.\n\nThe fish dataset\nTo demonstrate the ZIP regression model, we model and predict how many fish are caught by visitors at a state park using survey data. Many visitors catch zero fish, either because they did not fish at all, or because they were unlucky. The dataset contains data on 250 groups that went to a state park to fish. Each group was questioned about how many fish they caught (count), how many children were in the group (child), how many people were in the group (persons), if they used a live bait (livebait) and whether or not they brought a camper to the park (camper).\n\nfish_data = pd.read_csv(\"https://stats.idre.ucla.edu/stat/data/fish.csv\")\ncols = [\"count\", \"livebait\", \"camper\", \"persons\", \"child\"]\nfish_data = fish_data[cols]\nfish_data[\"livebait\"] = pd.Categorical(fish_data[\"livebait\"])\nfish_data[\"camper\"] = pd.Categorical(fish_data[\"camper\"])\nfish_data = fish_data[fish_data[\"count\"] &lt; 60] # remove outliers\n\n\nfish_data.head()\n\n\n\n\n\n\n\n\ncount\nlivebait\ncamper\npersons\nchild\n\n\n\n\n0\n0\n0\n0\n1\n0\n\n\n1\n0\n1\n1\n1\n0\n\n\n2\n0\n1\n0\n1\n0\n\n\n3\n0\n1\n1\n2\n1\n\n\n4\n1\n1\n0\n1\n0\n\n\n\n\n\n\n\n\n# Excess zeros, and skewed count\nplt.figure(figsize=(7, 3))\nsns.histplot(fish_data[\"count\"], discrete=True)\nplt.xlabel(\"Number of Fish Caught\");\n\n\n\n\n\n\n\n\nTo fit a ZIP regression model, we pass family=zero_inflated_poisson to the bmb.Model constructor.\n\nzip_model = bmb.Model(\n    \"count ~ livebait + camper + persons + child\", \n    fish_data, \n    family='zero_inflated_poisson'\n)\n\nzip_idata = zip_model.fit(\n    draws=1000, \n    target_accept=0.95, \n    random_seed=1234, \n    chains=4\n)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 2 jobs)\nNUTS: [psi, Intercept, livebait, camper, persons, child]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 20 seconds.\n\n\nLets take a look at the model components. Why is there only one linear model and link function defined for \\(\\mu\\). Where is the linear model and link function for \\(\\psi\\)? By default, the “main” (or first) formula is defined for the parent parameter; in this case \\(\\mu\\). Since we didn’t pass an additional formula for the non-parent parameter \\(\\psi\\), \\(\\psi\\) was never modeled as a function of the predictors as explained above. If we want to model both \\(\\mu\\) and \\(\\psi\\) as a function of the predictor, we need to expicitly pass two formulas.\n\nzip_model\n\n       Formula: count ~ livebait + camper + persons + child\n        Family: zero_inflated_poisson\n          Link: mu = log\n  Observations: 248\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 0.0, sigma: 9.5283)\n            livebait ~ Normal(mu: 0.0, sigma: 7.2685)\n            camper ~ Normal(mu: 0.0, sigma: 5.0733)\n            persons ~ Normal(mu: 0.0, sigma: 2.2583)\n            child ~ Normal(mu: 0.0, sigma: 2.9419)\n        \n        Auxiliary parameters\n            psi ~ Beta(alpha: 2.0, beta: 2.0)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\n\nformula = bmb.Formula(\n    \"count ~ livebait + camper + persons + child\", # parent parameter mu\n    \"psi ~ livebait + camper + persons + child\"    # non-parent parameter psi\n)\n\nzip_model = bmb.Model(\n    formula, \n    fish_data, \n    family='zero_inflated_poisson'\n)\n\nzip_idata = zip_model.fit(\n    draws=1000, \n    target_accept=0.95, \n    random_seed=1234, \n    chains=4\n)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 2 jobs)\nNUTS: [Intercept, livebait, camper, persons, child, psi_Intercept, psi_livebait, psi_camper, psi_persons, psi_child]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 33 seconds.\n\n\n\nzip_model\n\n       Formula: count ~ livebait + camper + persons + child\n                psi ~ livebait + camper + persons + child\n        Family: zero_inflated_poisson\n          Link: mu = log\n                psi = logit\n  Observations: 248\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 0.0, sigma: 9.5283)\n            livebait ~ Normal(mu: 0.0, sigma: 7.2685)\n            camper ~ Normal(mu: 0.0, sigma: 5.0733)\n            persons ~ Normal(mu: 0.0, sigma: 2.2583)\n            child ~ Normal(mu: 0.0, sigma: 2.9419)\n    target = psi\n        Common-level effects\n            psi_Intercept ~ Normal(mu: 0.0, sigma: 1.0)\n            psi_livebait ~ Normal(mu: 0.0, sigma: 1.0)\n            psi_camper ~ Normal(mu: 0.0, sigma: 1.0)\n            psi_persons ~ Normal(mu: 0.0, sigma: 1.0)\n            psi_child ~ Normal(mu: 0.0, sigma: 1.0)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\nNow, both \\(\\mu\\) and \\(\\psi\\) are defined as a function of a linear combination of the predictors. Additionally, we can see that the log and logit link functions are defined for \\(\\mu\\) and \\(\\psi\\), respectively.\n\nzip_model.graph()\n\n\n\n\n\n\n\n\nSince each parameter has a different link function, and each parameter has a different meaning, we must be careful on how the coefficients are interpreted. Coefficients without the substring “psi” correspond to the \\(\\mu\\) parameter (the mean of the Poisson process) and are on the log scale. Coefficients with the substring “psi” correspond to the \\(\\psi\\) parameter (this can be thought of as the log-odds of non-zero data) and are on the logit scale. Interpreting these coefficients can be easier with the interpret sub-package. Below, we will show how to use this sub-package to interpret the coefficients conditional on a set of the predictors.\n\naz.summary(\n    zip_idata, \n    var_names=[\"Intercept\", \"livebait\", \"camper\", \"persons\", \"child\"], \n    filter_vars=\"like\"\n)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-1.571\n0.310\n-2.130\n-0.972\n0.005\n0.004\n3826.0\n3061.0\n1.0\n\n\ncamper[1]\n0.263\n0.096\n0.085\n0.440\n0.001\n0.001\n4945.0\n2708.0\n1.0\n\n\nchild\n-0.796\n0.094\n-0.971\n-0.625\n0.001\n0.001\n4007.0\n3480.0\n1.0\n\n\nlivebait[1]\n1.608\n0.268\n1.133\n2.141\n0.004\n0.003\n4350.0\n3330.0\n1.0\n\n\npersons\n0.615\n0.045\n0.533\n0.700\n0.001\n0.000\n4979.0\n3290.0\n1.0\n\n\npsi_Intercept\n-1.442\n0.832\n-2.978\n0.126\n0.013\n0.009\n4156.0\n3034.0\n1.0\n\n\npsi_camper[1]\n0.844\n0.328\n0.226\n1.450\n0.004\n0.003\n6631.0\n3075.0\n1.0\n\n\npsi_child\n-1.891\n0.306\n-2.467\n-1.305\n0.005\n0.004\n3872.0\n3070.0\n1.0\n\n\npsi_livebait[1]\n-0.197\n0.689\n-1.490\n1.078\n0.011\n0.011\n4177.0\n2772.0\n1.0\n\n\npsi_persons\n0.914\n0.193\n0.575\n1.297\n0.003\n0.002\n4081.0\n3110.0\n1.0\n\n\n\n\n\n\n\n\n\nInterpret model parameters\nSince we have fit a distributional model, we can leverage the plot_predictions() function in the interpret sub-package to visualize how the \\(\\text{ZIPoisson}\\) parameters \\(\\mu\\) and \\(\\psi\\) vary as a covariate changes.\n\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 3))\n\nbmb.interpret.plot_predictions(\n    zip_model,\n    zip_idata,\n    conditional=\"persons\",\n    ax=ax[0]\n)\nax[0].set_ylabel(\"mu (fish count)\")\nax[0].set_title(\"$\\\\mu$ as a function of persons\")\n\nbmb.interpret.plot_predictions(\n    zip_model,\n    zip_idata,\n    conditional=\"persons\",\n    target=\"psi\",\n    ax=ax[1]\n)\nax[1].set_title(\"$\\\\psi$ as a function of persons\");\n\nDefault computed for conditional variable: persons\nDefault computed for unspecified variable: camper, child, livebait\nDefault computed for conditional variable: persons\nDefault computed for unspecified variable: camper, child, livebait\n\n\n\n\n\n\n\n\n\nInterpreting the left plot (the \\(\\mu\\) parameter) as the number of people in a group fishing increases, so does the number of fish caught. The right plot (the \\(\\psi\\) parameter) shows that as the number of people in a group fishing increases, the probability of the Poisson process increases. One interpretation of this is that as the number of people in a group increases, the probability of catching no fish decreases.\n\n\nPosterior predictive distribution\nLastly, lets plot the posterior predictive distribution against the observed data to see how well the model fits the data. To plot the samples, a utility function is defined below to assist in the plotting of discrete values.\n\ndef adjust_lightness(color, amount=0.5):\n    import matplotlib.colors as mc\n    import colorsys\n    try:\n        c = mc.cnames[color]\n    except:\n        c = color\n    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n    return colorsys.hls_to_rgb(c[0], c[1] * amount, c[2])\n\ndef plot_ppc_discrete(idata, bins, ax):\n    \n    def add_discrete_bands(x, lower, upper, ax, **kwargs):\n        for i, (l, u) in enumerate(zip(lower, upper)):\n            s = slice(i, i + 2)\n            ax.fill_between(x[s], [l, l], [u, u], **kwargs)\n\n    var_name = list(idata.observed_data.data_vars)[0]\n    y_obs = idata.observed_data[var_name].to_numpy()\n    \n    counts_list = []\n    for draw_values in az.extract(idata, \"posterior_predictive\")[var_name].to_numpy().T:\n        counts, _ = np.histogram(draw_values, bins=bins)\n        counts_list.append(counts)\n    counts_arr = np.stack(counts_list)\n\n    qts_90 = np.quantile(counts_arr, (0.05, 0.95), axis=0)\n    qts_70 = np.quantile(counts_arr, (0.15, 0.85), axis=0)\n    qts_50 = np.quantile(counts_arr, (0.25, 0.75), axis=0)\n    qts_30 = np.quantile(counts_arr, (0.35, 0.65), axis=0)\n    median = np.quantile(counts_arr, 0.5, axis=0)\n\n    colors = [adjust_lightness(\"C0\", x) for x in [1.8, 1.6, 1.4, 1.2, 0.9]]\n\n    add_discrete_bands(bins, qts_90[0], qts_90[1], ax=ax, color=colors[0])\n    add_discrete_bands(bins, qts_70[0], qts_70[1], ax=ax, color=colors[1])\n    add_discrete_bands(bins, qts_50[0], qts_50[1], ax=ax, color=colors[2])\n    add_discrete_bands(bins, qts_30[0], qts_30[1], ax=ax, color=colors[3])\n\n    \n    ax.step(bins[:-1], median, color=colors[4], lw=2, where=\"post\")\n    ax.hist(y_obs, bins=bins, histtype=\"step\", lw=2, color=\"black\", align=\"mid\")\n    handles = [\n        Line2D([], [], label=\"Observed data\", color=\"black\", lw=2),\n        Line2D([], [], label=\"Posterior predictive median\", color=colors[4], lw=2)\n    ]\n    ax.legend(handles=handles)\n    return ax\n\n\nzip_pps = zip_model.predict(idata=zip_idata, kind=\"response\", inplace=False)\n\nbins = np.arange(39)\nfig, ax = plt.subplots(figsize=(7, 3))\nax = plot_ppc_discrete(zip_pps, bins, ax)\nax.set_xlabel(\"Number of Fish Caught\")\nax.set_ylabel(\"Count\")\nax.set_title(\"ZIP model - Posterior Predictive Distribution\");\n\n\n\n\n\n\n\n\nThe model captures the number of zeros accurately. However, the model seems to slightly underestimate the counts 1 and 2. Nonetheless, the plot shows that the model captures the overall distribution of counts reasonably well.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Zero inflated models"
    ]
  },
  {
    "objectID": "notebooks/zero_inflated_regression.html#hurdle-poisson",
    "href": "notebooks/zero_inflated_regression.html#hurdle-poisson",
    "title": "Zero inflated models",
    "section": "Hurdle Poisson",
    "text": "Hurdle Poisson\nBoth ZIP and hurdle models both use two processes to generate data. The two models differ in their conceptualization of how the zeros are generated. In \\(\\text{ZIPoisson}\\), the zeroes can come from any of the processes, while in the hurdle Poisson they come only from one of the processes. Thus, a hurdle model assumes zero and positive values are generated from two independent processes. In the hurdle model, there are two components: (1) a “structural” process such as a binary model for modeling whether the response variable is zero or not, and (2) a process using a truncated model such as a truncated Poisson for modeling the counts. The result of these two components is a distribution that can be described as\n\\[P(Y=0) = 1 - \\psi\\]\n\\[P(Y=y_i) = \\psi \\frac{e^{-\\mu_i}\\mu_{i}^{y_i} / y_i!}{1 - e^{-\\mu_i}} \\ \\text{for} \\ y_i = 1, 2, 3,...,n\\]\nwhere \\(y_i\\) is the outcome, \\(\\mu\\) is the mean of the Poisson process where \\(\\mu \\ge 0\\), and \\(\\psi\\) is the probability of the Poisson process where \\(0 \\lt \\psi \\lt 1\\). The numerator of the second equation is the Poisson probability mass function, and the denominator is one minus the Poisson cumulative distribution function. This is a lot to digest. Again, let’s simulate some data to understand how data is generated from this process.\n\nx = np.arange(0, 22)\npsis = [0.7, 0.4]\nmus = [10, 4]\n\nplt.figure(figsize=(7, 3))\nfor psi, mu in zip(psis, mus):\n    pmf = stats.poisson.pmf(x, mu) # pmf evaluated at x given mu\n    cdf = stats.poisson.cdf(0, mu) # cdf evaluated at 0 given mu\n    pmf[0] = 1 - psi # 1.) generate zeros\n    pmf[1:] =  (psi * pmf[1:]) / (1 - cdf) # 2.) generate counts\n    pmf /= pmf.sum() # normalize to get probabilities\n    plt.plot(x, pmf, '-o', label='$\\\\psi$ = {}, $\\\\mu$ = {}'.format(psi, mu))\n\nplt.title(\"Hurdle Poisson Process\")\nplt.xlabel('x', fontsize=12)\nplt.ylabel('f(x)', fontsize=12)\nplt.legend(loc=1)\nplt.show()\n\n\n\n\n\n\n\n\nThe differences between the ZIP and hurdle models are subtle. Notice how in the code for the hurdle Poisson process, the zero counts are generate by (1 - psi) versus (1 - psi) + pmf[0] for the ZIP process. Additionally, the positive observations are generated by the process (psi * pmf[1:]) / (1 - cdf) where the numerator is a vector of probabilities for positive counts scaled by \\(\\psi\\) and the denominator uses the Poisson cumulative distribution function to evaluate the probability a count is greater than 0.\n\nHurdle regression model\nTo add predictors in the hurdle model, we follow the same specification as in the ZIP regression model section since both models have the same structure. The only difference is that the hurdle model uses a truncated Poisson distribution instead of a ZIP distribution. Right away, we will model both the parent and non-parent parameter as a function of the predictors.\n\nhurdle_formula = bmb.Formula(\n    \"count ~ livebait + camper + persons + child\", # parent parameter mu\n    \"psi ~ livebait + camper + persons + child\"    # non-parent parameter psi\n)\n\nhurdle_model = bmb.Model(\n    hurdle_formula, \n    fish_data, \n    family='hurdle_poisson'\n)\n\nhurdle_idata = hurdle_model.fit(\n    draws=1000, \n    target_accept=0.95, \n    random_seed=1234, \n    chains=4\n)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 2 jobs)\nNUTS: [Intercept, livebait, camper, persons, child, psi_Intercept, psi_livebait, psi_camper, psi_persons, psi_child]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 42 seconds.\n\n\n\nhurdle_model\n\n       Formula: count ~ livebait + camper + persons + child\n                psi ~ livebait + camper + persons + child\n        Family: hurdle_poisson\n          Link: mu = log\n                psi = logit\n  Observations: 248\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 0.0, sigma: 9.5283)\n            livebait ~ Normal(mu: 0.0, sigma: 7.2685)\n            camper ~ Normal(mu: 0.0, sigma: 5.0733)\n            persons ~ Normal(mu: 0.0, sigma: 2.2583)\n            child ~ Normal(mu: 0.0, sigma: 2.9419)\n    target = psi\n        Common-level effects\n            psi_Intercept ~ Normal(mu: 0.0, sigma: 1.0)\n            psi_livebait ~ Normal(mu: 0.0, sigma: 1.0)\n            psi_camper ~ Normal(mu: 0.0, sigma: 1.0)\n            psi_persons ~ Normal(mu: 0.0, sigma: 1.0)\n            psi_child ~ Normal(mu: 0.0, sigma: 1.0)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\n\nhurdle_model.graph()\n\n\n\n\n\n\n\n\nAs the same link functions are used for ZIP and Hurdle model, the coefficients can be interpreted in a similar manner.\n\naz.summary(\n    hurdle_idata,\n    var_names=[\"Intercept\", \"livebait\", \"camper\", \"persons\", \"child\"], \n    filter_vars=\"like\"\n)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-1.615\n0.363\n-2.278\n-0.915\n0.006\n0.005\n3832.0\n2121.0\n1.0\n\n\ncamper[1]\n0.271\n0.100\n0.073\n0.449\n0.001\n0.001\n6843.0\n2934.0\n1.0\n\n\nchild\n-0.791\n0.094\n-0.970\n-0.618\n0.001\n0.001\n4371.0\n3006.0\n1.0\n\n\nlivebait[1]\n1.661\n0.329\n1.031\n2.273\n0.005\n0.004\n4149.0\n1871.0\n1.0\n\n\npersons\n0.610\n0.045\n0.533\n0.700\n0.001\n0.000\n4848.0\n3196.0\n1.0\n\n\npsi_Intercept\n-2.780\n0.583\n-3.906\n-1.715\n0.008\n0.006\n4929.0\n3258.0\n1.0\n\n\npsi_camper[1]\n0.849\n0.298\n0.283\n1.378\n0.004\n0.003\n5523.0\n2855.0\n1.0\n\n\npsi_child\n-2.003\n0.282\n-2.555\n-1.517\n0.004\n0.003\n4021.0\n3183.0\n1.0\n\n\npsi_livebait[1]\n0.764\n0.427\n-0.067\n1.557\n0.006\n0.005\n5721.0\n2779.0\n1.0\n\n\npsi_persons\n1.040\n0.183\n0.719\n1.396\n0.003\n0.002\n3852.0\n3007.0\n1.0\n\n\n\n\n\n\n\n\nPosterior predictive samples\nAs with the ZIP model above, we plot the posterior predictive distribution against the observed data to see how well the model fits the data.\n\nhurdle_pps = hurdle_model.predict(idata=hurdle_idata, kind=\"response\", inplace=False)\n\nbins = np.arange(39)\nfig, ax = plt.subplots(figsize=(7, 3))\nax = plot_ppc_discrete(hurdle_pps, bins, ax)\nax.set_xlabel(\"Number of Fish Caught\")\nax.set_ylabel(\"Count\")\nax.set_title(\"Hurdle Model - Posterior Predictive Distribution\");\n\n\n\n\n\n\n\n\nThe plot looks similar to the ZIP model above. Nonetheless, the plot shows that the model captures the overall distribution of counts reasonably well.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Zero inflated models"
    ]
  },
  {
    "objectID": "notebooks/zero_inflated_regression.html#summary",
    "href": "notebooks/zero_inflated_regression.html#summary",
    "title": "Zero inflated models",
    "section": "Summary",
    "text": "Summary\nIn this notebook, two classes of models (ZIP and hurdle Poisson) for modeling zero-inflated data were presented and implemented in Bambi. The difference of the data generating process between the two models differ in how zeros are generated. The ZIP model uses a distribution that mixes two data generating processes. The first process generates zeros, and the second process uses a Poisson distribution to generate counts (of which some may be zero). The hurdle Poisson also uses two data generating processes, but doesn’t “mix” them. A process is used for generating zeros such as a binary model for modeling whether the response variable is zero or not, and a second process for modeling the counts. These two proceses are independent of each other.\nThe dataset used to demonstrate the two models had a large number of zeros. These zeros appeared because the group doesn’t fish, or because they fished, but caught zero fish. Because zeros could be generated due to two different reasons, the ZIP model, which allows zeros to be generated from a mixture of processes, seems to be more appropriate for this datset.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sun May 26 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\narviz     : 0.18.0\nscipy     : 1.13.0\nseaborn   : 0.13.2\nbambi     : 0.13.1.dev39+gb7d6a6cb\nnumpy     : 1.26.4\nmatplotlib: 3.8.4\npandas    : 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Zero inflated models"
    ]
  },
  {
    "objectID": "notebooks/test_sample_new_groups.html",
    "href": "notebooks/test_sample_new_groups.html",
    "title": "Bambi",
    "section": "",
    "text": "NOTE This notebook is not part of the documentation. It’s not meant to be in the webpage. It’s something I wrote when I was testing the new functionality and I think it’s nice to have it handy.\n\nimport arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\ndata = bmb.load_data(\"sleepstudy\")\n\n\ndata.head()\n\n\n\n\n\n\n\n\nReaction\nDays\nSubject\n\n\n\n\n0\n249.5600\n0\n308\n\n\n1\n258.7047\n1\n308\n\n\n2\n250.8006\n2\n308\n\n\n3\n321.4398\n3\n308\n\n\n4\n356.8519\n4\n308\n\n\n\n\n\n\n\n\nmodel = bmb.Model(\"Reaction ~ 1 + Days + (1 + Days | Subject)\", data)\nmodel\n\n       Formula: Reaction ~ 1 + Days + (1 + Days | Subject)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 180\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 298.5079, sigma: 261.0092)\n            Days ~ Normal(mu: 0.0, sigma: 48.8915)\n        \n        Group-level effects\n            1|Subject ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 261.0092))\n            Days|Subject ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 48.8915))\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 56.1721)\n\n\n\nidata = model.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [Reaction_sigma, Intercept, Days, 1|Subject_sigma, 1|Subject_offset, Days|Subject_sigma, Days|Subject_offset]\n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:15&lt;00:00 Sampling 2 chains, 0 divergences]\n    \n    \n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 15 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\ndf_new = data.head(10).reset_index(drop=True)\ndf_new[\"Subject\"] = \"xxx\"\ndf_new = pd.concat([df_new, data.head(10)])\ndf_new = df_new.reset_index(drop=True)\ndf_new\n\n\n\n\n\n\n\n\nReaction\nDays\nSubject\n\n\n\n\n0\n249.5600\n0\nxxx\n\n\n1\n258.7047\n1\nxxx\n\n\n2\n250.8006\n2\nxxx\n\n\n3\n321.4398\n3\nxxx\n\n\n4\n356.8519\n4\nxxx\n\n\n5\n414.6901\n5\nxxx\n\n\n6\n382.2038\n6\nxxx\n\n\n7\n290.1486\n7\nxxx\n\n\n8\n430.5853\n8\nxxx\n\n\n9\n466.3535\n9\nxxx\n\n\n10\n249.5600\n0\n308\n\n\n11\n258.7047\n1\n308\n\n\n12\n250.8006\n2\n308\n\n\n13\n321.4398\n3\n308\n\n\n14\n356.8519\n4\n308\n\n\n15\n414.6901\n5\n308\n\n\n16\n382.2038\n6\n308\n\n\n17\n290.1486\n7\n308\n\n\n18\n430.5853\n8\n308\n\n\n19\n466.3535\n9\n308\n\n\n\n\n\n\n\n\np = model.predict(idata, data=df_new, inplace=False, sample_new_groups=True)\n\nreaction_draws = p.posterior[\"Reaction_mean\"]\nmean = reaction_draws.mean((\"chain\", \"draw\")).to_numpy()\nbounds = reaction_draws.quantile((0.025, 0.975), (\"chain\", \"draw\")).to_numpy()\n\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n\naxes[0].scatter(df_new.iloc[10:][\"Days\"], df_new.iloc[10:][\"Reaction\"])\naxes[1].scatter(df_new.iloc[:10][\"Days\"], df_new.iloc[:10][\"Reaction\"])\n\naxes[0].fill_between(np.arange(10), bounds[0, 10:], bounds[1, 10:], alpha=0.5, color=\"C0\")\naxes[1].fill_between(np.arange(10), bounds[0, :10], bounds[1, :10], alpha=0.5, color=\"C0\")\n\naxes[0].set_title(\"Original participant\")\naxes[1].set_title(\"New participant\");\n\n\n\n\n\n\n\n\n\n\ndata = pd.read_csv(\"../../tests/data/crossed_random.csv\")\ndata[\"subj\"] = data[\"subj\"].astype(str)\ndata.head()\n\n\n\n\n\n\n\n\nUnnamed: 0\nsubj\nitem\nsite\nY\ncontinuous\ndummy\nthreecats\n\n\n\n\n0\n0\n0\n0\n0\n0.276766\n0.929616\n0\na\n\n\n1\n1\n1\n0\n0\n-0.058104\n0.008388\n0\na\n\n\n2\n2\n2\n0\n1\n-6.847861\n0.439645\n0\na\n\n\n3\n3\n3\n0\n1\n12.474619\n0.596366\n0\na\n\n\n4\n4\n4\n0\n2\n-0.426047\n0.709510\n0\na\n\n\n\n\n\n\n\n\nformula = \"Y ~ 0 + threecats + (0 + threecats | subj)\"\nmodel = bmb.Model(formula, data)\nmodel\n\n       Formula: Y ~ 0 + threecats + (0 + threecats | subj)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 120\n        Priors: \n    target = mu\n        Common-level effects\n            threecats ~ Normal(mu: [0. 0. 0.], sigma: [31.1617 31.1617 31.1617])\n        \n        Group-level effects\n            threecats|subj ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: [31.1617 31.1617 31.1617]))\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 5.8759)\n\n\n\nidata = model.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [Y_sigma, threecats, threecats|subj_sigma, threecats|subj_offset]\n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:08&lt;00:00 Sampling 2 chains, 0 divergences]\n    \n    \n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 8 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\nnew_data = pd.DataFrame(\n    {\n        \"threecats\": [\"a\", \"a\"],\n        \"subj\": [\"0\", \"11\"]\n    }\n)\nnew_data\n\n\n\n\n\n\n\n\nthreecats\nsubj\n\n\n\n\n0\na\n0\n\n\n1\na\n11\n\n\n\n\n\n\n\n\np1 = model.predict(idata, data=new_data, inplace=False, sample_new_groups=True)\n\n\nfig, axes = plt.subplots(2, 1, figsize=(7, 9), sharex=True)\n\ny1_grs = p1.posterior[\"Y_mean\"].sel(Y_obs=0).to_numpy().flatten()\ny2_grs = p1.posterior[\"Y_mean\"].sel(Y_obs=1).to_numpy().flatten()\n\naxes[0].hist(y1_grs, bins=20);\naxes[1].hist(y2_grs, bins=20);\n\n\n\n\n\n\n\n\n\n\ninhaler = pd.read_csv(\"../../tests/data/inhaler.csv\")\ninhaler[\"rating\"] = pd.Categorical(inhaler[\"rating\"], categories=[1, 2, 3, 4])\ninhaler[\"treat\"] = pd.Categorical(inhaler[\"treat\"])\n\nmodel = bmb.Model(\n    \"rating ~ 1 + period + treat + (1 + treat|subject)\", inhaler, family=\"categorical\"\n)\nidata = model.fit(tune=200, draws=200)\n\nOnly 200 samples in chain.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [Intercept, period, treat, 1|subject_sigma, 1|subject_offset, treat|subject_sigma, treat|subject_offset]\n\n\n\n\n\n\n\n    \n      \n      100.00% [800/800 00:11&lt;00:00 Sampling 2 chains, 1 divergences]\n    \n    \n\n\nSampling 2 chains for 200 tune and 200 draw iterations (400 + 400 draws total) took 12 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\ndf_new = inhaler.head(2).reset_index(drop=True)\ndf_new[\"subject\"] = [1, 999]\ndf_new\n\n\n\n\n\n\n\n\nsubject\nrating\ntreat\nperiod\ncarry\n\n\n\n\n0\n1\n1\n0.5\n0.5\n0\n\n\n1\n999\n1\n0.5\n0.5\n0\n\n\n\n\n\n\n\n\np = model.predict(idata, data=df_new, inplace=False, sample_new_groups=True)\n\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 9))\nbins = np.linspace(0, 1, 20)\n\nfor i, ax in enumerate(axes.ravel()):\n    x = p.posterior[\"rating_mean\"].sel({\"rating_dim\": f'{i + 1}'}).to_numpy()\n    ax.hist(x[..., 0].flatten(), bins=bins, histtype=\"step\", color=\"C0\")\n    ax.hist(x[..., 1].flatten(), bins=bins, histtype=\"step\", color=\"C1\")"
  },
  {
    "objectID": "notebooks/t-test.html",
    "href": "notebooks/t-test.html",
    "title": "Comparison of two means (T-test)",
    "section": "",
    "text": "import arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\naz.style.use(\"arviz-darkgrid\")\nnp.random.seed(1234)\nIn this notebook we demo two equivalent ways of performing a two-sample Bayesian t-test to compare the mean value of two Gaussian populations using Bambi.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Comparison of two means (T-test)"
    ]
  },
  {
    "objectID": "notebooks/t-test.html#generate-data",
    "href": "notebooks/t-test.html#generate-data",
    "title": "Comparison of two means (T-test)",
    "section": "Generate data",
    "text": "Generate data\nWe generate 160 values from a Gaussian with \\(\\mu=6\\) and \\(\\sigma=2.5\\) and another 120 values from a Gaussian’ with \\(\\mu=8\\) and \\(\\sigma=2\\)\n\na = np.random.normal(6, 2.5, 160)\nb = np.random.normal(8, 2, 120)\ndf = pd.DataFrame({\"Group\": [\"a\"] * 160 + [\"b\"] * 120, \"Val\": np.hstack([a, b])})\n\n\ndf.head()\n\n\n\n\n\n\n\n\nGroup\nVal\n\n\n\n\n0\na\n7.178588\n\n\n1\na\n3.022561\n\n\n2\na\n9.581767\n\n\n3\na\n5.218370\n\n\n4\na\n4.198528\n\n\n\n\n\n\n\n\naz.plot_violin({\"a\": a, \"b\": b});\n\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/arviz/plots/backends/matplotlib/violinplot.py:65: UserWarning: This figure was using a layout engine that is incompatible with subplots_adjust and/or tight_layout; not calling subplots_adjust.\n  fig.subplots_adjust(wspace=0)\n\n\n\n\n\n\n\n\n\nWhen we carry out a two sample t-test we are implicitly using a linear model that can be specified in different ways. One of these approaches is the following:\n\nModel 1\n\\[\n\\mu_i = \\beta_0 + \\beta_1 (i) + \\epsilon_i\n\\]\nwhere \\(i = 0\\) represents the population 1, \\(i = 1\\) the population 2 and \\(\\epsilon_i\\) is a random error with mean 0. If we replace the indicator variables for the two groups we have\n\\[\n\\mu_0 = \\beta_0 + \\epsilon_i\n\\]\nand\n\\[\n\\mu_1 = \\beta_0 + \\beta_1 + \\epsilon_i\n\\]\nif \\(\\mu_0 = \\mu_1\\) then\n\\[\n\\beta_0 + \\epsilon_i = \\beta_0 + \\beta_1 + \\epsilon_i\\\\\n\\] \\[\n\\beta_1 = 0\n\\]\nThus, we can see that testing whether the mean of the two populations are equal is equivalent to testing whether \\(\\beta_1\\) is 0.\n\n\nAnalysis\nWe start by instantiating our model and specifying the model previously described.\n\nmodel_1 = bmb.Model(\"Val ~ Group\", df)\nresults_1 = model_1.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, Group]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 2 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nWe’ve only specified the formula for the model and Bambi automatically selected priors distributions and values for their parameters. We can inspect both the setup and the priors as following:\n\nmodel_1\n\n       Formula: Val ~ Group\n        Family: gaussian\n          Link: mu = identity\n  Observations: 280\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 6.9762, sigma: 8.1247)\n            Group ~ Normal(mu: 0.0, sigma: 12.4107)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 2.4567)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\n\nmodel_1.plot_priors();\n\nSampling: [Group, Intercept, sigma]\n\n\n\n\n\n\n\n\n\nTo inspect our posterior and the sampling process we can call az.plot_trace(). The option kind='rank_vlines' gives us a variant of the rank plot that uses lines and dots and helps us to inspect the stationarity of the chains. Since there is no clear pattern or serious deviations from the horizontal lines, we can conclude the chains are stationary.\n\n\naz.plot_trace(results_1, kind=\"rank_vlines\");\n\n\n\n\n\n\n\n\n\naz.summary(results_1)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nGroup[b]\n2.004\n0.265\n1.548\n2.512\n0.005\n0.003\n3036.0\n1618.0\n1.0\n\n\nIntercept\n6.117\n0.180\n5.777\n6.459\n0.003\n0.002\n3049.0\n1512.0\n1.0\n\n\nsigma\n2.265\n0.096\n2.087\n2.444\n0.002\n0.001\n3570.0\n1662.0\n1.0\n\n\n\n\n\n\n\nIn the summary table we can see the 94% highest density interval for \\(\\beta_1\\) ranges from 1.511 to 2.499. Thus, according to the data and the model used, we conclude the difference between the two population means is somewhere between 1.2 and 2.2 and hence we support the hypotehsis that \\(\\beta_1 \\ne 0\\).\nSimilar conclusions can be made with the density estimate for the posterior distribution of \\(\\beta_1\\). As seen in the table, most of the probability for the difference in the mean roughly ranges from 1.2 to 2.2.\n\naz.plot_posterior(results_1, var_names=\"Group\", ref_val=0);\n\n\n\n\n\n\n\n\nAnother way to arrive to a similar conclusion is by calculating the probability that the parameter \\(\\beta_1 &gt; 0\\). This probability is equal to 1, telling us that the mean of the two populations are different.\n\n# Probabiliy that posterior is &gt; 0\n(results_1.posterior[\"Group\"] &gt; 0).mean().item()\n\n1.0\n\n\nThe linear model implicit in the t-test can also be specified without an intercept term, such is the case of Model 2.\n\n\nModel 2\nWhen we carry out a two sample t-test we’re implicitly using the following model:\n\\[\n\\mu_i = \\beta_i + \\epsilon_i\n\\]\nwhere \\(i = 0\\) represents the population 1, \\(i = 1\\) the population 2 and \\(\\epsilon\\) is a random error with mean 0. If we replace the indicator variables for the two groups we have\n\\[\n\\mu_0 = \\beta_0 + \\epsilon\n\\]\nand\n\\[\n\\mu_1 = \\beta_1 + \\epsilon\n\\]\nif \\(\\mu_0 = \\mu_1\\) then\n\\[\n\\beta_0 + \\epsilon = \\beta_1 + \\epsilon\\\\\n\\]\nThus, we can see that testing whether the mean of the two populations are equal is equivalent to testing whether \\(\\beta_0 = \\beta_1\\).\n\n\nAnalysis\nWe start by instantiating our model and specifying the model previously described. In this model we will bypass the intercept that Bambi adds by default by setting it to zero, even though setting to -1 has the same effect.\n\nmodel_2 = bmb.Model(\"Val ~ 0 + Group\", df)\nresults_2 = model_2.fit() \n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Group]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 2 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nWe’ve only specified the formula for the model and Bambi automatically selected priors distributions and values for their parameters. We can inspect both the setup and the priors as following:\n\nmodel_2\n\n       Formula: Val ~ 0 + Group\n        Family: gaussian\n          Link: mu = identity\n  Observations: 280\n        Priors: \n    target = mu\n        Common-level effects\n            Group ~ Normal(mu: [0. 0.], sigma: [12.4107 12.4107])\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 2.4567)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\n\nmodel_2.plot_priors();\n\nSampling: [Group, sigma]\n\n\n\n\n\n\n\n\n\nTo inspect our posterior and the sampling process we can call az.plot_trace(). The option kind='rank_vlines' gives us a variant of the rank plot that uses lines and dots and helps us to inspect the stationarity of the chains. Since there is no clear pattern or serious deviations from the horizontal lines, we can conclude the chains are stationary.\n\n\naz.plot_trace(results_2, kind=\"rank_vlines\");\n\n\n\n\n\n\n\n\n\naz.summary(results_2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nGroup[a]\n6.124\n0.177\n5.778\n6.431\n0.003\n0.002\n2735.0\n1407.0\n1.00\n\n\nGroup[b]\n8.115\n0.203\n7.708\n8.474\n0.004\n0.003\n3086.0\n1621.0\n1.00\n\n\nsigma\n2.265\n0.099\n2.075\n2.437\n0.002\n0.001\n2884.0\n1630.0\n1.01\n\n\n\n\n\n\n\nIn this summary we can observe the estimated distribution of means for each population. A simple way to compare them is subtracting one to the other. In the next plot we can se that the entirety of the distribution of differences is higher than zero and that the mean of population 2 is higher than the mean of population 1 by a mean of 2.\n\npost_group = results_2.posterior[\"Group\"]\ndiff = post_group.sel(Group_dim=\"b\") - post_group.sel(Group_dim=\"a\") \naz.plot_posterior(diff, ref_val=0);\n\n\n\n\n\n\n\n\nAnother way to arrive to a similar conclusion is by calculating the probability that the parameter \\(\\beta_1 - \\beta_0 &gt; 0\\). This probability equals to 1, telling us that the mean of the two populations are different.\n\n# Probabiliy that posterior is &gt; 0\n(post_group &gt; 0).mean().item()\n\n1.0\n\n\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sat May 25 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\npandas    : 2.2.2\nmatplotlib: 3.8.4\narviz     : 0.18.0\nbambi     : 0.13.1.dev37+g2a54df76.d20240525\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Comparison of two means (T-test)"
    ]
  },
  {
    "objectID": "notebooks/splines_cherry_blossoms.html",
    "href": "notebooks/splines_cherry_blossoms.html",
    "title": "Regression splines (Cherry blossom example)",
    "section": "",
    "text": "This example shows how to specify and fit a spline regression in Bambi. This example is based on this example from the PyMC docs.\nimport arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\naz.style.use(\"arviz-darkgrid\")\nSEED = 7355608",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Regression splines (Cherry blossom example)"
    ]
  },
  {
    "objectID": "notebooks/splines_cherry_blossoms.html#load-cherry-blossom-data",
    "href": "notebooks/splines_cherry_blossoms.html#load-cherry-blossom-data",
    "title": "Regression splines (Cherry blossom example)",
    "section": "Load Cherry Blossom data",
    "text": "Load Cherry Blossom data\nRichard McElreath popularized the Cherry Blossom dataset in the second edition of his excellent book Statistical Rethinking. This data represents the day in the year when the first bloom is observed for Japanese cherry blossoms between years 801 and 2015. In his book, Richard McElreath uses this dataset to introduce Basis Splines, or B-Splines in short.\nHere we use Bambi to fit a linear model using B-Splines with the Cherry Blossom data. This dataset can be loaded with Bambi as follows:\n\ndata = bmb.load_data(\"cherry_blossoms\")\ndata\n\n\n\n\n\n\n\n\nyear\ndoy\ntemp\ntemp_upper\ntemp_lower\n\n\n\n\n0\n801\nNaN\nNaN\nNaN\nNaN\n\n\n1\n802\nNaN\nNaN\nNaN\nNaN\n\n\n2\n803\nNaN\nNaN\nNaN\nNaN\n\n\n3\n804\nNaN\nNaN\nNaN\nNaN\n\n\n4\n805\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n\n\n1210\n2011\n99.0\nNaN\nNaN\nNaN\n\n\n1211\n2012\n101.0\nNaN\nNaN\nNaN\n\n\n1212\n2013\n93.0\nNaN\nNaN\nNaN\n\n\n1213\n2014\n94.0\nNaN\nNaN\nNaN\n\n\n1214\n2015\n93.0\nNaN\nNaN\nNaN\n\n\n\n\n1215 rows × 5 columns\n\n\n\nThe variable we are interested in modeling is \"doy\", which stands for Day of Year. Also notice this variable contains several missing value which are discarded next.\n\ndata = data.dropna(subset=[\"doy\"]).reset_index(drop=True)\ndata.shape\n\n(827, 5)",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Regression splines (Cherry blossom example)"
    ]
  },
  {
    "objectID": "notebooks/splines_cherry_blossoms.html#explore-the-data",
    "href": "notebooks/splines_cherry_blossoms.html#explore-the-data",
    "title": "Regression splines (Cherry blossom example)",
    "section": "Explore the data",
    "text": "Explore the data\nLet’s get started by creating a scatterplot to explore the values of \"doy\" for each year in the dataset.\n\n# We create a function because this plot is going to be used again later\ndef plot_scatter(data, figsize=(10, 6)):\n    _, ax = plt.subplots(figsize=figsize)\n    ax.scatter(data[\"year\"], data[\"doy\"], alpha=0.4, s=30)\n    ax.set_title(\"Day of the first bloom per year\")\n    ax.set_xlabel(\"Year\")\n    ax.set_ylabel(\"Days of the first bloom\")\n    return ax\n\n\nplot_scatter(data);\n\n\n\n\n\n\n\n\nWe can observe the day of the first bloom ranges between 85 and 125 approximately, which correspond to late March and early May respectively. On average, the first bloom occurs on the 105th day of the year, which is middle April.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Regression splines (Cherry blossom example)"
    ]
  },
  {
    "objectID": "notebooks/splines_cherry_blossoms.html#determine-knots",
    "href": "notebooks/splines_cherry_blossoms.html#determine-knots",
    "title": "Regression splines (Cherry blossom example)",
    "section": "Determine knots",
    "text": "Determine knots\nThe spline will have 15 knots. These knots are the boundaries of the basis functions. These knots split the range of the \"year\" variable into 16 contiguous sections. The basis functions make up a piecewise continuous polynomial, and so they are enforced to meet at the knots. We use the default degree for each piecewise polynomial, which is 3. The result is known as a cubic spline.\nBecause of using quantiles and not having observations for all the years in the time window under study, the knots are distributed unevenly over the range of \"year\" in such a way that the same proportion of values fall between each section.\n\nnum_knots = 15\nknots = np.quantile(data[\"year\"], np.linspace(0, 1, num_knots))\n\n\ndef plot_knots(knots, ax):\n    for knot in knots:\n        ax.axvline(knot, color=\"0.1\", alpha=0.4)\n    return ax\n\n\nax = plot_scatter(data)\nplot_knots(knots, ax);\n\n\n\n\n\n\n\n\nThe previous chart makes it easy to see the knots, represented by the vertical lines, are spaced unevenly over the years.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Regression splines (Cherry blossom example)"
    ]
  },
  {
    "objectID": "notebooks/splines_cherry_blossoms.html#the-model",
    "href": "notebooks/splines_cherry_blossoms.html#the-model",
    "title": "Regression splines (Cherry blossom example)",
    "section": "The model",
    "text": "The model\nThe B-spline model we are about to create is simply a linear regression model with synthetic predictor variables. These predictors are the basis functions that are derived from the original year predictor.\nIn math notation, we usa a \\(\\text{Normal}\\) distribution for the conditional distribution of \\(Y\\) when \\(X = x_i\\), i.e. \\(Y_i\\), the distribution of the day of the first bloom in a given year.\n\\[\nY_i \\sim \\text{Normal}(\\mu_i, \\sigma)\n\\]\nSo far, this looks like a regular linear regression model. The next line is where the spline comes into play:\n\\[\n\\mu_i = \\alpha + \\sum_{k=1}^K{w_kB_{k, i}}\n\\]\nThe line above tells that for each observation \\(i\\), the mean is influenced by all the basis functions (going from \\(k=1\\) to \\(k=K\\)), plus an intercept \\(\\alpha\\). The \\(w_k\\) values in the summation are the regression coefficients of each of the basis functions, and the \\(B_k\\) are the values of the basis functions.\nFinally, we will be using the following priors\n\\[\n\\begin{aligned}\n\\alpha & \\sim \\text{Normal}(100, 10) \\\\\nw_j & \\sim \\text{Normal}(0, 10)\\\\\n\\sigma & \\sim \\text{Exponential(1)}\n\\end{aligned}\n\\]\nwhere \\(j\\) indexes each of the contiguous sections given by the knots\n\n# We only pass the internal knots to the `bs()` function.\niknots = knots[1:-1]\n\n# Define dictionary of priors\npriors = {\n    \"Intercept\": bmb.Prior(\"Normal\", mu=100, sigma=10),\n    \"common\": bmb.Prior(\"Normal\", mu=0, sigma=10), \n    \"sigma\": bmb.Prior(\"Exponential\", lam=1)\n}\n\n# Define model\n# The intercept=True means the basis also spans the intercept, as originally done in the book example.\nmodel = bmb.Model(\"doy ~ bs(year, knots=iknots, intercept=True)\", data, priors=priors)\nmodel\n\n       Formula: doy ~ bs(year, knots=iknots, intercept=True)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 827\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 100.0, sigma: 10.0)\n            bs(year, knots=iknots, intercept=True) ~ Normal(mu: 0.0, sigma: 10.0)\n        \n        Auxiliary parameters\n            sigma ~ Exponential(lam: 1.0)\n\n\nLet’s create a function to plot each of the basis functions in the model.\n\ndef plot_spline_basis(basis, year, figsize=(10, 6)):\n    df = (\n        pd.DataFrame(basis)\n        .assign(year=year)\n        .melt(\"year\", var_name=\"basis_idx\", value_name=\"value\")\n    )\n\n    _, ax = plt.subplots(figsize=figsize)\n\n    for idx in df.basis_idx.unique():\n        d = df[df.basis_idx == idx]\n        ax.plot(d[\"year\"], d[\"value\"])\n    \n    return ax\n\nBelow, we create a chart to visualize the b-spline basis. The overlap between the functions means that, at any given point in time, the regression function is influenced by more than one basis function. For example, if we look at the year 1200, we can see the regression line is going to be influenced mostly by the violet and brown functions, and to a lesser extent by the green and cyan ones. In summary, this is what enables us to capture local patterns in a smooth fashion.\n\nB = model.components[\"mu\"].design.common[\"bs(year, knots=iknots, intercept=True)\"]\nax = plot_spline_basis(B, data[\"year\"].values)\nplot_knots(knots, ax);",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Regression splines (Cherry blossom example)"
    ]
  },
  {
    "objectID": "notebooks/splines_cherry_blossoms.html#fit-model",
    "href": "notebooks/splines_cherry_blossoms.html#fit-model",
    "title": "Regression splines (Cherry blossom example)",
    "section": "Fit model",
    "text": "Fit model\nNow we fit the model. In Bambi, it is as easy as calling the .fit() method on the Model instance.\n\n# The seed is to make results reproducible\nidata = model.fit(random_seed=SEED, idata_kwargs={\"log_likelihood\": True})\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, bs(year, knots=iknots, intercept=True)]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 10 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Regression splines (Cherry blossom example)"
    ]
  },
  {
    "objectID": "notebooks/splines_cherry_blossoms.html#analisys-of-the-results",
    "href": "notebooks/splines_cherry_blossoms.html#analisys-of-the-results",
    "title": "Regression splines (Cherry blossom example)",
    "section": "Analisys of the results",
    "text": "Analisys of the results\nIt is always good to use az.summary() to verify parameter estimates as well as effective sample sizes and R hat values. In this case, the main goal is not to interpret the coefficients of the basis spline, but analyze the ess and r_hat diagnostics. In first place, effective sample sizes don’t look impressively high. Most of them are between 300 and 700, which is low compared to the 2000 draws obtained. The only exception is the residual standard deviation sigma. Finally, the r_hat diagnostic is not always 1 for all the parameters, indicating there may be some issues with the mix of the chains.\n\naz.summary(idata)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n103.644\n2.419\n99.691\n108.377\n0.115\n0.082\n446.0\n723.0\n1.0\n\n\nbs(year, knots=iknots, intercept=True)[0]\n-3.262\n3.909\n-10.682\n3.781\n0.136\n0.097\n824.0\n1250.0\n1.0\n\n\nbs(year, knots=iknots, intercept=True)[1]\n-1.213\n4.016\n-8.644\n6.428\n0.132\n0.094\n918.0\n1337.0\n1.0\n\n\nbs(year, knots=iknots, intercept=True)[2]\n-1.296\n3.574\n-7.878\n5.467\n0.127\n0.090\n795.0\n1190.0\n1.0\n\n\nbs(year, knots=iknots, intercept=True)[3]\n4.549\n2.968\n-1.297\n9.678\n0.122\n0.086\n597.0\n954.0\n1.0\n\n\nbs(year, knots=iknots, intercept=True)[4]\n-1.137\n2.894\n-6.794\n4.092\n0.120\n0.085\n577.0\n892.0\n1.0\n\n\nbs(year, knots=iknots, intercept=True)[5]\n3.997\n2.957\n-1.706\n9.342\n0.119\n0.084\n622.0\n897.0\n1.0\n\n\nbs(year, knots=iknots, intercept=True)[6]\n-5.603\n2.911\n-10.905\n-0.138\n0.121\n0.086\n578.0\n861.0\n1.0\n\n\nbs(year, knots=iknots, intercept=True)[7]\n7.542\n2.870\n2.339\n12.969\n0.120\n0.085\n573.0\n811.0\n1.0\n\n\nbs(year, knots=iknots, intercept=True)[8]\n-1.304\n2.956\n-7.137\n3.645\n0.119\n0.084\n624.0\n1208.0\n1.0\n\n\nbs(year, knots=iknots, intercept=True)[9]\n2.753\n2.991\n-2.551\n8.544\n0.126\n0.089\n576.0\n1070.0\n1.0\n\n\nbs(year, knots=iknots, intercept=True)[10]\n4.337\n2.961\n-1.121\n9.648\n0.117\n0.083\n640.0\n1054.0\n1.0\n\n\nbs(year, knots=iknots, intercept=True)[11]\n-0.459\n2.897\n-6.121\n4.573\n0.117\n0.083\n615.0\n981.0\n1.0\n\n\nbs(year, knots=iknots, intercept=True)[12]\n5.253\n2.977\n-0.125\n10.722\n0.119\n0.084\n639.0\n794.0\n1.0\n\n\nbs(year, knots=iknots, intercept=True)[13]\n0.454\n3.055\n-5.468\n6.024\n0.123\n0.087\n620.0\n1035.0\n1.0\n\n\nbs(year, knots=iknots, intercept=True)[14]\n-1.123\n3.330\n-7.470\n4.998\n0.128\n0.091\n683.0\n969.0\n1.0\n\n\nbs(year, knots=iknots, intercept=True)[15]\n-7.222\n3.397\n-13.694\n-1.375\n0.121\n0.085\n794.0\n1080.0\n1.0\n\n\nbs(year, knots=iknots, intercept=True)[16]\n-8.025\n3.295\n-13.911\n-1.816\n0.119\n0.085\n764.0\n980.0\n1.0\n\n\nsigma\n5.944\n0.147\n5.673\n6.220\n0.003\n0.002\n2904.0\n1417.0\n1.0\n\n\n\n\n\n\n\nWe can also use az.plot_trace() to visualize the marginal posteriors and the sampling paths. These traces show a stationary random pattern. If these paths were not random stationary, we would be concerned about the convergence of the chains.\n\naz.plot_trace(idata);\n\n\n\n\n\n\n\n\nNow we can visualize the fitted basis functions. In addition, we include a thicker black line that represents the dot product between \\(B\\) and \\(w\\). This is the contribution of the b-spline to the linear predictor in the model.\n\nposterior_stacked = az.extract(idata)\nwp = posterior_stacked[\"bs(year, knots=iknots, intercept=True)\"].mean(\"sample\").values\n\nax = plot_spline_basis(B * wp.T, data[\"year\"].values)\nax.plot(data.year.values, np.dot(B, wp.T), color=\"black\", lw=3)\nplot_knots(knots, ax);",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Regression splines (Cherry blossom example)"
    ]
  },
  {
    "objectID": "notebooks/splines_cherry_blossoms.html#plot-predictions-and-credible-bands",
    "href": "notebooks/splines_cherry_blossoms.html#plot-predictions-and-credible-bands",
    "title": "Regression splines (Cherry blossom example)",
    "section": "Plot predictions and credible bands",
    "text": "Plot predictions and credible bands\nLet’s create a function to plot the predicted mean value as well as credible bands for it.\n\ndef plot_predictions(data, idata, model):\n    # Create a test dataset with observations spanning the whole range of year\n    new_data = pd.DataFrame({\"year\": np.linspace(data.year.min(), data.year.max(), num=500)})\n    \n    # Predict the day of first blossom\n    model.predict(idata, data=new_data)\n\n    posterior_stacked =  az.extract_dataset(idata)\n    # Extract these predictions\n    y_hat = posterior_stacked[\"mu\"]\n\n    # Compute the mean of the predictions, plotted as a single line.\n    y_hat_mean = y_hat.mean(\"sample\")\n\n    # Compute 94% credible intervals for the predictions, plotted as bands\n    hdi_data = np.quantile(y_hat, [0.03, 0.97], axis=1)\n\n    # Plot obserevd data\n    ax = plot_scatter(data)\n    \n    # Plot predicted line\n    ax.plot(new_data[\"year\"], y_hat_mean, color=\"firebrick\")\n    \n    # Plot credibility bands\n    ax.fill_between(new_data[\"year\"], hdi_data[0], hdi_data[1], alpha=0.4, color=\"firebrick\")\n    \n    # Add knots\n    plot_knots(knots, ax)\n    \n    return ax\n\n\nplot_predictions(data, idata, model);\n\n/tmp/ipykernel_46679/4286558085.py:8: FutureWarning: extract_dataset has been deprecated, please use extract\n  posterior_stacked =  az.extract_dataset(idata)",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Regression splines (Cherry blossom example)"
    ]
  },
  {
    "objectID": "notebooks/splines_cherry_blossoms.html#advanced-watch-out-the-underlying-design-matrix",
    "href": "notebooks/splines_cherry_blossoms.html#advanced-watch-out-the-underlying-design-matrix",
    "title": "Regression splines (Cherry blossom example)",
    "section": "Advanced: Watch out the underlying design matrix",
    "text": "Advanced: Watch out the underlying design matrix\nWe can write linear regression models in matrix form as\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta}\n\\]\nwhere \\(\\mathbf{y}\\) is the response column vector of shape \\((n, 1)\\). \\(\\mathbf{X}\\) is the design matrix that contains the values of the predictors for all the observations, of shape \\((n, p)\\). And \\(\\boldsymbol{\\beta}\\) is the column vector of regression coefficients of shape \\((n, 1)\\).\nBecause it’s not something that you’re supposed to consult regularly, Bambi does not expose the design matrix. However, with a some knowledge of the internals, it is possible to have access to it:\n\nnp.round(model.components[\"mu\"].design.common.design_matrix, 3)\n\narray([[1.   , 1.   , 0.   , ..., 0.   , 0.   , 0.   ],\n       [1.   , 0.96 , 0.039, ..., 0.   , 0.   , 0.   ],\n       [1.   , 0.767, 0.221, ..., 0.   , 0.   , 0.   ],\n       ...,\n       [1.   , 0.   , 0.   , ..., 0.002, 0.097, 0.902],\n       [1.   , 0.   , 0.   , ..., 0.   , 0.05 , 0.95 ],\n       [1.   , 0.   , 0.   , ..., 0.   , 0.   , 1.   ]])\n\n\nLet’s have a look at its shape:\n\nmodel.components[\"mu\"].design.common.design_matrix.shape\n\n(827, 18)\n\n\n827 is the number of years we have data for, and 18 is the number of predictors/coefficients in the model. We have the first column of ones due to the Intercept term. Then, there are sixteen columns associated with the the basis functions. And finally, one extra column because we used span_intercept=True when calling the function bs() in the model formula.\nNow we could compute the rank of the design matrix to check whether all the columns are linearly independent.\n\nnp.linalg.matrix_rank(model.components[\"mu\"].design.common.design_matrix)\n\n17\n\n\nSince \\(\\text{rank}(\\mathbf{X})\\) is smaller than the number of columns, we conclude the columns in \\(\\mathbf{X}\\) are not linearly independent.\nIf we have a second look at our code, we are going to figure out we’re spanning the intercept twice. The first time with the intercept term itself, and the second time in the spline basis.\nThis would have been a huge problem in a maximum likelihod estimation approach – we would have obtained an error instead of some parameter estimates. However, since we are doing Bayesian modeling, our priors ensured we obtain our regularized parameter estimates and everything seemed to work pretty well.\nNevertheless, we can still do better. Why would we want to span the intercept twice? Let’s create and fit the model again, this time without spanning the intercept in the spline basis.\n\n# Note we use the same priors\nmodel_new = bmb.Model(\"doy ~ bs(year, knots=iknots)\", data, priors=priors)\nidata_new = model_new.fit(random_seed=SEED, idata_kwargs={\"log_likelihood\": True})\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, bs(year, knots=iknots)]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 9 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nAnd let’s have a look at the summary\n\naz.summary(idata_new)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n102.358\n1.889\n98.707\n105.711\n0.084\n0.060\n505.0\n779.0\n1.0\n\n\nbs(year, knots=iknots)[0]\n-0.875\n3.832\n-7.709\n6.539\n0.135\n0.096\n807.0\n1356.0\n1.0\n\n\nbs(year, knots=iknots)[1]\n0.430\n2.954\n-4.934\n6.052\n0.083\n0.065\n1284.0\n1460.0\n1.0\n\n\nbs(year, knots=iknots)[2]\n5.714\n2.604\n0.465\n10.248\n0.097\n0.069\n720.0\n1266.0\n1.0\n\n\nbs(year, knots=iknots)[3]\n0.226\n2.446\n-4.181\n4.810\n0.092\n0.065\n708.0\n1168.0\n1.0\n\n\nbs(year, knots=iknots)[4]\n5.279\n2.590\n0.500\n10.089\n0.093\n0.066\n777.0\n1304.0\n1.0\n\n\nbs(year, knots=iknots)[5]\n-4.341\n2.412\n-8.440\n0.732\n0.089\n0.063\n736.0\n1127.0\n1.0\n\n\nbs(year, knots=iknots)[6]\n8.796\n2.421\n4.549\n13.533\n0.088\n0.062\n753.0\n1246.0\n1.0\n\n\nbs(year, knots=iknots)[7]\n0.029\n2.521\n-4.922\n4.602\n0.093\n0.066\n732.0\n1119.0\n1.0\n\n\nbs(year, knots=iknots)[8]\n4.004\n2.551\n-0.700\n8.912\n0.091\n0.064\n790.0\n1119.0\n1.0\n\n\nbs(year, knots=iknots)[9]\n5.651\n2.563\n1.126\n10.653\n0.092\n0.065\n773.0\n1350.0\n1.0\n\n\nbs(year, knots=iknots)[10]\n0.860\n2.508\n-3.605\n5.611\n0.091\n0.065\n756.0\n1174.0\n1.0\n\n\nbs(year, knots=iknots)[11]\n6.501\n2.544\n1.390\n10.852\n0.091\n0.064\n783.0\n1127.0\n1.0\n\n\nbs(year, knots=iknots)[12]\n1.716\n2.622\n-3.177\n6.699\n0.091\n0.065\n824.0\n1266.0\n1.0\n\n\nbs(year, knots=iknots)[13]\n0.118\n2.980\n-5.096\n5.831\n0.095\n0.067\n974.0\n1329.0\n1.0\n\n\nbs(year, knots=iknots)[14]\n-5.901\n3.032\n-11.364\n-0.319\n0.092\n0.065\n1087.0\n1447.0\n1.0\n\n\nbs(year, knots=iknots)[15]\n-6.734\n2.977\n-12.309\n-1.337\n0.101\n0.071\n883.0\n1399.0\n1.0\n\n\nsigma\n5.941\n0.152\n5.657\n6.219\n0.003\n0.002\n2631.0\n1420.0\n1.0\n\n\n\n\n\n\n\nThere are a couple of things to remark here\n\nThere are 16 coefficients associated with the b-spline now because we’re not spanning the intercept.\nThe ESS numbers have improved in all cases. Notice the sampler isn’t raising any warning about low ESS.\nr_hat coefficeints are still 1.\n\nWe can also compare the sampling times:\n\nidata.posterior.sampling_time\n\n9.64709210395813\n\n\n\nidata_new.posterior.sampling_time\n\n9.324542045593262\n\n\nSampling times are similar in this particular example. But in general, we expect the sampler to run faster when there aren’t structural dependencies in the design matrix.\nAnd what about predictions?\n\nplot_predictions(data, idata_new, model_new);\n\n/tmp/ipykernel_46679/4286558085.py:8: FutureWarning: extract_dataset has been deprecated, please use extract\n  posterior_stacked =  az.extract_dataset(idata)\n\n\n\n\n\n\n\n\n\nAnd model comparison?\n\nmodels_dict = {\"Original\": idata, \"New\": idata_new}\ndf_compare = az.compare(models_dict)\ndf_compare\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nNew\n0\n-2657.850604\n15.926137\n0.000000\n1.0\n21.193558\n0.000000\nFalse\nlog\n\n\nOriginal\n1\n-2658.586671\n16.913997\n0.736068\n0.0\n21.192815\n0.549973\nFalse\nlog\n\n\n\n\n\n\n\n\naz.plot_compare(df_compare, insample_dev=False);\n\n\n\n\n\n\n\n\nFinally let’s check influential points according to the k-hat value\n\n# Compute pointwise LOO\nloo_1 = az.loo(idata, pointwise=True)\nloo_2 = az.loo(idata_new, pointwise=True)\n\n\n# plot kappa values\naz.plot_khat(loo_1.pareto_k);\n\n\n\n\n\n\n\n\n\naz.plot_khat(loo_2.pareto_k);",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Regression splines (Cherry blossom example)"
    ]
  },
  {
    "objectID": "notebooks/splines_cherry_blossoms.html#final-comments",
    "href": "notebooks/splines_cherry_blossoms.html#final-comments",
    "title": "Regression splines (Cherry blossom example)",
    "section": "Final comments",
    "text": "Final comments\nAnother option could have been to use stronger priors on the coefficients associated with the spline functions. For example, the example written in PyMC uses \\(\\text{Normal}(0, 3)\\) priors on them instead of \\(\\text{Normal}(0, 10)\\).\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sun May 26 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\npandas    : 2.2.2\nbambi     : 0.13.1.dev39+gb7d6a6cb\nnumpy     : 1.26.4\narviz     : 0.18.0\nmatplotlib: 3.8.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Regression splines (Cherry blossom example)"
    ]
  },
  {
    "objectID": "notebooks/shooter_crossed_random_ANOVA.html",
    "href": "notebooks/shooter_crossed_random_ANOVA.html",
    "title": "Bayesian Workflow (Police Officer’s Dilemma)",
    "section": "",
    "text": "import arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\naz.style.use(\"arviz-darkgrid\")\nSEED = 1234\nHere we will analyze a dataset from experimental psychology in which a sample of 36 human participants engaged in what is called the shooter task, yielding 3600 responses and reaction times (100 from each subject). The link above gives some more information about the shooter task, but basically it is a sort of crude first-person-shooter video game in which the subject plays the role of a police officer. The subject views a variety of urban scenes, and in each round or “trial” a person or “target” appears on the screen after some random interval. This person is either Black or White (with 50% probability), and they are holding some object that is either a gun or some other object like a phone or wallet (with 50% probability). When a target appears, the subject has a very brief response window – 0.85 seconds in this particular experiment – within which to press one of two keyboard buttons indicating a “shoot” or “don’t shoot” response. Subjects receive points for correct and timely responses in each trial; subjects’ scores are penalized for incorrect reponses (i.e., shooting an unarmed person or failing to shoot an armed person) or if they don’t respond within the 0.85 response window. The goal of the task, from the subject’s perspective, is to maximize their score.\nThe typical findings in the shooter task are that",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Bayesian Workflow (Police Officer's Dilemma)"
    ]
  },
  {
    "objectID": "notebooks/shooter_crossed_random_ANOVA.html#load-and-examine-data",
    "href": "notebooks/shooter_crossed_random_ANOVA.html#load-and-examine-data",
    "title": "Bayesian Workflow (Police Officer’s Dilemma)",
    "section": "Load and examine data",
    "text": "Load and examine data\n\nshooter = pd.read_csv(\"data/shooter.csv\", na_values=\".\")\nshooter.head(10)\n\n\n\n\n\n\n\n\nsubject\ntarget\ntrial\nrace\nobject\ntime\nresponse\n\n\n\n\n0\n1\nw05\n19\nwhite\nnogun\n658.0\ncorrect\n\n\n1\n2\nb07\n19\nblack\ngun\n573.0\ncorrect\n\n\n2\n3\nw05\n19\nwhite\ngun\n369.0\ncorrect\n\n\n3\n4\nw07\n19\nwhite\ngun\n495.0\ncorrect\n\n\n4\n5\nw15\n19\nwhite\nnogun\n483.0\ncorrect\n\n\n5\n6\nw96\n19\nwhite\nnogun\n786.0\ncorrect\n\n\n6\n7\nw13\n19\nwhite\nnogun\n519.0\ncorrect\n\n\n7\n8\nw06\n19\nwhite\nnogun\n567.0\ncorrect\n\n\n8\n9\nb14\n19\nblack\ngun\n672.0\nincorrect\n\n\n9\n10\nw90\n19\nwhite\ngun\n457.0\ncorrect\n\n\n\n\n\n\n\nThe design of the experiment is such that the subject, target, and object (i.e., gun vs. no gun) factors are fully crossed: each subject views each target twice, once with a gun and once without a gun.\n\npd.crosstab(shooter[\"subject\"], [shooter[\"target\"], shooter[\"object\"]])\n\n\n\n\n\n\n\ntarget\nb01\nb02\nb03\nb04\nb05\n...\nw95\nw96\nw97\nw98\nw99\n\n\nobject\ngun\nnogun\ngun\nnogun\ngun\nnogun\ngun\nnogun\ngun\nnogun\n...\ngun\nnogun\ngun\nnogun\ngun\nnogun\ngun\nnogun\ngun\nnogun\n\n\nsubject\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n2\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n3\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n4\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n5\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n6\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n7\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n8\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n9\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n10\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n11\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n12\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n13\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n14\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n15\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n16\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n17\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n18\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n19\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n20\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n21\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n22\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n23\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n24\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n25\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n26\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n27\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n28\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n29\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n30\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n31\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n32\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n33\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n34\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n35\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n36\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n\n\n36 rows × 100 columns\n\n\n\nThe response speeds on each trial are recorded given as reaction times (milliseconds per response), but here we invert them to and multiply by 1000 so that we are analyzing response rates (responses per second). There is no theoretical reason to prefer one of these metrics over the other, but it turns out that response rates tend to have nicer distributional properties than reaction times (i.e., deviate less strongly from the standard Gaussian assumptions), so response rates will be a little more convenient for us by allowing us to use some fairly standard distributional models.\n\nshooter[\"rate\"] = 1000.0 / shooter[\"time\"]\n\n\nplt.hist(shooter[\"rate\"].dropna());",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Bayesian Workflow (Police Officer's Dilemma)"
    ]
  },
  {
    "objectID": "notebooks/shooter_crossed_random_ANOVA.html#fit-response-rate-models",
    "href": "notebooks/shooter_crossed_random_ANOVA.html#fit-response-rate-models",
    "title": "Bayesian Workflow (Police Officer’s Dilemma)",
    "section": "Fit response rate models",
    "text": "Fit response rate models\n\nSubject specific effects only\nOur first model is analogous to how the data from the shooter task are usually analyzed: incorporating all subject-level sources of variability, but ignoring the sampling variability due to the sample of 50 targets. This is a Bayesian generalized linear mixed model (GLMM) with a Normal response and with intercepts and slopes that vary randomly across subjects.\nOf note here is the S(x) syntax, which is from the Formulae library that we use to parse model formulas. This instructs Bambi to use contrast codes of -1 and +1 for the two levels of each of the common factors of race (black vs. white) and object (gun vs. no gun), so that the race and object coefficients can be interpreted as simple effects on average across the levels of the other factor (directly analogous, but not quite equivalent, to the main effects). This is the standard coding used in ANOVA.\n\nsubj_model = bmb.Model(\n    \"rate ~ S(race) * S(object) + (S(race) * S(object) | subject)\", \n    shooter, \n    dropna=True\n)\nsubj_fitted = subj_model.fit(random_seed=SEED)\n\nAutomatically removing 98/3600 rows from the dataset.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, S(race), S(object), S(race):S(object), 1|subject_sigma, 1|subject_offset, S(race)|subject_sigma, S(race)|subject_offset, S(object)|subject_sigma, S(object)|subject_offset, S(race):S(object)|subject_sigma, S(race):S(object)|subject_offset]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 42 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n\n\nFirst let’s visualize the default priors that Bambi automatically decided on for each of the parameters. We do this by calling the .plot_priors() method of the Model object.\n\nsubj_model.plot_priors();\n\nSampling: [1|subject_sigma, Intercept, S(object), S(object)|subject_sigma, S(race), S(race):S(object), S(race):S(object)|subject_sigma, S(race)|subject_sigma, sigma]\n\n\n\n\n\n\n\n\n\nThe priors on the common effects seem quite reasonable. Recall that because of the -1 vs +1 contrast coding, the coefficients correspond to half the difference between the two levels of each factor. So the priors on the common effects essentially say that the black vs. white and gun vs. no gun (and their interaction) response rate differences are very unlikely to be as large as a full response per second.\nNow let’s visualize the model estimates. We do this by passing the InferenceData object that resulted from the Model.fit() call to az.plot_trace().\n\naz.plot_trace(subj_fitted);\n\n\n\n\n\n\n\n\nEach distribution in the plots above has 2 densities because we used 2 MCMC chains, so we are viewing the results of all 2 chains prior to their aggregation. The main message from the plot above is that the chains all seem to have converged well and the resulting posterior distributions all look quite reasonable. It’s a bit easier to digest all this information in a concise, tabular form, which we can get by passing the object that resulted from the Model.fit() call to az.summary().\n\naz.summary(subj_fitted)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\n1|subject[1]\n-0.002\n0.027\n-0.053\n0.048\n0.001\n0.001\n1054.0\n1272.0\n1.0\n\n\n1|subject[2]\n-0.066\n0.026\n-0.114\n-0.015\n0.001\n0.001\n1178.0\n1214.0\n1.0\n\n\n1|subject[3]\n0.044\n0.026\n-0.006\n0.093\n0.001\n0.001\n1120.0\n1316.0\n1.0\n\n\n1|subject[4]\n0.065\n0.026\n0.010\n0.110\n0.001\n0.001\n1017.0\n1094.0\n1.0\n\n\n1|subject[5]\n-0.004\n0.028\n-0.051\n0.052\n0.001\n0.001\n1127.0\n1089.0\n1.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nS(race)|subject[black, 34]\n-0.000\n0.006\n-0.012\n0.012\n0.000\n0.000\n2490.0\n1485.0\n1.0\n\n\nS(race)|subject[black, 35]\n-0.001\n0.006\n-0.015\n0.011\n0.000\n0.000\n2500.0\n1560.0\n1.0\n\n\nS(race)|subject[black, 36]\n0.001\n0.006\n-0.012\n0.013\n0.000\n0.000\n2369.0\n1557.0\n1.0\n\n\nS(race)|subject_sigma[black]\n0.005\n0.004\n0.000\n0.012\n0.000\n0.000\n1102.0\n841.0\n1.0\n\n\nsigma\n0.240\n0.003\n0.234\n0.245\n0.000\n0.000\n3468.0\n1119.0\n1.0\n\n\n\n\n153 rows × 9 columns\n\n\n\nThe take-home message from the analysis seems to be that we do find evidence for the usual finding that subjects are especially quick to respond (presumably with a shoot response) to armed black targets and especially slow to respond to unarmed black targets (while unarmed white targets receive “don’t shoot” responses with less hesitation). We see this in the fact that the marginal posterior for the S(race):S(object) interaction coefficient is concentrated strongly away from 0.\n\n\nStimulus specific effects\nA major flaw in the analysis above is that stimulus specific effects are ignored. The model does include group specific effects for subjects, reflecting the fact that the subjects we observed are but a sample from the broader population of subjects we are interested in and that potentially could have appeared in our study. But the targets we observed – the 50 photographs of white and black men that subjets responded to – are also but a sample from the broader theoretical population of targets we are interested in talking about, and that we could have just as easily and justifiably used as the experimental stimuli in the study. Since the stimuli comprise a random sample, they are subject to sampling variability, and this sampling variability should be accounted in the analysis by including stimulus specific effects. For some more information on this, see here, particularly pages 62-63.\nTo account for this, we let the intercept and slope for object be different for each target. Specific slopes for object across targets are possible because, if you recall, the design of the study was such that each target gets viewed twice by each subject, once with a gun and once without a gun. However, because each target is always either white or black, it’s not possible to add group specific slopes for the race factor or the interaction.\n\nstim_model = bmb.Model(\n    \"rate ~ S(race) * S(object) + (S(race) * S(object) | subject) + (S(object) | target)\", \n    shooter, \n    dropna=True\n)\nstim_fitted = stim_model.fit(random_seed=SEED)\n\nAutomatically removing 98/3600 rows from the dataset.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, S(race), S(object), S(race):S(object), 1|subject_sigma, 1|subject_offset, S(race)|subject_sigma, S(race)|subject_offset, S(object)|subject_sigma, S(object)|subject_offset, S(race):S(object)|subject_sigma, S(race):S(object)|subject_offset, 1|target_sigma, 1|target_offset, S(object)|target_sigma, S(object)|target_offset]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 56 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\nThe effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n\n\nNow let’s look at the results…\n\naz.plot_trace(stim_fitted);\n\n\n\n\n\n\n\n\n\naz.summary(stim_fitted)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\n1|subject[1]\n-0.005\n0.024\n-0.053\n0.036\n0.001\n0.001\n442.0\n852.0\n1.0\n\n\n1|subject[2]\n-0.069\n0.026\n-0.114\n-0.019\n0.001\n0.001\n566.0\n1167.0\n1.0\n\n\n1|subject[3]\n0.049\n0.025\n0.005\n0.097\n0.001\n0.001\n535.0\n952.0\n1.0\n\n\n1|subject[4]\n0.070\n0.024\n0.024\n0.116\n0.001\n0.001\n556.0\n948.0\n1.0\n\n\n1|subject[5]\n0.002\n0.023\n-0.044\n0.045\n0.001\n0.001\n476.0\n831.0\n1.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nS(race)|subject[black, 34]\n-0.000\n0.006\n-0.013\n0.014\n0.000\n0.000\n2159.0\n1656.0\n1.0\n\n\nS(race)|subject[black, 35]\n-0.002\n0.007\n-0.017\n0.011\n0.000\n0.000\n1891.0\n1621.0\n1.0\n\n\nS(race)|subject[black, 36]\n0.002\n0.007\n-0.011\n0.016\n0.000\n0.000\n1768.0\n1735.0\n1.0\n\n\nS(race)|subject_sigma[black]\n0.006\n0.004\n0.000\n0.014\n0.000\n0.000\n861.0\n940.0\n1.0\n\n\nsigma\n0.205\n0.003\n0.201\n0.210\n0.000\n0.000\n1857.0\n1418.0\n1.0\n\n\n\n\n255 rows × 9 columns\n\n\n\nThere are two interesting things to note here. The first is that the key interaction effect, S(race):S(object) is much less clear now. The marginal posterior is still mostly concentrated away from 0, but there’s certainly a nontrivial part that overlaps with 0; 2.9% of the distribution, to be exact.\n\n(stim_fitted.posterior[\"S(race):S(object)\"] &lt; 0).mean()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'S(race):S(object)' ()&gt; Size: 8B\narray(0.0605)xarray.DataArray'S(race):S(object)'0.0605array(0.0605)Coordinates: (0)Indexes: (0)Attributes: (0)\n\n\nThe second interesting thing is that the two new variance components in the model, those associated with the stimulus specific effects, are actually rather large. This actually largely explains the first fact above, since if these where estimated to be close to 0 anyway, the model estimates wouldn’t be much different than they were in the subj_model. It makes sense that there is a strong tendency for different targets to elicit difference reaction times on average, which leads to a large estimate of 1|target_sigma.\nLess obviously, the large estimate of S(object)|target_sigma (targets tend to vary a lot in their response rate differences when they have a gun vs. some other object) also makes sense, because in this experiment, different targets were pictured with different non-gun objects. Some of these objects, such as a bright red can of Coca-Cola, are not easily confused with a gun, so subjects are able to quickly decide on the correct response. Other objects, such as a black cell phone, are possibly easier to confuse with a gun, so subjects take longer to decide on the correct response when confronted with this object.\nSince each target is yoked to a particular non-gun object, there is good reason to expect large target-to-target variability in the object effect, which is indeed what we see in the model estimates.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Bayesian Workflow (Police Officer's Dilemma)"
    ]
  },
  {
    "objectID": "notebooks/shooter_crossed_random_ANOVA.html#fit-response-models",
    "href": "notebooks/shooter_crossed_random_ANOVA.html#fit-response-models",
    "title": "Bayesian Workflow (Police Officer’s Dilemma)",
    "section": "Fit response models",
    "text": "Fit response models\nHere we seek evidence of the second traditional finding, that subjects are more likely to response ‘shoot’ toward black targets than toward white targets, regardless of whether they are armed or not. Currently the dataset just records whether the given response was correct or not, so first we transformed this into whether the response was ‘shoot’ or ‘dontshoot’.\n\nshooter[\"shoot_or_not\"] = shooter[\"response\"].astype(str)\n\n# armed targets\nnew_values = {\"correct\": \"shoot\", \"incorrect\": \"dontshoot\", \"timeout\": np.nan}\nshooter.loc[shooter[\"object\"] == \"gun\", \"shoot_or_not\"] = (\n    shooter.loc[shooter[\"object\"] == \"gun\", \"response\"].astype(str).replace(new_values)\n)\n    \n# unarmed targets\nnew_values = {\"correct\": \"dontshoot\", \"incorrect\": \"shoot\", \"timeout\": np.nan}\nshooter.loc[shooter[\"object\"] == \"nogun\", \"shoot_or_not\"] = (\n    shooter.loc[shooter[\"object\"] == \"nogun\", \"response\"].astype(str).replace(new_values)\n)\n    \n# view result\nshooter.head(20)\n\n\n\n\n\n\n\n\nsubject\ntarget\ntrial\nrace\nobject\ntime\nresponse\nrate\nshoot_or_not\n\n\n\n\n0\n1\nw05\n19\nwhite\nnogun\n658.0\ncorrect\n1.519757\ndontshoot\n\n\n1\n2\nb07\n19\nblack\ngun\n573.0\ncorrect\n1.745201\nshoot\n\n\n2\n3\nw05\n19\nwhite\ngun\n369.0\ncorrect\n2.710027\nshoot\n\n\n3\n4\nw07\n19\nwhite\ngun\n495.0\ncorrect\n2.020202\nshoot\n\n\n4\n5\nw15\n19\nwhite\nnogun\n483.0\ncorrect\n2.070393\ndontshoot\n\n\n5\n6\nw96\n19\nwhite\nnogun\n786.0\ncorrect\n1.272265\ndontshoot\n\n\n6\n7\nw13\n19\nwhite\nnogun\n519.0\ncorrect\n1.926782\ndontshoot\n\n\n7\n8\nw06\n19\nwhite\nnogun\n567.0\ncorrect\n1.763668\ndontshoot\n\n\n8\n9\nb14\n19\nblack\ngun\n672.0\nincorrect\n1.488095\ndontshoot\n\n\n9\n10\nw90\n19\nwhite\ngun\n457.0\ncorrect\n2.188184\nshoot\n\n\n10\n11\nw91\n19\nwhite\nnogun\n599.0\ncorrect\n1.669449\ndontshoot\n\n\n11\n12\nb17\n19\nblack\nnogun\n769.0\ncorrect\n1.300390\ndontshoot\n\n\n12\n13\nb04\n19\nblack\nnogun\n600.0\ncorrect\n1.666667\ndontshoot\n\n\n13\n14\nw17\n19\nwhite\nnogun\n653.0\ncorrect\n1.531394\ndontshoot\n\n\n14\n15\nb93\n19\nblack\ngun\n468.0\ncorrect\n2.136752\nshoot\n\n\n15\n16\nw96\n19\nwhite\ngun\n546.0\ncorrect\n1.831502\nshoot\n\n\n16\n17\nw91\n19\nwhite\ngun\n591.0\nincorrect\n1.692047\ndontshoot\n\n\n17\n18\nb95\n19\nblack\ngun\nNaN\ntimeout\nNaN\nNaN\n\n\n18\n19\nb09\n19\nblack\ngun\n656.0\ncorrect\n1.524390\nshoot\n\n\n19\n20\nb02\n19\nblack\ngun\n617.0\ncorrect\n1.620746\nshoot\n\n\n\n\n\n\n\nLet’s skip straight to the correct model that includes stimulus specific effects. This looks quite similiar to the stim_model from above except that we change the response to the new shoot_or_not variable – notice the [shoot] syntax indicating that we wish to model the prbability that shoot_or_not=='shoot', not shoot_or_not=='dontshoot' – and then change to family='bernoulli' to indicate a mixed effects logistic regression.\n\nstim_response_model = bmb.Model(\n    \"shoot_or_not[shoot] ~ S(race)*S(object) + (S(race)*S(object) | subject) + (S(object) | target)\",\n    shooter,\n    family=\"bernoulli\",\n    dropna=True\n)\n\n# Note we increased target_accept from default 0.8 to 0.9 because there were divergences\nstim_response_fitted = stim_response_model.fit(\n    draws=2000, \n    target_accept=0.9,\n    random_seed=SEED\n)\n\nAutomatically removing 98/3600 rows from the dataset.\nModeling the probability that shoot_or_not==shoot\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [Intercept, S(race), S(object), S(race):S(object), 1|subject_sigma, 1|subject_offset, S(race)|subject_sigma, S(race)|subject_offset, S(object)|subject_sigma, S(object)|subject_offset, S(race):S(object)|subject_sigma, S(race):S(object)|subject_offset, 1|target_sigma, 1|target_offset, S(object)|target_sigma, S(object)|target_offset]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 2_000 draw iterations (2_000 + 4_000 draws total) took 105 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nShow the trace plot\n\naz.plot_trace(stim_response_fitted);\n\n\n\n\n\n\n\n\nLooks pretty good! Now for the more concise summary.\n\naz.summary(stim_response_fitted)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\n1|subject[1]\n0.001\n0.252\n-0.480\n0.527\n0.003\n0.004\n5646.0\n3085.0\n1.0\n\n\n1|subject[2]\n-0.066\n0.254\n-0.611\n0.399\n0.004\n0.004\n5251.0\n3002.0\n1.0\n\n\n1|subject[3]\n-0.107\n0.266\n-0.655\n0.338\n0.004\n0.003\n4875.0\n3263.0\n1.0\n\n\n1|subject[4]\n-0.004\n0.246\n-0.551\n0.437\n0.003\n0.004\n5518.0\n3142.0\n1.0\n\n\n1|subject[5]\n0.056\n0.236\n-0.413\n0.517\n0.003\n0.003\n5391.0\n2993.0\n1.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nS(race)|subject[black, 33]\n0.087\n0.206\n-0.242\n0.529\n0.003\n0.002\n4548.0\n3006.0\n1.0\n\n\nS(race)|subject[black, 34]\n-0.057\n0.208\n-0.517\n0.304\n0.003\n0.003\n5185.0\n3111.0\n1.0\n\n\nS(race)|subject[black, 35]\n-0.018\n0.199\n-0.453\n0.339\n0.003\n0.003\n5602.0\n2976.0\n1.0\n\n\nS(race)|subject[black, 36]\n-0.095\n0.237\n-0.595\n0.303\n0.004\n0.003\n4390.0\n3126.0\n1.0\n\n\nS(race)|subject_sigma[black]\n0.181\n0.137\n0.000\n0.419\n0.003\n0.002\n1880.0\n1873.0\n1.0\n\n\n\n\n254 rows × 9 columns\n\n\n\nThere is some slight evidence here for the hypothesis that subjects are more likely to shoot the black targets, regardless of whether they are armed or not, but the evidence is not too strong. The marginal posterior for the S(race) coefficient is mostly concentrated away from 0, but it overlaps even more in this case with 0 than did the key interaction effect in the previous model.\n\n(stim_response_fitted.posterior[\"S(race)\"] &lt; 0).mean()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'S(race)' ()&gt; Size: 8B\narray(0.058)xarray.DataArray'S(race)'0.058array(0.058)Coordinates: (0)Indexes: (0)Attributes: (0)\n\n\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sun May 26 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\nnumpy     : 1.26.4\nbambi     : 0.13.1.dev39+gb7d6a6cb\narviz     : 0.18.0\nmatplotlib: 3.8.4\npandas    : 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Bayesian Workflow (Police Officer's Dilemma)"
    ]
  },
  {
    "objectID": "notebooks/quantile_regression.html",
    "href": "notebooks/quantile_regression.html",
    "title": "Quantile Regression",
    "section": "",
    "text": "import arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\naz.style.use(\"arviz-darkgrid\")\nSEED = 12947\nUsually when doing regression we model the conditional mean of some distribution. Common cases are a Normal distribution for continuous unbounded responses, a Poisson distribution for count data, etc.\nQuantile regression, instead estimates a conditional quantile of the response variable. If the quantile is 0.5, then we will be estimating the median (instead of the mean), this could be useful as a way of performing robust regression, in a similar fashion as using a Student-t distribution instead of a Normal. But for some problem we actually care of the behaviour of the response away from the mean (or median). For example, in medical research, pathologies or potential health risks occur at high or low quantile, for instance, overweight and underweight. In some other fields like ecology, quantile regression is justified due to the existence of complex interactions between variables, where the effect of one variable on another is different for different ranges of the variable.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Quantile Regression"
    ]
  },
  {
    "objectID": "notebooks/quantile_regression.html#asymmetric-laplace-distribution",
    "href": "notebooks/quantile_regression.html#asymmetric-laplace-distribution",
    "title": "Quantile Regression",
    "section": "Asymmetric Laplace distribution",
    "text": "Asymmetric Laplace distribution\nAt first it could be weird to think which distribution we should use as the likelihood for quantile regression or how to write a Bayesian model for quantile regression. But it turns out the answer is quite simple, we just need to use the asymmetric Laplace distribution. This distribution has one parameter controling the mean, another for the scale and a third one for the asymmetry. There are at least two alternative parametrizations regarding this asymmetric parameter. In terms of \\(\\kappa\\) a parameter that goes from 0 to \\(\\infty\\) and in terms of \\(q\\) a number between 0 and 1. This later parametrization is more intuitive for quantile regression as we can directly interpre it as the quantile of interest.\nOn the next cell we compute the pdf of 3 distribution from the Asymmetric Laplace family\n\nx = np.linspace(-6, 6, 2000)\nquantiles =  np.array([0.2, 0.5, 0.8])\nfor q, m in zip(quantiles, [0, 0, -1]):\n    κ = (q/(1-q))**0.5\n    plt.plot(x, stats.laplace_asymmetric(κ, m, 1).pdf(x), label=f\"q={q:}, μ={m}, σ=1\")\nplt.yticks([]);\nplt.legend();\n\n\n\n\n\n\n\n\nWe are going to use a simple dataset to model the Body Mass Index for Dutch kids and young men as a function of their age.\n\ndata = pd.read_csv(\"data/bmi.csv\")\ndata.head()\n\n\n\n\n\n\n\n\nage\nbmi\n\n\n\n\n0\n0.03\n13.235289\n\n\n1\n0.04\n12.438775\n\n\n2\n0.04\n14.541775\n\n\n3\n0.04\n11.773954\n\n\n4\n0.04\n15.325614\n\n\n\n\n\n\n\nAs we can see from the next figure the relationship between BMI and age is far from linear, and hence we are going to use splines.\n\nplt.plot(data.age, data.bmi, \"k.\");\nplt.xlabel(\"Age\")\nplt.ylabel(\"BMI\");\n\n\n\n\n\n\n\n\nWe are going to model 3 quantiles, 0.1, 0.5 and 0.9. For that reasoson we are going to fit 3 separated models, being the sole different the value of kappa of the Asymmetric Laplace distribution, that will be fix at a different value each time. In the future Bambi will allow to directly work with the parameter q instead of kappa, in the meantime we have to apply a transformation to go from quantiles to suitable values of kappa.\n\\[\n\\kappa = \\sqrt{\\frac{q}{1 - q}}\n\\]\n\nquantiles = np.array([0.1, 0.5, 0.9])\nkappas = (quantiles/(1-quantiles))**0.5\n\nknots = np.quantile(data.age, np.linspace(0, 1, 10))[1:-1]\n\nidatas = []\nfor κ in kappas:\n    model = bmb.Model(\"bmi ~ bs(age, knots=knots)\",\n                      data=data, family=\"asymmetriclaplace\", priors={\"kappa\": κ})\n    idata = model.fit()\n    model.predict(idata)\n    idatas.append(idata)\n\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [b, Intercept, bs(age, knots=knots)]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 20 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [b, Intercept, bs(age, knots=knots)]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 14 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/tensor/math.py:1115: FutureWarning: sgn is deprecated and will stop working in the future, use sign instead.\n  warnings.warn(\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [b, Intercept, bs(age, knots=knots)]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 21 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nWe can see the result of the 3 fitted curves in the next figure. One feature that stand-out is that the gap or distance between the median (orange) line and the two other lines is not the same. Also the shapes of the curve while following a similar pattern, are not exactly the same.\n\nplt.plot(data.age, data.bmi, \".\", color=\"0.5\")\nfor idata, q in zip(idatas, quantiles):\n    plt.plot(data.age.values, idata.posterior[\"mu\"].mean((\"chain\", \"draw\")),\n            label=f\"q={q:}\", lw=3);\n    \nplt.legend()\nplt.xlabel(\"Age\")\nplt.ylabel(\"BMI\");\n\n\n\n\n\n\n\n\nTo better undestand these remarks let’s compute a simple linear regression and then compute the same 3 quantiles from that fit.\n\nmodel_g = bmb.Model(\"bmi ~ bs(age, knots=knots)\", data=data)\nidata_g = model_g.fit()\nmodel_g.predict(idata_g, kind=\"response\")\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, bs(age, knots=knots)]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 12 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\nidata_g_mean_quantiles = idata_g.posterior_predictive[\"bmi\"].quantile(quantiles, (\"chain\", \"draw\"))\n\n\nplt.plot(data.age, data.bmi, \".\", color=\"0.5\")\nfor q in quantiles:\n    plt.plot(data.age.values, idata_g_mean_quantiles.sel(quantile=q), label=f\"q={q:}\");\n    \nplt.legend()\nplt.xlabel(\"Age\")\nplt.ylabel(\"BMI\");\n\n\n\n\n\n\n\n\nWe can see that when we use a Gaussian family and from that fit we compute the quantiles, the quantiles q=0.1 and q=0.9 are symetrical with respect to q=0.5, also the shape of the curves is essentially the same just shifted up or down. Additionally the Asymmetric Laplace family allows the model to account for the increased variability in BMI as the age increases, while for the Gaussian family that variability always stays the same.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sat May 25 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\nscipy     : 1.13.1\narviz     : 0.18.0\npandas    : 2.2.2\nbambi     : 0.13.1.dev37+g2a54df76.d20240525\nmatplotlib: 3.8.4\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Quantile Regression"
    ]
  },
  {
    "objectID": "notebooks/polynomial_regression.html",
    "href": "notebooks/polynomial_regression.html",
    "title": "Polynomial Regression",
    "section": "",
    "text": "This example has been contributed by Tyler James Burch (@tjburch on GitHub).\nimport arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nplt.style.use(\"arviz-darkgrid\")\nSEED = 1234\n# Temporary fix to make outputs cleaner\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nThis example will discuss polynomial regression using Bambi. Unlike many other examples shown, there aren’t specific polynomial methods or families implemented in Bambi, most of the interesting behavior for polynomial regression occurs within the formula definition. Regardless, there are some nuances that are useful to be aware of.\nThis example uses the kinematic equations from classical mechanics as a backdrop. Specifically, an object in motion experiencing constant acceleration can be described by the following:\n\\[x_f = \\frac{1}{2} a t^2 + v_0 t + x_0\\]\nWhere \\(x_0\\) and \\(x_f\\) are the initial and final locations, \\(v_0\\) is the initial velocity, and \\(a\\) is acceleration.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Polynomial Regression"
    ]
  },
  {
    "objectID": "notebooks/polynomial_regression.html#a-falling-ball",
    "href": "notebooks/polynomial_regression.html#a-falling-ball",
    "title": "Polynomial Regression",
    "section": "A falling ball",
    "text": "A falling ball\nFirst, we’ll consider a simple falling ball, released from 50 meters. In this situation, \\(v_0 = 0\\) \\(m\\)/\\(s\\), \\(x_0 = 50\\) \\(m\\) and \\(a = g\\), the acceleration due to gravity, \\(-9.81\\) \\(m\\)/\\(s^2\\). So dropping out the \\(v_0 t\\) component, the equation takes the form:\n\\[x_f = \\frac{1}{2} g t^2 + x_0\\]\nWe’ll start by simulating data for the first 2 seconds of motion. We will also assume some measurement error with a gaussian distribution of \\(\\sigma = 0.3\\).\n\ng = -9.81  # acceleration due to gravity (m/s^2)\nt = np.linspace(0, 2, 100)  # time in seconds\ninital_height = 50\nx_falling = 0.5 * g * t**2 + inital_height\n\nrng = np.random.default_rng(SEED)\nnoise = rng.normal(0, 0.3, x_falling.shape)\nx_obs_falling = x_falling + noise\ndf_falling = pd.DataFrame({\"t\": t, \"x\": x_obs_falling})\n\nfig, ax = plt.subplots(figsize=(10, 6))\nax.scatter(t, x_obs_falling, label=\"Observed Displacement\", color=\"C0\")\nax.plot(t, x_falling, label=\"True Function\", color=\"C1\")\nax.set(xlabel=\"Time (s)\", ylabel=\"Displacement (m)\")\nax.legend();\n\n\n\n\n\n\n\n\nCasting the equation \\(x_f = \\frac{1}{2} g t^2 + x_0\\) into a regression context, we let time (\\(t\\)) be the independent variable, and final location (\\(x_f\\)) be the response/dependent variable. This allows our coefficients to be proportional to \\(g\\) and \\(x_0\\). The intercept, \\(\\beta_0\\) corresponds exactly to \\(x_0\\). Letting \\(\\beta_1 = \\frac{1}{2} g\\) then gives \\(g = 2\\beta_1\\) when \\(x_1 = t^2\\), meaning we”re doing polynomial regression. We can put this into Bambi via the following, optionally including the + 1 to emphasize that we choose to include the coefficient.\n\nmodel_falling = bmb.Model(\"x ~ I(t**2) + 1\", df_falling)\nresults_falling = model_falling.fit(idata_kwargs={\"log_likelihood\": True}, random_seed=SEED)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, I(t ** 2)]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 2 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nThe term I(t**2) indicates to evaluate inside the I. For including just the \\(t^2\\) term, you can express it any of the following ways:\n\nI(t**2)\n{t**2}\nSquare the data directly, and pass it as a new column\n\nTo verify, we”ll fit the other two versions as well.\n\nmodel_falling_variation1 = bmb.Model(\n    \"x ~ {t**2} + 1\",  # Using {t**2} syntax\n    df_falling\n)\nresults_variation1 = model_falling_variation1.fit(random_seed=SEED)\n\nmodel_falling_variation2 = bmb.Model(\n    \"x ~ tsquared + 1\",  # Using data with the t variable squared\n    df_falling.assign(tsquared=t**2)  # Creating the tsquared variable for use in the formula\n)\nresults_variation2 = model_falling_variation2.fit(random_seed=SEED)\n\nprint(\"I{t**2} coefficient: \", round(results_falling.posterior[\"I(t ** 2)\"].values.mean(), 4))\nprint(\"{t**2} coefficient: \", round(results_variation1.posterior[\"I(t ** 2)\"].values.mean(), 4))\nprint(\"tsquared coefficient: \", round(results_variation2.posterior[\"tsquared\"].values.mean(), 4))\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, I(t ** 2)]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 2 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, tsquared]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 2 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nI{t**2} coefficient:  -4.8471\n{t**2} coefficient:  -4.8471\ntsquared coefficient:  -4.8471\n\n\nEach of these provides identical results, giving -4.9, which is \\(g/2\\). This makes the acceleration exactly the \\(-9.81\\) \\(m\\)/\\(s^2\\) acceleration that generated the data. Looking at our model summary,\n\naz.summary(results_falling)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nI(t ** 2)\n-4.847\n0.028\n-4.901\n-4.798\n0.000\n0.000\n3127.0\n1408.0\n1.0\n\n\nIntercept\n49.961\n0.051\n49.854\n50.050\n0.001\n0.001\n3125.0\n1233.0\n1.0\n\n\nsigma\n0.336\n0.024\n0.293\n0.383\n0.000\n0.000\n2550.0\n1595.0\n1.0\n\n\n\n\n\n\n\nWe see that both \\(g/2 = -4.9\\) (so \\(g=-9.81\\)) and the original height of \\(x_0 = 50\\) \\(m\\) are recovered, along with the injected noise.\nWe can then use the model to answer some questions, for example, when would the ball land? This would correspond to \\(x_f = 0\\).\n\\[\n0 = \\frac{1}{2} g t^2 - x_0\n\\]\n\\[\nt = \\sqrt{2x_0 / g}\n\\]\n\ncalculated_x0 = results_falling.posterior[\"Intercept\"].values.mean()\ncalculated_g = -2 * results_falling.posterior[\"I(t ** 2)\"].values.mean()\ncalculated_land = np.sqrt(2 * calculated_x0 / calculated_g)\nprint(f\"The ball will land at {round(calculated_land, 2)} seconds\")\n\nThe ball will land at 3.21 seconds\n\n\nOr if we want to account for our measurement error and use the full posterior,\n\ncalculated_x0_posterior = results_falling.posterior[\"Intercept\"].values\ncalculated_g_posterior = -2 * results_falling.posterior[\"I(t ** 2)\"].values\ncalculated_land_posterior = np.sqrt(2 * calculated_x0_posterior / calculated_g_posterior)\nlower_est = round(np.quantile(calculated_land_posterior, 0.025), 2)  \nupper_est = round(np.quantile(calculated_land_posterior, 0.975), 2)\nprint(f\"The ball landing will be measured between {lower_est} and {upper_est} seconds\")\n\nThe ball landing will be measured between 3.19 and 3.23 seconds",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Polynomial Regression"
    ]
  },
  {
    "objectID": "notebooks/polynomial_regression.html#projectile-motion",
    "href": "notebooks/polynomial_regression.html#projectile-motion",
    "title": "Polynomial Regression",
    "section": "Projectile Motion",
    "text": "Projectile Motion\nNext, instead of a ball strictly falling, instead imagine one thrown straight upward. In this case, we add the initial velocity back into the equation.\n\\[x_f = \\frac{1}{2} g t^2 + v_0 t + x_0\\]\nWe will envision the ball tossed upward, starting at 1.5 meters above ground level. It will be tossed at 7 m/s upward. It will also stop when hitting the ground.\n\nv0 = 7\nx0 = 1.5\nx_projectile = (1/2) * g * t**2 + v0 * t + x0\nnoise = rng.normal(0, 0.2, x_projectile.shape)\nx_obs_projectile = x_projectile + noise\ndf_projectile = pd.DataFrame({\"t\": t, \"tsq\": t**2, \"x\": x_obs_projectile, \"x_true\": x_projectile})\ndf_projectile = df_projectile[df_projectile[\"x\"] &gt;= 0]\n\nfig, ax = plt.subplots(figsize=(10, 6))\n\nax.scatter(df_projectile.t, df_projectile.x, label=\"Observed Displacement\", color=\"C0\")\nax.plot(df_projectile.t, df_projectile.x_true, label='True Function', color=\"C1\")\nax.set(xlabel=\"Time (s)\", ylabel=\"Displacement (m)\", ylim=(0, None))\nax.legend();\n\n\n\n\n\n\n\n\nModeling this using Bambi, we must include the linear term on time to capture the inital velocity. We’ll do the following regression,\n\\[x_f = \\beta_0 + \\beta_1 t + \\beta_2 t^2\\]\nWhich then maps the solved coefficents to the following: \\(\\beta_0 = x_0\\), \\(\\beta_1 = v_0\\), and \\(\\beta_2 = \\frac{g}{2}\\).\n\nmodel_projectile_all_terms = bmb.Model(\"x ~ I(t**2) + t + 1\", df_projectile)\nfit_projectile_all_terms = model_projectile_all_terms.fit(idata_kwargs={\"log_likelihood\": True}, target_accept=0.9, random_seed=SEED)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, I(t ** 2), t]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 8 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\naz.summary(fit_projectile_all_terms)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nI(t ** 2)\n-4.871\n0.114\n-5.090\n-4.665\n0.004\n0.003\n890.0\n936.0\n1.0\n\n\nIntercept\n1.560\n0.064\n1.442\n1.679\n0.002\n0.001\n1093.0\n1099.0\n1.0\n\n\nsigma\n0.202\n0.017\n0.171\n0.234\n0.000\n0.000\n1195.0\n1102.0\n1.0\n\n\nt\n6.913\n0.188\n6.565\n7.257\n0.006\n0.004\n897.0\n916.0\n1.0\n\n\n\n\n\n\n\n\nhdi = az.hdi(fit_projectile_all_terms.posterior, hdi_prob=0.95)\nprint(f\"Initial height: {hdi['Intercept'].sel(hdi='lower'):.2f} to {hdi['Intercept'].sel(hdi='higher'):.2f} meters (True: {x0} m)\")\nprint(f\"Initial velocity: {hdi['t'].sel(hdi='lower'):.2f} to {hdi['t'].sel(hdi='higher'):.2f} meters per second (True: {v0} m/s)\")\nprint(f\"Acceleration: {2*hdi['I(t ** 2)'].sel(hdi='lower'):.2f} to {2*hdi['I(t ** 2)'].sel(hdi='higher'):.2f} meters per second squared (True: {g} m/s^2)\")\n\nInitial height: 1.44 to 1.68 meters (True: 1.5 m)\nInitial velocity: 6.53 to 7.26 meters per second (True: 7 m/s)\nAcceleration: -10.17 to -9.30 meters per second squared (True: -9.81 m/s^2)\n\n\nWe once again are able to recover all our input parameters.\nIn addition to directly calculating all terms, to include all polynomial terms up to a given degree you can use the poly keyword. We don’t do that in this notebook for two reasons. First, by default it orthogonalizes the terms making it ill-suited to this example since the coefficients have physical meaning. For more information on the orthogonalization, please see the orthogonal polynomial notebook. The orthogonalization process can be disabled by the raw argument of poly, but we still elect not to use it because in later examples we decide to use different effects on the \\(t\\) term vs the \\(t^2\\) term, and doing so is not easy when using poly. However, just to show that the results match when using the raw = True argument, we’ll fit the same model as above.\n\nmodel_poly_raw = bmb.Model(\"x ~ poly(t, 2, raw=True)\", df_projectile)\nfit_poly_raw = model_poly_raw.fit(idata_kwargs={\"log_likelihood\": True}, random_seed=SEED)\naz.summary(fit_poly_raw)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, poly(t, 2, raw=True)]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 7 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n1.562\n0.064\n1.446\n1.686\n0.002\n0.001\n1220.0\n1319.0\n1.0\n\n\npoly(t, 2, raw=True)[0]\n6.910\n0.183\n6.538\n7.237\n0.006\n0.004\n977.0\n1077.0\n1.0\n\n\npoly(t, 2, raw=True)[1]\n-4.869\n0.110\n-5.084\n-4.670\n0.003\n0.002\n1004.0\n1184.0\n1.0\n\n\nsigma\n0.202\n0.017\n0.171\n0.234\n0.000\n0.000\n1399.0\n1215.0\n1.0\n\n\n\n\n\n\n\nWe see the same results, where poly(t, 2, raw=True)[0] corresponds to the coefficient on \\(t\\) (\\(v_0\\) in our example), and poly(t, 2, raw=True)[1] is the coefficient on \\(t^2\\) (\\(\\frac{g}{2}\\)).",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Polynomial Regression"
    ]
  },
  {
    "objectID": "notebooks/polynomial_regression.html#measuring-gravity-on-a-new-planet",
    "href": "notebooks/polynomial_regression.html#measuring-gravity-on-a-new-planet",
    "title": "Polynomial Regression",
    "section": "Measuring gravity on a new planet",
    "text": "Measuring gravity on a new planet\nIn the next example, you’ve been recruited to join the space program as a research scientist, looking to directly measure the gravity on a new planet, PlanetX. You don’t know anything about this planet or it’s safety, so you have time for one, and only one, throw of a ball. However, you’ve perfected your throwing mechanics, and can achieve the same initial velocity wherever you are. To baseline, you make a toss on planet Earth, warm up your spacecraft and stop at Mars to make a toss, then travel far away, and make a toss on PlanetX.\nFirst we simulate data for this experiment.\n\ndef simulate_throw(v0, g, noise_std, time_step=0.25, max_time=10, seed=1234):\n    rng = np.random.default_rng(seed)\n    times = np.arange(0, max_time, time_step)\n    heights = v0 * times - 0.5 * g * times**2\n    heights_with_noise = heights + rng.normal(0, noise_std, len(times))    \n    valid_indices = heights_with_noise &gt;= 0\n    return times[valid_indices], heights_with_noise[valid_indices], heights[valid_indices]\n\n# Define the parameters\nv0 = 20  # Initial velocity (m/s)\ng_planets = {\"Earth\": 9.81, \"Mars\": 3.72, \"PlanetX\": 6.0}  # Gravitational acceleration (m/s^2)\nnoise_std = 1.5  # Standard deviation for noise\n\n# Generate data\nrecords = []\nfor planet, g in g_planets.items():\n    times, heights, heights_true = simulate_throw(v0, g, noise_std)\n    for time, height, height_true in zip(times, heights, heights_true):\n        records.append([planet, time, height, height_true])\n\n# Convert to a DataFrame\ndf = pd.DataFrame(records, columns=[\"Planet\", \"Time\", \"Height\", \"Height_true\"])\ndf[\"Planet\"] = df[\"Planet\"].astype(\"category\")\n\nAnd drawing those trajectories,\n\nfig, ax = plt.subplots(figsize=(10, 6))\n\nfor i, planet in enumerate(df[\"Planet\"].cat.categories):\n    subset = df[df[\"Planet\"] == planet]\n    ax.plot(subset[\"Time\"], subset[\"Height_true\"], alpha=0.7, color=f\"C{i}\")\n    ax.scatter(subset[\"Time\"], subset[\"Height\"], alpha=0.7, label=planet, color=f\"C{i}\")\n\nax.set(\n    xlabel=\"Time (seconds)\", ylabel=\"Height (meters)\", title=\"Trajectory Comparison\", ylim=(0, None)\n)\nax.legend(title=\"Planet\");\n\n\n\n\n\n\n\n\nWe now aim to model this data. We again use the folowing equation (calling displacement \\(h\\) for height):\n\\[\nh = \\frac{1}{2} g_{p} t^2 + v_{0} t\n\\]\nwhere \\(g_p\\) now has a subscript to indicate the planet that we’re throwing from.\nIn Bambi, we’ll do the following:\nHeight ~ I(Time**2):Planet + Time + 0\nwhich corresponds one-to-one with the above formula. The intercept is eliminated since we start from \\(x=0\\).\n\nplanet_model = bmb.Model(\"Height ~ I(Time**2):Planet + Time + 0\", df)\nplanet_model.build()\nplanet_model.graph()\n\n\n\n\n\n\n\n\n\nplanet_fit = planet_model.fit(chains=4, idata_kwargs={\"log_likelihood\": True}, random_seed=SEED)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 2 jobs)\nNUTS: [sigma, I(Time ** 2):Planet, Time]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 13 seconds.\n\n\nThe model has fit. Let’s look at how we did recovering the simulated parameters.\n\naz.summary(planet_fit)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nI(Time ** 2):Planet[Earth]\n-4.995\n0.076\n-5.139\n-4.855\n0.002\n0.001\n1659.0\n1779.0\n1.0\n\n\nI(Time ** 2):Planet[Mars]\n-1.883\n0.022\n-1.926\n-1.843\n0.001\n0.000\n1229.0\n1533.0\n1.0\n\n\nI(Time ** 2):Planet[PlanetX]\n-3.016\n0.036\n-3.083\n-2.949\n0.001\n0.001\n1352.0\n1739.0\n1.0\n\n\nTime\n20.123\n0.165\n19.812\n20.429\n0.005\n0.003\n1235.0\n1703.0\n1.0\n\n\nsigma\n1.756\n0.144\n1.516\n2.043\n0.003\n0.002\n1806.0\n2076.0\n1.0\n\n\n\n\n\n\n\nGetting the gravities back to the physical value,\n\nhdi = az.hdi(planet_fit.posterior, hdi_prob=0.95)\nprint(f\"g for Earth: {2*hdi['I(Time ** 2):Planet'].sel({'I(Time ** 2):Planet_dim':'Earth', 'hdi':'lower'}):.2f} to {2*hdi['I(Time ** 2):Planet'].sel({'I(Time ** 2):Planet_dim':'Earth', 'hdi':'higher'}):.2f} meters (True: -9.81 m)\")\nprint(f\"g for Mars: {2*hdi['I(Time ** 2):Planet'].sel({'I(Time ** 2):Planet_dim':'Mars', 'hdi':'lower'}):.2f} to {2*hdi['I(Time ** 2):Planet'].sel({'I(Time ** 2):Planet_dim':'Mars', 'hdi':'higher'}):.2f} meters (True: -3.72 m)\")\nprint(f\"g for PlanetX: {2*hdi['I(Time ** 2):Planet'].sel({'I(Time ** 2):Planet_dim':'PlanetX', 'hdi':'lower'}):.2f} to {2*hdi['I(Time ** 2):Planet'].sel({'I(Time ** 2):Planet_dim':'PlanetX', 'hdi':'higher'}):.2f} meters (True: -6.0 m)\")\nprint(f\"Initial velocity: {hdi['Time'].sel(hdi='lower'):.2f} to {hdi['Time'].sel(hdi='higher'):.2f} meters per second (True: 20 m/s)\")\n\ng for Earth: -10.30 to -9.70 meters (True: -9.81 m)\ng for Mars: -3.85 to -3.68 meters (True: -3.72 m)\ng for PlanetX: -6.18 to -5.90 meters (True: -6.0 m)\nInitial velocity: 19.79 to 20.43 meters per second (True: 20 m/s)\n\n\nWe can see that we’re pretty close to recovering most the parameters, but the fit isn’t great. Plotting the posteriors for \\(g\\) agsint the true values,\n\nearth_posterior = -2 * planet_fit.posterior[\"I(Time ** 2):Planet\"].sel({\"I(Time ** 2):Planet_dim\": \"Earth\"})\nplanetx_posterior = -2 * planet_fit.posterior[\"I(Time ** 2):Planet\"].sel({\"I(Time ** 2):Planet_dim\": \"PlanetX\"})\nmars_posterior = -2 * planet_fit.posterior[\"I(Time ** 2):Planet\"].sel({\"I(Time ** 2):Planet_dim\": \"Mars\"}) \n\nfig, axs = plt.subplots(1, 3, figsize=(12, 6))\naz.plot_posterior(earth_posterior, ref_val=9.81, ax=axs[0])\naxs[0].set_title(\"Posterior $g$ on Earth\")\naz.plot_posterior(mars_posterior, ref_val=3.72, ax=axs[1])\naxs[1].set_title(\"Posterior $g$ on Mars\")\naz.plot_posterior(planetx_posterior, ref_val=6.0, ax=axs[2])\naxs[2].set_title(\"Posterior $g$ on PlanetX\");\n\n\n\n\n\n\n\n\nThe fit seems to work, more or less, but certainly could be improved.\n\nAdding a prior\nBut, we can do better! We have a very good idea of the acceleration due to gravity on Earth and Mars, so why not use that information? From an experimental standpoint, we can consider these throws from a calibration mindset, allowing us to get some information on the resolution of our detector, and our throwing apparatus. The model will spend considerably less time trying pin down those parameters, and will better explore other parameters with already good values of the \\(g\\) terms locked in.\nFor Earth, at the extremes, \\(g\\) takes values as low as 9.78 \\(m\\)/\\(s^2\\) (at the Equator) up to 9.83 (at the Poles). So we can add a very strong prior,\n\\[\ng_{\\text{Earth}} \\sim \\text{Normal}(-9.81, 0.025)\n\\]\nFor Mars, we know the mean value is about 3.72 \\(m\\)/\\(s^2\\). There’s less information on local variation readily available by a cursory search, however we know that the radius of Mars is about half that of Earth, so \\(\\sigma = \\frac{0.025}{2} = 0.0125\\) might make sense, but to be conservative we’ll round that up to \\(\\sigma = 0.02\\).\n\\[\ng_{\\text{Mars}} \\sim \\text{Normal}(-3.72, 0.02)\n\\]\nFor PlanetX, we must use a very loose prior. We might say that we know the ball took longer to fall than Earth, but not as long as on Mars, so we can split the difference. Then set a very wide \\(\\sigma\\) value.\n\\[\ng_{\\text{PlanetX}} \\sim \\text{Normal}(\\frac{-9.81 - 3.72}{2}, 3) = \\text{Normal}(-6.77, 3)\n\\]\nSince these correspond to \\(g/2\\), we’ll divide all values by 2 when putting them into Bambi. Additionally, we know the balls landed eventually, so \\(g\\) must be negative. We’ll truncate the upper limit of the distribution at 0.\nNow, for defining this in Bambi, the term of interest is I(Time ** 2):Planet. Often, you set one prior that applies to all groups, however, if you want to set each group individually, you can pass a list to the bmb.Prior definition. The broadcasting rules from PyMC apply here, so it could equivalently take a numpy array. You’ll notice that the priors are passed alphabetically by group name.\n\n\npriors = {\n    \"I(Time ** 2):Planet\": bmb.Prior(\n        \"TruncatedNormal\",\n        mu=[\n            -9.81/2,  # Earth\n            -3.72/2,  # Mars\n            -6.77/2    # PlanetX\n        ],\n        sigma=[ \n            0.025/2,  # Earth \n            0.02/2,   # Mars\n            3/2       # PlanetX\n        ],\n        upper=[0, 0, 0]\n    )} \n\nplanet_model_with_prior = bmb.Model(\n    'Height ~ I(Time**2):Planet + Time + 0',\n    df,\n    priors=priors\n)\n\nplanet_model_with_prior.build()\nidata = planet_model_with_prior.prior_predictive()\naz.summary(idata.prior, kind=\"stats\")\n\nSampling: [Height, I(Time ** 2):Planet, Time, sigma]\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\nI(Time ** 2):Planet[Earth]\n-4.905\n0.012\n-4.927\n-4.881\n\n\nI(Time ** 2):Planet[Mars]\n-1.860\n0.010\n-1.875\n-1.839\n\n\nI(Time ** 2):Planet[PlanetX]\n-3.407\n1.440\n-6.275\n-0.874\n\n\nTime\n-0.552\n15.200\n-23.585\n30.847\n\n\nmu[0]\n-0.445\n3.800\n-6.203\n7.405\n\n\n...\n...\n...\n...\n...\n\n\nmu[77]\n-115.814\n100.895\n-286.910\n72.314\n\n\nmu[78]\n-125.960\n106.379\n-309.774\n69.448\n\n\nmu[79]\n-136.532\n111.989\n-330.351\n68.152\n\n\nmu[80]\n-147.529\n117.726\n-351.004\n67.998\n\n\nsigma\n14.737\n13.655\n0.044\n37.748\n\n\n\n\n86 rows × 4 columns\n\n\n\nHere we’ve sampled the prior predictive and can see that our priors are correctly specified to the associated planets.\nNext we fit the model.\n\nplanet_fit_with_prior = planet_model_with_prior.fit(chains=4, idata_kwargs={\"log_likelihood\": True}, random_seed=SEED)\naz.summary(planet_fit_with_prior)\nplanet_model_with_prior.predict(planet_fit_with_prior, kind=\"pps\");\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 2 jobs)\nNUTS: [sigma, I(Time ** 2):Planet, Time]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 17 seconds.\n\n\n\naz.summary(planet_fit_with_prior)[0:5]\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nI(Time ** 2):Planet[Earth]\n-4.907\n0.012\n-4.928\n-4.884\n0.000\n0.000\n4359.0\n3199.0\n1.0\n\n\nI(Time ** 2):Planet[Mars]\n-1.862\n0.008\n-1.878\n-1.846\n0.000\n0.000\n2657.0\n2611.0\n1.0\n\n\nI(Time ** 2):Planet[PlanetX]\n-2.985\n0.022\n-3.026\n-2.944\n0.000\n0.000\n3121.0\n2938.0\n1.0\n\n\nTime\n19.958\n0.074\n19.830\n20.105\n0.001\n0.001\n2514.0\n2572.0\n1.0\n\n\nsigma\n1.753\n0.140\n1.508\n2.027\n0.002\n0.002\n3667.0\n3010.0\n1.0\n\n\n\n\n\n\n\nWe see some improvements here! Off the cuff, these look better, you’ll notice the \\(v_0\\) coefficient on Time covers the true value of 20 m/s.\nNow taking a look at the effects before and after adding the prior on the gravities,\n\nearth_posterior_2 = -2 *  planet_fit_with_prior.posterior[\"I(Time ** 2):Planet\"].sel({\"I(Time ** 2):Planet_dim\": \"Earth\"})\nmars_posterior_2 = -2 * planet_fit_with_prior.posterior[\"I(Time ** 2):Planet\"].sel({\"I(Time ** 2):Planet_dim\": \"Mars\"})\nplanetx_posterior_2 = -2 * planet_fit_with_prior.posterior[\"I(Time ** 2):Planet\"].sel({\"I(Time ** 2):Planet_dim\": \"PlanetX\"})\n\nfig, axs = plt.subplots(2, 3, figsize=(12, 6), sharex='col')\naz.plot_posterior(earth_posterior, ref_val=9.81, ax=axs[0,0])\naxs[0,0].set_title(\"Earth $g$ - No Prior\")\naz.plot_posterior(mars_posterior, ref_val=3.72, ax=axs[0,1])\naxs[0,1].set_title(\"Mars $g$ - No Prior\")\naz.plot_posterior(planetx_posterior, ref_val=6.0, ax=axs[0,2])\naxs[0,2].set_title(\"PlanetX $g$ - No Prior\")\n\naz.plot_posterior(earth_posterior_2, ref_val=9.81, ax=axs[1,0])\naxs[1,0].set_title(\"Earth $g$ - Priors Used\")\naz.plot_posterior(mars_posterior_2, ref_val=3.72, ax=axs[1,1])\naxs[1,1].set_title(\"Mars $g$ - Priors Used\")\naz.plot_posterior(planetx_posterior_2, ref_val=6.0, ax=axs[1,2])\naxs[1,2].set_title(\"PlanetX $g$ - Priors Used\");\n\n\n\n\n\n\n\n\nAdding the prior gives smaller uncertainties for Earth and Mars by design, however, we can see the estimate for PlanetX has also considerably improved by injecting our knowledge into the model.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sun May 26 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\npandas    : 2.2.2\nnumpy     : 1.26.4\narviz     : 0.18.0\nmatplotlib: 3.8.4\nbambi     : 0.13.1.dev39+gb7d6a6cb\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Polynomial Regression"
    ]
  },
  {
    "objectID": "notebooks/plot_predictions.html",
    "href": "notebooks/plot_predictions.html",
    "title": "Plot Conditional Adjusted Predictions",
    "section": "",
    "text": "This notebook shows how to use, and the capabilities, of the plot_predictions function. The plot_predictions function is a part of Bambi’s sub-package interpret that features a set of tools used to interpret complex regression models that is inspired by the R package marginaleffects.",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Plot Conditional Adjusted Predictions"
    ]
  },
  {
    "objectID": "notebooks/plot_predictions.html#interpreting-generalized-linear-models",
    "href": "notebooks/plot_predictions.html#interpreting-generalized-linear-models",
    "title": "Plot Conditional Adjusted Predictions",
    "section": "Interpreting Generalized Linear Models",
    "text": "Interpreting Generalized Linear Models\nThe purpose of the generalized linear model (GLM) is to unify the approaches needed to analyze data for which either: (1) the assumption of a linear relation between \\(x\\) and \\(y\\), or (2) the assumption of normal variation is not appropriate. GLMs are typically specified in three stages: 1. the linear predictor \\(\\eta = X\\beta\\) where \\(X\\) is an \\(n\\) x \\(p\\) matrix of explanatory variables. 2. the link function \\(g(\\cdot)\\) that relates the linear predictor to the mean of the outcome variable \\(\\mu = g^{-1}(\\eta) = g^{-1}(X\\beta)\\) 3. the random component specifying the distribution of the outcome variable \\(y\\) with mean \\(\\mathbb{E}(y|X) = \\mu\\).\nBased on these three specifications, the mean of the distribution of \\(y\\), given \\(X\\), is determined by \\(X\\beta: \\mathbb{E}(y|X) = g^{-1}(X\\beta)\\).\nGLMs are a broad family of models where the output \\(y\\) is typically assumed to follow an exponential family distribution, e.g., Binomial, Poisson, Gamma, Exponential, and Normal. The job of the link function is to map the linear space of the model \\(X\\beta\\) onto the non-linear space of a parameter like \\(\\mu\\). Commonly used link function are the logit and log link. Also known as the canonical link functions. This brief introduction to GLMs is not meant to be exhuastive, and another good starting point is the Bambi Basic Building Blocks example.\nDue to the link function, there are typically three quantities of interest to interpret in a GLM: 1. the linear predictor \\(\\eta\\) 2. the mean \\(\\mu = g^{-1}(\\eta)\\) 3. the response variable \\(Y \\sim \\mathcal{D}(\\mu, \\theta)\\) where \\(\\mu\\) is the mean parameter and \\(\\theta\\) is (possibly) a vector that contains all the other “nuissance” parameters of the distribution.\nAs modelers, we are usually more interested in interpreting (2) and (3). However, \\(\\mu\\) is not always on the same scale of the response variable and can be more difficult to interpret. Rather, the response scale is a more interpretable scale. Additionally, it is often the case that modelers would like to analyze how a model parameter varies across a range of explanatory variable values. To achieve such an analysis, Bambi has taken inspiration from the R package marginaleffects, and implemented a plot_predictions function that plots the conditional adjusted predictions to aid in the interpretation of GLMs. Below, it is briefly discussed what are conditionally adjusted predictions, how they are computed, and ultimately how to use the plot_predictions function.",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Plot Conditional Adjusted Predictions"
    ]
  },
  {
    "objectID": "notebooks/plot_predictions.html#conditionally-adjusted-predictions",
    "href": "notebooks/plot_predictions.html#conditionally-adjusted-predictions",
    "title": "Plot Conditional Adjusted Predictions",
    "section": "Conditionally Adjusted Predictions",
    "text": "Conditionally Adjusted Predictions\nAdjusted predictions refers to the outcome predicted by a fitted model on a specified scale for a given combination of values of the predictor variables, such as their observed values, their means, or some user specified grid of values. The specification of the scale to make the predictions, the link or response scale, refers to the scale used to estimate the model. In normal linear regression, the link scale and the response scale are identical, and therefore, the adjusted prediction is expressed as the mean value of the response variable at the given values of the predictor variables. On the other hand, a logistic regression’s link and response scale are not identical. An adjusted prediction on the link scale will be represented as the log-odds of a successful response given values of the predictor variables. Whereas an adjusted prediction on the response scale gives the probability that the response variable equals 1. The conditional part of conditionally adjusted predictions represents the specific predictor(s) and its values we would like to condition on when plotting predictions.\n\nComputing Adjusted Predictions\nThe objective of plotting conditional adjusted predictions is to visualize how a parameter of the (conditional) response distribution varies as a function of (some) explanatory variables. In predictions, there are three scenarios to compute conditional adjusted predictions:\n\nuser provided values\na grid of equally spaced and central values\nempirical distribution (original data used to fit the model)\n\nIn the case of (1) above, a dictionary is passed with the explanatory variables as keys, and the values to condition on are the values. With this dictionary, Bambi assembles all pairwise combinations (transitions) of the specified explanatory variables into a new “hypothetical” dataset. Covariates not existient in the dictionary are held at their mean or mode.\nIn (2), a string or list is passed with the name(s) of the explanatory variable(s) to create a grid of equally spaced values. This is done by holding all other explanatory variables constant at some specified value, a reference grid, that may or may not correspond to actual observations in the dataset used to fit the model. By default, the plot_predictions function uses a grid of 200 equally spaced values between the minimum and maximum values of the specified explanatory variable as the reference grid.\nLastly, in (3), the original data used to fit the model is used to compute predictions. This is known as unit level predictions.\nUsing the data, from scenario 1, 2, or 3, the plot_predictions function uses the fitted model to then compute the predictions. The plot_predictions function then uses these predictions to plot the model parameter as a function of (some) explanatory variable.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport warnings\n\nimport bambi as bmb\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Plot Conditional Adjusted Predictions"
    ]
  },
  {
    "objectID": "notebooks/plot_predictions.html#gaussian-linear-model",
    "href": "notebooks/plot_predictions.html#gaussian-linear-model",
    "title": "Plot Conditional Adjusted Predictions",
    "section": "Gaussian Linear Model",
    "text": "Gaussian Linear Model\nFor the first demonstration, we will use a Gaussian linear regression model with the mtcars dataset to better understand the plot_predictions function and its arguments. The mtcars dataset was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models). The following is a brief description of the variables in the dataset:\n\nmpg: Miles/(US) gallon\ncyl: Number of cylinders\ndisp: Displacement (cu.in.)\nhp: Gross horsepower\ndrat: Rear axle ratio\nwt: Weight (1000 lbs)\nqsec: 1/4 mile time\nvs: Engine (0 = V-shaped, 1 = straight)\nam: Transmission (0 = automatic, 1 = manual)\ngear: Number of forward gear\n\n\n# Load data\ndata = bmb.load_data('mtcars')\ndata[\"cyl\"] = data[\"cyl\"].replace({4: \"low\", 6: \"medium\", 8: \"high\"})\ndata[\"gear\"] = data[\"gear\"].replace({3: \"A\", 4: \"B\", 5: \"C\"})\ndata[\"cyl\"] = pd.Categorical(data[\"cyl\"], categories=[\"low\", \"medium\", \"high\"], ordered=True)\n\n# Define and fit the Bambi model\nmodel = bmb.Model(\"mpg ~ 0 + hp * wt + cyl + gear\", data)\nidata = model.fit(draws=1000, target_accept=0.95, random_seed=1234)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [sigma, hp, wt, hp:wt, cyl, gear]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 147 seconds.\n\n\nWe can print the Bambi model object to obtain the model components. Below, we see that the Gaussian linear model uses an identity link function that results in no transformation of the linear predictor to the mean of the outcome variable, and the distrbution of the likelihood is Gaussian.\n\nDefault values\nNow that we have fitted the model, we can visualize how a model parameter varies as a function of (some) interpolated covariate. For this example, we will visualize how the mean response mpg varies as a function of the covariate hp.\nThe Bambi model, ArviZ inference data object (containing the posterior samples and the data used to fit the model), and a list or dictionary of covariates, in this example only hp, are passed to the plot_predictions function. The plot_predictions function then computes the conditional adjusted predictions for each covariate in the list or dictionary using the method described above. The plot_predictions function returns a matplotlib figure object that can be further customized.\n\nfig, ax = plt.subplots(figsize=(7, 3), dpi=120)\nbmb.interpret.plot_predictions(model, idata, \"hp\", ax=ax);\n\nDefault computed for conditional variable: hp\nDefault computed for unspecified variable: cyl, gear, wt\n\n\n\n\n\n\n\n\n\nBefore we talk about the plot, you will notice that some messages have been logged to the console. By default interpret is verbose and logs a message to the console if a default value is computed for covariates in conditional. This is useful because unless the documentation is read, it can be difficult to tell which covariates are having default values computed for. Thus, Bambi has a config file bmb.config[\"INTERPRET_VERBOSE\"] where we can specify whether or not to log messages. By default, this is set to true. To turn off logging, set bmb.config[\"INTERPRET_VERBOSE\"] = False. From here on, we will turn off logging.\nThe plot above shows that as hp increases, the mean mpg decreases. As stated above, this insight was obtained by creating the reference grid and then using the fitted model to compute the predicted values of the model parameter, in this example mpg, at each value of the reference grid.\nBy default, plot_predictions uses the highest density interval (HDI) of the posterior distribution to compute the credible interval of the conditional adjusted predictions. The HDI is a Bayesian analog to the frequentist confidence interval. The HDI is the shortest interval that contains a specified probability of the posterior distribution. By default, plot_predictions uses the 94% HDI.\nplot_predictions uses the posterior distribution by default to visualize some mean outcome parameter . However, the posterior predictive distribution can also be plotted by specifying pps=True where pps stands for posterior predictive samples of the response variable.\n\nbmb.config[\"INTERPRET_VERBOSE\"] = False\n\n\nfig, ax = plt.subplots(figsize=(7, 3), dpi=120)\nbmb.interpret.plot_predictions(model, idata, \"hp\", pps=True, ax=ax);\n\n\n\n\n\n\n\n\nHere, we notice that the uncertainty in the conditional adjusted predictions is much larger than the uncertainty when pps=False. This is because the posterior predictive distribution accounts for the uncertainty in the model parameters and the uncertainty in the data. Whereas, the posterior distribution only accounts for the uncertainty in the model parameters.\nAdditionally, predictions can be called to obtain a summary dataframe of the data, mean predictions (estimate), and uncertainty interval. The covariate columns in this dataframe is used to create the plot.\n\nsummary_df = bmb.interpret.predictions(model, idata, \"hp\", pps=True)\nsummary_df.head(10)\n\n\n\n\n\n\n\n\nhp\ncyl\ngear\nwt\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\n52\nhigh\nA\n3.21725\n21.753967\n15.879149\n28.467278\n\n\n1\n57\nhigh\nA\n3.21725\n21.626621\n15.401400\n28.073208\n\n\n2\n63\nhigh\nA\n3.21725\n21.380708\n15.193230\n27.758124\n\n\n3\n69\nhigh\nA\n3.21725\n21.220707\n15.203868\n27.537716\n\n\n4\n75\nhigh\nA\n3.21725\n21.016281\n15.097675\n27.076450\n\n\n5\n80\nhigh\nA\n3.21725\n20.824757\n15.074355\n26.626349\n\n\n6\n86\nhigh\nA\n3.21725\n20.597090\n14.910748\n26.088777\n\n\n7\n92\nhigh\nA\n3.21725\n20.307775\n14.679274\n25.904986\n\n\n8\n98\nhigh\nA\n3.21725\n20.240255\n14.765620\n25.693768\n\n\n9\n103\nhigh\nA\n3.21725\n19.970688\n14.348661\n25.422012\n\n\n\n\n\n\n\nplot_predictions allows up to three covariates to be plotted simultaneously where the first element in the list represents the main (x-axis) covariate, the second element the group (hue / color), and the third element the facet (panel). However, when plotting more than one covariate, it can be useful to pass specific group and panel arguments to aid in the interpretation of the plot. Therefore, subplot_kwargs allows the user to manipulate the plotting by passing a dictionary where the keys are {\"main\": ..., \"group\": ..., \"panel\": ...} and the values are the names of the covariates to be plotted. For example, passing two covariates hp and wt and specifying subplot_kwargs={\"main\": \"hp\", \"group\": \"wt\", \"panel\": \"wt\"}.\n\nbmb.interpret.plot_predictions(\n    model=model, \n    idata=idata, \n    conditional={\"hp\": np.linspace(50, 350, 50), \"wt\": np.linspace(1, 6, 5)},\n    legend=False,\n    subplot_kwargs={\"main\": \"hp\", \"group\": \"wt\", \"panel\": \"wt\"},\n    fig_kwargs={\"figsize\": (20, 8), \"sharey\": True}\n)\nplt.tight_layout();\n\n\n\n\n\n\n\n\nFurthermore, categorical covariates can also be plotted. We plot the the mean mpg as a function of the two categorical covariates gear and cyl below. The plot_predictions function automatically plots the conditional adjusted predictions for each level of the categorical covariate. Furthermore, when passing a list of covariates into the plot_predictions function, the list will be converted into a dictionary object where the key is taken from (“horizontal”, “color”, “panel”) and the values are the names of the variables. By default, the first element of the list is specified as the “horizontal” covariate, the second element of the list is specified as the “color” covariate, and the third element of the list is mapped to different plot panels.\n\nfig, ax = plt.subplots(figsize=(7, 3), dpi=120)\nbmb.interpret.plot_predictions(model, idata, [\"gear\", \"cyl\"], ax=ax);\n\n\n\n\n\n\n\n\n\n\nUser provided values\nIn the previous example, default values were computed to construct a reference grid to compute the conditional adjusted predictions. We can also pass our own values for the covariates into conditional using a dictionary where the key-value pairs are the covariate and value(s) of interest. For example, if we wanted to compute the predictions for hp=100, wt=[1.5, 3.5], and cyl=[\"low\", \"medium\", \"high\"] we would pass the following dictionary in the code block below. As can be seen, several data types can be passed such as: np.ndarray, list, int, float, and str.\nFurthermore, Bambi by default, maps the order of the dict keys to the main, group, and panel of the matplotlib figure. Below, since hp is the first key, this is used for the x-axis, wt for the group (color), and cyl for the panel (facet).\n\nbmb.interpret.plot_predictions(\n    model,\n    idata,\n    conditional={\n        \"hp\": [100, 120],\n        \"wt\": np.array([1.5, 3.5]),\n        \"cyl\": [\"low\", \"medium\", \"high\"]\n        },\n   fig_kwargs={\"figsize\": (10, 4), \"sharey\": True}\n);\n\n\n\n\n\n\n\n\nBefore the plot is described, lets see how the dictionary passed to conditional was used to create the dataset in order to compute predictions.\n\nsummary_df = bmb.interpret.predictions(\n    model,\n    idata,\n    conditional={\n        \"hp\": [100, 120],\n        \"wt\": np.array([1.5, 3.5]),\n        \"cyl\": [\"low\", \"medium\", \"high\"]\n        },\n)\nsummary_df\n\n\n\n\n\n\n\n\nhp\nwt\ncyl\ngear\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\n100\n1.5\nhigh\nA\n26.566766\n21.969808\n30.943151\n\n\n1\n100\n1.5\nlow\nA\n27.329344\n23.732834\n31.023226\n\n\n2\n100\n1.5\nmedium\nA\n25.571809\n21.451557\n29.660434\n\n\n3\n100\n3.5\nhigh\nA\n19.050509\n15.782297\n22.263920\n\n\n4\n100\n3.5\nlow\nA\n19.813088\n16.472862\n23.414660\n\n\n5\n100\n3.5\nmedium\nA\n18.055552\n15.632819\n20.474585\n\n\n6\n120\n1.5\nhigh\nA\n25.300803\n21.208498\n29.449365\n\n\n7\n120\n1.5\nlow\nA\n26.063382\n21.954223\n29.802325\n\n\n8\n120\n1.5\nmedium\nA\n24.305846\n20.088821\n28.257285\n\n\n9\n120\n3.5\nhigh\nA\n18.441151\n15.569090\n20.982979\n\n\n10\n120\n3.5\nlow\nA\n19.203729\n15.518468\n22.845879\n\n\n11\n120\n3.5\nmedium\nA\n17.446194\n14.967520\n19.927605\n\n\n\n\n\n\n\nWhen a dictionary is passed, that informs Bambi that the user wants to compute predictions on user provided values. Thus, a pairwise grid is constructed using the dictionary values. Otherwise, a dataframe of unequal array lengths cannot be constructed. Furthermore, since gear was not passed as a key, but was a term in the model, the default value of A was computed for it.\nGiven we now know that a pairwise grid was computed usiong the conditional dict, One interpretation of the plot above is that across all cylinder groups, a larger wt results in a lower mean mpg.\n\n\nUnit level predictions\nIn the previous example, user provided values were computed to construct a pairwise grid to compute the conditional adjusted predictions. It is also possible to compute predictions using the observed (empirical) data used to fit the model and then average over a specific or set of covariates to obtain average adjusted predictions. This is known as unit level predictions. To compute unit level predictions, do not pass any values to the conditional arg. and or specify None (the default).\n\nsummary_df = bmb.interpret.predictions(\n    model,\n    idata,\n    conditional=None\n)\nsummary_df.head()\n\n\n\n\n\n\n\n\ncyl\ngear\nhp\nwt\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\nmedium\nB\n110\n2.620\n22.233743\n20.121823\n24.395500\n\n\n1\nmedium\nB\n110\n2.875\n21.317279\n19.250855\n23.284851\n\n\n2\nlow\nB\n93\n2.320\n25.916714\n24.242191\n27.574153\n\n\n3\nmedium\nA\n110\n3.215\n18.775156\n16.444976\n21.276683\n\n\n4\nhigh\nA\n175\n3.440\n16.917035\n15.219165\n18.653843\n\n\n\n\n\n\n\n\n# data used to fit the model\nmodel.data[[\"cyl\", \"gear\", \"hp\", \"wt\"]].head()\n\n\n\n\n\n\n\n\ncyl\ngear\nhp\nwt\n\n\n\n\n0\nmedium\nB\n110\n2.620\n\n\n1\nmedium\nB\n110\n2.875\n\n\n2\nlow\nB\n93\n2.320\n\n\n3\nmedium\nA\n110\n3.215\n\n\n4\nhigh\nA\n175\n3.440\n\n\n\n\n\n\n\nNotice how the data in the summary dataframe and model data are the same.\n\nMarginalizing over covariates\nSince the empirical distrubution is used for computing predictions, the same number of rows (\\(32\\)) is returned as the data used to fit the model. To average over a covariate, use the average_by argument. If True is passed, then predictions averages over all covariates and a single estimate is returned. Else, if a single or list of covariates are passed, then predictions averages by the covariates passed.\n\nsummary_df = bmb.interpret.predictions(\n    model,\n    idata,\n    conditional=None,\n    average_by=True\n)\nsummary_df\n\n\n\n\n\n\n\n\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\n20.06417\n17.895285\n22.250253\n\n\n\n\n\n\n\n\n\nAverage by subgroups\nIt is still possible to plot predictions when computing unit level predictions. However, now a covariate(s) must be passed to average_by to obtain average adjusted predictions by group. In the plot below, we obtain average predictions grouped by gear and cyl.\n\nbmb.interpret.plot_predictions(\n    model,\n    idata,\n    conditional=None,\n    average_by=[\"gear\", \"cyl\"],\n    fig_kwargs={\"figsize\": (7, 3)},\n);",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Plot Conditional Adjusted Predictions"
    ]
  },
  {
    "objectID": "notebooks/plot_predictions.html#negative-binomial-model",
    "href": "notebooks/plot_predictions.html#negative-binomial-model",
    "title": "Plot Conditional Adjusted Predictions",
    "section": "Negative Binomial Model",
    "text": "Negative Binomial Model\nLets move onto a model that uses a distribution that is a member of the exponential distribution family and utilizes a link function. For this, we will implement the Negative binomial model from the students absences example. School administrators study the attendance behavior of high school juniors at two schools. Predictors of the number of days of absence include the type of program in which the student is enrolled and a standardized test in math. We have attendance data on 314 high school juniors. The variables of insterest in the dataset are the following:\n\ndaysabs: The number of days of absence. It is our response variable.\nprogr: The type of program. Can be one of ‘General’, ‘Academic’, or ‘Vocational’.\nmath: Score in a standardized math test.\n\n\n# Load data, define and fit Bambi model\ndata = pd.read_stata(\"https://stats.idre.ucla.edu/stat/stata/dae/nb_data.dta\")\ndata[\"prog\"] = data[\"prog\"].map({1: \"General\", 2: \"Academic\", 3: \"Vocational\"})\n\nmodel_interaction = bmb.Model(\n    \"daysabs ~ 0 + prog + scale(math) + prog:scale(math)\",\n    data,\n    family=\"negativebinomial\"\n)\nidata_interaction = model_interaction.fit(\n    draws=1000, target_accept=0.95, random_seed=1234, chains=4\n)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [alpha, prog, scale(math), prog:scale(math)]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 15 seconds.\n\n\nThis model utilizes a log link function and a negative binomial distribution for the likelihood. Also note that this model also contains an interaction prog:sale(math).\n\nmodel_interaction\n\n       Formula: daysabs ~ 0 + prog + scale(math) + prog:scale(math)\n        Family: negativebinomial\n          Link: mu = log\n  Observations: 314\n        Priors: \n    target = mu\n        Common-level effects\n            prog ~ Normal(mu: [0. 0. 0.], sigma: [5.0102 7.4983 5.2746])\n            scale(math) ~ Normal(mu: 0.0, sigma: 2.5)\n            prog:scale(math) ~ Normal(mu: [0. 0.], sigma: [6.1735 4.847 ])\n        \n        Auxiliary parameters\n            alpha ~ HalfCauchy(beta: 1.0)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\n\nfig, ax = plt.subplots(figsize=(7, 3), dpi=120)\nbmb.interpret.plot_predictions(\n    model_interaction, \n    idata_interaction, \n    \"math\", \n    ax=ax, \n    pps=False\n);\n\n\n\n\n\n\n\n\nThe plot above shows that as math increases, the mean daysabs decreases. However, as the model contains an interaction term, the effect of math on daysabs depends on the value of prog. Therefore, we will use plot_predictions to plot the conditional adjusted predictions for each level of prog.\n\nfig, ax = plt.subplots(figsize=(7, 3), dpi=120)\nbmb.interpret.plot_predictions(\n    model_interaction, \n    idata_interaction, \n    [\"math\", \"prog\"], \n    ax=ax, \n    pps=False\n);\n\n\n\n\n\n\n\n\nPassing specific subplot_kwargs can allow for a more interpretable plot. Especially when the posterior predictive distribution plot results in overlapping credible intervals.\n\nbmb.interpret.plot_predictions(\n    model_interaction, \n    idata_interaction, \n    conditional=[\"math\", \"prog\"],\n    pps=True,\n    subplot_kwargs={\"main\": \"math\", \"group\": \"prog\", \"panel\": \"prog\"},\n    legend=False,\n    fig_kwargs={\"figsize\": (16, 5), \"sharey\": True}\n);",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Plot Conditional Adjusted Predictions"
    ]
  },
  {
    "objectID": "notebooks/plot_predictions.html#logistic-regression",
    "href": "notebooks/plot_predictions.html#logistic-regression",
    "title": "Plot Conditional Adjusted Predictions",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nTo further demonstrate the plot_predictions function, we will implement a logistic regression model. This example is taken from the marginaleffects plot_predictions documentation. The internet movie database, http://imdb.com/, is a website devoted to collecting movie data supplied by studios and fans. It claims to be the biggest movie database on the web and is run by Amazon. The movies in this dataset were selected for inclusion if they had a known length and had been rated by at least one imdb user. The dataset below contains 28,819 rows and 24 columns. The variables of interest in the dataset are the following: - title. Title of the movie. - year. Year of release. - budget. Total budget (if known) in US dollars - length. Length in minutes. - rating. Average IMDB user rating. - votes. Number of IMDB users who rated this movie. - r1-10. Multiplying by ten gives percentile (to nearest 10%) of users who rated this movie a 1. - mpaa. MPAA rating. - action, animation, comedy, drama, documentary, romance, short. Binary variables represent- ing if movie was classified as belonging to that genre.\n\ndata = pd.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2movies/movies.csv\")\n\ndata[\"style\"] = \"Other\"\ndata.loc[data[\"Action\"] == 1, \"style\"] = \"Action\"\ndata.loc[data[\"Comedy\"] == 1, \"style\"] = \"Comedy\"\ndata.loc[data[\"Drama\"] == 1, \"style\"] = \"Drama\"\ndata[\"certified_fresh\"] = (data[\"rating\"] &gt;= 8) * 1\ndata = data[data[\"length\"] &lt; 240]\n\npriors = {\"style\": bmb.Prior(\"Normal\", mu=0, sigma=2)}\nmodel = bmb.Model(\"certified_fresh ~ 0 + length * style\", data=data, priors=priors, family=\"bernoulli\")\nidata = model.fit(random_seed=1234, target_accept=0.9, init=\"adapt_diag\")\n\nModeling the probability that certified_fresh==1\nAuto-assigning NUTS sampler...\nInitializing NUTS using adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [length, style, length:style]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1686 seconds.\n\n\nThe logistic regression model uses a logit link function and a Bernoulli likelihood. Therefore, the link scale is the log-odds of a successful response and the response scale is the probability of a successful response.\n\nmodel\n\n       Formula: certified_fresh ~ 0 + length * style\n        Family: bernoulli\n          Link: p = logit\n  Observations: 58662\n        Priors: \n    target = p\n        Common-level effects\n            length ~ Normal(mu: 0.0, sigma: 0.0283)\n            style ~ Normal(mu: 0.0, sigma: 2.0)\n            length:style ~ Normal(mu: [0. 0. 0.], sigma: [0.0263 0.0263 0.0263])\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\nAgain, by default, the plot_predictions function plots the mean outcome on the response scale. Therefore, the plot below shows the probability of a successful response certified_fresh as a function of length.\n\nfig, ax = plt.subplots(figsize=(7, 3), dpi=120)\nbmb.interpret.plot_predictions(model, idata, \"length\", ax=ax);\n\n\n\n\n\n\n\n\nAdditionally, we can see how the probability of certified_fresh varies as a function of categorical covariates.\n\nfig, ax = plt.subplots(figsize=(7, 3), dpi=120)\nbmb.interpret.plot_predictions(model, idata, \"style\", ax=ax);",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Plot Conditional Adjusted Predictions"
    ]
  },
  {
    "objectID": "notebooks/plot_predictions.html#plotting-other-model-parameters",
    "href": "notebooks/plot_predictions.html#plotting-other-model-parameters",
    "title": "Plot Conditional Adjusted Predictions",
    "section": "Plotting other model parameters",
    "text": "Plotting other model parameters\nplot_predictions also has the argument target where target determines what parameter of the response distribution is plotted as a function of the explanatory variables. This argument is useful in distributional models, i.e., when the response distribution contains a parameter for location, scale and or shape. The default of this argument is mean and passing a parameter into target only works when the argument pps=False because when pps=True the posterior predictive distribution is plotted and thus, can only refer to the outcome variable (instead of any of the parameters of the response distribution). For this example, we will simulate our own dataset.\n\nrng = np.random.default_rng(121195)\nN = 200\na, b = 0.5, 1.1\nx = rng.uniform(-1.5, 1.5, N)\nshape = np.exp(0.3 + x * 0.5 + rng.normal(scale=0.1, size=N))\ny = rng.gamma(shape, np.exp(a + b * x) / shape, N)\ndata_gamma = pd.DataFrame({\"x\": x, \"y\": y})\n\nformula = bmb.Formula(\"y ~ x\", \"alpha ~ x\")\nmodel = bmb.Model(formula, data_gamma, family=\"gamma\")\nidata = model.fit(random_seed=1234)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Intercept, x, alpha_Intercept, alpha_x]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 18 seconds.\nThere were 8 divergences after tuning. Increase `target_accept` or reparameterize.\n\n\n\nmodel\n\n       Formula: y ~ x\n                alpha ~ x\n        Family: gamma\n          Link: mu = inverse\n                alpha = log\n  Observations: 200\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 0.0, sigma: 2.5037)\n            x ~ Normal(mu: 0.0, sigma: 2.8025)\n    target = alpha\n        Common-level effects\n            alpha_Intercept ~ Normal(mu: 0.0, sigma: 1.0)\n            alpha_x ~ Normal(mu: 0.0, sigma: 1.0)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\nThe model we defined uses a gamma distribution parameterized by alpha and mu where alpha utilizes a log link and mu goes through an inverse link. Therefore, we can plot either: (1) the mu of the response distribution (which is the default), or (2) alpha of the response distribution as a function of the explanatory variable \\(x\\).\n\n# First, the mean of the response (default)\nfig, ax = plt.subplots(figsize=(7, 3), dpi=120)\nbmb.interpret.plot_predictions(model, idata, \"x\", ax=ax);\n\n\n\n\n\n\n\n\nBelow, instead of plotting the default target, target=mean, we set target=alpha to visualize how the model parameter alpha varies as a function of the x predictor.\n\n# Second, another param. of the distribution: alpha\nfig, ax = plt.subplots(figsize=(7, 3), dpi=120)\nbmb.interpret.plot_predictions(model, idata, \"x\", target=\"alpha\", ax=ax);\n\n\n\n\n\n\n\n\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Fri Aug 16 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\nmatplotlib: 3.8.4\nbambi     : 0.14.1.dev12+g64e57423.d20240730\nnumpy     : 1.26.4\npandas    : 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Plot Conditional Adjusted Predictions"
    ]
  },
  {
    "objectID": "notebooks/orthogonal_polynomial_reg.html",
    "href": "notebooks/orthogonal_polynomial_reg.html",
    "title": "Orthogonal Polynomial regression",
    "section": "",
    "text": "This example has been contributed by Tyler James Burch (@tjburch on GitHub). While the content in this notebook can stand alone, it is a companion to the polynomial regression notebook, which contains additional useful examples.\nimport arviz as az\nimport bambi as bmb\nimport formulae\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport scipy\nimport seaborn as sns\nfrom typing import Optional\n\nplt.style.use(\"arviz-darkgrid\")\nSEED = 1234\nnp.random.seed(SEED)\n# Temporary fix to make outputs cleaner\nimport warnings\nwarnings.filterwarnings(\"ignore\")",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Orthogonal Polynomial regression"
    ]
  },
  {
    "objectID": "notebooks/orthogonal_polynomial_reg.html#revisiting-polynomial-regression",
    "href": "notebooks/orthogonal_polynomial_reg.html#revisiting-polynomial-regression",
    "title": "Orthogonal Polynomial regression",
    "section": "Revisiting Polynomial Regression",
    "text": "Revisiting Polynomial Regression\nTo start, we’ll recreate the projectile motion data defined in the polynomial regression notebook with \\(x_0 = 1.5\\) \\(m\\) and \\(v_0 = 7\\) \\(m\\)/\\(s\\). This will follow:\n\\[\nx_f = \\frac{1}{2} g t^2 + v_0 t + x_0\n\\]\nWhere \\(g\\) will be the acceleration of gravity on Earth, \\(-9.81\\) \\(m\\)/\\(s^2\\). First we’ll generate the data.\n\ng = -9.81\nv0 = 7\nx0 = 1.5\nt = np.linspace(0, 2, 100)\nx_projectile = (1/2) * g * t**2 + v0 * t + x0\nnoise = np.random.normal(0, 0.2, x_projectile.shape)\nx_obs_projectile = x_projectile + noise\ndf_projectile = pd.DataFrame({\"t\": t, \"x\": x_obs_projectile, \"x_true\": x_projectile})\ndf_projectile = df_projectile[df_projectile[\"x\"] &gt;= 0]\n\nplt.scatter(df_projectile.t, df_projectile.x, label='Observed Displacement', color=\"C0\")\nplt.plot(df_projectile.t, df_projectile.x_true, label='True Function', color=\"C1\")\nplt.xlabel('Time (s)')\nplt.ylabel('Displacement (m)')\nplt.ylim(bottom=0)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nPutting this into Bambi, we set \\(\\beta_2 = \\frac{g}{2}\\), \\(\\beta_1 = v_0\\), and \\(\\beta_0 = x_0\\), then perform the following regression:\n\\[\nx_f = \\beta_2 t^2 + \\beta_1 t + \\beta_0\n\\]\nWe expect to recover \\(\\beta_2 = -4.905\\), \\(\\beta_1 = 7\\), \\(\\beta_0 = 1.5\\) from our fit. We start with the approach from the other notebook where we explicitly tell formulae to calculate coefficients on \\(t^2\\) and \\(t\\).\n\nmodel_projectile_all_terms = bmb.Model(\"x ~ I(t**2) + t + 1\", df_projectile)\nfit_projectile_all_terms = model_projectile_all_terms.fit(idata_kwargs={\"log_likelihood\": True}, random_seed=SEED)\naz.summary(fit_projectile_all_terms)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [sigma, Intercept, I(t ** 2), t]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 9 seconds.\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nI(t ** 2)\n-4.875\n0.112\n-5.095\n-4.673\n0.002\n0.002\n2121.0\n2049.0\n1.0\n\n\nIntercept\n1.518\n0.066\n1.389\n1.636\n0.001\n0.001\n2299.0\n2047.0\n1.0\n\n\nsigma\n0.201\n0.016\n0.172\n0.232\n0.000\n0.000\n2950.0\n2330.0\n1.0\n\n\nt\n6.962\n0.187\n6.622\n7.325\n0.004\n0.003\n1958.0\n1925.0\n1.0\n\n\n\n\n\n\n\nThe parameters are recovered as anticipated.\nIf you want to include all terms of a variable up to a given degree, you can also use the keyword poly. So if we want the linear and quadratic effects, as in this case, we would designate poly(t, 2).\n\nmodel_projectile_poly = bmb.Model(\"x ~ poly(t, 2) + 1\", df_projectile)\nfit_projectile_poly = model_projectile_poly.fit(idata_kwargs={\"log_likelihood\": True}, random_seed=SEED)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [sigma, Intercept, poly(t, 2)]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.\n\n\n\naz.summary(fit_projectile_poly)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n2.872\n0.023\n2.828\n2.913\n0.000\n0.000\n5984.0\n3512.0\n1.0\n\n\npoly(t, 2)[0]\n-3.893\n0.204\n-4.275\n-3.504\n0.003\n0.002\n6053.0\n3345.0\n1.0\n\n\npoly(t, 2)[1]\n-8.770\n0.196\n-9.141\n-8.413\n0.003\n0.002\n4844.0\n3327.0\n1.0\n\n\nsigma\n0.201\n0.016\n0.171\n0.232\n0.000\n0.000\n7190.0\n3089.0\n1.0\n\n\n\n\n\n\n\nNow there are fitted coefficients for \\(t\\) and \\(t^2\\), but wait, those aren’t the parameters we used! What’s going on here?",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Orthogonal Polynomial regression"
    ]
  },
  {
    "objectID": "notebooks/orthogonal_polynomial_reg.html#the-poly-keyword",
    "href": "notebooks/orthogonal_polynomial_reg.html#the-poly-keyword",
    "title": "Orthogonal Polynomial regression",
    "section": "The poly Keyword",
    "text": "The poly Keyword\nTo fully understand what’s going on under the hood, we must wade into some linear algebra. When the poly keyword is used, instead of directly using the values of \\(x, x^2, x^3, \\dots, x^n\\), it converts them into orthogonal polynomials. When including the effect from multiple polynomial terms, there will generally be correlation between them. Including all of these into a model can be a problem from the fitting perspective due to multicollinearity. By orthogonalizing, the correlation is removed by design.\nAs it turns out, it’s difficult to get any information on how the orthogonalization is performed. Here is the implementation for poly in formulae, but to fully understand, I went into the source code for the R Stats library where poly is defined as a function for use on any vector, and took a look at its code.\nHere’s a step-by-step summary, along with a toy example for \\(x^4\\).\n\nThe data is first centered around the mean for stability\n\n\nX = np.array([1, 2, 3, 4, 5])\n\nmean = np.mean(X)\nX_centered = X - mean\nprint(f\"Array: {X}, mean: {mean}.\\nCentered: {X_centered}\")\n\nArray: [1 2 3 4 5], mean: 3.0.\nCentered: [-2. -1.  0.  1.  2.]\n\n\n\nA Vandermonde matrix is created. This just takes the input data and generates a matrix where columns represent increasing polynomial degrees. In this example, the first column is \\(x^0\\), a constant term. The second is \\(x^1\\), or the centered data. The third column is \\(x^2\\), the fourth is \\(x^3\\), the last is \\(x^4\\).\n\n\ndegree = 4\nsimple_vander = np.vander(X_centered, N=degree+1, increasing=True)\nsimple_vander\n\narray([[ 1., -2.,  4., -8., 16.],\n       [ 1., -1.,  1., -1.,  1.],\n       [ 1.,  0.,  0.,  0.,  0.],\n       [ 1.,  1.,  1.,  1.,  1.],\n       [ 1.,  2.,  4.,  8., 16.]])\n\n\n\nQR decomposition is performed. There are several methods to doing this in practice, the most common being the Gram-Schmidt process. Here I just take advantage of the Numpy implementation. We take the above matrix and convert it into two components, an orthogonal matrix \\(Q\\), and an upper triangular matrix \\(R\\).\n\n\nq, r = np.linalg.qr(simple_vander)\nprint(\"Orthogonal matrix Q:\\n\", q.round(4))\nprint(\"\\nUpper triangular matrix R:\\n\", r.round(4))\n\nOrthogonal matrix Q:\n [[-0.4472 -0.6325  0.5345 -0.3162 -0.1195]\n [-0.4472 -0.3162 -0.2673  0.6325  0.4781]\n [-0.4472 -0.     -0.5345  0.     -0.7171]\n [-0.4472  0.3162 -0.2673 -0.6325  0.4781]\n [-0.4472  0.6325  0.5345  0.3162 -0.1195]]\n\nUpper triangular matrix R:\n [[ -2.2361  -0.      -4.4721  -0.     -15.2053]\n [  0.       3.1623   0.      10.7517   0.    ]\n [  0.       0.       3.7417   0.      16.5702]\n [  0.       0.       0.       3.7947   0.    ]\n [  0.       0.       0.       0.      -2.8685]]\n\n\n\nLast take the dot product of \\(Q\\) with the diagonal elements of \\(R\\). \\(Q\\) is then scaled to the magnitude of the polynomial degrees in \\(R\\). This serves as our transformation matrix which transforms input data into the space defined by the orthogonal polynomials.\n\n\ndiagonal = np.diag(np.diag(r))  # First call gets elements, second creates diag matrix\ntransformation_matrix = np.dot(q, diagonal)\nprint(transformation_matrix.round(4))\n\n[[ 1.     -2.      2.     -1.2     0.3429]\n [ 1.     -1.     -1.      2.4    -1.3714]\n [ 1.     -0.     -2.      0.      2.0571]\n [ 1.      1.     -1.     -2.4    -1.3714]\n [ 1.      2.      2.      1.2     0.3429]]\n\n\n\nFrom the transformation matrix, we get squared norms (norm2), which give us the scale of each polynomial. We also get the value by which we need to shift each polynomial to match the centered data (alpha).\n\n\nnorm2 = np.sum(transformation_matrix**2, axis=0)\n\nweighted_sums = np.sum(\n    (transformation_matrix**2) * np.reshape(X_centered, (-1, 1)),\n    axis=0\n)        \nnormalized_sums = weighted_sums / norm2\nadjusted_sums = normalized_sums + mean\nalpha = adjusted_sums[:degree]\n\nprint(f\"Norm2: {norm2}\\nalpha: {alpha}\")\n\nNorm2: [ 5.         10.         14.         14.4         8.22857143]\nalpha: [3. 3. 3. 3.]\n\n\n\nFinally, we iteratively apply this to all desired polynomial degrees, shifting the data and scaling by the squared norms appropriately to maintain orthogonality with the prior term.\n\n\ntransformed_X = np.full((len(X), degree+1), np.nan)\ntransformed_X[:,0] = 1\ntransformed_X[:, 1] = X - alpha[0]\nfor i in range(1, degree):\n    transformed_X[:, i + 1] = (\n        (X - alpha[i]) * transformed_X[:, i] -\n        (norm2[i] / norm2[i - 1]) * transformed_X[:, i - 1]\n    )\n\ntransformed_X /= np.sqrt(norm2)\ntransformed_X  \n\narray([[ 0.4472136 , -0.63245553,  0.53452248, -0.31622777,  0.11952286],\n       [ 0.4472136 , -0.31622777, -0.26726124,  0.63245553, -0.47809144],\n       [ 0.4472136 ,  0.        , -0.53452248, -0.        ,  0.71713717],\n       [ 0.4472136 ,  0.31622777, -0.26726124, -0.63245553, -0.47809144],\n       [ 0.4472136 ,  0.63245553,  0.53452248,  0.31622777,  0.11952286]])\n\n\nThis is now a matrix of orthogonalized polynomials of X. The first column is just a constant. The second column corresponds to the input \\(x\\), the next is \\(x^2\\) and so on. In most implementations, the constant term is eliminated, giving us the following final matrix.\n\ntransformed_X[:,1:]\n\narray([[-0.63245553,  0.53452248, -0.31622777,  0.11952286],\n       [-0.31622777, -0.26726124,  0.63245553, -0.47809144],\n       [ 0.        , -0.53452248, -0.        ,  0.71713717],\n       [ 0.31622777, -0.26726124, -0.63245553, -0.47809144],\n       [ 0.63245553,  0.53452248,  0.31622777,  0.11952286]])\n\n\nThe approach shown in this derivation been reproduced below as a Scikit-Learn style class below, where the fit method calculates the coefficients and the transform method returns orthoginalized data. It is also at this gist, including the typical BaseEstimator, TransformerMixin inheritances.\n\nclass OrthogonalPolynomialTransformer:\n    \"\"\"Transforms input data using orthogonal polynomials.\"\"\"\n    \n    def __init__(self, degree: int = 1) -&gt; None:\n        self.degree = degree + 1  # Account for constant term\n        self.norm2 = None\n        self.alpha = None\n\n    def fit(self, X: np.ndarray, y: Optional[np.ndarray] = None) -&gt; 'OrthogonalPolynomialTransformer':\n        \"\"\"Calculate transformation matrix, extract norm2 and alpha.\"\"\" \n        # Reset state-related attributes at the beginning of each fit call\n        self.norm2 = None\n        self.alpha = None\n\n        X = np.asarray(X).flatten()\n        if self.degree &gt;= len(np.unique(X)):\n            raise ValueError(\"'degree' must be less than the number of unique data points.\")\n        \n        # Center data around its mean\n        mean = np.mean(X)\n        X_centered = X - mean\n        \n        # Create Vandermonde matrix for centered data and perform QR decomposition\n        vandermonde = np.vander(X_centered, N=self.degree + 1, increasing=True)\n        Q, R = np.linalg.qr(vandermonde)\n        \n        # Compute transformation matrix and norms\n        diagonal = np.diag(np.diag(R))  # extract diagonal, then create diagonal matrix\n        transformation_matrix = np.dot(Q, diagonal)\n        self.norm2 = np.sum(transformation_matrix**2, axis=0)\n        \n        # Get alpha\n        # Normalized weighted sum sqared of transformation matrix\n        weighted_sums = np.sum(\n            (transformation_matrix**2) * np.reshape(X_centered, (-1, 1)),\n            axis=0\n        )        \n        normalized_sums = weighted_sums / self.norm2\n        adjusted_sums = normalized_sums + mean\n        self.alpha = adjusted_sums[:self.degree]\n        return self\n\n    def transform(self, X: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Iteratively apply up to 'degree'.\"\"\"\n        X = np.asarray(X).flatten()\n        transformed_X = np.empty((len(X), self.degree + 1))  # Adjusted to include all polynomial degrees\n        \n        transformed_X[:, 0] = 1  # x^0 \n        if self.degree &gt; 0:\n            transformed_X[:, 1] = X - self.alpha[0]\n\n        if self.degree &gt; 1:\n            for i in range(1, self.degree):\n                transformed_X[:, i + 1] = (\n                    (X - self.alpha[i]) * transformed_X[:, i] -\n                    (self.norm2[i] / self.norm2[i - 1]) * transformed_X[:, i - 1]\n                )\n\n        transformed_X /= np.sqrt(self.norm2)\n        \n        # return without constant term\n        return transformed_X[:, 1:self.degree]  \n\n    def fit_transform(self, X: np.ndarray, y: Optional[np.ndarray] = None) -&gt; np.ndarray:\n        self.fit(X, y)\n        return self.transform(X)\n\nAn example call is shown below. It’s worth noting that in this implementation, the constant term is not returned, the first column corresponds to \\(x\\), the second to \\(x^2\\), and the third to \\(x^3\\).\n\nX = np.array([1, 2, 3, 4, 5])\npoly3 = OrthogonalPolynomialTransformer(degree=3).fit(X)\npoly3.transform(X)\n\narray([[-0.63245553,  0.53452248, -0.31622777],\n       [-0.31622777, -0.26726124,  0.63245553],\n       [ 0.        , -0.53452248, -0.        ],\n       [ 0.31622777, -0.26726124, -0.63245553],\n       [ 0.63245553,  0.53452248,  0.31622777]])\n\n\nThis matches what you may get when calling the same function in R:\n&gt; poly(X, 4)\n                 1          2             3          4\n[1,] -6.324555e-01  0.5345225 -3.162278e-01  0.1195229\n[2,] -3.162278e-01 -0.2672612  6.324555e-01 -0.4780914\n[3,] -3.288380e-17 -0.5345225  9.637305e-17  0.7171372\n[4,]  3.162278e-01 -0.2672612 -6.324555e-01 -0.4780914\n[5,]  6.324555e-01  0.5345225  3.162278e-01  0.1195229\nor, most relevant, from formulae,\n\nformulae_poly = formulae.transforms.Polynomial()\nformulae_poly(X, 4)\n\narray([[-0.63245553,  0.53452248, -0.31622777,  0.11952286],\n       [-0.31622777, -0.26726124,  0.63245553, -0.47809144],\n       [ 0.        , -0.53452248, -0.        ,  0.71713717],\n       [ 0.31622777, -0.26726124, -0.63245553, -0.47809144],\n       [ 0.63245553,  0.53452248,  0.31622777,  0.11952286]])\n\n\nFor an example, applying this function to x over a domain from 0-10,\n\n# Generate data\nx = np.linspace(0, 10, 100)\nx2 = x**2\n\n# Orthogonalize\ntransformer = OrthogonalPolynomialTransformer(degree=2)\nx_orthogonalized = transformer.fit_transform(x)\nx_orth = x_orthogonalized[:, 0]\nx2_orth = x_orthogonalized[:, 1]\n\n# Make a correlation matrix\ndata = np.vstack([x, x2, x_orth, x2_orth]).T\ndf = pd.DataFrame(data, columns=['x', '$x^2$', '$x$ Orth', '$x^2$ Orth'])\ncorrelation_matrix = df.corr()\nsns.heatmap(correlation_matrix, annot=True, cmap='Reds')\nplt.xticks(rotation=45)\nplt.show()\n\n\n\n\n\n\n\n\nWe now see that the orthogonalized version of \\(x\\) and \\(x^2\\) are no longer correlated to each other. Next, we construct a response variable and plot against it.\n\ny = 3 * x2  + x\n\nfig, axs = plt.subplots(2, 2, figsize=(8, 6), sharey='row')\n\n# Plot configurations - variable, label, linear fit tuple\nplots = [\n    (x, 'x', False),\n    (x2, '$x^2$', False),\n    (x_orth, 'Orthogonalized $x$', True), \n    (x2_orth, 'Orthogonalized $x^2$', False)\n]\n\nfor ax, plot_data in zip(axs.flat, plots):\n    x_val, xlabel = plot_data[:2]\n    if len(plot_data) == 3 and plot_data[2]:  # Check if regression line is needed\n        sns.regplot(x=x_val, y=y, ax=ax, line_kws={\"color\": \"C1\"})\n    else:\n        sns.scatterplot(x=x_val, y=y, ax=ax)\n    ax.set(xlabel=xlabel, ylabel='y')\n\n    # Check if this is the $x^2$ Orth vs y plot to add a vertical line at 0\n    if plot_data[1] == 'Orthogonalized $x^2$':\n        ax.axvline(0, color='k', linestyle='--')  # Add vertical line at x=0\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe top half shows the response variable against \\(x\\) and \\(x^2\\), this should look familiar.\nThe bottom half shows the new orthogonalized polynomial terms. First, you’ll notice the domain is centered at 0 and more compressed than the original scale, which is done within the orthogonalization process. Otherwise, the \\(x\\) term is the same. Remember in the construction, the first order is untouched, then subsequent terms are built orthogonal to the first degree polynomial.\nI’ve shown a linear fit on top of the first order term. What you’ll notice is that the orthogonalized \\(x^2\\) correspond to the residuals of this line. At the lowest values of \\(y\\), the fit is poor, and this is where the orthogonalized \\(x^2\\) is highest. As the first order term crosses the linear fit, you see the orthogonalized \\(x^2\\) cross zero, then go to negative values as it dips under the linear fit. It crosses 0 one more time and then is once again poor at the highest values shown. Since the \\(x^2\\) is proportional to the residuals of the first order term, if we plot the orthogonalized \\(x^2\\) term against the residuals, we should see a linear trend.\n\n# Perform linear fit on x_orth vs y\nslope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x_orth, y)\n\n# Calculate the residuals\ny_pred = intercept + slope * x_orth\nresiduals = y - y_pred\n\n# Plot x_orth vs y with linear fit\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.scatter(x_orth, y, label='Original data')\nplt.plot(x_orth, y_pred, color='C1', label='Fitted line')\nplt.xlabel('$x$ Orth')\nplt.ylabel('y')\nplt.title('$x$ Orth vs y with Linear Fit')\nplt.legend()\n\n# Plot x2_orth vs residuals\nplt.subplot(1, 2, 2)\nplt.scatter(x2_orth, residuals)\nplt.xlabel('$x^2$ Orth')\nplt.ylabel('Residuals')\nplt.title('$x^2$ Orth vs Residuals')\nplt.axhline(0, color='black', linestyle='--')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAnd, in fact, the linear trend bears out when plotting the orthogonal \\(x^2\\) vs the residuals.\nWe can take this a degree higher and look at a cubic term.\n\nx3 = x**3\nx2 = x**2\n# Creating a cubic function with an up and down pattern\ny_cubic = 2.5* x3 - 15*x2 + 55 * x \n\ntransformer = OrthogonalPolynomialTransformer(degree=3)\nx_orthogonalized = transformer.fit_transform(x)\nx_orth = x_orthogonalized[:, 0]\nx2_orth = x_orthogonalized[:, 1]\nx3_orth = x_orthogonalized[:, 2]\n\nfig, axs = plt.subplots(2, 3, figsize=(12, 8), sharey='row')\n\n# Plot configurations\nplots = [\n    (x, 'x', 'x vs y', False),\n    (x2, '$x^2$', '$x^2$ vs y', False),\n    (x3, '$x^3$', '$x^3$ vs y', False),\n    (x_orth, '$x$ Orth', '$x$ Orth vs y', True),  # Indicate to add regression line for this plot\n    (x2_orth, '$x^2$ Orth', '$x^2$ Orth vs y', True),  # Indicate to add regression line for this plot too\n    (x3_orth, '$x^3$ Orth', '$x^3$ Orth vs y',False)\n]\n\nfor ax, plot_data in zip(axs.flat, plots):\n    x_val, xlabel, title = plot_data[:3]\n    if len(plot_data) == 4 and plot_data[3]:  # Check if regression line is needed\n        sns.regplot(x=x_val, y=y_cubic, ax=ax, line_kws={\"color\": \"C1\"})\n    else:\n        sns.scatterplot(x=x_val, y=y_cubic, ax=ax)\n    ax.set(xlabel=xlabel, ylabel='y', title=title)\n\n    # Check if this is the $x^2$ Orth vs y plot to add a vertical line at 0\n    if title == '$x^2$ Orth vs y':\n        ax.axvline(0, color='k', linestyle='--')  # Add vertical line at x=0\n    # Check if this is the $x^3$ Orth vs y plot to add a vertical line at 0\n    if title == '$x^3$ Orth vs y':\n        ax.axvline(0, color='k', linestyle='--')  # Add vertical line at x=0\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAt a cubic level, it’s a bit more difficult to see the trends, however, the procedure is still the same. We can model each subsequent term against the residuals of the prior, and we can see that since this data was constructed from a cubic function, the \\(x^3\\) plot against the residuals of the \\(x^2\\) term is linear.\n\n# Perform linear fit on x_orth vs y\nslope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x_orth, y_cubic)\n\n# Calculate the residuals\ny_pred = intercept + slope * x_orth\nresiduals = y_cubic - y_pred\n\n# Perform linear fit on residuals vs x2_orth\nslope_res, intercept_res, r_value_res, p_value_res, std_err_res = scipy.stats.linregress(x2_orth, residuals)\n\n# Calculate the second order residuals\nresiduals_pred = intercept_res + slope_res * x2_orth\nsecond_order_residuals = residuals - residuals_pred\n\n# Plot x_orth vs y with linear fit\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1, 3, 1)\nsns.scatterplot(x=x_orth, y=y_cubic, hue=np.arange(len(x_orth)), palette=\"viridis\", legend=False)\nplt.plot(x_orth, y_pred, color='black', label='Linear Model')\nplt.xlabel('$x$ Orth')\nplt.ylabel('y')\nplt.title('$x$ Orth vs y with Linear Fit')\nplt.legend()\n\n# Plot x2_orth vs residuals\nplt.subplot(1, 3, 2)\nsns.scatterplot(x=x2_orth, y=residuals, hue=np.arange(len(x2_orth)), palette=\"viridis\", legend=False)\nplt.plot(x2_orth, residuals_pred, color='black')\nplt.xlabel('$x^2$ Orth')\nplt.ylabel('Residuals')\nplt.title('$x^2$ Orth vs Residuals')\nplt.axhline(0, color='grey', linestyle='--', zorder=-1)\nplt.legend()\n\n# Plot x3_orth vs second order residuals\nplt.subplot(1, 3, 3)\nsns.scatterplot(x=x3_orth, y=second_order_residuals, hue=np.arange(len(x3_orth)), palette=\"viridis\", legend=False)\nplt.xlabel('$x^3$ Orth')\nplt.ylabel('Second Order Residuals')\nplt.title('$x^3$ Orth vs Second Order Residuals')\nplt.axhline(0, color='grey', linestyle='--', zorder=-1)\nplt.annotate('Point hue denotes index', \n             xy=(0.99, 0.05), ha='right', xycoords='axes fraction', fontsize=14, color='black')\n\nplt.tight_layout()\nplt.show()\n\nNo artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n\n\n\n\n\n\n\n\n\nThe main takeaway of this deep dive is the following: The poly keyword when used in a formula creates orthogonal polynomials. This is well-suited for fitting statistical models, since it eliminates the risk of multicollinearity between terms.\nThis wasn’t used in the other notebook since we were trying to recover parameters associated with each term. However, if you’re building a statistical model, especially one in which prediction is the focus, they may be the appropriate approach.\nAs one final note, the formulae version of poly does include a raw argument, which allows you to get the non-orthogonalized versions of each polynomial term. You can call that in Bambi like bmb.Model(\"y ~ poly(x, 4, raw=True)\", df).",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Orthogonal Polynomial regression"
    ]
  },
  {
    "objectID": "notebooks/orthogonal_polynomial_reg.html#orthogonal-polynomials-in-practice",
    "href": "notebooks/orthogonal_polynomial_reg.html#orthogonal-polynomials-in-practice",
    "title": "Orthogonal Polynomial regression",
    "section": "Orthogonal Polynomials in Practice",
    "text": "Orthogonal Polynomials in Practice\nIn order to see the poly keyword in action, we’ll take a look at the cars dataset. This dataset, preloaded into Seaborn, includes information on cars manufactured between 1970-1982. First we’ll load it in and take a look at the included variables.\n\ndf_mpg = sns.load_dataset(\"mpg\")\ndf_mpg.head()\n\n\n\n\n\n\n\n\nmpg\ncylinders\ndisplacement\nhorsepower\nweight\nacceleration\nmodel_year\norigin\nname\n\n\n\n\n0\n18.0\n8\n307.0\n130.0\n3504\n12.0\n70\nusa\nchevrolet chevelle malibu\n\n\n1\n15.0\n8\n350.0\n165.0\n3693\n11.5\n70\nusa\nbuick skylark 320\n\n\n2\n18.0\n8\n318.0\n150.0\n3436\n11.0\n70\nusa\nplymouth satellite\n\n\n3\n16.0\n8\n304.0\n150.0\n3433\n12.0\n70\nusa\namc rebel sst\n\n\n4\n17.0\n8\n302.0\n140.0\n3449\n10.5\n70\nusa\nford torino\n\n\n\n\n\n\n\nIn this example, we’ll take a look at how a car’s fuel efficiency (mpg) relates to it’s horsepower (hp).\nTo start, we’ll just plot the joint distribution, as well as the distribution of the response variable as well.\n\ndf_mpg = df_mpg.dropna(subset=[\"horsepower\", \"mpg\"])\n\n\nplt.figure(figsize=(14, 6))\nplt.subplot(1, 2, 1)\nsns.regplot(data=df_mpg, x=\"horsepower\", y=\"mpg\", line_kws={\"color\": \"firebrick\"})\n\nplt.subplot(1, 2, 2)\nsns.histplot(df_mpg[\"mpg\"], edgecolor=\"black\", kde=True)\nplt.xlabel('MPG')\nplt.ylabel('Count')\nplt.title('Histogram of MPG')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nImmediately, we see that the linear fit doesn’t seem to model this data perfectly, it exhibits some nonlinearity. We’ll use a polynomial regression in order to see if we can improve that fit and capture the curvature. We will first fit a linear model as a benchmark.\n\nmpg_hp_linear_mod = bmb.Model(\"mpg ~ horsepower\", df_mpg)\nmpg_hp_linear_fit = mpg_hp_linear_mod.fit(idata_kwargs={\"log_likelihood\": True}, random_seed=SEED)\nmpg_hp_linear_mod.predict(mpg_hp_linear_fit, kind=\"response\")\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [sigma, Intercept, horsepower]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.\n\n\n\nfig = plt.figure()\nfor p in [.68, .95]:\n    bmb.interpret.plot_predictions(\n        mpg_hp_linear_mod,\n        mpg_hp_linear_fit,\n        \"horsepower\",\n        pps=True,\n        legend=True,\n        prob=p,\n        ax=plt.gca()\n    )\nsns.scatterplot(data=df_mpg, x=\"horsepower\", y=\"mpg\", color='blue', label='True Data');\n\nDefault computed for conditional variable: horsepower\nDefault computed for conditional variable: horsepower\n\n\n\n\n\n\n\n\n\nLooking at this plot with the 68% and 95% CIs shown, the fit looks okay. Most notably, at about 160 hp, then the data diverge from the fit pretty drastically. The fit at low hp values isn’t particularly good either, there’s quite a bit that falls outside of our 95% CI. This can be accented pretty heavily by looking at the the residuals from the mean of the model.\n\npredicted_mpg = mpg_hp_linear_fit.posterior[\"mu\"].mean((\"chain\", \"draw\"))\nresiduals = df_mpg[\"mpg\"] - predicted_mpg\nsns.scatterplot(data=df_mpg, x=\"horsepower\", y=residuals)\nplt.axhline(0, color='black', lw=2)\nplt.ylabel(\"Residuals\")\nplt.title('Residuals for linear model')\n\nText(0.5, 1.0, 'Residuals for linear model')\n\n\n\n\n\n\n\n\n\nThis is definitely not flat like we would ideally like it.\nNext we fit a polynomial regression, including a square term.\n\nmpg_hp_sq_mod = bmb.Model(\"mpg ~ poly(horsepower, 2)\", df_mpg)\nmpg_hp_sq_fit = mpg_hp_sq_mod.fit(idata_kwargs={\"log_likelihood\": True}, random_seed=SEED)\nmpg_hp_sq_mod.predict(mpg_hp_sq_fit, kind=\"response\")\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [sigma, Intercept, poly(horsepower, 2)]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 6 seconds.\n\n\n\nfig = plt.figure()\nfor p in [.68, .95]:\n    bmb.interpret.plot_predictions(\n        mpg_hp_sq_mod,\n        mpg_hp_sq_fit,\n        \"horsepower\",\n        pps=True,\n        legend=True,\n        prob=p,\n        ax=plt.gca()\n    )\nsns.scatterplot(data=df_mpg, x=\"horsepower\", y=\"mpg\", color='blue', label='True Data')\nplt.title(\"Quadratic Fit\")\n\nDefault computed for conditional variable: horsepower\nDefault computed for conditional variable: horsepower\n\n\nText(0.5, 1.0, 'Quadratic Fit')\n\n\n\n\n\n\n\n\n\nVisually, this seems to look better. Particularly at high values, the model follows the pattern in the data much, much better, since we allow for curvature by including the polynomial term. Generating the same residual plot gives the following,\n\npredicted_mpg = mpg_hp_sq_fit.posterior[\"mu\"].mean((\"chain\", \"draw\"))\nresiduals = df_mpg[\"mpg\"] - predicted_mpg\nsns.scatterplot(data=df_mpg, x=\"horsepower\", y=residuals)\nplt.axhline(0, color='black', lw=2)\nplt.ylabel(\"Residuals\")\nplt.title('Residuals for quadratic model')\n\nText(0.5, 1.0, 'Residuals for quadratic model')\n\n\n\n\n\n\n\n\n\nThis is far closer to flat than before.\nFor a true comparison, we can look at the elpd difference between the models.\n\naz.compare({\"Linear\": mpg_hp_linear_fit, \"Quadratic\": mpg_hp_sq_fit})\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nQuadratic\n0\n-1137.457520\n4.391553\n0.000000\n0.915406\n18.118483\n0.00000\nFalse\nlog\n\n\nLinear\n1\n-1182.021676\n3.548755\n44.564155\n0.084594\n15.109327\n10.36876\nFalse\nlog\n\n\n\n\n\n\n\nThe quadradic model performs better by LOO-CV.\n\nCautionary Tales\nLast, we’re going to investigate a couple of pitfalls with polynomial regression.\n\nFitting too many polynomial degrees\nTypically, when fitting a statistical model, you want to come to your data with a hypothesis and motivate your polynomial degree based on domain knowledge and expertise with the data. Instead of being principled, we’re going to throw caution to the wind and iteratively fit models from degree 1-10 and then see which performs best.\n\npoly_fits, poly_models = {}, {}\nfor degree in range(1, 10):\n    model = bmb.Model(f\"mpg ~ poly(horsepower, {degree})\", df_mpg)\n    fit = model.fit(idata_kwargs={\"log_likelihood\": True}, random_seed=SEED, progressbar=False)\n    poly_models[f\"Poly{degree}\"] = model\n    poly_fits[f\"Poly{degree}\"] = fit\n\ncmp = az.compare(poly_fits)\ncmp\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [sigma, Intercept, poly(horsepower, 1)]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [sigma, Intercept, poly(horsepower, 2)]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 5 seconds.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [sigma, Intercept, poly(horsepower, 3)]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 7 seconds.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [sigma, Intercept, poly(horsepower, 4)]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 8 seconds.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [sigma, Intercept, poly(horsepower, 5)]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 8 seconds.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [sigma, Intercept, poly(horsepower, 6)]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 9 seconds.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [sigma, Intercept, poly(horsepower, 7)]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 9 seconds.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [sigma, Intercept, poly(horsepower, 8)]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 9 seconds.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [sigma, Intercept, poly(horsepower, 9)]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 9 seconds.\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nPoly7\n0\n-1133.056651\n9.286158\n0.000000\n6.605585e-01\n18.850219\n0.000000\nFalse\nlog\n\n\nPoly6\n1\n-1134.077639\n8.816832\n1.020989\n4.232600e-13\n18.638394\n1.793307\nFalse\nlog\n\n\nPoly8\n2\n-1134.642557\n10.942848\n1.585906\n4.274684e-13\n18.820855\n0.664368\nTrue\nlog\n\n\nPoly5\n3\n-1134.839670\n7.652049\n1.783020\n4.280794e-13\n18.505057\n3.502449\nFalse\nlog\n\n\nPoly9\n4\n-1135.162445\n11.876625\n2.105794\n4.271587e-13\n18.921941\n1.593423\nTrue\nlog\n\n\nPoly2\n5\n-1137.457507\n4.391540\n4.400857\n4.134037e-13\n18.118477\n6.449275\nFalse\nlog\n\n\nPoly3\n6\n-1138.255418\n5.693683\n5.198768\n2.744510e-01\n18.401059\n6.961385\nFalse\nlog\n\n\nPoly4\n7\n-1138.824420\n7.106027\n5.767770\n4.337785e-13\n18.322672\n6.128835\nFalse\nlog\n\n\nPoly1\n8\n-1181.947800\n3.478546\n48.891149\n6.499044e-02\n15.115759\n10.986985\nFalse\nlog\n\n\n\n\n\n\n\nWow! A 7th-degree polynomial seems to do better than the quadratic one we fit before. But we must also notice that most ELPD values are very similar. Let’s do a plot, so we can more easily grasp how different models are according to the ELPD. We are going to use az.plot_compare, and we are going to add a blue band to indicate models that have an ELPD difference of less than 4 with respect to the first-ranked model. Essentially models that are that close can not be distinguished when using ELPD.\n\nax = az.plot_compare(cmp, figsize=(12, 4), plot_ic_diff=False, legend=False);\nbest_loo = cmp[\"elpd_loo\"].iloc[0]\nax.axvspan(best_loo-4, best_loo, color=\"C0\", alpha=0.2);\n\n\n\n\n\n\n\n\nWe can see that Poly6, Poly8, Poly5 and Poly9 are all very similar (within a difference of 4 units). Evenmore, all model except from Poly1 have overlaping standard errors.\nOverall, this is telling us that there is no clear gain in predictive performance once we move beyond a quadratic model. If we want to pick a single model, then we need another criteria to decide. If we have no reason to prefer a more complex model, choosing the simpler one (Poly2 in this example) is a good heuristic.\nBefore deciding let’s do a couple more plot. First, see what those residuals look like!\n\nbest_model = poly_models[\"Poly7\"]\nbest_fit = poly_fits[\"Poly7\"]\nbest_model.predict(best_fit, kind=\"response\")\n\npredicted_mpg = best_fit.posterior[\"mu\"].mean((\"chain\", \"draw\"))\nresiduals = df_mpg[\"mpg\"] - predicted_mpg\nsns.scatterplot(data=df_mpg, x=\"horsepower\", y=residuals)\nplt.axhline(0, color='black', lw=2)\nplt.ylabel(\"Residuals\")\nplt.title('Residuals for degree 7 model');\n\n\n\n\n\n\n\n\nHey, that looks pretty good, the residuals appear nice and flat. Before we go full steam ahead with this model, let’s take a look at the posterior predictive distribution.\n\nfig = plt.figure()\nfor p in [.68, .95]:\n    bmb.interpret.plot_predictions(\n        best_model,\n        best_fit,\n        \"horsepower\",\n        pps=True,\n        legend=True,\n        prob=p,\n        ax=plt.gca()\n    )\nsns.scatterplot(data=df_mpg, x=\"horsepower\", y=\"mpg\", color='blue', label='True Data')\nplt.title(\"Best Fit Model: 7th Degree Polynomial\");\n\nDefault computed for conditional variable: horsepower\nDefault computed for conditional variable: horsepower\n\n\n\n\n\n\n\n\n\nUh-oh. You can see that while this gave the best elpd, and had a nice residual plot, it’s obviously overfit, as expected given that we already show that the difference with the quadratic model is small. Given our knowledge about how cars operate, we expect a decreasing trend of fuel efficiency at higher horsepower. The 7th degree polynomial absolutely is not consistent with that. First, looking at the low values, it increases before starting the decreasing trend. Second, it starts to go back up at the high end of the data, strongly latching onto a couple of points that are likely driven by noise.\nThis behavior evokes the classic quote,\n\n“With four parameters I can fit an elephant, and with five I can make him wiggle his trunk.” - John von Neumann\n\nThe takeaway here is that as you fit higher polynomial degrees, you increase the risk of overfitting.\n\n\nExtrapolation of polynomial models\nWith any model, we should be careful when extrapolating and ensure our assumptions hold, but this particularly applies when considering polynomial regression. Since we consider the higher order polynomials, terms can quickly blow up outside of our domain.\nFor example, with the quadratic fit, we see that the drop in mpg flattens out at higher horsepower. However, if you look closely at the posterior predictive of the quadratic model, you can start to see the fit rise again at the end. But, if we extend this beyond the bounds, due to the curvature of a second degree polynomial, we see a reversal of the negative effect on horsepower, where our quadratic model implies a higher horsepower leads to better mpg.\n\nextrapolate_x_hp = np.linspace(0, 500, 250)  \nmpg_hp_sq_mod.predict(mpg_hp_sq_fit, data=pd.DataFrame({\"horsepower\": extrapolate_x_hp}))\n\nsns.scatterplot(data=df_mpg, x=\"horsepower\", y=\"mpg\", color='blue', label='True Data')\nplt.plot(\n    extrapolate_x_hp,\n    mpg_hp_sq_fit.posterior[\"mu\"].mean((\"chain\", \"draw\")),\n    color=\"red\",\n    label=\"Extrapolated Fit\",\n)\nplt.xlim(left=0, right=extrapolate_x_hp.max())\n\nplt.legend(frameon=False)\n\n\n\n\n\n\n\n\nThis is strictly untrue based on what we know about cars and what we’ve seen in the data, so you would not want to use the model outside of the intended domain. If that is the goal, you would want to find more appropriate specification. Something like an exponential or inverse fit may be appropriate, in order to make sure the fit approaches 0, while still forbidding predictions below 0.\nExtrapolation issues are not unique to polynomial regression, for example we run into forbidden values with linear regression when extrapolating too.\n\nmpg_hp_linear_mod.predict(mpg_hp_linear_fit, data=pd.DataFrame({\"horsepower\": extrapolate_x_hp}))\nsns.scatterplot(data=df_mpg, x=\"horsepower\", y=\"mpg\", color='blue', label='True Data')\n\nplt.plot(\n    extrapolate_x_hp,\n    mpg_hp_linear_fit.posterior[\"mu\"].mean((\"chain\", \"draw\")),\n    color=\"red\",\n    label=\"Predicted\"\n)\nplt.fill_between(extrapolate_x_hp, plt.ylim()[0], 0, color='grey', alpha=0.5, label=\"MPG Forbidden region\")\nplt.xlim(left=0, right=extrapolate_x_hp.max())\nplt.ylim(bottom=mpg_hp_linear_fit.posterior[\"mu\"].mean((\"chain\", \"draw\")).min())\nplt.legend(frameon=False);\n\n\n\n\n\n\n\n\nHowever, it is highlighted in this notebook because, due to the nature of polynomial regression, it can be very sensitive outside the fitting domain. Just for fun to wrap this notebook up, we will take a look at what the 7th order “best model” does outside of where we fit the model.\n\nextrapolate_x_hp = np.linspace(0, 300, 250)  \nbest_model.predict(best_fit, data=pd.DataFrame({\"horsepower\": extrapolate_x_hp}))\n\nsns.scatterplot(data=df_mpg, x=\"horsepower\", y=\"mpg\", color='blue', label='True Data')\nplt.plot(\n    extrapolate_x_hp,\n    best_fit.posterior[\"mu\"].mean((\"chain\", \"draw\")),\n    color=\"red\",\n    label=\"Extrapolated Fit\",\n)\nplt.fill_between(extrapolate_x_hp, plt.ylim()[0], 0, color='grey', alpha=0.5, label=\"MPG Forbidden region\")\n\nplt.xlim(left=0, right=extrapolate_x_hp.max())\nplt.ylim(bottom=best_fit.posterior[\"mu\"].mean((\"chain\", \"draw\")).min())\nplt.legend(frameon=False);\n\n\n\n\n\n\n\n\nYikes.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Thu Jul 11 2024\n\nPython implementation: CPython\nPython version       : 3.11.5\nIPython version      : 8.16.1\n\nbambi     : 0.12.1.dev63+g18e3db6f.d20240711\nscipy     : 1.11.4\npandas    : 2.1.2\nnumpy     : 1.24.4\nseaborn   : 0.13.2\narviz     : 0.19.0.dev0\nformulae  : 0.5.3\nmatplotlib: 3.8.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Orthogonal Polynomial regression"
    ]
  },
  {
    "objectID": "notebooks/negative_binomial.html",
    "href": "notebooks/negative_binomial.html",
    "title": "Negative Binomial Regression (Students absence example)",
    "section": "",
    "text": "The negative binomial distribution is flexible with multiple possible formulations. For example, it can model the number of trials or failures in a sequence of independent Bernoulli trials with probability of success (or failure) \\(p\\) until the \\(k\\)-th “success”. If we want to model the number of trials until the \\(k\\)-th success, the probability mass function (pmf) results:\n\\[\np(y | k, p)= \\binom{y - 1}{y-k}(1 -p)^{y - k}p^k\n\\]\nwhere \\(0 \\le p \\le 1\\) is the probability of success in each Bernoulli trial, \\(k &gt; 0\\), usually integer, \\(y \\in \\{k, k + 1, \\cdots\\}\\) and \\(Y\\) is the number of trials until the \\(k\\)-th success.\nIn this case, since we are modeling the number of trials until the \\(k\\)-th success, \\(y\\) starts at \\(k\\) and can be any integer greater than or equal to \\(k\\). If instead we want to model the number of failures until the \\(k\\)-th success, we can use the same definition but \\(Y\\) represents failures and starts at \\(0\\) and there’s a slightly different pmf:\n\\[\np(y | k, p)= \\binom{y + k - 1}{k-1}(1 -p)^{y}p^k\n\\]\nIn this case, \\(y\\) starts at \\(0\\) and can be any integer greater than or equal to \\(0\\). When modeling failures, \\(y\\) starts at 0, when modeling trials, \\(y\\) starts at \\(k\\).\nThese are not the only ways of defining the negative binomial distribution, there are plenty of options! One of the most interesting, and the one you see in PyMC, the library we use in Bambi for the backend, is as a continuous mixture. The negative binomial distribution describes a Poisson random variable whose rate is also a random variable (not a fixed constant!) following a gamma distribution. Or in other words, conditional on a gamma-distributed variable \\(\\mu\\), the variable \\(Y\\) has a Poisson distribution with mean \\(\\mu\\).\nUnder this alternative definition, the pmf is\n\\[\n\\displaystyle p(y | k, \\alpha) = \\binom{y + \\alpha - 1}{y} \\left(\\frac{\\alpha}{\\mu + \\alpha}\\right)^\\alpha\\left(\\frac{\\mu}{\\mu + \\alpha}\\right)^y\n\\]\nwhere \\(\\mu\\) is the parameter of the Poisson distribution (the mean, and variance too!) and \\(\\alpha\\) is the rate parameter of the gamma.\n\nimport arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom scipy.stats import nbinom\n\n\naz.style.use(\"arviz-darkgrid\")\n\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nSciPy uses the number of failures until \\(k\\) successes definition, therefore \\(y\\) starts at 0. In the following plot, we have the probability of observing \\(y\\) failures before we see \\(k=3\\) successes.\n\ny = np.arange(0, 30)\nk = 3\np1 = 0.5\np2 = 0.3\n\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n\nax[0].bar(y, nbinom.pmf(y, k, p1))\nax[0].set_xticks(np.linspace(0, 30, num=11))\nax[0].set_title(f\"k = {k}, p = {p1}\")\n\nax[1].bar(y, nbinom.pmf(y, k, p2))\nax[1].set_xticks(np.linspace(0, 30, num=11))\nax[1].set_title(f\"k = {k}, p = {p2}\")\n\nfig.suptitle(\"Y = Number of failures until k successes\", fontsize=16);\n\n\n\n\n\n\n\n\nFor example, when \\(p=0.5\\), the probability of seeing \\(y=0\\) failures before 3 successes (or in other words, the probability of having 3 successes out of 3 trials) is 0.125, and the probability of seeing \\(y=3\\) failures before 3 successes is 0.156.\n\nprint(nbinom.pmf(y, k, p1)[0])\nprint(nbinom.pmf(y, k, p1)[3])\n\n0.12499999999999997\n0.15624999999999992\n\n\nTo change the definition to the number of trials until \\(k\\) successes, we just need to shift the whole thing to the right by adding \\(k\\) to the \\(y\\) values.\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n\nax[0].bar(y + k, nbinom.pmf(y, k, p1))\nax[0].set_xticks(np.linspace(3, 30, num=10))\nax[0].set_title(f\"k = {k}, p = {p1}\")\n\nax[1].bar(y + k, nbinom.pmf(y, k, p2))\nax[1].set_xticks(np.linspace(3, 30, num=10))\nax[1].set_title(f\"k = {k}, p = {p2}\")\n\nfig.suptitle(\"Y = Number of trials until k successes\", fontsize=16);",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Negative Binomial Regression (Students absence example)"
    ]
  },
  {
    "objectID": "notebooks/negative_binomial.html#negative-binomial-distribution-review",
    "href": "notebooks/negative_binomial.html#negative-binomial-distribution-review",
    "title": "Negative Binomial Regression (Students absence example)",
    "section": "",
    "text": "The negative binomial distribution is flexible with multiple possible formulations. For example, it can model the number of trials or failures in a sequence of independent Bernoulli trials with probability of success (or failure) \\(p\\) until the \\(k\\)-th “success”. If we want to model the number of trials until the \\(k\\)-th success, the probability mass function (pmf) results:\n\\[\np(y | k, p)= \\binom{y - 1}{y-k}(1 -p)^{y - k}p^k\n\\]\nwhere \\(0 \\le p \\le 1\\) is the probability of success in each Bernoulli trial, \\(k &gt; 0\\), usually integer, \\(y \\in \\{k, k + 1, \\cdots\\}\\) and \\(Y\\) is the number of trials until the \\(k\\)-th success.\nIn this case, since we are modeling the number of trials until the \\(k\\)-th success, \\(y\\) starts at \\(k\\) and can be any integer greater than or equal to \\(k\\). If instead we want to model the number of failures until the \\(k\\)-th success, we can use the same definition but \\(Y\\) represents failures and starts at \\(0\\) and there’s a slightly different pmf:\n\\[\np(y | k, p)= \\binom{y + k - 1}{k-1}(1 -p)^{y}p^k\n\\]\nIn this case, \\(y\\) starts at \\(0\\) and can be any integer greater than or equal to \\(0\\). When modeling failures, \\(y\\) starts at 0, when modeling trials, \\(y\\) starts at \\(k\\).\nThese are not the only ways of defining the negative binomial distribution, there are plenty of options! One of the most interesting, and the one you see in PyMC, the library we use in Bambi for the backend, is as a continuous mixture. The negative binomial distribution describes a Poisson random variable whose rate is also a random variable (not a fixed constant!) following a gamma distribution. Or in other words, conditional on a gamma-distributed variable \\(\\mu\\), the variable \\(Y\\) has a Poisson distribution with mean \\(\\mu\\).\nUnder this alternative definition, the pmf is\n\\[\n\\displaystyle p(y | k, \\alpha) = \\binom{y + \\alpha - 1}{y} \\left(\\frac{\\alpha}{\\mu + \\alpha}\\right)^\\alpha\\left(\\frac{\\mu}{\\mu + \\alpha}\\right)^y\n\\]\nwhere \\(\\mu\\) is the parameter of the Poisson distribution (the mean, and variance too!) and \\(\\alpha\\) is the rate parameter of the gamma.\n\nimport arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom scipy.stats import nbinom\n\n\naz.style.use(\"arviz-darkgrid\")\n\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nSciPy uses the number of failures until \\(k\\) successes definition, therefore \\(y\\) starts at 0. In the following plot, we have the probability of observing \\(y\\) failures before we see \\(k=3\\) successes.\n\ny = np.arange(0, 30)\nk = 3\np1 = 0.5\np2 = 0.3\n\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n\nax[0].bar(y, nbinom.pmf(y, k, p1))\nax[0].set_xticks(np.linspace(0, 30, num=11))\nax[0].set_title(f\"k = {k}, p = {p1}\")\n\nax[1].bar(y, nbinom.pmf(y, k, p2))\nax[1].set_xticks(np.linspace(0, 30, num=11))\nax[1].set_title(f\"k = {k}, p = {p2}\")\n\nfig.suptitle(\"Y = Number of failures until k successes\", fontsize=16);\n\n\n\n\n\n\n\n\nFor example, when \\(p=0.5\\), the probability of seeing \\(y=0\\) failures before 3 successes (or in other words, the probability of having 3 successes out of 3 trials) is 0.125, and the probability of seeing \\(y=3\\) failures before 3 successes is 0.156.\n\nprint(nbinom.pmf(y, k, p1)[0])\nprint(nbinom.pmf(y, k, p1)[3])\n\n0.12499999999999997\n0.15624999999999992\n\n\nTo change the definition to the number of trials until \\(k\\) successes, we just need to shift the whole thing to the right by adding \\(k\\) to the \\(y\\) values.\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n\nax[0].bar(y + k, nbinom.pmf(y, k, p1))\nax[0].set_xticks(np.linspace(3, 30, num=10))\nax[0].set_title(f\"k = {k}, p = {p1}\")\n\nax[1].bar(y + k, nbinom.pmf(y, k, p2))\nax[1].set_xticks(np.linspace(3, 30, num=10))\nax[1].set_title(f\"k = {k}, p = {p2}\")\n\nfig.suptitle(\"Y = Number of trials until k successes\", fontsize=16);",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Negative Binomial Regression (Students absence example)"
    ]
  },
  {
    "objectID": "notebooks/negative_binomial.html#negative-binomial-in-glm",
    "href": "notebooks/negative_binomial.html#negative-binomial-in-glm",
    "title": "Negative Binomial Regression (Students absence example)",
    "section": "Negative binomial in GLM",
    "text": "Negative binomial in GLM\nThe negative binomial distribution belongs to the exponential family, and the canonical link function is\n\\[\ng(\\mu_i) = \\log\\left(\\frac{\\mu_i}{k + \\mu_i}\\right) = \\log\\left(\\frac{k}{\\mu_i} + 1\\right)\n\\]\nbut it is difficult to interpret. The log link is usually preferred because of the analogy with Poisson model, and it also tends to give better results.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Negative Binomial Regression (Students absence example)"
    ]
  },
  {
    "objectID": "notebooks/negative_binomial.html#load-and-explore-students-data",
    "href": "notebooks/negative_binomial.html#load-and-explore-students-data",
    "title": "Negative Binomial Regression (Students absence example)",
    "section": "Load and explore Students data",
    "text": "Load and explore Students data\nThis example is based on this UCLA example.\nSchool administrators study the attendance behavior of high school juniors at two schools. Predictors of the number of days of absence include the type of program in which the student is enrolled and a standardized test in math. We have attendance data on 314 high school juniors.\nThe variables of interest in the dataset are\n\ndaysabs: The number of days of absence. It is our response variable.\nprogr: The type of program. Can be one of ‘General’, ‘Academic’, or ‘Vocational’.\nmath: Score in a standardized math test.\n\n\ndata = pd.read_stata(\"https://stats.idre.ucla.edu/stat/stata/dae/nb_data.dta\")\n\n\ndata.head()\n\n\n\n\n\n\n\n\nid\ngender\nmath\ndaysabs\nprog\n\n\n\n\n0\n1001.0\nmale\n63.0\n4.0\n2.0\n\n\n1\n1002.0\nmale\n27.0\n4.0\n2.0\n\n\n2\n1003.0\nfemale\n20.0\n2.0\n2.0\n\n\n3\n1004.0\nfemale\n16.0\n3.0\n2.0\n\n\n4\n1005.0\nfemale\n2.0\n3.0\n2.0\n\n\n\n\n\n\n\nWe assign categories to the values 1, 2, and 3 of our \"prog\" variable.\n\ndata[\"prog\"] = data[\"prog\"].map({1: \"General\", 2: \"Academic\", 3: \"Vocational\"})\ndata.head()\n\n\n\n\n\n\n\n\nid\ngender\nmath\ndaysabs\nprog\n\n\n\n\n0\n1001.0\nmale\n63.0\n4.0\nAcademic\n\n\n1\n1002.0\nmale\n27.0\n4.0\nAcademic\n\n\n2\n1003.0\nfemale\n20.0\n2.0\nAcademic\n\n\n3\n1004.0\nfemale\n16.0\n3.0\nAcademic\n\n\n4\n1005.0\nfemale\n2.0\n3.0\nAcademic\n\n\n\n\n\n\n\nThe Academic program is the most popular program (167/314) and General is the least popular one (40/314)\n\ndata[\"prog\"].value_counts()\n\nprog\nAcademic      167\nVocational    107\nGeneral        40\nName: count, dtype: int64\n\n\nLet’s explore the distributions of math score and days of absence for each of the three programs listed above. The vertical lines indicate the mean values.\n\nfig, ax = plt.subplots(3, 2, figsize=(8, 6), sharex=\"col\")\nprograms = list(data[\"prog\"].unique())\nprograms.sort()\n\nfor idx, program in enumerate(programs):\n    # Histogram\n    ax[idx, 0].hist(data[data[\"prog\"] == program][\"math\"], edgecolor='black', alpha=0.9)\n    ax[idx, 0].axvline(data[data[\"prog\"] == program][\"math\"].mean(), color=\"C1\")\n    \n    # Barplot\n    days = data[data[\"prog\"] == program][\"daysabs\"]\n    days_mean = days.mean()\n    days_counts = days.value_counts()\n    values = list(days_counts.index)\n    count = days_counts.values\n    ax[idx, 1].bar(values, count, edgecolor='black', alpha=0.9)\n    ax[idx, 1].axvline(days_mean, color=\"C1\")\n    \n    # Titles\n    ax[idx, 0].set_title(program)\n    ax[idx, 1].set_title(program)\n\nplt.setp(ax[-1, 0], xlabel=\"Math score\")\nplt.setp(ax[-1, 1], xlabel=\"Days of absence\");\n\n\n\n\n\n\n\n\nThe first impression we have is that the distribution of math scores is not equal for any of the programs. It looks right-skewed for students under the Academic program, left-skewed for students under the Vocational program, and roughly uniform for students in the General program (although there’s a drop in the highest values). Clearly those in the Vocational program has the highest mean for the math score.\nOn the other hand, the distribution of the days of absence is right-skewed in all cases. Students in the General program present the highest absence mean while the Vocational group is the one who misses fewer classes on average.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Negative Binomial Regression (Students absence example)"
    ]
  },
  {
    "objectID": "notebooks/negative_binomial.html#models",
    "href": "notebooks/negative_binomial.html#models",
    "title": "Negative Binomial Regression (Students absence example)",
    "section": "Models",
    "text": "Models\nWe are interested in measuring the association between the type of the program and the math score with the days of absence. It’s also of interest to see if the association between math score and days of absence is different in each type of program.\nIn order to answer our questions, we are going to fit and compare two models. The first model uses the type of the program and the math score as predictors. The second model also includes the interaction between these two variables. The score in the math test is going to be standardized in both cases to make things easier for the sampler and save some seconds. A good idea to follow along is to run these models without scaling math and comparing how long it took to fit.\nWe are going to use a negative binomial likelihood to model the days of absence. But let’s stop here and think why we use this likelihood. Earlier, we said that the negative binomial distributon arises when our variable represents the number of trials until we got \\(k\\) successes. However, the number of trials is fixed, i.e. the number of school days in a given year is not a random variable. So if we stick to the definition, we could think of the two alternative views for this problem\n\nEach of the \\(n\\) days is a trial, and we record whether the student is absent (\\(y=1\\)) or not (\\(y=0\\)). This corresponds to a binary regression setting, where we could think of logistic regression or something alike. A problem here is that we have the sum of \\(y\\) for a student, but not the \\(n\\).\nThe whole school year represents the space where events occur and we count how many absences we see in that space for each student. This gives us a Poisson regression setting (count of an event in a given space or time).\n\nWe also know that when \\(n\\) is large and \\(p\\) is small, the Binomial distribution can be approximated with a Poisson distribution with \\(\\lambda = n * p\\). We don’t know exactly \\(n\\) in this scenario, but we know it is around 180, and we do know that \\(p\\) is small because you can’t skip classes all the time. So both modeling approaches should give similar results.\nBut then, why negative binomial? Can’t we just use a Poisson likelihood?\nYes, we can. However, using a Poisson likelihood implies that the mean is equal to the variance, and that is usually an unrealistic assumption. If it turns out the variance is either substantially smaller or greater than the mean, the Poisson regression model results in a poor fit. Alternatively, if we use a negative binomial likelihood, the variance is not forced to be equal to the mean, and there’s more flexibility to handle a given dataset, and consequently, the fit tends to be better.\n\nModel 1\n\\[\n\\log(\\mathbb{E}[Y_i]) = \\beta_1 \\text{Academic}_i + \\beta_2 \\text{General}_i + \\beta_3 \\text{Vocational}_i + \\beta_4 \\text{Math\\_std}_i\n\\]\n\n\nModel 2\n\\[\n\\log(\\mathbb{E}[Y_i]) = \\beta_1 \\text{Academic}_i + \\beta_2 \\text{General}_i + \\beta_3 \\text{Vocational}_i + \\beta_4 \\text{Math\\_std}_i\n            + \\beta_5 \\text{General}_i \\cdot \\text{Math\\_std}_i + \\beta_6 \\text{Vocational}_i \\cdot \\text{Math\\_std}_i\n\\]\nIn both cases we have the following dummy variables\n\\[\\text{Academic}_i =\n\\left\\{\n    \\begin{array}{ll}\n        1 & \\textrm{if student is under Academic program} \\\\\n        0 & \\textrm{other case}\n    \\end{array}\n\\right.\n\\]\n\\[\\text{General}_i =\n\\left\\{\n    \\begin{array}{ll}\n        1 & \\textrm{if student is under General program} \\\\\n        0 & \\textrm{other case}\n    \\end{array}\n\\right.\n\\]\n\\[\\text{Vocational}_i =\n\\left\\{\n    \\begin{array}{ll}\n        1 & \\textrm{if student is under Vocational program} \\\\\n        0 & \\textrm{other case}\n    \\end{array}\n\\right.\n\\]\nand \\(Y\\) represents the days of absence.\nSo, for example, the first model for a student under the Vocational program reduces to \\[\n\\log(\\mathbb{E}[Y_i]) = \\beta_3 + \\beta_4 \\text{Math\\_std}_i\n\\]\nAnd one last thing to note is we’ve decided not to include an intercept term, that’s why you don’t see any \\(\\beta_0\\) above. This choice allows us to represent the effect of each program directly with \\(\\beta_1\\), \\(\\beta_2\\), and \\(\\beta_3\\).",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Negative Binomial Regression (Students absence example)"
    ]
  },
  {
    "objectID": "notebooks/negative_binomial.html#model-fit",
    "href": "notebooks/negative_binomial.html#model-fit",
    "title": "Negative Binomial Regression (Students absence example)",
    "section": "Model fit",
    "text": "Model fit\nIt’s very easy to fit these models with Bambi. We just pass a formula describing the terms in the model and Bambi will know how to handle each of them correctly. The 0 on the right hand side of ~ simply means we don’t want to have the intercept term that is added by default. scale(math) tells Bambi we want to use standardize math before being included in the model. By default, Bambi uses a log link for negative binomial GLMs. We’ll stick to this default here.\n\nModel 1\n\nmodel_additive = bmb.Model(\"daysabs ~ 0 + prog + scale(math)\", data, family=\"negativebinomial\")\nidata_additive = model_additive.fit()\n\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [alpha, prog, scale(math)]\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n\n\n\n\nModel 2\nFor this second model we just add prog:scale(math) to indicate the interaction. A shorthand would be to use y ~ 0 + prog*scale(math), which uses the full interaction operator. In other words, it just means we want to include the interaction between prog and scale(math) as well as their main effects.\n\nmodel_interaction = bmb.Model(\"daysabs ~ 0 + prog + scale(math) + prog:scale(math)\", data, family=\"negativebinomial\")\nidata_interaction = model_interaction.fit()\n\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [alpha, prog, scale(math), prog:scale(math)]\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Negative Binomial Regression (Students absence example)"
    ]
  },
  {
    "objectID": "notebooks/negative_binomial.html#explore-models",
    "href": "notebooks/negative_binomial.html#explore-models",
    "title": "Negative Binomial Regression (Students absence example)",
    "section": "Explore models",
    "text": "Explore models\nThe first thing we do is calling az.summary(). Here we pass the InferenceData object the .fit() returned. This prints information about the marginal posteriors for each parameter in the model as well as convergence diagnostics.\n\naz.summary(idata_additive)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n1.020\n0.104\n0.819\n1.211\n0.002\n0.001\n4558.0\n3393.0\n1.0\n\n\nprog[Academic]\n1.888\n0.083\n1.737\n2.044\n0.001\n0.001\n5597.0\n3513.0\n1.0\n\n\nprog[General]\n2.340\n0.165\n2.028\n2.651\n0.002\n0.002\n6092.0\n3322.0\n1.0\n\n\nprog[Vocational]\n1.049\n0.117\n0.837\n1.272\n0.002\n0.001\n4895.0\n2808.0\n1.0\n\n\nscale(math)\n-0.150\n0.064\n-0.261\n-0.023\n0.001\n0.001\n4579.0\n3433.0\n1.0\n\n\n\n\n\n\n\n\naz.summary(idata_interaction)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n1.016\n0.103\n0.833\n1.217\n0.002\n0.001\n4598.0\n3093.0\n1.0\n\n\nprog[Academic]\n1.880\n0.087\n1.720\n2.045\n0.001\n0.001\n4763.0\n3075.0\n1.0\n\n\nprog[General]\n2.342\n0.170\n2.047\n2.682\n0.003\n0.002\n4540.0\n3075.0\n1.0\n\n\nprog[Vocational]\n0.986\n0.127\n0.756\n1.227\n0.002\n0.001\n4663.0\n3392.0\n1.0\n\n\nprog:scale(math)[General]\n0.008\n0.170\n-0.304\n0.331\n0.003\n0.002\n4118.0\n3218.0\n1.0\n\n\nprog:scale(math)[Vocational]\n0.194\n0.162\n-0.112\n0.496\n0.003\n0.002\n4006.0\n3399.0\n1.0\n\n\nscale(math)\n-0.191\n0.081\n-0.346\n-0.043\n0.001\n0.001\n3984.0\n2941.0\n1.0\n\n\n\n\n\n\n\nThe information in the two tables above can be visualized in a more concise manner using a forest plot. ArviZ provides us with plot_forest(). There we simply pass a list containing the InferenceData objects of the models we want to compare.\n\naz.plot_forest(\n    [idata_additive, idata_interaction],\n    model_names=[\"Additive\", \"Interaction\"],\n    var_names=[\"prog\", \"scale(math)\"],\n    combined=True,\n    figsize=(8, 4)\n);\n\n\n\n\n\n\n\n\nOne of the first things one can note when seeing this plot is the similarity between the marginal posteriors. Maybe one can conclude that the variability of the marginal posterior of scale(math) is slightly lower in the model that considers the interaction, but the difference is not significant.\nWe can also make conclusions about the association between the program and the math score with the days of absence. First, we see the posterior for the Vocational group is to the left of the posterior for the two other programs, meaning it is associated with fewer absences (as we have seen when first exploring our data). There also seems to be a difference between General and Academic, where we may conclude the students in the General group tend to miss more classes.\nIn addition, the marginal posterior for math shows negative values in both cases. This means that students with higher math scores tend to miss fewer classes. Below, we see a forest plot with the posteriors for the coefficients of the interaction effects. Both of them overlap with 0, which means the data does not give much evidence to support there is an interaction effect between program and math score (i.e., the association between math and days of absence is similar for all the programs).\n\naz.plot_forest(idata_interaction, var_names=[\"prog:scale(math)\"], combined=True, figsize=(8, 4))\nplt.axvline(0);",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Negative Binomial Regression (Students absence example)"
    ]
  },
  {
    "objectID": "notebooks/negative_binomial.html#plot-predicted-mean-response",
    "href": "notebooks/negative_binomial.html#plot-predicted-mean-response",
    "title": "Negative Binomial Regression (Students absence example)",
    "section": "Plot predicted mean response",
    "text": "Plot predicted mean response\nWe finish this example showing how we can get predictions for new data and plot the mean response for each program together with confidence intervals.\n\nmath_score = np.arange(1, 100)\n\n# This function takes a model and an InferenceData object.\n# It returns of length 3 with predictions for each type of program.\ndef predict(model, idata):\n    predictions = []\n    for program in programs:\n        new_data = pd.DataFrame({\"math\": math_score, \"prog\": [program] * len(math_score)})\n        new_idata = model.predict(\n            idata, \n            data=new_data,\n            inplace=False\n        )\n        prediction = new_idata.posterior[\"mu\"]\n        predictions.append(prediction)\n    \n    return predictions\n\n\nprediction_additive = predict(model_additive, idata_additive)\nprediction_interaction = predict(model_interaction, idata_interaction)\n\n\nmu_additive = [prediction.mean((\"chain\", \"draw\")) for prediction in prediction_additive]\nmu_interaction = [prediction.mean((\"chain\", \"draw\")) for prediction in prediction_interaction]\n\n\nfig, ax = plt.subplots(1, 2, sharex=True, sharey=True, figsize = (10, 4))\n\nfor idx, program in enumerate(programs):\n    ax[0].plot(math_score, mu_additive[idx], label=f\"{program}\", color=f\"C{idx}\", lw=2)\n    az.plot_hdi(math_score, prediction_additive[idx], color=f\"C{idx}\", ax=ax[0])\n\n    ax[1].plot(math_score, mu_interaction[idx], label=f\"{program}\", color=f\"C{idx}\", lw=2)\n    az.plot_hdi(math_score, prediction_interaction[idx], color=f\"C{idx}\", ax=ax[1])\n\nax[0].set_title(\"Additive\");\nax[1].set_title(\"Interaction\");\nax[0].set_xlabel(\"Math score\")\nax[1].set_xlabel(\"Math score\")\nax[0].set_ylim(0, 25)\nax[0].legend(loc=\"upper right\");\n\n\n\n\n\n\n\n\nAs we can see in this plot, the interval for the mean response for the Vocational program does not overlap with the interval for the other two groups, representing the group of students who miss fewer classes. On the right panel we can also see that including interaction terms does not change the slopes significantly because the posterior distributions of these coefficients have a substantial overlap with 0.\nIf you’ve made it to the end of this notebook and you’re still curious about what else you can do with these two models, you’re invited to use az.compare() to compare the fit of the two models. What do you expect before seeing the plot? Why? Is there anything else you could do to improve the fit of the model?\nAlso, if you’re still curious about what this model would have looked like with the Poisson likelihood, you just need to replace family=\"negativebinomial\" with family=\"poisson\" and then you’re ready to compare results!\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Tue Feb 25 2025\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.27.0\n\nmatplotlib: 3.9.2\npandas    : 2.2.3\nbambi     : 0.15.0\nnumpy     : 1.26.4\narviz     : 0.19.0\n\nWatermark: 2.5.0",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Negative Binomial Regression (Students absence example)"
    ]
  },
  {
    "objectID": "notebooks/model_comparison.html",
    "href": "notebooks/model_comparison.html",
    "title": "Logistic Regression and Model Comparison with Bambi and ArviZ",
    "section": "",
    "text": "The adults dataset is comprised of census data from 1994 in United States.\nThe goal is to use demographic variables to predict whether an individual makes more than $50,000 per year.\nThe following is a description of the variables in the dataset.\n\nage: Individual’s age\nworkclass: Labor class.\nfnlwgt: It is not specified, but we guess it is a final sampling weight.\neducation: Education level as a categorical variable.\neducational_num: Education level as numerical variable. It does not reflect years of education.\nmarital_status: Marital status.\noccupation: Occupation.\nrelationship: Relationship with the head of household.\nrace: Individual’s race.\nsex: Individual’s sex.\ncapital_gain: Capital gain during unspecified period of time.\ncapital_loss: Capital loss during unspecified period of time.\nhs_week: Hours of work per week.\nnative_country: Country of birth.\nincome: Income as a binary variable (either below or above 50K per year).\n\nWe are only using the following variables in this example: income, sex, race, age, and hs_week. This subset is comprised of both categorical and numerical variables which allows us to visualize how to incorporate both types in a logistic regression model while helping to keep the analysis simpler.\n\nimport arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport matplotlib.lines as mlines\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport warnings\n\nfrom scipy.special import expit as invlogit\n\n\n# Disable a FutureWarning in ArviZ at the moment of running the notebook\naz.style.use(\"arviz-darkgrid\")\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n\ndata = bmb.load_data(\"adults\")\n\n\ndata.info()\ndata.head()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 32561 entries, 0 to 32560\nData columns (total 5 columns):\n #   Column   Non-Null Count  Dtype \n---  ------   --------------  ----- \n 0   income   32561 non-null  object\n 1   sex      32561 non-null  object\n 2   race     32561 non-null  object\n 3   age      32561 non-null  int64 \n 4   hs_week  32561 non-null  int64 \ndtypes: int64(2), object(3)\nmemory usage: 1.2+ MB\n\n\n\n\n\n\n\n\n\nincome\nsex\nrace\nage\nhs_week\n\n\n\n\n0\n&lt;=50K\nMale\nWhite\n39\n40\n\n\n1\n&lt;=50K\nMale\nWhite\n50\n13\n\n\n2\n&lt;=50K\nMale\nWhite\n38\n40\n\n\n3\n&lt;=50K\nMale\nBlack\n53\n40\n\n\n4\n&lt;=50K\nFemale\nBlack\n28\n40\n\n\n\n\n\n\n\nCategorical variables are presented as from type object. In this step we convert them to category.\n\ncategorical_cols = data.columns[data.dtypes == object].tolist()\nfor col in categorical_cols:\n    data[col] = data[col].astype(\"category\")\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 32561 entries, 0 to 32560\nData columns (total 5 columns):\n #   Column   Non-Null Count  Dtype   \n---  ------   --------------  -----   \n 0   income   32561 non-null  category\n 1   sex      32561 non-null  category\n 2   race     32561 non-null  category\n 3   age      32561 non-null  int64   \n 4   hs_week  32561 non-null  int64   \ndtypes: category(3), int64(2)\nmemory usage: 604.7 KB\n\n\nInstead of going straight to fitting models, we’re going to do a some exploratory analysis of the variables in the dataset. First we have some plots, and then some conclusions about the information in the plots.\n\n# Just a utilitary function to truncate labels and avoid overlapping in plots\ndef truncate_labels(ticklabels, width=8):\n    def truncate(label, width):\n        if len(label) &gt; width - 3:\n            return label[0 : (width - 4)] + \"...\"\n        else:\n            return label\n\n    labels = [x.get_text() for x in ticklabels]\n    labels = [truncate(lbl, width) for lbl in labels]\n\n    return labels\n\n\nfig, axes = plt.subplots(3, 2, figsize=(12, 15))\nsns.countplot(x=\"income\", color=\"C0\", data=data, ax=axes[0, 0], saturation=1)\nsns.countplot(x=\"sex\", color=\"C0\", data=data, ax=axes[0, 1], saturation=1);\nsns.countplot(x=\"race\", color=\"C0\", data=data, ax=axes[1, 0], saturation=1);\naxes[1, 0].set_xticklabels(truncate_labels(axes[1, 0].get_xticklabels()))\naxes[1, 1].hist(data[\"age\"], bins=20);\naxes[1, 1].set_xlabel(\"Age\")\naxes[1, 1].set_ylabel(\"Count\")\naxes[2, 0].hist(data[\"hs_week\"], bins=20);\naxes[2, 0].set_xlabel(\"Hours of work / week\")\naxes[2, 0].set_ylabel(\"Count\")\naxes[2, 1].axis('off');\n\n/tmp/ipykernel_41813/1570134311.py:5: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n  axes[1, 0].set_xticklabels(truncate_labels(axes[1, 0].get_xticklabels()))\n\n\n\n\n\n\n\n\n\nHighlights\n\nApproximately 25% of the people make more than 50K a year.\nTwo thirds of the subjects are males.\nThe great majority of the subjects are white, only a minority are black and the other categories are very infrequent.\nThe distribution of age is skewed to the right, as one might expect.\nThe distribution of hours of work per week looks weird at first sight. But what is a typical workload per week? You got it, 40 hours :).\n\nWe only keep the races black and white to simplify the analysis. The other categories don’t appear very often in our data.\nNow, we see the distribution of income for the different levels of our explanatory variables. Numerical variables are binned to make the analysis possible.\n\ndata = data[data[\"race\"].isin([\"Black\", \"White\"])]\ndata[\"race\"] = data[\"race\"].cat.remove_unused_categories()\nage_bins = [17, 25, 35, 45, 65, 90]\ndata[\"age_binned\"] = pd.cut(data[\"age\"], age_bins)\nhours_bins = [0, 20, 40, 60, 100]\ndata[\"hs_week_binned\"] = pd.cut(data[\"hs_week\"], hours_bins)\n\n\nfig, axes = plt.subplots(3, 2, figsize=(12, 15))\nsns.countplot(x=\"income\", color=\"C0\", data=data, ax=axes[0, 0])\nsns.countplot(x=\"sex\", hue=\"income\", data=data, ax=axes[0, 1])\nsns.countplot(x=\"race\", hue=\"income\", data=data, ax=axes[1, 0])\nsns.countplot(x=\"age_binned\", hue=\"income\", data=data, ax=axes[1, 1])\nsns.countplot(x=\"hs_week_binned\", hue=\"income\", data=data, ax=axes[2, 0])\naxes[2, 1].axis(\"off\");\n\n\n\n\n\n\n\n\nSome quick and gross info from the plots\n\nThe probability of making more than \\$50k a year is larger if you are a Male.\nA person also has more probability of making more than \\$50k/yr if she/he is White.\nFor age, we see the probability of making more than \\$50k a year increases as the variable increases, up to a point where it starts to decrease.\nAlso, the more hours a person works per week, the higher the chance of making more than \\$50k/yr. There’s a big jump in that probability when the hours of work per week jump from the (20, 40] bin to the (40, 60] one.\n\nSome data preparation before fitting our model. Here we standardize numerical variables age and hs_week because it may help sampler convergence. Also, we compute their second and third power. These powers will be sequantialy added to the model.\n\nage_mean = np.mean(data[\"age\"])\nage_std = np.std(data[\"age\"])\nhs_mean = np.mean(data[\"hs_week\"])\nhs_std = np.std(data[\"hs_week\"])\n\ndata[\"age\"] = (data[\"age\"] - age_mean) / age_std\ndata[\"age2\"] = data[\"age\"] ** 2\ndata[\"age3\"] = data[\"age\"] ** 3\ndata[\"hs_week\"] = (data[\"hs_week\"] - hs_mean) / hs_std\ndata[\"hs_week2\"] = data[\"hs_week\"] ** 2\ndata[\"hs_week3\"] = data[\"hs_week\"] ** 3\n\ndata = data.drop(columns=[\"age_binned\", \"hs_week_binned\"])\n\nThis is how our data looks like before fitting the models.\n\ndata.head()\n\n\n\n\n\n\n\n\nincome\nsex\nrace\nage\nhs_week\nage2\nage3\nhs_week2\nhs_week3\n\n\n\n\n0\n&lt;=50K\nMale\nWhite\n0.024207\n-0.037250\n0.000586\n0.000014\n0.001388\n-0.000052\n\n\n1\n&lt;=50K\nMale\nWhite\n0.827984\n-2.222326\n0.685557\n0.567630\n4.938734\n-10.975479\n\n\n2\n&lt;=50K\nMale\nWhite\n-0.048863\n-0.037250\n0.002388\n-0.000117\n0.001388\n-0.000052\n\n\n3\n&lt;=50K\nMale\nBlack\n1.047195\n-0.037250\n1.096618\n1.148374\n0.001388\n-0.000052\n\n\n4\n&lt;=50K\nFemale\nBlack\n-0.779569\n-0.037250\n0.607728\n-0.473766\n0.001388\n-0.000052",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Logistic Regression and Model Comparison with Bambi and ArviZ"
    ]
  },
  {
    "objectID": "notebooks/model_comparison.html#adults-dataset",
    "href": "notebooks/model_comparison.html#adults-dataset",
    "title": "Logistic Regression and Model Comparison with Bambi and ArviZ",
    "section": "",
    "text": "The adults dataset is comprised of census data from 1994 in United States.\nThe goal is to use demographic variables to predict whether an individual makes more than $50,000 per year.\nThe following is a description of the variables in the dataset.\n\nage: Individual’s age\nworkclass: Labor class.\nfnlwgt: It is not specified, but we guess it is a final sampling weight.\neducation: Education level as a categorical variable.\neducational_num: Education level as numerical variable. It does not reflect years of education.\nmarital_status: Marital status.\noccupation: Occupation.\nrelationship: Relationship with the head of household.\nrace: Individual’s race.\nsex: Individual’s sex.\ncapital_gain: Capital gain during unspecified period of time.\ncapital_loss: Capital loss during unspecified period of time.\nhs_week: Hours of work per week.\nnative_country: Country of birth.\nincome: Income as a binary variable (either below or above 50K per year).\n\nWe are only using the following variables in this example: income, sex, race, age, and hs_week. This subset is comprised of both categorical and numerical variables which allows us to visualize how to incorporate both types in a logistic regression model while helping to keep the analysis simpler.\n\nimport arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport matplotlib.lines as mlines\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport warnings\n\nfrom scipy.special import expit as invlogit\n\n\n# Disable a FutureWarning in ArviZ at the moment of running the notebook\naz.style.use(\"arviz-darkgrid\")\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n\ndata = bmb.load_data(\"adults\")\n\n\ndata.info()\ndata.head()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 32561 entries, 0 to 32560\nData columns (total 5 columns):\n #   Column   Non-Null Count  Dtype \n---  ------   --------------  ----- \n 0   income   32561 non-null  object\n 1   sex      32561 non-null  object\n 2   race     32561 non-null  object\n 3   age      32561 non-null  int64 \n 4   hs_week  32561 non-null  int64 \ndtypes: int64(2), object(3)\nmemory usage: 1.2+ MB\n\n\n\n\n\n\n\n\n\nincome\nsex\nrace\nage\nhs_week\n\n\n\n\n0\n&lt;=50K\nMale\nWhite\n39\n40\n\n\n1\n&lt;=50K\nMale\nWhite\n50\n13\n\n\n2\n&lt;=50K\nMale\nWhite\n38\n40\n\n\n3\n&lt;=50K\nMale\nBlack\n53\n40\n\n\n4\n&lt;=50K\nFemale\nBlack\n28\n40\n\n\n\n\n\n\n\nCategorical variables are presented as from type object. In this step we convert them to category.\n\ncategorical_cols = data.columns[data.dtypes == object].tolist()\nfor col in categorical_cols:\n    data[col] = data[col].astype(\"category\")\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 32561 entries, 0 to 32560\nData columns (total 5 columns):\n #   Column   Non-Null Count  Dtype   \n---  ------   --------------  -----   \n 0   income   32561 non-null  category\n 1   sex      32561 non-null  category\n 2   race     32561 non-null  category\n 3   age      32561 non-null  int64   \n 4   hs_week  32561 non-null  int64   \ndtypes: category(3), int64(2)\nmemory usage: 604.7 KB\n\n\nInstead of going straight to fitting models, we’re going to do a some exploratory analysis of the variables in the dataset. First we have some plots, and then some conclusions about the information in the plots.\n\n# Just a utilitary function to truncate labels and avoid overlapping in plots\ndef truncate_labels(ticklabels, width=8):\n    def truncate(label, width):\n        if len(label) &gt; width - 3:\n            return label[0 : (width - 4)] + \"...\"\n        else:\n            return label\n\n    labels = [x.get_text() for x in ticklabels]\n    labels = [truncate(lbl, width) for lbl in labels]\n\n    return labels\n\n\nfig, axes = plt.subplots(3, 2, figsize=(12, 15))\nsns.countplot(x=\"income\", color=\"C0\", data=data, ax=axes[0, 0], saturation=1)\nsns.countplot(x=\"sex\", color=\"C0\", data=data, ax=axes[0, 1], saturation=1);\nsns.countplot(x=\"race\", color=\"C0\", data=data, ax=axes[1, 0], saturation=1);\naxes[1, 0].set_xticklabels(truncate_labels(axes[1, 0].get_xticklabels()))\naxes[1, 1].hist(data[\"age\"], bins=20);\naxes[1, 1].set_xlabel(\"Age\")\naxes[1, 1].set_ylabel(\"Count\")\naxes[2, 0].hist(data[\"hs_week\"], bins=20);\naxes[2, 0].set_xlabel(\"Hours of work / week\")\naxes[2, 0].set_ylabel(\"Count\")\naxes[2, 1].axis('off');\n\n/tmp/ipykernel_41813/1570134311.py:5: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n  axes[1, 0].set_xticklabels(truncate_labels(axes[1, 0].get_xticklabels()))\n\n\n\n\n\n\n\n\n\nHighlights\n\nApproximately 25% of the people make more than 50K a year.\nTwo thirds of the subjects are males.\nThe great majority of the subjects are white, only a minority are black and the other categories are very infrequent.\nThe distribution of age is skewed to the right, as one might expect.\nThe distribution of hours of work per week looks weird at first sight. But what is a typical workload per week? You got it, 40 hours :).\n\nWe only keep the races black and white to simplify the analysis. The other categories don’t appear very often in our data.\nNow, we see the distribution of income for the different levels of our explanatory variables. Numerical variables are binned to make the analysis possible.\n\ndata = data[data[\"race\"].isin([\"Black\", \"White\"])]\ndata[\"race\"] = data[\"race\"].cat.remove_unused_categories()\nage_bins = [17, 25, 35, 45, 65, 90]\ndata[\"age_binned\"] = pd.cut(data[\"age\"], age_bins)\nhours_bins = [0, 20, 40, 60, 100]\ndata[\"hs_week_binned\"] = pd.cut(data[\"hs_week\"], hours_bins)\n\n\nfig, axes = plt.subplots(3, 2, figsize=(12, 15))\nsns.countplot(x=\"income\", color=\"C0\", data=data, ax=axes[0, 0])\nsns.countplot(x=\"sex\", hue=\"income\", data=data, ax=axes[0, 1])\nsns.countplot(x=\"race\", hue=\"income\", data=data, ax=axes[1, 0])\nsns.countplot(x=\"age_binned\", hue=\"income\", data=data, ax=axes[1, 1])\nsns.countplot(x=\"hs_week_binned\", hue=\"income\", data=data, ax=axes[2, 0])\naxes[2, 1].axis(\"off\");\n\n\n\n\n\n\n\n\nSome quick and gross info from the plots\n\nThe probability of making more than \\$50k a year is larger if you are a Male.\nA person also has more probability of making more than \\$50k/yr if she/he is White.\nFor age, we see the probability of making more than \\$50k a year increases as the variable increases, up to a point where it starts to decrease.\nAlso, the more hours a person works per week, the higher the chance of making more than \\$50k/yr. There’s a big jump in that probability when the hours of work per week jump from the (20, 40] bin to the (40, 60] one.\n\nSome data preparation before fitting our model. Here we standardize numerical variables age and hs_week because it may help sampler convergence. Also, we compute their second and third power. These powers will be sequantialy added to the model.\n\nage_mean = np.mean(data[\"age\"])\nage_std = np.std(data[\"age\"])\nhs_mean = np.mean(data[\"hs_week\"])\nhs_std = np.std(data[\"hs_week\"])\n\ndata[\"age\"] = (data[\"age\"] - age_mean) / age_std\ndata[\"age2\"] = data[\"age\"] ** 2\ndata[\"age3\"] = data[\"age\"] ** 3\ndata[\"hs_week\"] = (data[\"hs_week\"] - hs_mean) / hs_std\ndata[\"hs_week2\"] = data[\"hs_week\"] ** 2\ndata[\"hs_week3\"] = data[\"hs_week\"] ** 3\n\ndata = data.drop(columns=[\"age_binned\", \"hs_week_binned\"])\n\nThis is how our data looks like before fitting the models.\n\ndata.head()\n\n\n\n\n\n\n\n\nincome\nsex\nrace\nage\nhs_week\nage2\nage3\nhs_week2\nhs_week3\n\n\n\n\n0\n&lt;=50K\nMale\nWhite\n0.024207\n-0.037250\n0.000586\n0.000014\n0.001388\n-0.000052\n\n\n1\n&lt;=50K\nMale\nWhite\n0.827984\n-2.222326\n0.685557\n0.567630\n4.938734\n-10.975479\n\n\n2\n&lt;=50K\nMale\nWhite\n-0.048863\n-0.037250\n0.002388\n-0.000117\n0.001388\n-0.000052\n\n\n3\n&lt;=50K\nMale\nBlack\n1.047195\n-0.037250\n1.096618\n1.148374\n0.001388\n-0.000052\n\n\n4\n&lt;=50K\nFemale\nBlack\n-0.779569\n-0.037250\n0.607728\n-0.473766\n0.001388\n-0.000052",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Logistic Regression and Model Comparison with Bambi and ArviZ"
    ]
  },
  {
    "objectID": "notebooks/model_comparison.html#the-model",
    "href": "notebooks/model_comparison.html#the-model",
    "title": "Logistic Regression and Model Comparison with Bambi and ArviZ",
    "section": "The model",
    "text": "The model\nWe will use a logistic regression model to estimate the probability of making more than \\$50K as a function of age, hours of work per week, sex, race and education level.\nIf we have a binary response variable \\(Y\\) and a set of predictors or explanatory variables \\(X_1, X_2, \\cdots, X_p\\) the logistic regression model can be defined as follows:\n\\[\\log{\\left(\\frac{\\pi}{1 - \\pi}\\right)} = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p\\]\nwhere \\(\\pi = P(Y = 1)\\) (a.k.a. probability of success) and \\(\\beta_0, \\beta_1, \\cdots \\beta_p\\) are unknown parameters. The term on the left side is the logarithm of the odds ratio or simply known as the log-odds. With little effort, the expression can be re-arranged to express our probability of interest, \\(\\pi\\), as a function of the betas and the predictors.\n\\[\n\\pi = \\frac{e^{\\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p}}{1 + e^{\\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p}}\n    = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p)}}\n\\]\nWe need to specify a prior and a likelihood in order to draw samples from the posterior distribution. We could use sociological knowledge about the effects of age and education on income, but instead, let’s use the default prior specification in Bambi.\nThe likelihood is the product of \\(n\\) Bernoulli trials, \\(\\prod_{i=1}^{n}{p_i^y(1-p_i)^{1-y_i}}\\) where \\(p_i = P(Y=1)\\).\nIn our case, we have\n\\[Y =\n\\left\\{\n    \\begin{array}{ll}\n        1 & \\textrm{if the person makes more than 50K per year} \\\\\n        0 & \\textrm{if the person makes less than 50K per year}\n    \\end{array}\n\\right.\n\\]\n\\[\\pi = P(Y=1)\\]\nBut this is a Bambi example, right? Let’s see how Bambi can helps us to build a logistic regression model.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Logistic Regression and Model Comparison with Bambi and ArviZ"
    ]
  },
  {
    "objectID": "notebooks/model_comparison.html#model-1",
    "href": "notebooks/model_comparison.html#model-1",
    "title": "Logistic Regression and Model Comparison with Bambi and ArviZ",
    "section": "Model 1:",
    "text": "Model 1:\n\\[\n\\log{\\left(\\frac{\\pi}{1 - \\pi}\\right)} = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3 + \\beta_4 X_4   \n\\]\nWhere:\n\\[\n\\begin{split}\nX_1 &= \\displaystyle \\frac{\\text{Age} - \\text{mean(Age)}}{\\text{std(Age)}} \\\\\nX_2 &= \\displaystyle \\frac{\\text{Hours week} - \\text{mean(Hours week)}}{\\text{std(Hours week)}} \\\\\nX_3 &=\n\\left\\{\n    \\begin{array}{ll}\n        1 & \\textrm{if the person is male} \\\\\n        0 & \\textrm{if the person is female}\n    \\end{array}\n\\right. \\\\\nX_4 &=\n\\left\\{\n    \\begin{array}{ll}\n        1 & \\textrm{if the person is white} \\\\\n        0 & \\textrm{if the person is black}\n    \\end{array}\n\\right.\n\\end{split}\n\\]\n\nmodel1 = bmb.Model(\"income['&gt;50K'] ~ sex + race + age + hs_week\", data, family=\"bernoulli\")\nfitted1 = model1.fit(draws=1000, idata_kwargs={\"log_likelihood\": True})\n\nModeling the probability that income==&gt;50K\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [Intercept, sex, race, age, hs_week]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 23 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\naz.plot_trace(fitted1);\naz.summary(fitted1)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-2.635\n0.062\n-2.752\n-2.516\n0.001\n0.001\n2651.0\n1600.0\n1.0\n\n\nage\n0.579\n0.015\n0.551\n0.605\n0.000\n0.000\n1636.0\n1697.0\n1.0\n\n\nhs_week\n0.505\n0.014\n0.478\n0.532\n0.000\n0.000\n1667.0\n1507.0\n1.0\n\n\nrace[White]\n0.630\n0.058\n0.525\n0.745\n0.001\n0.001\n2870.0\n1646.0\n1.0\n\n\nsex[Male]\n1.019\n0.037\n0.952\n1.089\n0.001\n0.001\n2502.0\n1684.0\n1.0",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Logistic Regression and Model Comparison with Bambi and ArviZ"
    ]
  },
  {
    "objectID": "notebooks/model_comparison.html#model-2",
    "href": "notebooks/model_comparison.html#model-2",
    "title": "Logistic Regression and Model Comparison with Bambi and ArviZ",
    "section": "Model 2",
    "text": "Model 2\n\\[\n\\log{\\left(\\frac{\\pi}{1 - \\pi}\\right)} = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_1^2 + \\beta_3 X_2 + \\beta_4 X_2^2\n                                         + \\beta_5 X_3 + \\beta_6 X_4\n\\]\nWhere:\n\\[\n\\begin{aligned}\n    X_1 &= \\displaystyle \\frac{\\text{Age} - \\text{mean(Age)}}{\\text{std(Age)}} \\\\\n    X_2 &= \\displaystyle \\frac{\\text{Hours week} - \\text{mean(Hours week)}}{\\text{std(Hours week)}} \\\\\n    X_3 &=\n    \\left\\{\n        \\begin{array}{ll}\n            1 & \\textrm{if the person is male} \\\\\n            0 & \\textrm{if the person is female}\n        \\end{array}\n    \\right. \\\\\n    X_4 &=\n    \\left\\{\n        \\begin{array}{ll}\n            1 & \\textrm{if the person is white} \\\\\n            0 & \\textrm{if the person is black}\n        \\end{array}\n    \\right. \\\\\n\\end{aligned}\n\\]\n\nmodel2 = bmb.Model(\"income['&gt;50K'] ~ sex + race + age + age2 + hs_week + hs_week2\", data, family=\"bernoulli\")\nfitted2 = model2.fit(idata_kwargs={\"log_likelihood\": True})\n\nModeling the probability that income==&gt;50K\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [Intercept, sex, race, age, age2, hs_week, hs_week2]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 36 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\naz.plot_trace(fitted2);\naz.summary(fitted2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-2.284\n0.061\n-2.403\n-2.169\n0.001\n0.001\n2324.0\n1373.0\n1.0\n\n\nage\n1.069\n0.023\n1.027\n1.116\n0.001\n0.000\n1857.0\n1470.0\n1.0\n\n\nage2\n-0.537\n0.018\n-0.568\n-0.502\n0.000\n0.000\n1760.0\n1671.0\n1.0\n\n\nhs_week\n0.498\n0.021\n0.458\n0.537\n0.001\n0.000\n1787.0\n1521.0\n1.0\n\n\nhs_week2\n-0.087\n0.008\n-0.102\n-0.071\n0.000\n0.000\n1807.0\n1470.0\n1.0\n\n\nrace[White]\n0.704\n0.058\n0.591\n0.807\n0.001\n0.001\n2317.0\n1149.0\n1.0\n\n\nsex[Male]\n1.005\n0.037\n0.936\n1.075\n0.001\n0.001\n1898.0\n1531.0\n1.0",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Logistic Regression and Model Comparison with Bambi and ArviZ"
    ]
  },
  {
    "objectID": "notebooks/model_comparison.html#model-3",
    "href": "notebooks/model_comparison.html#model-3",
    "title": "Logistic Regression and Model Comparison with Bambi and ArviZ",
    "section": "Model 3",
    "text": "Model 3\n\\[\n\\log{\\left(\\frac{\\pi}{1 - \\pi}\\right)} = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_1^2 + \\beta_3 X_1^3 + \\beta_4 X_2\n                                         + \\beta_5 X_2^2 + \\beta_6 X_2^3 + \\beta_7 X_3 + \\beta_8 X_4\n\\]\nWhere:\n\\[\n\\begin{aligned}\n    X_1 &= \\displaystyle \\frac{\\text{Age} - \\text{mean(Age)}}{\\text{std(Age)}} \\\\\n    X_2 &= \\displaystyle \\frac{\\text{Hours week} - \\text{mean(Hours week)}}{\\text{std(Hours week)}} \\\\\n    X_3 &=\n    \\left\\{\n        \\begin{array}{ll}\n            1 & \\textrm{if the person is male} \\\\\n            0 & \\textrm{if the person is female}\n        \\end{array}\n    \\right. \\\\\n    X_4 &=\n    \\left\\{\n        \\begin{array}{ll}\n            1 & \\textrm{if the person is white} \\\\\n            0 & \\textrm{if the person is black}\n        \\end{array}\n    \\right.\n\\end{aligned}\n\\]\n\nmodel3 = bmb.Model(\n    \"income['&gt;50K'] ~ age + age2 + age3 + hs_week + hs_week2 + hs_week3 + sex + race\",\n    data,\n    family=\"bernoulli\"\n)\nfitted3 = model3.fit(\n    draws=1000, random_seed=1234, target_accept=0.9, idata_kwargs={\"log_likelihood\": True}\n)\n\nModeling the probability that income==&gt;50K\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [Intercept, age, age2, age3, hs_week, hs_week2, hs_week3, sex, race]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 94 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\naz.plot_trace(fitted3);\naz.summary(fitted3)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-2.146\n0.065\n-2.266\n-2.023\n0.001\n0.001\n2855.0\n1152.0\n1.00\n\n\nage\n0.963\n0.024\n0.916\n1.007\n0.001\n0.000\n2205.0\n1628.0\n1.00\n\n\nage2\n-0.893\n0.031\n-0.951\n-0.834\n0.001\n0.001\n1300.0\n1440.0\n1.00\n\n\nage3\n0.174\n0.011\n0.153\n0.193\n0.000\n0.000\n1375.0\n1376.0\n1.00\n\n\nhs_week\n0.613\n0.025\n0.568\n0.662\n0.001\n0.000\n1958.0\n1378.0\n1.00\n\n\nhs_week2\n-0.011\n0.010\n-0.030\n0.009\n0.000\n0.000\n1661.0\n1443.0\n1.00\n\n\nhs_week3\n-0.035\n0.004\n-0.041\n-0.028\n0.000\n0.000\n1529.0\n1287.0\n1.00\n\n\nrace[White]\n0.679\n0.062\n0.555\n0.792\n0.001\n0.001\n2480.0\n1330.0\n1.01\n\n\nsex[Male]\n0.985\n0.039\n0.916\n1.062\n0.001\n0.001\n2153.0\n1337.0\n1.00",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Logistic Regression and Model Comparison with Bambi and ArviZ"
    ]
  },
  {
    "objectID": "notebooks/model_comparison.html#model-comparison",
    "href": "notebooks/model_comparison.html#model-comparison",
    "title": "Logistic Regression and Model Comparison with Bambi and ArviZ",
    "section": "Model comparison",
    "text": "Model comparison\nWe can perform a Bayesian model comparison very easily with az.compare(). Here we pass a dictionary with the InferenceData objects that Model.fit() returned and az.compare() returns a data frame that is ordered from best to worst according to the criteria used. By default, ArviZ uses loo, which is an estimation of leave one out cross validation. Another option is the widely applicable information criterion (WAIC). For more information about the information criteria available and other options within the function see the docs.\n\nmodels_dict = {\n    \"model1\": fitted1,\n    \"model2\": fitted2,\n    \"model3\": fitted3\n}\ndf_compare = az.compare(models_dict)\ndf_compare\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nmodel3\n0\n-13987.380720\n9.891946\n0.000000\n1.0\n89.340034\n0.000000\nFalse\nlog\n\n\nmodel2\n1\n-14154.783286\n7.803931\n167.402566\n0.0\n91.308343\n19.849452\nFalse\nlog\n\n\nmodel1\n2\n-14915.787100\n4.796550\n928.406380\n0.0\n91.029032\n38.924942\nFalse\nlog\n\n\n\n\n\n\n\n\naz.plot_compare(df_compare, insample_dev=False);\n\n\n\n\n\n\n\n\nThere is a difference in the point estimations (empty circles) between the model with cubic terms (model 3) and the model with quadratic terms (model 2) but there is some overlap between their interval estimations. This time, we are going to select model 2 and do some extra little work with it because from previous experience with this dataset we know there is no substantial difference between them, and model 2 is simpler. However, as we mention in the final remarks, this is not the best you can achieve with this dataset. If you want, you could also try to add other predictors, such as education level and see how it impacts in the model comparison :).",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Logistic Regression and Model Comparison with Bambi and ArviZ"
    ]
  },
  {
    "objectID": "notebooks/model_comparison.html#probability-estimation",
    "href": "notebooks/model_comparison.html#probability-estimation",
    "title": "Logistic Regression and Model Comparison with Bambi and ArviZ",
    "section": "Probability estimation",
    "text": "Probability estimation\nIn this section we plot age vs the probability of making more than 50K a year given different profiles.\nWe set hours of work per week at 40 hours and assign a grid from 18 to 75 age. They’re standardized because they were standardized when we fitted the model.\nHere we use az.plot_hdi() to get Highest Density Interval plots. We get two bands for each profile. One corresponds to an hdi probability of 0.94 (the default) and the other to an hdi probability of 0.5.\n\nHS_WEEK = (40 - hs_mean) / hs_std\nAGE = (np.linspace(18, 75) - age_mean) / age_std\n\nfig, ax = plt.subplots()\nhandles = []\ni = 0\n\nfor race in [\"Black\", \"White\"]:\n    for sex in [\"Female\", \"Male\"]:  \n        color = f\"C{i}\"\n        label = f\"{race} - {sex}\"\n        handles.append(mlines.Line2D([], [], color=color, label=label, lw=3))\n        \n        new_data = pd.DataFrame({\n            \"sex\": [sex] * len(AGE),\n            \"race\": [race] * len(AGE), \n            \"age\": AGE,\n            \"age2\": AGE ** 2,\n            \"hs_week\": [HS_WEEK] * len(AGE),\n            \"hs_week2\": [HS_WEEK ** 2] * len(AGE),\n        })\n        new_idata = model2.predict(fitted2, data=new_data, inplace=False)\n        mean = new_idata.posterior[\"p\"].values\n\n        az.plot_hdi(AGE * age_std + age_mean, mean, ax=ax, color=color)\n        az.plot_hdi(AGE * age_std + age_mean, mean, ax=ax, color=color, hdi_prob=0.5)\n        i += 1\n\nax.set_xlabel(\"Age\")\nax.set_ylabel(\"P(Income &gt; $50K)\")\nax.legend(handles=handles, loc=\"upper left\");\n\n\n\n\n\n\n\n\nThe highest posterior density bands show how the probability of earning more than 50K changes with age for a given profile. In all the cases, we see the probability of making more than $50K increases with age until approximately age 52, when the probability begins to drop off. We can interpret narrow portions of a curve as places where we have low uncertainty and spread out portions of the bands as places where we have somewhat higher uncertainty about our coefficient values.\n\nFinal remarks\nIn this notebook we’ve seen how easy it is to incorporate ArviZ into a Bambi workflow to perform model comparison based on information criteria such as LOO and WAIC. However, an attentive reader might have seen that the highest density interval plot never shows a predicted probability greater than 0.5 (which is not good if we expect to predict that at least some people working 40hrs/wk make more than \\$50k/yr). You can increase the hours of work per week for the profiles we’ve used and the HDIs will show larger values. But we won’t be seeing the whole picture.\nAlthough we’re using some demographic variables such as sex and race, the cells resulting from the combinations of their levels are still very heterogeneous. For example, we are mixing individuals of all educational levels. A possible next step is to incorporate education into the different models we compared. If any of the readers (yes, you!) is interested in doing so, here there are some notes that may help\n\nEducation is an ordinal categorical variable with a lot of levels.\n\nExplore the conditional distribution of income given education levels.\nSee what are the counts/proportions of people within each education level.\nCollapse categories (but respect the ordinality!). Try to end up with 5 or less categories if possible.\n\nStart with a model with only age, sex, race, hs_week and education. Then incorporate higher order terms (second and third powers for example). Don’t go beyond fourth powers.\nLook for a nice activity to do while the sampler does its job.\nWe know it’s going to take a couple of hours to fit all those models :)\n\nAnd finally, please feel free to open a new issue if you think there’s something that we can improve.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sun May 26 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\nnumpy     : 1.26.4\nmatplotlib: 3.8.4\nseaborn   : 0.13.2\npandas    : 2.2.2\nbambi     : 0.13.1.dev39+gb7d6a6cb\narviz     : 0.18.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Logistic Regression and Model Comparison with Bambi and ArviZ"
    ]
  },
  {
    "objectID": "notebooks/logistic_regression.html",
    "href": "notebooks/logistic_regression.html",
    "title": "Logistic Regression (Vote intention with ANES data)",
    "section": "",
    "text": "import arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\naz.style.use(\"arviz-darkgrid\")\nSEED = 7355608",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Logistic Regression (Vote intention with ANES data)"
    ]
  },
  {
    "objectID": "notebooks/logistic_regression.html#load-and-examine-american-national-election-studies-anes-data",
    "href": "notebooks/logistic_regression.html#load-and-examine-american-national-election-studies-anes-data",
    "title": "Logistic Regression (Vote intention with ANES data)",
    "section": "Load and examine American National Election Studies (ANES) data",
    "text": "Load and examine American National Election Studies (ANES) data\nThese data are from the 2016 pilot study. The full study consisted of 1200 people, but here we’ve selected the subset of 487 people who responded to a question about whether they would vote for Hillary Clinton or Donald Trump.\n\ndata = bmb.load_data(\"ANES\")\ndata.head()\n\n\n\n\n\n\n\n\nvote\nage\nparty_id\n\n\n\n\n0\nclinton\n56\ndemocrat\n\n\n1\ntrump\n65\nrepublican\n\n\n2\nclinton\n80\ndemocrat\n\n\n3\ntrump\n38\nrepublican\n\n\n4\ntrump\n60\nrepublican\n\n\n\n\n\n\n\nOur outcome variable is vote, which gives peoples’ responses to the following question prompt:\n“If the 2016 presidential election were between Hillary Clinton for the Democrats and Donald Trump for the Republicans, would you vote for Hillary Clinton, Donald Trump, someone else, or probably not vote?”\n\ndata[\"vote\"].value_counts()\n\nvote\nclinton         215\ntrump           158\nsomeone_else     48\nName: count, dtype: int64\n\n\nThe two predictors we’ll examine are a respondent’s age and their political party affiliation, party_id, which is their response to the following question prompt:\n“Generally speaking, do you usually think of yourself as a Republican, a Democrat, an independent, or what?”\n\ndata[\"party_id\"].value_counts()\n\nparty_id\ndemocrat       186\nindependent    138\nrepublican      97\nName: count, dtype: int64\n\n\nThese two predictors are somewhat correlated, but not all that much:\n\nfig, ax = plt.subplots(1, 3, figsize=(10, 4), sharey=True, constrained_layout=True)\nkey = dict(zip(data[\"party_id\"].unique(), range(3)))\nfor label, df in data.groupby(\"party_id\"):\n    ax[key[label]].hist(df[\"age\"])\n    ax[key[label]].set_xlim([18, 90])\n    ax[key[label]].set_xlabel(\"Age\")\n    ax[key[label]].set_ylabel(\"Frequency\")\n    ax[key[label]].set_title(label)\n    ax[key[label]].axvline(df[\"age\"].mean(), color=\"C1\")\n\n\n\n\n\n\n\n\nWe can get a pretty clear idea of how party identification is related to voting intentions by just looking at a contingency table for these two variables:\n\npd.crosstab(data[\"vote\"], data[\"party_id\"])\n\n\n\n\n\n\n\nparty_id\ndemocrat\nindependent\nrepublican\n\n\nvote\n\n\n\n\n\n\n\nclinton\n159\n51\n5\n\n\nsomeone_else\n10\n22\n16\n\n\ntrump\n17\n65\n76\n\n\n\n\n\n\n\nBut our main question here will be: How is respondent age related to voting intentions, and is this relationship different for different party affiliations? For this we will use a logistic regression.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Logistic Regression (Vote intention with ANES data)"
    ]
  },
  {
    "objectID": "notebooks/logistic_regression.html#build-clinton_model",
    "href": "notebooks/logistic_regression.html#build-clinton_model",
    "title": "Logistic Regression (Vote intention with ANES data)",
    "section": "Build clinton_model",
    "text": "Build clinton_model\nTo keep this simple, let’s look at only the data from people who indicated that they would vote for either Clinton or Trump, and we’ll model the probability of voting for Clinton.\n\nclinton_data = data.loc[data[\"vote\"].isin([\"clinton\", \"trump\"]), :]\nclinton_data.head()\n\n\n\n\n\n\n\n\nvote\nage\nparty_id\n\n\n\n\n0\nclinton\n56\ndemocrat\n\n\n1\ntrump\n65\nrepublican\n\n\n2\nclinton\n80\ndemocrat\n\n\n3\ntrump\n38\nrepublican\n\n\n4\ntrump\n60\nrepublican\n\n\n\n\n\n\n\n\nLogistic regression\nWe’ll use a logistic regression model to estimate the probability of voting for Clinton as a function of age and party affiliation. We can think we have a response variable \\(Y\\) defined as\n\\[\nY =\n\\left\\{\n    \\begin{array}{ll}\n        1 & \\textrm{if the person votes for Clinton} \\\\\n        0 & \\textrm{if the person votes for Trump}\n    \\end{array}\n\\right.\n\\]\nand we are interested in modelling \\(\\pi = P(Y = 1)\\) (a.k.a. probability of success) based on two explanatory variables, age and party affiliation.\nA logistic regression is a model that links the \\(\\text{logit}(\\pi)\\) to a linear combination of the predictors. In our example, we’re going to include a main effect for party affiliation and the interaction effect between party affiliation and age (i.e. we’ll have a different age slope for each affiliation). The mathematical equation for our model is\n$$\n\\[\\begin{aligned}\n    \\log{\\left(\\frac{\\pi}{1 - \\pi}\\right)} &=\n    \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3 X_4 + \\beta_4 X_1 X_4 + \\beta_5 X_2 X_4 \\\\\n\n    X_1 &= \\left\\{\n        \\begin{array}{ll}\n            1 & \\textrm{if party affiliation is Independent} \\\\\n            0 & \\textrm{in other case}\n        \\end{array}\n    \\right. \\\\\n\n    X_2 &= \\left\\{\n        \\begin{array}{ll}\n            1 & \\textrm{if party affiliation is Republican} \\\\\n            0 & \\textrm{in other case}\n        \\end{array}\n    \\right. \\\\\n\n    X_3 &=\n    \\left\\{\n        \\begin{array}{ll}\n            1 & \\textrm{if party affiliation is Democrat} \\\\\n            0 & \\textrm{in other case}\n        \\end{array}\n    \\right. \\\\\n\n    X_4 &= \\text{Age}\n\\end{aligned}\\]\n$$\nNotice we don’t have a main effect for \\(X_3\\). This happens because Democrat party affiliation is being taken as baseline in the encoding of the categorical variable party_id and \\(\\beta_1\\) and \\(\\beta_2\\) represent deviations from that baseline. Thus, we see the main effect of Democrat affiliation is being represented by the Intercept, \\(\\beta_0\\).\nIf we represent the right hand side of the model equation with \\(\\eta\\), the expression can be re-arranged to express our probability of interest, \\(\\pi\\), as a function of the linear predictor \\(\\eta\\).\n\\[\\pi = \\frac{e^\\eta}{1 + e^\\eta}= \\frac{1}{1 + e^{-\\eta}}\\]\nSince we’re Bayesian folks who draw samples from posteriors, we need to specify a prior for the parameters as well as a likelihood function before accomplishing our task. In this occasion, we’re going to use the default priors in Bambi and just note the likelihood is the product of \\(n\\) Bernoulli trials, \\(\\prod_{i=1}^{n}{p_i^y(1-p_i)^{1-y_i}}\\) where \\(p_i = P(Y=1)\\) and \\(y_i = 1\\) if the vote intention is for Clinton and \\(y_i = 0\\) if Trump.\n\n\nSpecify and fit model in Bambi\nSpecifying and fitting the model is simple. Bambi is good and doesn’t ask us to translate all the math to code. We just need to specify our model using the formula syntax and pass the correct family argument. Notice the (optional) syntax that we use on the left-hand-side of the formula: We say vote[clinton] to instruct Bambi that we wish the model the probability that vote=='clinton', rather than the probability that vote=='trump'. If we leave this unspecified, Bambi will just pick one of the events to model, but will inform you which one it picked when you build the model (and again when you look at model summaries).\nOn the right-hand-side of the formula we use party_id + party_id:age to instruct Bambi that we want to use party_id and the interaction between party_id and age as the explanatory variables in the model.\n\n\nclinton_model = bmb.Model(\"vote['clinton'] ~ party_id + party_id:age\", clinton_data, family=\"bernoulli\")\nclinton_fitted = clinton_model.fit(\n    draws=2000, target_accept=0.85, random_seed=SEED, idata_kwargs={\"log_likelihood\": True}\n)\n\nModeling the probability that vote==clinton\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Intercept, party_id, party_id:age]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 21 seconds.\n\n\nWe can print the model object to see information about the response distribution, the link function and the priors.\n\nclinton_model\n\n       Formula: vote['clinton'] ~ party_id + party_id:age\n        Family: bernoulli\n          Link: p = logit\n  Observations: 373\n        Priors: \n    target = p\n        Common-level effects\n            Intercept ~ Normal(mu: 0.0, sigma: 1.5)\n            party_id ~ Normal(mu: [0. 0.], sigma: [1. 1.])\n            party_id:age ~ Normal(mu: [0. 0. 0.], sigma: [0.0582 0.0582 0.0582])\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\nUnder the hood, Bambi selected Gaussian priors for all the parameters in the model. By construction, all the priors, except the one for Intercept, are centered around 0, which is consistent with the desired weakly informative behavior. The standard deviation is specific to each parameter.\nSome more info about these default priors can be found in this technical paper.\nWe can also call clinton_model.plot_priors() to visualize the sensitive default priors Bambi has chosen for us.\n\nclinton_model.plot_priors();\n\nSampling: [Intercept, party_id, party_id:age]\n\n\n\n\n\n\n\n\n\nNow let’s check out the results! We get traceplots and density estimates for the posteriors with az.plot_trace() and a summary of the posteriors with az.summary().\n\naz.plot_trace(clinton_fitted, compact=False);\n\n\n\n\n\n\n\n\n\naz.summary(clinton_fitted)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n1.392\n0.553\n0.378\n2.451\n0.007\n0.005\n6778.0\n5131.0\n1.0\n\n\nparty_id[independent]\n-0.046\n0.650\n-1.221\n1.173\n0.008\n0.008\n6081.0\n4477.0\n1.0\n\n\nparty_id[republican]\n-0.603\n0.814\n-2.142\n0.933\n0.010\n0.008\n6336.0\n5269.0\n1.0\n\n\nparty_id:age[democrat]\n0.018\n0.012\n-0.004\n0.042\n0.000\n0.000\n6588.0\n5188.0\n1.0\n\n\nparty_id:age[independent]\n-0.032\n0.010\n-0.052\n-0.014\n0.000\n0.000\n6877.0\n4836.0\n1.0\n\n\nparty_id:age[republican]\n-0.082\n0.024\n-0.127\n-0.038\n0.000\n0.000\n5677.0\n5113.0\n1.0",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Logistic Regression (Vote intention with ANES data)"
    ]
  },
  {
    "objectID": "notebooks/logistic_regression.html#model-assessment",
    "href": "notebooks/logistic_regression.html#model-assessment",
    "title": "Logistic Regression (Vote intention with ANES data)",
    "section": "Model assessment",
    "text": "Model assessment\nBefore moving forward to inference, we can evaluate the quality of the model’s fit. We will take a look at two different ways of assessing how good is the model’s fit using its predictions.\n\nSeparation plot\nThere is a way of assessing the performance of a model with binary outcomes (such as logistic regression) in a visual way called separation plot. In a separation plot, the model’s predictions are averaged, ordered and represented as consecutive vertical lines. These vertical lines are colored according to the class indicated by their corresponding observed value, in this case light blue indicates class 0 (vote == 'Trump') and blue represents class 1 (vote =='Clinton'). We can use the ArviZ’ implementation of the separation plot, but first we have to obtain the model’s predictions.\n\nclinton_model.predict(clinton_fitted, kind=\"response\")\n\n\nax = az.plot_separation(clinton_fitted, y=\"vote\", figsize=(9,0.5));\n\n\n\n\n\n\n\n\nIn this separation plot we can see that some observations are misspredicted, specially in the right hand side of the plot where the model predicts Trump votes when there were really Clinton ones. We can further investigate this using another of ArviZ model evaluation tool.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Logistic Regression (Vote intention with ANES data)"
    ]
  },
  {
    "objectID": "notebooks/logistic_regression.html#hat-kappa-parameter",
    "href": "notebooks/logistic_regression.html#hat-kappa-parameter",
    "title": "Logistic Regression (Vote intention with ANES data)",
    "section": "\\(\\hat \\kappa\\) parameter",
    "text": "\\(\\hat \\kappa\\) parameter\nWe can also use ArviZ to compute LOO and find influential observations using the estimated \\(\\hat \\kappa\\) parameter value.\n\n# compute pointwise LOO\nloo = az.loo(clinton_fitted, pointwise=True)\n\n\n# plot kappa values\naz.plot_khat(loo.pareto_k);\n\n\n\n\n\n\n\n\nA first look at the khat plot shows that most observations’ \\(\\hat \\kappa\\) values are grouped together in a range that goes up to roughly 0.2. Above that value, we observe some dispersion and a few points that stand out by having the highest \\(\\hat \\kappa\\) values.\nAn observation is influential in the sense that if we refit the data by first removing that observation from the data set, the fitted result will be more different than if we do the same for a non influential observation. Clearly the level of influence of observations can vary continuously. An observation can be influential either because it is an outlier (a measurement error, a data entry error, etc) or because the model is not flexible enough to capture the observation. The approximations used to compute LOO are no longer reliable for \\(\\hat \\kappa &gt; 0.7\\).\nLet us first take a look at the observation with the highest \\(\\hat \\kappa\\).\n\nax = az.plot_khat(loo.pareto_k.values.ravel())\nsorted_kappas = np.sort(loo.pareto_k.values.ravel())\n\n# find observation where the kappa value exceeds the threshold\nthreshold = sorted_kappas[-1:]\nax.axhline(threshold, ls=\"--\", color=\"orange\")\ninfluential_observations = clinton_data.reset_index()[loo.pareto_k.values &gt;= threshold].index\n\nfor x in influential_observations:\n    y = loo.pareto_k.values[x]\n    ax.text(x, y + 0.01, str(x), ha=\"center\", va=\"baseline\")\n\n\n\n\n\n\n\n\n\nclinton_data.reset_index()[loo.pareto_k.values &gt;= threshold]\n\n\n\n\n\n\n\n\nindex\nvote\nage\nparty_id\n\n\n\n\n191\n215\ntrump\n95\nrepublican\n\n\n\n\n\n\n\nThis observation corresponds to a 95 year old Republican party member that voted for Trump.\n\nLet us take a look at six observations with the highest \\(\\hat \\kappa\\) values.\n\nax = az.plot_khat(loo.pareto_k)\n\n# find observation where the kappa value exceeds the threshold\nthreshold = sorted_kappas[-6:].min()\nax.axhline(threshold, ls=\"--\", color=\"orange\")\ninfluential_observations = clinton_data.reset_index()[loo.pareto_k.values &gt;= threshold].index\n\nfor x in influential_observations:\n    y = loo.pareto_k.values[x]\n    ax.text(x, y + 0.01, str(x), ha=\"center\", va=\"baseline\")\n\n\n\n\n\n\n\n\n\nclinton_data.reset_index()[loo.pareto_k.values&gt;=threshold]\n\n\n\n\n\n\n\n\nindex\nvote\nage\nparty_id\n\n\n\n\n34\n34\ntrump\n83\nrepublican\n\n\n45\n46\ntrump\n75\ndemocrat\n\n\n58\n64\ntrump\n84\nrepublican\n\n\n62\n68\ntrump\n91\nrepublican\n\n\n191\n215\ntrump\n95\nrepublican\n\n\n365\n410\nclinton\n55\nrepublican\n\n\n\n\n\n\n\nObservations number 34, 58, 62, and 191 correspond to individuals in under represented age groups in the data set. The rest correspond to Republican party members that voted for Clinton. Let us check how many observations we have of individuals older than 80 years old.\n\nclinton_data[clinton_data.age &gt; 80]\n\n\n\n\n\n\n\n\nvote\nage\nparty_id\n\n\n\n\n34\ntrump\n83\nrepublican\n\n\n64\ntrump\n84\nrepublican\n\n\n68\ntrump\n91\nrepublican\n\n\n97\nclinton\n83\ndemocrat\n\n\n215\ntrump\n95\nrepublican\n\n\n246\nclinton\n82\ndemocrat\n\n\n403\nclinton\n81\ndemocrat\n\n\n\n\n\n\n\nLet us check how many observations there are of Republicans who voted for Clinton\n\nclinton_data[(clinton_data.vote =='clinton') & (clinton_data.party_id == 'republican')]\n\n\n\n\n\n\n\n\nvote\nage\nparty_id\n\n\n\n\n170\nclinton\n27\nrepublican\n\n\n248\nclinton\n36\nrepublican\n\n\n359\nclinton\n22\nrepublican\n\n\n361\nclinton\n37\nrepublican\n\n\n410\nclinton\n55\nrepublican\n\n\n\n\n\n\n\nThere are only two observations for individuals older than 80 years old and five observations for individuals of the Republican party that vote for Clinton. The fact that the model finds it difficult to predict for these observations is related to model uncertainty, due to a scarce number of observations that exhibit these characteristics.\nLet us repeat the separation plot, this time marking the observations we have analyzed. This plot will show us how the model predicted these particular observations.\n\nimport matplotlib.patheffects as pe\n\nax = az.plot_separation(clinton_fitted, y=\"vote\", figsize=(9, 0.5))\n\ny = np.random.uniform(0.1, 0.5, size=len(influential_observations))\n\nfor x, y in zip(influential_observations, y):\n    text = str(x)\n    x = x / len(clinton_data)\n    ax.scatter(x, y, marker=\"+\", s=50, color=\"red\", zorder=3)\n    ax.text(\n        x, y + 0.1, text, color=\"white\", ha=\"center\", va=\"bottom\",\n        path_effects=[pe.withStroke(linewidth=2, foreground=\"black\")]\n    )\n\n\n\n\n\n\n\n\n\nclinton_data.reset_index()[loo.pareto_k.values&gt;=threshold]\n\n\n\n\n\n\n\n\nindex\nvote\nage\nparty_id\n\n\n\n\n34\n34\ntrump\n83\nrepublican\n\n\n45\n46\ntrump\n75\ndemocrat\n\n\n58\n64\ntrump\n84\nrepublican\n\n\n62\n68\ntrump\n91\nrepublican\n\n\n191\n215\ntrump\n95\nrepublican\n\n\n365\n410\nclinton\n55\nrepublican\n\n\n\n\n\n\n\nThis assessment helped us to further understand the model and quality of the fit. It also illustrates the intuition that we should be cautious when predicting for under represented age groups and voting behaviours.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Logistic Regression (Vote intention with ANES data)"
    ]
  },
  {
    "objectID": "notebooks/logistic_regression.html#run-inference",
    "href": "notebooks/logistic_regression.html#run-inference",
    "title": "Logistic Regression (Vote intention with ANES data)",
    "section": "Run Inference",
    "text": "Run Inference\nGrab the posteriors samples of the age slopes for the three party_id categories.\n\nparties = [\"democrat\", \"independent\", \"republican\"]\ndem, ind, rep = [clinton_fitted.posterior[\"party_id:age\"].sel({\"party_id:age_dim\":party}) for party in parties]\n\nPlot the marginal posteriors for the age slopes for the three political affiliations.\n\n_, ax = plt.subplots()\nfor idx, x in enumerate([dem, ind, rep]):\n    az.plot_dist(x, label=x[\"party_id:age_dim\"].item(), plot_kwargs={\"color\": f\"C{idx}\"}, ax=ax)\nax.legend(loc=\"upper left\");\n\n\n\n\n\n\n\n\nNow, using the joint posterior, we can answer our questions in terms of probabilities.\nWhat is the probability that the Democrat slope is greater than the Republican slope?\n\n(dem &gt; rep).mean().item()\n\n1.0\n\n\nProbability that the Democrat slope is greater than the Independent slope?\n\n(dem &gt; ind).mean().item()\n\n1.0\n\n\nProbability that the Independent slope is greater than the Republican slope?\n\n(ind &gt; rep).mean().item()\n\n0.9795\n\n\nProbability that the Democrat slope is greater than 0?\n\n(dem &gt; 0).mean().item()\n\n0.93775\n\n\nProbability that the Republican slope is less than 0?\n\n(rep &lt; 0).mean().item()\n\n0.999875\n\n\nProbability that the Independent slope is less than 0?\n\n(ind &lt; 0).mean().item()\n\n0.999625\n\n\nIf we look at the plot of the marginal posteriors, we may be suspicious that, for example, the probability that Democrat slope is greater than the Republican slope is 0.998 (almost 1!), given the overlap between the blue and green density functions. However, we can’t answer such a question using the marginal posteriors only, as shown in the plot. Since Democrat and Republican slopes (\\(\\beta_3\\) and \\(\\beta_5\\), respectively) are random variables, we need to use their joint distribution to answer probability questions that involve both of them. The fact that logical comparisons (e.g. &gt; in dem &gt; ind) are performed elementwise ensures we’re using samples from the joint posterior as we should. We also note that when the question involves only one of the random variables, it is fine to use the marginal distribution (e.g. (rep &lt; 0).mean()).\nFinally, all these comments may have not been necessary since we didn’t need to mention anything about marginal or joint distributions when performing the calculations, we’ve just grabbed the samples and applied some basic math. But that’s an advantage of Bambi and the Bayesian approach. Things that are not so simple, became simpler :)",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Logistic Regression (Vote intention with ANES data)"
    ]
  },
  {
    "objectID": "notebooks/logistic_regression.html#spaghetti-plot-of-model-predictions",
    "href": "notebooks/logistic_regression.html#spaghetti-plot-of-model-predictions",
    "title": "Logistic Regression (Vote intention with ANES data)",
    "section": "Spaghetti plot of model predictions",
    "text": "Spaghetti plot of model predictions\nHere we make use of the Model.predict() method to predict the probability of voting for Clinton for an out-of-sample dataset that we create.\n\nage = np.arange(18, 91)\nnew_data = pd.DataFrame({\n    \"age\": np.tile(age, 3),\n    \"party_id\": np.repeat([\"democrat\", \"republican\", \"independent\"], len(age))\n})\nnew_data\n\n\n\n\n\n\n\n\nage\nparty_id\n\n\n\n\n0\n18\ndemocrat\n\n\n1\n19\ndemocrat\n\n\n2\n20\ndemocrat\n\n\n3\n21\ndemocrat\n\n\n4\n22\ndemocrat\n\n\n...\n...\n...\n\n\n214\n86\nindependent\n\n\n215\n87\nindependent\n\n\n216\n88\nindependent\n\n\n217\n89\nindependent\n\n\n218\n90\nindependent\n\n\n\n\n219 rows × 2 columns\n\n\n\nObtain predictions for the new dataset. By default, Bambi is going to obtain a posterior distribution for the mean probability of voting for Clinton. These values are stored as the \"p\" variable in clinton_fitted.posterior.\n\nclinton_model.predict(clinton_fitted, data=new_data)\n\n\n# Select a sample of posterior values for the mean probability of voting for Clinton\nvote_posterior = az.extract_dataset(clinton_fitted, num_samples=2000)[\"p\"]\n\n/tmp/ipykernel_13027/1918123043.py:2: FutureWarning: extract_dataset has been deprecated, please use extract\n  vote_posterior = az.extract_dataset(clinton_fitted, num_samples=2000)[\"p\"]\n\n\nMake the plot!\n\n_, ax = plt.subplots(figsize=(7, 5))\n\nfor i, party in enumerate([\"democrat\", \"republican\", \"independent\"]):\n    # Which rows in new_data correspond to party?\n    idx = new_data.index[new_data[\"party_id\"] == party].tolist()\n    ax.plot(age, vote_posterior[idx], alpha=0.04, color=f\"C{i}\")\n\nax.set_ylabel(\"P(vote='clinton' | age)\")\nax.set_xlabel(\"Age\", fontsize=15)\nax.set_ylim(0, 1)\nax.set_xlim(18, 90);\n\n\n\n\n\n\n\n\nThe following is a rough interpretation of the information contained in the plot we’ve just created.\nAccording to our logistic model, the mean probability of voting for Clinton is almost always 0.8 or greater for Democrats no matter the age (blue line). Also, the older the person, the closer the mean probability of voting Clinton to 1.\nOn the other hand, Republicans have a non-zero probability of voting for Clinton when they are young, but it tends to zero for older persons (green line). We can also note the high variability of P(vote = ‘Clinton’) for young Republicans. This reflects our high uncertainty when estimating this probability and it is due to the small amount of Republicans in that age range plus there are only 5 Republicans out of 97 voting for Clinton in the dataset.\nFinally, the mean probability of voting Clinton for the independents is around 0.7 for the youngest and decreases towards 0.2 as they get older (orange line). Since the spread of the lines is similar along all the ages, we can conclude our uncertainty in this estimate is similar for all the age groups.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Thu Aug 15 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\nmatplotlib: 3.8.4\nbambi     : 0.14.1.dev12+g64e57423.d20240730\narviz     : 0.18.0\npandas    : 2.2.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Logistic Regression (Vote intention with ANES data)"
    ]
  },
  {
    "objectID": "notebooks/hsgp_2d.html",
    "href": "notebooks/hsgp_2d.html",
    "title": "Gaussian Processes in 2D",
    "section": "",
    "text": "This article demonstrates how to use Bambi with Gaussian Processes with 2 dimensional predictors. Bambi supports Gaussian Processes through the low-rank approximation known as Hilbert Space Gaussian Processes. For references see Hilbert Space Methods for Reduced-Rank Gaussian Process Regression and Practical Hilbert Space Approximate Bayesian Gaussian Processes for Probabilistic Programming.\nIf you prefer a video format, have a look at Introduction to Hilbert Space GPs in PyMC given by Bill Engels.\nimport arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pymc as pm\nThe goal of this notebook is to showcase Bambi’s support for Gaussian Processes on two-dimensional data using the HSGP approximation.\nTo achieve this, we begin by creating a matrix of coordinates that will serve as the locations where we measure the values of a continuous response variable.\nx1 = np.linspace(0, 10, 12)\nx2 = np.linspace(0, 10, 12)\nxx, yy = np.meshgrid(x1, x2)\nX = np.column_stack([xx.flatten(), yy.flatten()])\nX.shape\n\n(144, 2)",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Gaussian Processes in 2D"
    ]
  },
  {
    "objectID": "notebooks/hsgp_2d.html#isotropic-samples",
    "href": "notebooks/hsgp_2d.html#isotropic-samples",
    "title": "Gaussian Processes in 2D",
    "section": "Isotropic samples",
    "text": "Isotropic samples\nIn modeling multi-dimensional data with a Gaussian Process, we must choose between using an isotropic or an anisotropic Gaussian Process. An isotropic GP applies the same degree of smoothing to all predictors and is rotationally invariant. On the other hand, an anisotropic GP assigns different degrees of smoothing to each predictor and is not rotationally invariant.\nFurthermore, as the hsgp() function allows for the creation of separate GP contribution terms for the levels of a categorical variable through its by argument, we also examine both single-group and multiple-group scenarios.\n\nA single group\nWe create a covariance kernel using ExpQuad from the gp submodule in PyMC. Note that the lengthscale and amplitude for both dimensions are 2 and 1.2, respectively. Then, we simply use NumPy to get a random draw from the 144-dimensional multivariate normal distribution.\n\nrng = np.random.default_rng(1234)\n\nell = 2\ncov = 1.2 * pm.gp.cov.ExpQuad(2, ls=ell)\nK = cov(X).eval()\nmu = np.zeros(X.shape[0])\nprint(mu.shape, K.shape)\n\nf = rng.multivariate_normal(mu, K)\n\nfig, ax = plt.subplots()\nax.scatter(xx, yy, c=f, s=900, marker=\"s\");\n\n(144,) (144, 144)\n\n\n\n\n\n\n\n\n\nSince Bambi works with long-format data frames, we need to reshape our data before creating the data frame.\n\ndata = pd.DataFrame(\n    {\n        \"x\": np.tile(xx.flatten(), 1),\n        \"y\": np.tile(yy.flatten(), 1), \n        \"outcome\": f.flatten()\n    }\n)\n\nNow, let’s construct the model. The only notable distinction from the one-dimensional case is that we provide two unnamed arguments to the hsgp() function, representing the predictors on each dimension.\n\nprior_hsgp = {\n    \"sigma\": bmb.Prior(\"Exponential\", lam=3),\n    \"ell\": bmb.Prior(\"InverseGamma\", mu=2, sigma=0.2),\n}\npriors = {\n    \"hsgp(x, y, c=1.5, m=10)\": prior_hsgp, \n    \"sigma\": bmb.Prior(\"HalfNormal\", sigma=2)\n}\nmodel = bmb.Model(\"outcome ~ 0 + hsgp(x, y, c=1.5, m=10)\", data, priors=priors)\nmodel.set_alias({\"hsgp(x, y, c=1.5, m=10)\": \"hsgp\"})\nmodel\n\n       Formula: outcome ~ 0 + hsgp(x, y, c=1.5, m=10)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 144\n        Priors: \n    target = mu\n        HSGP contributions\n            hsgp(x, y, c=1.5, m=10)\n                cov: ExpQuad\n                sigma ~ Exponential(lam: 3.0)\n                ell ~ InverseGamma(mu: 2.0, sigma: 0.2)\n        \n        Auxiliary parameters\n            sigma ~ HalfNormal(sigma: 2.0)\n\n\nThe parameters c and m of the HSGP aproximation are specific to each dimension, and can have different values for each. However, as we are passing scalars instead of sequences, Bambi will internally recycle them, causing the HSGP approximation to use the same values of c and m for both dimensions.\nLet’s build the internal PyMC model and create a graph to have a visual representation of the relationships between the model parameters.\n\nmodel.build()\nmodel.graph()\n\n\n\n\n\n\n\n\nAnd finally, we quickly fit the model and show a traceplot to explore the posterior and spot any issues with the sampler.\n\nidata = model.fit(inference_method=\"numpyro_nuts\", target_accept=0.9, num_chains=4)\nprint(idata.sample_stats.diverging.sum().item())\n\nsample: 100%|████████████████████████████████████████████████████████████████| 1500/1500 [01:43&lt;00:00, 14.53it/s]\n\n\n0\n\n\n\naz.plot_trace(\n    idata, \n    var_names=[\"hsgp_sigma\", \"hsgp_ell\", \"sigma\"], \n    backend_kwargs={\"layout\": \"constrained\"}\n);\n\n\n\n\n\n\n\n\nWe don’t see any divergences. However, the autocorrelation in the chains for the covariance function parameters, along with the insufficient mixing, indicates that there may be an issue with the prior specification of the model.\nSince the goal of the notebook is to simply show what features Bambi supports and how to use them, we won’t further investigate these issues. However, such posteriors shouldn’t be considered in any serious application.\nFrom now on, the notebook will follow the same structure as the one already shown, which consists of\n\nData simulation with some specific settings\nCreation of the Bambi model\nBuilding of the internal PyMC model and visualization of the graph\nModel fit and inspection of the traceplot\n\n\n\nMultiple groups - same covariance function\nIn this scenario we have multiple groups that share the same covariance function.\n\nrng = np.random.default_rng(123)\n\nell = 2\ncov = 1.2 * pm.gp.cov.ExpQuad(2, ls=ell)\nK = cov(X).eval()\nmu = np.zeros(X.shape[0])\n\nf = rng.multivariate_normal(mu, K, 3)\n\nfig, axes = plt.subplots(1, 3, figsize=(12, 4))\nfor i, ax in enumerate(axes):\n    ax.scatter(xx, yy, c=f[i], s=320, marker=\"s\")\n    ax.grid(False)\n    ax.set_title(f\"Group {i}\")\n\n\n\n\n\n\n\n\n\ndata = pd.DataFrame(\n    {\n        \"x\": np.tile(xx.flatten(), 3),\n        \"y\": np.tile(yy.flatten(), 3),\n        \"group\": np.repeat(list(\"ABC\"), 12 * 12),\n        \"outcome\": f.flatten()\n    }\n)\n\nNotice we don’t modify anything substantial in the call to hsgp() for now.\n\nprior_hsgp = {\n    \"sigma\": bmb.Prior(\"Exponential\", lam=3),\n    \"ell\": bmb.Prior(\"InverseGamma\", mu=2, sigma=0.2),\n}\npriors = {\n    \"hsgp(x, y, by=group, c=1.5, m=10)\": prior_hsgp, \n    \"sigma\": bmb.Prior(\"HalfNormal\", sigma=2)\n}\nmodel = bmb.Model(\"outcome ~ 0 + hsgp(x, y, by=group, c=1.5, m=10)\", data, priors=priors)\nmodel.set_alias({\"hsgp(x, y, by=group, c=1.5, m=10)\": \"hsgp\"})\nprint(model)\nmodel.build()\nmodel.graph()\n\n       Formula: outcome ~ 0 + hsgp(x, y, by=group, c=1.5, m=10)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 432\n        Priors: \n    target = mu\n        HSGP contributions\n            hsgp(x, y, by=group, c=1.5, m=10)\n                cov: ExpQuad\n                sigma ~ Exponential(lam: 3.0)\n                ell ~ InverseGamma(mu: 2.0, sigma: 0.2)\n        \n        Auxiliary parameters\n            sigma ~ HalfNormal(sigma: 2.0)\n\n\n\n\n\n\n\n\n\n\nidata = model.fit(inference_method=\"numpyro_nuts\", target_accept=0.9, num_chains=4)\nprint(idata.sample_stats.diverging.sum().item())\n\nsample: 100%|████████████████████████████████████████████████████████████████| 1500/1500 [04:33&lt;00:00,  5.48it/s]\n\n\n0\n\n\n\naz.plot_trace(\n    idata, \n    var_names=[\"hsgp_sigma\", \"hsgp_ell\", \"sigma\"], \n    backend_kwargs={\"layout\": \"constrained\"}\n);\n\n\n\n\n\n\n\n\nWhile we have three groups, we only have one hsgp_sigma and one hsgp_ell for all groups. This is because, by default, the HSGP contributions by groups use the same instance of the covariance function.\n\n\nMultiple groups - different covariance function\nAgain we have multiple groups. But this time, each group has specific values for the amplitude and the lengthscale.\n\nrng = np.random.default_rng(12)\n\nsigmas = [1.2, 1.5, 1.8]\nells = [1.5, 2, 3]\n\nsamples = []\nfor sigma, ell in zip(sigmas, ells):\n    cov = sigma * pm.gp.cov.ExpQuad(2, ls=ell)\n    K = cov(X).eval()\n    mu = np.zeros(X.shape[0])\n    samples.append(rng.multivariate_normal(mu, K))\n\nf = np.stack(samples)\nfig, axes = plt.subplots(1, 3, figsize=(12, 4))\nfor i, ax in enumerate(axes):\n    ax.scatter(xx, yy, c=f[i], s=320, marker=\"s\")\n    ax.grid(False)\n    ax.set_title(f\"Group {i}\")\n\n\n\n\n\n\n\n\n\ndata = pd.DataFrame(\n    {\n        \"x\": np.tile(xx.flatten(), 3),\n        \"y\": np.tile(yy.flatten(), 3),\n        \"group\": np.repeat(list(\"ABC\"), 12 * 12),\n        \"outcome\": f.flatten()\n    }\n)\n\nIn situations like this, we can tell Bambi not to use the same covariance function for all the groups with share_cov=False and Bambi will create a separate instance for each group, resulting in group specific estimates of the amplitude and the lengthscale.\nNotice, however, we’re still using the same kind of covariance function, which in this case is ExpQuad.\n\nprior_hsgp = {\n    \"sigma\": bmb.Prior(\"Exponential\", lam=3),\n    \"ell\": bmb.Prior(\"InverseGamma\", mu=2, sigma=0.2),\n}\npriors = {\n    \"hsgp(x, y, by=group, c=1.5, m=10, share_cov=False)\": prior_hsgp, \n    \"sigma\": bmb.Prior(\"HalfNormal\", sigma=2)\n}\nmodel = bmb.Model(\n    \"outcome ~ 0 + hsgp(x, y, by=group, c=1.5, m=10, share_cov=False)\", \n    data, \n    priors=priors\n)\nmodel.set_alias({\"hsgp(x, y, by=group, c=1.5, m=10, share_cov=False)\": \"hsgp\"})\nprint(model)\nmodel.build()\nmodel.graph()\n\n       Formula: outcome ~ 0 + hsgp(x, y, by=group, c=1.5, m=10, share_cov=False)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 432\n        Priors: \n    target = mu\n        HSGP contributions\n            hsgp(x, y, by=group, c=1.5, m=10, share_cov=False)\n                cov: ExpQuad\n                sigma ~ Exponential(lam: 3.0)\n                ell ~ InverseGamma(mu: 2.0, sigma: 0.2)\n        \n        Auxiliary parameters\n            sigma ~ HalfNormal(sigma: 2.0)\n\n\n\n\n\n\n\n\n\nSee the all the HSGP related parameters gained the new dimension hsgp_by.\n\nidata = model.fit(inference_method=\"numpyro_nuts\", target_accept=0.9, num_chains=4)\nprint(idata.sample_stats.diverging.sum().item())\n\nsample: 100%|████████████████████████████████████████████████████████████████| 1500/1500 [05:12&lt;00:00,  4.81it/s]\n\n\n0\n\n\n\naz.plot_trace(\n    idata, \n    var_names=[\"hsgp_sigma\", \"hsgp_ell\", \"sigma\"], \n    backend_kwargs={\"layout\": \"constrained\"}\n);\n\n\n\n\n\n\n\n\nUnlike the previous case, now there are three hsgp_sigma and three hsgp_ell parameters, one per group. We can see them in different colors in the visualization.",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Gaussian Processes in 2D"
    ]
  },
  {
    "objectID": "notebooks/hsgp_2d.html#anisotropic-samples",
    "href": "notebooks/hsgp_2d.html#anisotropic-samples",
    "title": "Gaussian Processes in 2D",
    "section": "Anisotropic samples",
    "text": "Anisotropic samples\nIn this second part we repeat exactly the same that we did for the isotropic case. First, we start with a single group. Then, we continue with multiple groups that share the covariance function. And finally, multiple groups with different covariance functions. The main difference is that we use iso=False, which asks to use an anisotropic GP.\n\nA single group\n\nrng = np.random.default_rng(1234)\n\nell = [2, 0.9]\ncov = 1.2 * pm.gp.cov.ExpQuad(2, ls=ell)\nK = cov(X).eval()\nmu = np.zeros(X.shape[0])\n\nf = rng.multivariate_normal(mu, K)\n\nfig, ax = plt.subplots(figsize = (4.5, 4.5))\nax.scatter(xx, yy, c=f, s=900, marker=\"s\");\n\n\n\n\n\n\n\n\n\ndata = pd.DataFrame(\n    {\n        \"x\": np.tile(xx.flatten(), 1),\n        \"y\": np.tile(yy.flatten(), 1), \n        \"outcome\": f.flatten()\n    }\n)\n\n\nprior_hsgp = {\n    \"sigma\": bmb.Prior(\"Exponential\", lam=3),\n    \"ell\": bmb.Prior(\"InverseGamma\", mu=2, sigma=0.2),\n}\npriors = {\n    \"hsgp(x, y, c=1.5, m=10, iso=False)\": prior_hsgp, \n    \"sigma\": bmb.Prior(\"HalfNormal\", sigma=2)\n}\nmodel = bmb.Model(\"outcome ~ 0 + hsgp(x, y, c=1.5, m=10, iso=False)\", data, priors=priors)\nmodel.set_alias({\"hsgp(x, y, c=1.5, m=10, iso=False)\": \"hsgp\"})\nprint(model)\nmodel.build()\nmodel.graph()\n\n       Formula: outcome ~ 0 + hsgp(x, y, c=1.5, m=10, iso=False)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 144\n        Priors: \n    target = mu\n        HSGP contributions\n            hsgp(x, y, c=1.5, m=10, iso=False)\n                cov: ExpQuad\n                sigma ~ Exponential(lam: 3.0)\n                ell ~ InverseGamma(mu: 2.0, sigma: 0.2)\n        \n        Auxiliary parameters\n            sigma ~ HalfNormal(sigma: 2.0)\n\n\n\n\n\n\n\n\n\nAlthough there is only one group in this case, the graph includes a hsgp_var dimension. This dimension represents the variables in the HSGP component, indicating that there is one lengthscale parameter per variable.\n\nidata = model.fit(inference_method=\"numpyro_nuts\", target_accept=0.9, num_chains=4)\nprint(idata.sample_stats.diverging.sum().item())\n\nsample: 100%|████████████████████████████████████████████████████████████████| 1500/1500 [00:20&lt;00:00, 74.63it/s]\n\n\n0\n\n\n\naz.plot_trace(\n    idata, \n    var_names=[\"hsgp_sigma\", \"hsgp_ell\", \"sigma\"], \n    backend_kwargs={\"layout\": \"constrained\"}\n);\n\n\n\n\n\n\n\n\n\n\nMultiple groups - same covariance function\n\nrng = np.random.default_rng(123)\n\nell = [2, 0.9]\ncov = 1.2 * pm.gp.cov.ExpQuad(2, ls=ell)\nK = cov(X).eval()\nmu = np.zeros(X.shape[0])\n\nf = rng.multivariate_normal(mu, K, 3)\n\nfig, axes = plt.subplots(1, 3, figsize=(12, 4))\nfor i, ax in enumerate(axes):\n    ax.scatter(xx, yy, c=f[i], s=320, marker=\"s\")\n    ax.grid(False)\n    ax.set_title(f\"Group {i}\")\n\n\n\n\n\n\n\n\n\ndata = pd.DataFrame(\n    {\n        \"x\": np.tile(xx.flatten(), 3),\n        \"y\": np.tile(yy.flatten(), 3),\n        \"group\": np.repeat(list(\"ABC\"), 12 * 12),\n        \"outcome\": f.flatten()\n    }\n)\n\n\nprior_hsgp = {\n    \"sigma\": bmb.Prior(\"Exponential\", lam=3),\n    \"ell\": bmb.Prior(\"InverseGamma\", mu=2, sigma=0.2),\n}\npriors = {\n    \"hsgp(x, y, by=group, c=1.5, m=10, iso=False)\": prior_hsgp, \n    \"sigma\": bmb.Prior(\"HalfNormal\", sigma=2)\n}\nmodel = bmb.Model(\"outcome ~ 0 + hsgp(x, y, by=group, c=1.5, m=10, iso=False)\", data, priors=priors)\nmodel.set_alias({\"hsgp(x, y, by=group, c=1.5, m=10, iso=False)\": \"hsgp\"})\nprint(model)\nmodel.build()\nmodel.graph()\n\n       Formula: outcome ~ 0 + hsgp(x, y, by=group, c=1.5, m=10, iso=False)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 432\n        Priors: \n    target = mu\n        HSGP contributions\n            hsgp(x, y, by=group, c=1.5, m=10, iso=False)\n                cov: ExpQuad\n                sigma ~ Exponential(lam: 3.0)\n                ell ~ InverseGamma(mu: 2.0, sigma: 0.2)\n        \n        Auxiliary parameters\n            sigma ~ HalfNormal(sigma: 2.0)\n\n\n\n\n\n\n\n\n\n\nidata = model.fit(inference_method=\"numpyro_nuts\", target_accept=0.9, num_chains=4)\nprint(idata.sample_stats.diverging.sum().item())\n\nsample: 100%|████████████████████████████████████████████████████████████████| 1500/1500 [00:41&lt;00:00, 36.57it/s]\n\n\n0\n\n\n\naz.plot_trace(\n    idata, \n    var_names=[\"hsgp_sigma\", \"hsgp_ell\", \"sigma\"], \n    backend_kwargs={\"layout\": \"constrained\"}\n);\n\n\n\n\n\n\n\n\n\n\nMultiple groups - different covariance function\n\nrng = np.random.default_rng(12)\n\nsigmas = [1.2, 1.5, 1.8]\nells = [[1.5, 0.8], [2, 1.5], [3, 1]]\n\nsamples = []\nfor sigma, ell in zip(sigmas, ells):\n    cov = sigma * pm.gp.cov.ExpQuad(2, ls=ell)\n    K = cov(X).eval()\n    mu = np.zeros(X.shape[0])\n    samples.append(rng.multivariate_normal(mu, K))\n\nf = np.stack(samples)\nfig, axes = plt.subplots(1, 3, figsize=(12, 4))\nfor i, ax in enumerate(axes):\n    ax.scatter(xx, yy, c=f[i], s=320, marker=\"s\")\n    ax.grid(False)\n    ax.set_title(f\"Group {i}\")\n\n\n\n\n\n\n\n\n\ndata = pd.DataFrame(\n    {\n        \"x\": np.tile(xx.flatten(), 3),\n        \"y\": np.tile(yy.flatten(), 3),\n        \"group\": np.repeat(list(\"ABC\"), 12 * 12),\n        \"outcome\": f.flatten()\n    }\n)\n\n\nprior_hsgp = {\n    \"sigma\": bmb.Prior(\"Exponential\", lam=3),\n    \"ell\": bmb.Prior(\"InverseGamma\", mu=2, sigma=0.2),\n}\npriors = {\n    \"hsgp(x, y, by=group, c=1.5, m=10, iso=False, share_cov=False)\": prior_hsgp, \n    \"sigma\": bmb.Prior(\"HalfNormal\", sigma=2)\n}\nmodel = bmb.Model(\n    \"outcome ~ 0 + hsgp(x, y, by=group, c=1.5, m=10, iso=False, share_cov=False)\", \n    data, \n    priors=priors\n)\nmodel.set_alias({\"hsgp(x, y, by=group, c=1.5, m=10, iso=False, share_cov=False)\": \"hsgp\"})\nprint(model)\nmodel.build()\nmodel.graph()\n\n       Formula: outcome ~ 0 + hsgp(x, y, by=group, c=1.5, m=10, iso=False, share_cov=False)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 432\n        Priors: \n    target = mu\n        HSGP contributions\n            hsgp(x, y, by=group, c=1.5, m=10, iso=False, share_cov=False)\n                cov: ExpQuad\n                sigma ~ Exponential(lam: 3.0)\n                ell ~ InverseGamma(mu: 2.0, sigma: 0.2)\n        \n        Auxiliary parameters\n            sigma ~ HalfNormal(sigma: 2.0)\n\n\n\n\n\n\n\n\n\n\nidata = model.fit(inference_method=\"numpyro_nuts\", target_accept=0.9, num_chains=4)\nprint(idata.sample_stats.diverging.sum().item())\n\nsample: 100%|████████████████████████████████████████████████████████████████| 1500/1500 [00:52&lt;00:00, 28.43it/s]\n\n\n0\n\n\n\naz.plot_trace(\n    idata, \n    var_names=[\"hsgp_sigma\", \"hsgp_ell\", \"sigma\"], \n    backend_kwargs={\"layout\": \"constrained\"}\n);",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Gaussian Processes in 2D"
    ]
  },
  {
    "objectID": "notebooks/hsgp_2d.html#a-more-complex-example-poisson-likelihood-with-group-specific-effects",
    "href": "notebooks/hsgp_2d.html#a-more-complex-example-poisson-likelihood-with-group-specific-effects",
    "title": "Gaussian Processes in 2D",
    "section": "A more complex example: Poisson likelihood with group-specific effects",
    "text": "A more complex example: Poisson likelihood with group-specific effects\nFor this final demonstration we’re going to use a simulated dataset where the outcome is a count variable. For the predictors, we have the location in terms of the latitude and longitude, as well as other variables such as the year of the measurement, the site where the measure was made, and one continuous predictor.\n\ndata = pd.read_csv(\"data/poisson_data.csv\")\ndata[\"Year\"] = pd.Categorical(data[\"Year\"])\nprint(data.shape)\ndata.head()\n\n(100, 6)\n\n\n\n\n\n\n\n\n\nYear\nCount\nSite\nLat\nLon\nX1\n\n\n\n\n0\n2015\n4\nSite1\n47.559880\n7.216754\n3.316140\n\n\n1\n2016\n0\nSite1\n47.257079\n7.135390\n2.249612\n\n\n2\n2015\n0\nSite1\n47.061967\n7.804383\n2.835283\n\n\n3\n2016\n0\nSite1\n47.385533\n7.433145\n2.776692\n\n\n4\n2015\n1\nSite1\n47.034987\n7.434643\n2.295769\n\n\n\n\n\n\n\nWe can visualize the outcome variable by location and year.\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\nfor i, (ax, year) in enumerate(zip(axes, [2015, 2016])):\n    mask = data[\"Year\"] == year\n    x = data.loc[mask, \"Lat\"]\n    y = data.loc[mask, \"Lon\"]\n    count = data.loc[mask, \"Count\"]\n    ax.scatter(x, y, c=count, s=30, marker=\"s\")\n    ax.set_title(f\"Year {year}\")\n\n\n\n\n\n\n\n\nThere’s not much we can conclude from here but it’s not a problem. The most relevant part of the example is not the data itself, but how to use Bambi to include GP components in a complex model.\nIt’s very easy to create a model that uses both regular common and group-specific predictors as well as a GP contribution term. We just add them to the model formula, treat hsgp() as any other call, and that’s it!\nBelow we have common effects for the Year, the interaction between X1 and Year, and group-specific intercepts by Site. Finally, we add hsgp() as any other call.\n\nformula = \"Count ~ 0 + Year + X1:Year + (1|Site) + hsgp(Lon, Lat, by=Year, m=5, c=1.5)\"\nmodel = bmb.Model(formula, data, family=\"poisson\")\nmodel\n\n       Formula: Count ~ 0 + Year + X1:Year + (1|Site) + hsgp(Lon, Lat, by=Year, m=5, c=1.5)\n        Family: poisson\n          Link: mu = log\n  Observations: 100\n        Priors: \n    target = mu\n        Common-level effects\n            Year ~ Normal(mu: [0. 0.], sigma: [5. 5.])\n            X1:Year ~ Normal(mu: [0. 0.], sigma: [1.5693 1.4766])\n        \n        Group-level effects\n            1|Site ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 5.3683))\n        \n        HSGP contributions\n            hsgp(Lon, Lat, by=Year, m=5, c=1.5)\n                cov: ExpQuad\n                sigma ~ Exponential(lam: 1.0)\n                ell ~ InverseGamma(alpha: 3.0, beta: 2.0)\n\n\nLet’s use an alias to make the graph representation more readable.\n\nmodel.set_alias({\"hsgp(Lon, Lat, by=Year, m=5, c=1.5)\": \"gp\"})\nmodel.build()\nmodel.graph()\n\n\n\n\n\n\n\n\nAnd finally, let’s fit the model.\n\nidata = model.fit(inference_method=\"numpyro_nuts\", target_accept=0.99, num_chains=4)\nprint(idata.sample_stats.diverging.sum().item())\n\nsample: 100%|████████████████████████████████████████████████████████████████| 1500/1500 [00:18&lt;00:00, 79.90it/s]\n\n\n143\n\n\n\naz.plot_trace(\n    idata, \n    var_names=[\"gp_sigma\", \"gp_ell\", \"gp_weights\"], \n    backend_kwargs={\"layout\": \"constrained\"}\n);\n\n\n\n\n\n\n\n\nNotice the posteriors for the gp_weights are all centered at zero. This is a symptom of the absence of any spatial effect.\n\naz.plot_trace(\n    idata, \n    var_names=[\"Year\", \"X1:Year\"], \n    backend_kwargs={\"layout\": \"constrained\"}\n);\n\n\n\n\n\n\n\n\n\naz.plot_trace(\n    idata, \n    var_names=[\"1|Site\", \"1|Site_sigma\"], \n    backend_kwargs={\"layout\": \"constrained\"}\n);",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Gaussian Processes in 2D"
    ]
  },
  {
    "objectID": "notebooks/how_bambi_works.html",
    "href": "notebooks/how_bambi_works.html",
    "title": "Basic building blocks",
    "section": "",
    "text": "Bambi builds linear predictors of the form\n\\[\n\\pmb{\\eta} = \\mathbf{X}\\pmb{\\beta} + \\mathbf{Z}\\pmb{u}\n\\]\nThe linear predictor is the sum of two kinds of contributions\n\n\\(\\mathbf{X}\\pmb{\\beta}\\) is the common (fixed) effects contribution\n\\(\\mathbf{Z}\\pmb{u}\\) is the group-specific (random) effects contribution\n\nBoth contributions obey the same rule: A dot product between a data object and a parameter object."
  },
  {
    "objectID": "notebooks/how_bambi_works.html#example",
    "href": "notebooks/how_bambi_works.html#example",
    "title": "Basic building blocks",
    "section": "Example",
    "text": "Example\n\nimport arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\naz.style.use(\"arviz-darkgrid\")\n\n\ndata = bmb.load_data(\"sleepstudy\")\n\n\ndef plot_data(data):\n    fig, axes = plt.subplots(2, 9, figsize=(16, 7.5), sharey=True, sharex=True, dpi=300, constrained_layout=False)\n    fig.subplots_adjust(left=0.075, right=0.975, bottom=0.075, top=0.925, wspace=0.03)\n\n    axes_flat = axes.ravel()\n\n    for i, subject in enumerate(data[\"Subject\"].unique()):\n        ax = axes_flat[i]\n        idx = data.index[data[\"Subject\"] == subject].tolist()\n        days = data.loc[idx, \"Days\"].to_numpy()\n        reaction = data.loc[idx, \"Reaction\"].to_numpy()\n\n        # Plot observed data points\n        ax.scatter(days, reaction, color=\"C0\", ec=\"black\", alpha=0.7)\n\n        # Add a title\n        ax.set_title(f\"Subject: {subject}\", fontsize=14)\n\n    ax.xaxis.set_ticks([0, 2, 4, 6, 8])\n    fig.text(0.5, 0.02, \"Days\", fontsize=14)\n    fig.text(0.03, 0.5, \"Reaction time (ms)\", rotation=90, fontsize=14, va=\"center\")\n\n    return axes\n\nplot_data(data);\n\n\n\n\n\n\n\n\nThe model\n\\[\n\\begin{aligned}\n\\mu_i & = \\beta_0 + \\beta_1 \\text{Days}_i + u_{0i} + u_{1i}\\text{Days}_i \\\\\n\\beta_0 & \\sim \\text{Normal} \\\\\n\\beta_1 & \\sim \\text{Normal} \\\\\nu_{0i} & \\sim \\text{Normal}(0, \\sigma_{u_0}) \\\\\nu_{1i} & \\sim \\text{Normal}(0, \\sigma_{u_1}) \\\\\n\\sigma_{u_0} & \\sim \\text{HalfNormal} \\\\\n\\sigma_{u_1} & \\sim \\text{HalfNormal} \\\\\n\\sigma  & \\sim \\text{HalfStudentT} \\\\\n\\text{Reaction}_i & \\sim \\text{Normal}(\\mu_i, \\sigma)\n\\end{aligned}\n\\]\nWritten in a slightly different way (and omitting some priors)…\n\\[\n\\begin{aligned}\n\\mu_i & = \\text{Intercept}_i + \\text{Slope}_i \\text{Days}_i \\\\\n\\text{Intercept}_i & = \\beta_0 + u_{0i} \\\\\n\\text{Slope}_i & = \\beta_1 + u_{1i} \\\\\n\\sigma & \\sim \\text{HalfStudentT} \\\\\n\\text{Reaction}_i & \\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n\\end{aligned}\n\\]\nWe can see both the intercept and the slope are made of a “common” component and a “subject-specific” deflection.\nUnder the general representation written above…\n\\[\n\\begin{aligned}\n\\pmb{\\mu} &= \\mathbf{X}\\pmb{\\beta} + \\mathbf{Z}\\pmb{u} \\\\\n\\pmb{\\beta}    &\\sim \\text{Normal} \\\\\n\\pmb{u}        &\\sim \\text{Normal}(0, \\text{diag}(\\sigma_{\\pmb{u}})) \\\\\n\\sigma         &\\sim \\text{HalfStudenT} \\\\\n\\sigma_{\\pmb{u}} &\\sim \\text{HalfNormal} \\\\\nY_i  &\\sim \\text{Normal}(\\mu_i, \\sigma)\n\\end{aligned}\n\\]\n\nmodel = bmb.Model(\"Reaction ~ 1 + Days + (1 + Days | Subject)\", data, categorical=\"Subject\")\nmodel\n\n       Formula: Reaction ~ 1 + Days + (1 + Days | Subject)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 180\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 298.5079, sigma: 261.0092)\n            Days ~ Normal(mu: 0.0, sigma: 48.8915)\n        \n        Group-level effects\n            1|Subject ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 261.0092))\n            Days|Subject ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 48.8915))\n        \n        Auxiliary parameters\n            Reaction_sigma ~ HalfStudentT(nu: 4.0, sigma: 56.1721)\n\n\n\nmodel.build()\nmodel.graph()\n\n\n\n\n\n\n\n\n\ndm = model.response_component.design\ndm\n\nDesignMatrices\n\n                  (rows, cols)\nResponse:               (180,)\nCommon:               (180, 2)\nGroup-specific:      (180, 36)\n\nUse .reponse, .common, or .group to access the different members.\n\n\n\nprint(dm.response, \"\\n\")\nprint(np.array(dm.response)[:5])\n\nResponseMatrix  \n  name: Reaction\n  kind: numeric\n  shape: (180,)\n\nTo access the actual design matrix do 'np.array(this_obj)' \n\n[249.56   258.7047 250.8006 321.4398 356.8519]\n\n\n\nprint(dm.common, \"\\n\")\nprint(np.array(dm.common)[:5])\n\nCommonEffectsMatrix with shape (180, 2)\nTerms:  \n  Intercept  \n    kind: intercept\n    column: 0\n  Days  \n    kind: numeric\n    column: 1\n\nTo access the actual design matrix do 'np.array(this_obj)' \n\n[[1 0]\n [1 1]\n [1 2]\n [1 3]\n [1 4]]\n\n\n\nprint(dm.group, \"\\n\")\nprint(np.array(dm.group)[:14])\n\nGroupEffectsMatrix with shape (180, 36)\nTerms:  \n  1|Subject  \n    kind: intercept\n    groups: ['308', '309', '310', '330', '331', '332', '333', '334', '335', '337', '349', '350',\n      '351', '352', '369', '370', '371', '372']\n    columns: 0:18\n  Days|Subject  \n    kind: numeric\n    groups: ['308', '309', '310', '330', '331', '332', '333', '334', '335', '337', '349', '350',\n      '351', '352', '369', '370', '371', '372']\n    columns: 18:36\n\nTo access the actual design matrix do 'np.array(this_obj)' \n\n[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n\n\n\nmodel.response_component.intercept_term\n\nCommonTerm(  \n  name: Intercept,\n  prior: Normal(mu: 298.5079, sigma: 261.0092),\n  shape: (180,),\n  categorical: False\n)\n\n\n\nmodel.response_component.common_terms\n\n{'Days': CommonTerm(  \n   name: Days,\n   prior: Normal(mu: 0.0, sigma: 48.8915),\n   shape: (180,),\n   categorical: False\n )}\n\n\n\nmodel.response_component.group_specific_terms\n\n{'1|Subject': GroupSpecificTerm(  \n   name: 1|Subject,\n   prior: Normal(mu: 0.0, sigma: HalfNormal(sigma: 261.0092)),\n   shape: (180, 18),\n   categorical: False,\n   groups: ['308', '309', '310', '330', '331', '332', '333', '334', '335', '337', '349', '350', '351', '352', '369', '370', '371', '372']\n ),\n 'Days|Subject': GroupSpecificTerm(  \n   name: Days|Subject,\n   prior: Normal(mu: 0.0, sigma: HalfNormal(sigma: 48.8915)),\n   shape: (180, 18),\n   categorical: False,\n   groups: ['308', '309', '310', '330', '331', '332', '333', '334', '335', '337', '349', '350', '351', '352', '369', '370', '371', '372']\n )}\n\n\nTerms not only exist in the Bambi world. There are three (!!) types of terms being created.\n\nFormulae has its terms\n\nAgnostic information design matrix information\n\nBambi has its terms\n\nContains both the information given by formulae and metadata relevant to Bambi (priors)\n\nThe backend has its terms\n\nAccept a Bambi term and knows how to “compile” itself to that backend.\nE.g. the PyMC backend terms know how to write one or more PyMC distributions out of a Bambi term.\n\n\nCould we have multiple backends? In principle yes. But there’s one aspect which is convoluted, dims and coords, and the solution we found (not the best) prevented us from separating all stuff and making the front-end completely independent of the backend.\nFormulae terms\n\ndm.common.terms\n\n{'Intercept': Intercept(), 'Days': Term([Variable(Days)])}\n\n\n\ndm.group.terms\n\n{'1|Subject': GroupSpecificTerm(\n   expr= Intercept(),\n   factor= Term([Variable(Subject)])\n ),\n 'Days|Subject': GroupSpecificTerm(\n   expr= Term([Variable(Days)]),\n   factor= Term([Variable(Subject)])\n )}\n\n\nBambi terms\n\nmodel.response_component.terms\n\n{'Intercept': CommonTerm(  \n   name: Intercept,\n   prior: Normal(mu: 298.5079, sigma: 261.0092),\n   shape: (180,),\n   categorical: False\n ),\n 'Days': CommonTerm(  \n   name: Days,\n   prior: Normal(mu: 0.0, sigma: 48.8915),\n   shape: (180,),\n   categorical: False\n ),\n '1|Subject': GroupSpecificTerm(  \n   name: 1|Subject,\n   prior: Normal(mu: 0.0, sigma: HalfNormal(sigma: 261.0092)),\n   shape: (180, 18),\n   categorical: False,\n   groups: ['308', '309', '310', '330', '331', '332', '333', '334', '335', '337', '349', '350', '351', '352', '369', '370', '371', '372']\n ),\n 'Days|Subject': GroupSpecificTerm(  \n   name: Days|Subject,\n   prior: Normal(mu: 0.0, sigma: HalfNormal(sigma: 48.8915)),\n   shape: (180, 18),\n   categorical: False,\n   groups: ['308', '309', '310', '330', '331', '332', '333', '334', '335', '337', '349', '350', '351', '352', '369', '370', '371', '372']\n ),\n 'Reaction': ResponseTerm(  \n   name: Reaction,\n   prior: Normal(mu: 0.0, sigma: 1.0),\n   shape: (180,),\n   categorical: False\n )}\n\n\nRandom idea: Perhaps in a future we can make Bambi more extensible by using generics-based API and some type of register. I haven’t thought about it at all yet."
  },
  {
    "objectID": "notebooks/hierarchical_binomial_bambi.html",
    "href": "notebooks/hierarchical_binomial_bambi.html",
    "title": "Hierarchical Logistic regression with Binomial family",
    "section": "",
    "text": "This notebook shows how to build a hierarchical logistic regression model with the Binomial family in Bambi.\nThis example is based on the Hierarchical baseball article in Bayesian Analysis Recipes, a collection of articles on how to do Bayesian data analysis with PyMC3 made by Eric Ma.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Hierarchical Logistic regression with Binomial family"
    ]
  },
  {
    "objectID": "notebooks/hierarchical_binomial_bambi.html#problem-description",
    "href": "notebooks/hierarchical_binomial_bambi.html#problem-description",
    "title": "Hierarchical Logistic regression with Binomial family",
    "section": "Problem description",
    "text": "Problem description\nExtracted from the original work:\n\nBaseball players have many metrics measured for them. Let’s say we are on a baseball team, and would like to quantify player performance, one metric being their batting average (defined by how many times a batter hit a pitched ball, divided by the number of times they were up for batting (“at bat”)). How would you go about this task?",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Hierarchical Logistic regression with Binomial family"
    ]
  },
  {
    "objectID": "notebooks/hierarchical_binomial_bambi.html#load-libraries-and-data",
    "href": "notebooks/hierarchical_binomial_bambi.html#load-libraries-and-data",
    "title": "Hierarchical Logistic regression with Binomial family",
    "section": "Load libraries and data",
    "text": "Load libraries and data\n\nimport arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom matplotlib.lines import Line2D\nfrom matplotlib.patches import Patch\n\n\nrandom_seed = 1234\n\nWe first need some measurements of batting data. Today we’re going to use data from the Baseball Databank. It is a compilation of historical baseball data in a convenient, tidy format, distributed under Open Data terms.\nThis repository contains several datasets in the form of .csv files. This example is going to use the Batting.csv file, which can be loaded directly with Bambi in a convenient way.\n\ndf = bmb.load_data(\"batting\")\n\n# Then clean some of the data\ndf[\"AB\"] = df[\"AB\"].replace(0, np.nan)\ndf = df.dropna()\ndf[\"batting_avg\"] = df[\"H\"] / df[\"AB\"]\ndf = df[df[\"yearID\"] &gt;= 2016]\ndf = df.iloc[0:15] \ndf.head(5)\n\n\n\n\n\n\n\n\nplayerID\nyearID\nstint\nteamID\nlgID\nG\nAB\nR\nH\n2B\n...\nSB\nCS\nBB\nSO\nIBB\nHBP\nSH\nSF\nGIDP\nbatting_avg\n\n\n\n\n101348\nabadfe01\n2016\n1\nMIN\nAL\n39\n1.0\n0\n0\n0\n...\n0.0\n0.0\n0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000000\n\n\n101350\nabreujo02\n2016\n1\nCHA\nAL\n159\n624.0\n67\n183\n32\n...\n0.0\n2.0\n47\n125.0\n7.0\n15.0\n0.0\n9.0\n21.0\n0.293269\n\n\n101352\nackledu01\n2016\n1\nNYA\nAL\n28\n61.0\n6\n9\n0\n...\n0.0\n0.0\n8\n9.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.147541\n\n\n101353\nadamecr01\n2016\n1\nCOL\nNL\n121\n225.0\n25\n49\n7\n...\n2.0\n3.0\n24\n47.0\n0.0\n4.0\n3.0\n0.0\n5.0\n0.217778\n\n\n101355\nadamsma01\n2016\n1\nSLN\nNL\n118\n297.0\n37\n74\n18\n...\n0.0\n1.0\n25\n81.0\n1.0\n2.0\n0.0\n3.0\n5.0\n0.249158\n\n\n\n\n5 rows × 23 columns\n\n\n\nFrom all the columns above, we’re going to use the following:\n\nplayerID: Unique identification for the player.\nAB: Number of times the player was up for batting.\nH: Number of times the player hit the ball while batting.\nbatting_avg: Simply ratio between H and AB.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Hierarchical Logistic regression with Binomial family"
    ]
  },
  {
    "objectID": "notebooks/hierarchical_binomial_bambi.html#explore-our-data",
    "href": "notebooks/hierarchical_binomial_bambi.html#explore-our-data",
    "title": "Hierarchical Logistic regression with Binomial family",
    "section": "Explore our data",
    "text": "Explore our data\nIt’s always good to explore the data before starting to write down our models. This is very useful to gain a good understanding of the distribution of the variables and their relationships, and even anticipate some problems that may occur during the sampling process.\nThe following graph summarizes the percentage of hits, as well as the number of times the players were up for batting and the number of times they hit the ball.\n\nBLUE = \"#2a5674\"\nRED = \"#b13f64\"\n\n\n_, ax = plt.subplots(figsize=(10, 6))\n\n# Customize x limits. \n# This adds space on the left side to indicate percentage of hits.\nax.set_xlim(-120, 320)\n\n# Add dots for the the number of hits and the times at bat\nax.scatter(df[\"H\"], list(range(15)), s=140, color=RED, zorder=10)\nax.scatter(df[\"AB\"], list(range(15)), s=140, color=BLUE, zorder=10)\n\n# Also a line connecting them\nax.hlines(list(range(15)), df[\"H\"], df[\"AB\"], color=\"#b3b3b3\", lw=4)\n\nax.axvline(ls=\"--\", lw=1.4, color=\"#a3a3a3\")\nax.hlines(list(range(15)), -110, -50, lw=6, color=\"#b3b3b3\", capstyle=\"round\")\nax.scatter(60 * df[\"batting_avg\"] - 110, list(range(15)), s=28, color=RED, zorder=10)\n\n# Add the percentage of hits\nfor j in range(15): \n    text = f\"{round(df['batting_avg'].iloc[j] * 100)}%\"\n    ax.text(-12, j, text, ha=\"right\", va=\"center\", fontsize=14, color=\"#333\")\n\n# Customize tick positions and labels\nax.yaxis.set_ticks(list(range(15)))\nax.yaxis.set_ticklabels(df[\"playerID\"])\nax.xaxis.set_ticks(range(0, 400, 100))\n\n# Create handles for the legend (just dots and labels)\nhandles = [\n    Line2D(\n        [0], [0], label=\"Hits\", marker=\"o\", color=\"None\", markeredgewidth=0, \n        markerfacecolor=RED, markersize=13\n    ),\n    Line2D(\n        [0], [0], label=\"At Bat\", marker=\"o\", color=\"None\", markeredgewidth=0,\n        markerfacecolor=BLUE, markersize=12\n    )\n]\n\n# Add legend on top-right corner\nlegend = ax.legend(\n    handles=handles, \n    loc=1, \n    fontsize=14, \n    handletextpad=0.4,\n    frameon=True\n)\n\n# Finally add labels and a title\nax.set_xlabel(\"Count\", fontsize=14)\nax.set_ylabel(\"Player\", fontsize=14)\nax.set_title(\"How often do batters hit the ball?\", fontsize=20);\n\n\n\n\n\n\n\n\nThe first thing one can see is that the number of times players were up for batting varies quite a lot. Some players have been there for very few times, while there are others who have been there hundreds of times. We can also note the percentage of hits is usually a number between 12% and 29%.\nThere are two players, alberma01 and abadfe01, who had only one chance to bat. The first one hit the ball, while the latter missed. That’s why alberma01 as a 100% hit percentage, while abadfe01 has 0%. There’s another player, aguilje01, who has a success record of 0% because he missed all the few opportunities he had to bat. These extreme situations, where the empirical estimation lives in the boundary of the parameter space, are associated with estimation problems when using a maximum-likelihood estimation approach. Nonetheless, they can also impact the sampling process, especially when using wide priors.\nAs a final note, abreujo02, has been there for batting 624 times, and thus the grey dot representing this number does not appear in the plot.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Hierarchical Logistic regression with Binomial family"
    ]
  },
  {
    "objectID": "notebooks/hierarchical_binomial_bambi.html#non-hierarchical-model",
    "href": "notebooks/hierarchical_binomial_bambi.html#non-hierarchical-model",
    "title": "Hierarchical Logistic regression with Binomial family",
    "section": "Non-hierarchical model",
    "text": "Non-hierarchical model\nLet’s get started with a simple cell-means logistic regression for \\(p_i\\), the probability of hitting the ball for the player \\(i\\)\n\\[\n\\begin{array}{lr}\n    \\displaystyle \\text{logit}(p_i) = \\beta_i & \\text{with } i = 0, \\cdots, 14\n\\end{array}   \n\\]\nWhere\n\\[\n\\beta_i \\sim \\text{Normal}(0, \\ \\sigma_{\\beta}),\n\\]\n\\(\\sigma_{\\beta}\\) is a common constant for all the players, and \\(\\text{logit}(p_i) = \\log\\left(\\frac{p_i}{1 - p_i}\\right)\\).\nSpecifying this model is quite simple in Bambi thanks to its formula interface.\nFirst of all, note this is a Binomial family and the response involves both the number of hits (H) and the number of times at bat (AB). We use the p(x, n) function for the response term. This just tells Bambi we want to model the proportion resulting from dividing x over n.\nThe right-hand side of the formula is \"0 + playerID\". This means the model includes a coefficient for each player ID, but does not include a global intercept.\nFinally, using the Binomial family is as easy as passing family=\"binomial\". By default, the link function for this family is link=\"logit\", so there’s nothing to change there.\n\nmodel_non_hierarchical = bmb.Model(\"p(H, AB) ~ 0 + playerID\", df, family=\"binomial\")\nmodel_non_hierarchical\n\n       Formula: p(H, AB) ~ 0 + playerID\n        Family: binomial\n          Link: p = logit\n  Observations: 15\n        Priors: \n    target = p\n        Common-level effects\n            playerID ~ Normal(mu: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma: [1. 1. 1. 1. 1. 1.\n                1. 1. 1. 1. 1. 1. 1. 1. 1.])\n\n\n\nidata_non_hierarchical = model_non_hierarchical.fit(random_seed=random_seed)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [playerID]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 5 seconds.\n\n\nNext we observe the posterior of the coefficient for each player. The compact=False argument means we want separated panels for each player.\n\naz.plot_trace(idata_non_hierarchical, compact=False, backend_kwargs={\"layout\": \"constrained\"});\n\n\n\n\n\n\n\n\nSo far so good! The traceplots indicate the sampler worked well.\nNow, let’s keep this posterior aside for later use and let’s fit the hierarchical version.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Hierarchical Logistic regression with Binomial family"
    ]
  },
  {
    "objectID": "notebooks/hierarchical_binomial_bambi.html#hierarchical-model",
    "href": "notebooks/hierarchical_binomial_bambi.html#hierarchical-model",
    "title": "Hierarchical Logistic regression with Binomial family",
    "section": "Hierarchical model",
    "text": "Hierarchical model\nThis model incorporates a group-specific intercept for each player:\n\\[\n\\begin{array}{lr}\n    \\displaystyle \\text{logit}(p_i) = \\alpha + \\gamma_i & \\text{with } i = 0, \\cdots, 14\n\\end{array}   \n\\]\nwhere\n\\[\n\\begin{array}{c}\n    \\alpha \\sim \\text{Normal}(0, \\ \\sigma_{\\alpha}) \\\\\n    \\gamma_i \\sim \\text{Normal}(0, \\ \\sigma_{\\gamma}) \\\\\n    \\sigma_{\\gamma} \\sim \\text{HalfNormal}(\\tau_{\\gamma})\n\\end{array}\n\\]\nThe group-specific terms are indicated with the | operator in the formula. In this case, since there is an intercept for each player, we write 1|playerID.\n\nmodel_hierarchical = bmb.Model(\"p(H, AB) ~ 1 + (1|playerID)\", df, family=\"binomial\")\nmodel_hierarchical\n\n       Formula: p(H, AB) ~ 1 + (1|playerID)\n        Family: binomial\n          Link: p = logit\n  Observations: 15\n        Priors: \n    target = p\n        Common-level effects\n            Intercept ~ Normal(mu: 0.0, sigma: 1.5)\n        \n        Group-level effects\n            1|playerID ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 2.5))\n\n\n\nidata_hierarchical = model_hierarchical.fit(random_seed=random_seed)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Intercept, 1|playerID_sigma, 1|playerID_offset]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 14 seconds.\nThere were 6 divergences after tuning. Increase `target_accept` or reparameterize.\n\n\nSometimes, there can be several divergences when fitting a hierarchical model. What can we do in that case?\nOne thing we could try is increasing target_accept. But if there are many divergences, that suggests a problem with the underlying model. Let’s take a look at the prior predictive distribution to see whether our priors are too informative or too wide.\nThe Model instance has a method called prior_predictive() that generates samples from the prior predictive distribution. It returns an InferenceData object that contains the values of the prior predictive distribution.\n\nidata_prior = model_hierarchical.prior_predictive()\nprior = az.extract_dataset(idata_prior, group=\"prior_predictive\")[\"p(H, AB)\"]\n\nSampling: [1|playerID_offset, 1|playerID_sigma, Intercept, p(H, AB)]\n/tmp/ipykernel_12852/2686921361.py:2: FutureWarning: extract_dataset has been deprecated, please use extract\n  prior = az.extract_dataset(idata_prior, group=\"prior_predictive\")[\"p(H, AB)\"]\n\n\nIf we inspect the DataArray, we see there are 500 draws (sample) for each of the 15 players (__obs__)\nLet’s plot these distributions together with the observed proportion of hits for every player here.\n\n# We define this function because this plot is going to be repeated below.\ndef plot_prior_predictive(df, prior):\n    AB = df[\"AB\"].values\n    H = df[\"H\"].values\n\n    fig, axes = plt.subplots(5, 3, figsize=(10, 6), sharex=\"col\")\n\n    for idx, ax in enumerate(axes.ravel()):\n        pps = prior.sel({\"__obs__\":idx})\n        ab = AB[idx]\n        h = H[idx]\n        hist = ax.hist(pps / ab, bins=25, color=\"#a3a3a3\")\n        ax.axvline(h / ab, color=RED, lw=2)\n        ax.set_yticks([])\n        ax.tick_params(labelsize=12)\n    \n    fig.subplots_adjust(left=0.025, right=0.975, hspace=0.05, wspace=0.05, bottom=0.125)\n    fig.legend(\n        handles=[Line2D([0], [0], label=\"Observed proportion\", color=RED, linewidth=2)],\n        handlelength=1.5,\n        handletextpad=0.8,\n        borderaxespad=0,\n        frameon=True,\n        fontsize=11, \n        bbox_to_anchor=(0.975, 0.92),\n        loc=\"right\"\n        \n    )\n    fig.text(0.5, 0.05, \"Prior probability of hitting\", fontsize=15, ha=\"center\", va=\"baseline\")\n\n\nplot_prior_predictive(df, prior)\n\n\n\n\n\n\n\n\nIndeed, priors are too wide! Let’s use tighter priors and see what’s the result\n\npriors = {\n    \"Intercept\": bmb.Prior(\"Normal\", mu=0, sigma=1),\n    \"1|playerID\": bmb.Prior(\"Normal\", mu=0, sigma=bmb.Prior(\"HalfNormal\", sigma=1))\n}\nmodel_hierarchical = bmb.Model(\"p(H, AB) ~ 1 + (1|playerID)\", df, family=\"binomial\", priors=priors)\nmodel_hierarchical\n\n       Formula: p(H, AB) ~ 1 + (1|playerID)\n        Family: binomial\n          Link: p = logit\n  Observations: 15\n        Priors: \n    target = p\n        Common-level effects\n            Intercept ~ Normal(mu: 0.0, sigma: 1.0)\n        \n        Group-level effects\n            1|playerID ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 1.0))\n\n\nNow let’s check the prior predictive distribution for these new priors.\n\nmodel_hierarchical.build()\nidata_prior = model_hierarchical.prior_predictive()\nprior = az.extract_dataset(idata_prior, group=\"prior_predictive\")[\"p(H, AB)\"]\nplot_prior_predictive(df, prior)\n\nSampling: [1|playerID_offset, 1|playerID_sigma, Intercept, p(H, AB)]\n/tmp/ipykernel_12852/1302716284.py:3: FutureWarning: extract_dataset has been deprecated, please use extract\n  prior = az.extract_dataset(idata_prior, group=\"prior_predictive\")[\"p(H, AB)\"]\n\n\n\n\n\n\n\n\n\nDefinetely it looks much better. Now the priors tend to have a symmetric shape with a mode at 0.5, with substantial probability on the whole domain.\n\nidata_hierarchical = model_hierarchical.fit(random_seed=random_seed)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Intercept, 1|playerID_sigma, 1|playerID_offset]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 13 seconds.\nThere were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n\n\nLet’s try with increasing target_accept and the number of tune samples.\n\nidata_hierarchical = model_hierarchical.fit(tune=2000, draws=2000, target_accept=0.95, random_seed=random_seed)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Intercept, 1|playerID_sigma, 1|playerID_offset]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 2_000 tune and 2_000 draw iterations (8_000 + 8_000 draws total) took 24 seconds.\n\n\n\nvar_names = [\"Intercept\", \"1|playerID\", \"1|playerID_sigma\"]\naz.plot_trace(idata_hierarchical, var_names=var_names, compact=False, backend_kwargs={\"layout\": \"constrained\"});\n\n\n\n\n\n\n\n\nLet’s jump onto the next section where we plot and compare the probability of hit for the players using both models.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Hierarchical Logistic regression with Binomial family"
    ]
  },
  {
    "objectID": "notebooks/hierarchical_binomial_bambi.html#compare-predictions",
    "href": "notebooks/hierarchical_binomial_bambi.html#compare-predictions",
    "title": "Hierarchical Logistic regression with Binomial family",
    "section": "Compare predictions",
    "text": "Compare predictions\nNow we’re going to plot the distribution of the probability of hit for each player, using both models.\nBut before doing that, we need to obtain the posterior in that scale. We could manually take the posterior of the coefficients, compute the linear predictor, and transform that to the probability scale. But that’s a lot of work!\nFortunately, Bambi models have a method called .predict() that we can use to predict in the probability scale. By default, it modifies in-place the InferenceData object we pass to it. Then, the posterior samples can be found in the variable p.\n\nmodel_non_hierarchical.predict(idata_non_hierarchical)\nmodel_hierarchical.predict(idata_hierarchical)\n\nLet’s create a forestplot using the posteriors obtained with both models so we can compare them very easily .\n\n_, ax = plt.subplots(figsize = (8, 8))\n\n# Add vertical line for the global probability of hitting\nax.axvline(x=(df[\"H\"] / df[\"AB\"]).mean(), ls=\"--\", color=\"black\", alpha=0.5)\n\n# Create forestplot with ArviZ, only for the mean.\naz.plot_forest(\n    [idata_non_hierarchical, idata_hierarchical], \n    var_names=\"p\", \n    combined=True, \n    colors=[\"#666666\", RED], \n    linewidth=2.6, \n    markersize=8,\n    ax=ax\n)\n\n# Create custom y axis tick labels\nylabels = [f\"H: {round(h)}, AB: {round(ab)}\" for h, ab in zip(df[\"H\"].values, df[\"AB\"].values)]\nylabels = list(reversed(ylabels))\n\n# Put the labels for the y axis in the mid of the original location of the tick marks.\nax.set_yticklabels(ylabels, ha=\"right\")\n\n# Create legend\nhandles = [\n    Patch(label=\"Non-hierarchical\", facecolor=\"#666666\"),\n    Patch(label=\"Hierarchical\", facecolor=RED),\n    Line2D([0], [0], label=\"Mean probability\", ls=\"--\", color=\"black\", alpha=0.5)\n]\n\nlegend = ax.legend(handles=handles, loc=4, fontsize=14, frameon=True, framealpha=0.8);\n\n\n\n\n\n\n\n\nOne of the first things one can see is that not only the center of the distributions varies but also their dispersion. Those posteriors that are very wide are associated with players who have batted only once or few times, while tighter posteriors correspond to players who batted several times.\nPlayers who have extreme empirical proportions have similar extreme posteriors under the non-hierarchical model. However, under the hierarchical model, these distributions are now shrunk towards the global mean. Extreme values are very unlikely under the hierarchical model.\nAnd finally, paraphrasing Eric, there’s nothing ineherently right or wrong about shrinkage and hierarchical models. Whether this is reasonable or not depends on our prior knowledge about the problem. And to me, after having seen the hit rates of the other players, it is much more reasonable to shrink extreme posteriors based on very few data points towards the global mean rather than just let them concentrate around 0 or 1.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Thu Aug 15 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\nbambi     : 0.14.1.dev12+g64e57423.d20240730\nnumpy     : 1.26.4\nmatplotlib: 3.8.4\narviz     : 0.18.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Hierarchical Logistic regression with Binomial family"
    ]
  },
  {
    "objectID": "notebooks/hierarchical_binomial_bambi.html#footnotes",
    "href": "notebooks/hierarchical_binomial_bambi.html#footnotes",
    "title": "Hierarchical Logistic regression with Binomial family",
    "section": "Footnotes",
    "text": "Footnotes\n\n By default, the .predict() method obtains the posterior for the mean of the likelihood distribution. This mean would be \\(np\\) for the Binomial family. However, since \\(n\\) varies from observation to observation, it returns the value of \\(p\\), as if it was a Bernoulli family.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Hierarchical Logistic regression with Binomial family"
    ]
  },
  {
    "objectID": "notebooks/distributional_models.html",
    "href": "notebooks/distributional_models.html",
    "title": "Distributional models",
    "section": "",
    "text": "import arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom matplotlib.lines import Line2D\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning) # ArviZ\n\naz.style.use(\"arviz-doc\")\nFor most regression models, a function of the mean (aka the location parameter) of the response distribution is defined as a linear function of certain predictors, while the remaining parameters are considered auxiliary. For instance, if the response is a Gaussian, we model \\(\\mu\\) as a combination of predictors and \\(\\sigma\\) is estimated from the data, but assumed to be constant for all observations.\nInstead, with distributional models we can specify predictor terms for all parameters of the response distribution. This can be useful, for example, to model heteroskedasticity, i.e. unequal variance. In this notebook we are going to do exactly that.\nTo better understand distributional models, let’s begin fitting a non-distributional models. We are going to model the following syntetic dataset. And we are going to use a Gamma response with a log link function.\nrng = np.random.default_rng(121195)\nN = 200\na, b = 0.5, 1.1\nx = rng.uniform(-1.5, 1.5, N)\nshape = np.exp(0.3 + x * 0.5 + rng.normal(scale=0.1, size=N))\ny = rng.gamma(shape, np.exp(a + b * x) / shape, N)\ndata = pd.DataFrame({\"x\": x, \"y\": y})\nnew_data = pd.DataFrame({\"x\": np.linspace(-1.5, 1.5, num=50)})",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Distributional models"
    ]
  },
  {
    "objectID": "notebooks/distributional_models.html#constant-alpha",
    "href": "notebooks/distributional_models.html#constant-alpha",
    "title": "Distributional models",
    "section": "Constant alpha",
    "text": "Constant alpha\n\nformula = bmb.Formula(\"y ~ x\")\nmodel_constant = bmb.Model(formula, data, family=\"gamma\", link=\"log\")\nmodel_constant\n\n       Formula: y ~ x\n        Family: gamma\n          Link: mu = log\n  Observations: 200\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 0.0, sigma: 2.5037)\n            x ~ Normal(mu: 0.0, sigma: 2.8025)\n        \n        Auxiliary parameters\n            alpha ~ HalfCauchy(beta: 1.0)\n\n\n\nmodel_constant.build()\nmodel_constant.graph()\n\n\n\n\n\n\n\n\nTake a moment to inspect the textual and graphical representations of the model, to ensure you understand how the parameters are related.\n\nidata_constant = model_constant.fit(random_seed=121195, idata_kwargs={\"log_likelihood\": True})\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [alpha, Intercept, x]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 8 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nOnce the model is fitted let’s visually inspect the result in terms of the mean (the line in the following figure) and the individual predictions (the band).\n\nmodel_constant.predict(idata_constant, kind=\"response_params\", data=new_data)\nmodel_constant.predict(idata_constant, kind=\"response\", data=new_data)\n\nqts_constant = (\n    az.extract(idata_constant.posterior_predictive, var_names=\"y\")\n    .quantile([0.025, 0.975], \"sample\")\n    .to_numpy()\n)\nmean_constant = (\n    az.extract(idata_constant.posterior_predictive, var_names=\"y\")\n    .mean(\"sample\")\n    .to_numpy()\n)\n\n\nfig, ax = plt.subplots(figsize=(8, 4.5), dpi=120)\n\naz.plot_hdi(new_data[\"x\"], qts_constant, ax=ax, fill_kwargs={\"alpha\": 0.4})\nax.plot(new_data[\"x\"], mean_constant, color=\"C0\", lw=2)\nax.scatter(data[\"x\"], data[\"y\"], color=\"k\", alpha=0.2)\nax.set(xlabel=\"Predictor\", ylabel=\"Outcome\");\n\n\n\n\n\n\n\n\nThe model correctly model that the outcome increases with the values of the predictor. So far so good, let’s dive into the heart of the matter.",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Distributional models"
    ]
  },
  {
    "objectID": "notebooks/distributional_models.html#varying-alpha",
    "href": "notebooks/distributional_models.html#varying-alpha",
    "title": "Distributional models",
    "section": "Varying alpha",
    "text": "Varying alpha\nNow we are going to build the same model as before with the only, but crucial difference, that we are also going to make alpha depend on the predictor. The syntax is very simple besides the usual “y ~ x”, we now add “alpha ~ x”. Neat!\n\nformula_varying = bmb.Formula(\"y ~ x\", \"alpha ~ x\")\nmodel_varying = bmb.Model(formula_varying, data, family=\"gamma\", link={\"mu\": \"log\", \"alpha\": \"log\"})\nmodel_varying\n\n       Formula: y ~ x\n                alpha ~ x\n        Family: gamma\n          Link: mu = log\n                alpha = log\n  Observations: 200\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 0.0, sigma: 2.5037)\n            x ~ Normal(mu: 0.0, sigma: 2.8025)\n    target = alpha\n        Common-level effects\n            alpha_Intercept ~ Normal(mu: 0.0, sigma: 1.0)\n            alpha_x ~ Normal(mu: 0.0, sigma: 1.0)\n\n\n\nmodel_varying.build()\nmodel_varying.graph()\n\n\n\n\n\n\n\n\nTake another moment to inspect the textual and visual representations of model_varying and also go back and compare those from model_constant.\n\nidata_varying = model_varying.fit(\n    random_seed=121195, \n    idata_kwargs={\"log_likelihood\": True},\n    include_response_params=True,\n)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [Intercept, x, alpha_Intercept, alpha_x]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 8 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nNow, with both models being fitted, let’s see how the alpha parameter differs between both models. In the next figure you can see a blueish KDE for the alpha parameter estimated with model_constant and 200 black KDEs for the alpha parameter estimated from the model_varying. You can count it if you want :-), but we know they should be 200 because we should have one for each one of the 200 observations.\n\nfig, ax = plt.subplots(figsize=(8, 4.5), dpi=120)\n\nfor idx in idata_varying.posterior.coords.get(\"__obs__\"):\n    values = idata_varying.posterior[\"alpha\"].sel(__obs__=idx).to_numpy().flatten()\n    grid, pdf = az.kde(values)\n    ax.plot(grid, pdf, lw=0.05, color=\"k\")\n\nvalues = idata_constant.posterior[\"alpha\"].to_numpy().flatten()\ngrid, pdf = az.kde(values)\nax.plot(grid, pdf, lw=2, color=\"C0\");\n\n# Create legend\nhandles = [\n    Line2D([0], [0], label=\"Varying alpha\", lw=1.5, color=\"k\", alpha=0.6),\n    Line2D([0], [0], label=\"Constant alpha\", lw=1.5, color=\"C0\")\n]\n\nlegend = ax.legend(handles=handles, loc=\"upper right\", fontsize=14)\n\nax.set(xlabel=\"Alpha posterior\", ylabel=\"Density\");\n\n\n\n\n\n\n\n\nThis is nice statistical art and a good insight into what the model is actully doing. But at this point you may be wondering how results looks like and more important how different they are from model_constant. Let’s plot the mean and predictions as we did before, but for both models.\n\nmodel_varying.predict(idata_varying, kind=\"response_params\", data=new_data)\nmodel_varying.predict(idata_varying, kind=\"response\", data=new_data)\n\nqts_varying = (\n    az.extract(idata_varying.posterior_predictive, var_names=\"y\")\n    .quantile([0.025, 0.975], \"sample\")\n    .to_numpy()\n)\nmean_varying = (\n    az.extract(idata_varying.posterior_predictive, var_names=\"y\")\n    .mean(\"sample\")\n    .to_numpy()\n)\n\n\nfig, ax = plt.subplots(figsize=(8, 4.5), dpi=120)\n\naz.plot_hdi(new_data[\"x\"], qts_constant, ax=ax, fill_kwargs={\"alpha\": 0.4})\nax.plot(new_data[\"x\"], mean_constant, color=\"C1\", label=\"constant\")\n\naz.plot_hdi(new_data[\"x\"], qts_varying, ax=ax, fill_kwargs={\"alpha\": 0.4, \"color\":\"k\"})\nax.plot(new_data[\"x\"], mean_varying, color=\"k\", label=\"varying\")\nax.set(xlabel=\"Predictor\", ylabel=\"Outcome\");\nplt.legend();\n\n\n\n\n\n\n\n\nWe can see that mean is virtually the same for both model but the predictions are not, in particular for larger values of the predictiors.\nWe can also check that the models actually looks different under the LOO metric, with a slight preference for the varying model.\n\naz.compare({\"constant\": idata_constant, \"varying\": idata_varying})\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nvarying\n0\n-309.143281\n3.785955\n0.000000\n0.939557\n16.468110\n0.000000\nFalse\nlog\n\n\nconstant\n1\n-318.913529\n2.958352\n9.770248\n0.060443\n15.832034\n4.560753\nFalse\nlog",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Distributional models"
    ]
  },
  {
    "objectID": "notebooks/distributional_models.html#distributional-models-with-splines",
    "href": "notebooks/distributional_models.html#distributional-models-with-splines",
    "title": "Distributional models",
    "section": "Distributional models with splines",
    "text": "Distributional models with splines\nTime to step up our game. In this example we are going to use the bikes data set from the University of California Irvine’s Machine Learning Repository, and we are going to estimate the number of rental bikes rented per hour over a 24 hour period.\nAs the number of bikes is a count variable we are going to use a negativebinomial family, and we are going to use two splines: one for the mean, and one for alpha.\n\ndata = bmb.load_data(\"bikes\")\n# Remove data, you may later try to refit the model to the whole data\ndata = data[::50]\ndata = data.reset_index(drop=True)\n\n\nformula = bmb.Formula(\n    \"count ~ 0 + bs(hour, 8, intercept=True)\",\n    \"alpha ~ 0 + bs(hour, 8, intercept=True)\"\n)\nmodel_bikes = bmb.Model(formula, data, family=\"negativebinomial\")\nmodel_bikes\n\n       Formula: count ~ 0 + bs(hour, 8, intercept=True)\n                alpha ~ 0 + bs(hour, 8, intercept=True)\n        Family: negativebinomial\n          Link: mu = log\n                alpha = log\n  Observations: 348\n        Priors: \n    target = mu\n        Common-level effects\n            bs(hour, 8, intercept=True) ~ Normal(mu: [0. 0. 0. 0. 0. 0. 0. 0.], sigma: [11.3704 13.9185\n                11.9926 10.6887 10.6819 12.1271 13.623  11.366 ])\n\n    target = alpha\n        Common-level effects\n            alpha_bs(hour, 8, intercept=True) ~ Normal(mu: 0.0, sigma: 1.0)\n\n\n\nidata_bikes = model_bikes.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [bs(hour, 8, intercept=True), alpha_bs(hour, 8, intercept=True)]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 13 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\nhour = np.linspace(0, 23, num=200)\nnew_data = pd.DataFrame({\"hour\": hour})\nmodel_bikes.predict(idata_bikes, data=new_data, kind=\"response\")\n\n\nq = [0.025, 0.975]\ndims = (\"chain\", \"draw\")\n\nmean = idata_bikes.posterior[\"mu\"].mean(dims).to_numpy()\nmean_interval = idata_bikes.posterior[\"mu\"].quantile(q, dims).to_numpy()\ny_interval = idata_bikes.posterior_predictive[\"count\"].quantile(q, dims).to_numpy()\n\nfig, ax = plt.subplots(figsize=(12, 4))\nax.scatter(data[\"hour\"], data[\"count\"], alpha=0.3, color=\"k\")\nax.plot(hour, mean, color=\"C3\")\nax.fill_between(hour, mean_interval[0],mean_interval[1], alpha=0.5, color=\"C1\");\naz.plot_hdi(hour, y_interval, fill_kwargs={\"color\": \"C1\", \"alpha\": 0.3}, ax=ax);\n\n\n\n\n\n\n\n\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Thu Jul 04 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\nnumpy     : 1.26.4\narviz     : 0.18.0\nmatplotlib: 3.8.4\npandas    : 2.2.2\nbambi     : 0.13.1.dev45+ge8510ea5.d20240704\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Distributional models"
    ]
  },
  {
    "objectID": "notebooks/circular_regression.html",
    "href": "notebooks/circular_regression.html",
    "title": "Circular Regression",
    "section": "",
    "text": "import arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom matplotlib.lines import Line2D\nfrom scipy import stats\n\n\naz.style.use(\"arviz-white\")\n\nDirectional statistics, also known as circular statistics or spherical statistics, refers to a branch of statistics dealing with data which domain is the unit circle, as opposed to “linear” data which support is the real line. Circular data is convenient when dealing with directions or rotations. Some examples include temporal periods like hours or days, compass directions, dihedral angles in biomolecules, etc.\nThe fact that a Sunday can be both the day before or after a Monday, or that 0 is a “better average” for 2 and 358 degrees than 180 are illustrations that circular data and circular statistical methods are better equipped to deal with this kind of problem than the more familiar methods 1.\nThere are a few circular distributions, one of them is the VonMises distribution, that we can think as the cousin of the Gaussian that lives in circular space. The domain of this distribution is any interval of length \\(2\\pi\\). We are going to adopt the convention that the interval goes from \\(-\\pi\\) to \\(\\pi\\), so for example 0 radians is the same as \\(2\\pi\\). The VonMises is defined using two parameters, the mean \\(\\mu\\) (the circular mean) and the concentration \\(\\kappa\\), with \\(\\frac{1}{\\kappa}\\) being analogue of the variance. Let see a few example of the VonMises family:\n\nx = np.linspace(-np.pi, np.pi, 200)\nmus = [0., 0., 0.,  -2.5]\nkappas = [.001, 0.5,  3, 0.5]\nfor mu, kappa in zip(mus, kappas):\n    pdf = stats.vonmises.pdf(x, kappa, loc=mu)\n    plt.plot(x, pdf, label=r'$\\mu$ = {}, $\\kappa$ = {}'.format(mu, kappa))\nplt.yticks([])\nplt.legend(loc=1);\n\n\n\n\n\n\n\n\nWhen doing linear regression a commonly used link function is \\(2 \\arctan(u)\\) this ensure that values over the real line are mapped into the interval \\([-\\pi, \\pi]\\)\n\nu = np.linspace(-12, 12, 200)\nplt.plot(u, 2*np.arctan(u))\nplt.xlabel(\"Reals\")\nplt.ylabel(\"Radians\");\n\n\n\n\n\n\n\n\nBambi supports circular regression with the VonMises family, to exemplify this we are going to use a dataset from the following experiment. 31 periwinkles (a kind of sea snail) were removed from it original place and released down shore. Then, our task is to model the direction of motion as function of the distance travelled by them after being release.\n\ndata = bmb.load_data(\"periwinkles\")\ndata.head()\n\n\n\n\n\n\n\n\ndistance\ndirection\n\n\n\n\n0\n107\n1.169371\n\n\n1\n46\n1.151917\n\n\n2\n33\n1.291544\n\n\n3\n67\n1.064651\n\n\n4\n122\n1.012291\n\n\n\n\n\n\n\nJust to compare results, we are going to use the VonMises family and the normal (default) family.\n\nmodel_vm = bmb.Model(\"direction ~ distance\", data, family=\"vonmises\")\nidata_vm = model_vm.fit(include_response_params=True)\n\nmodel_n = bmb.Model(\"direction ~ distance\", data)\nidata_n = model_n.fit(include_response_params=True)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [kappa, Intercept, distance]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 11 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, distance]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 7 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\naz.summary(idata_vm, var_names=[\"~mu\"])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n1.699\n0.334\n1.075\n2.305\n0.012\n0.009\n865.0\n933.0\n1.0\n\n\ndistance\n-0.011\n0.004\n-0.019\n-0.002\n0.000\n0.000\n1046.0\n1054.0\n1.0\n\n\nkappa\n2.610\n0.581\n1.610\n3.705\n0.017\n0.012\n1194.0\n1363.0\n1.0\n\n\n\n\n\n\n\n\n_, ax = plt.subplots(1,2, figsize=(8, 4), sharey=True)\nposterior_mean = bmb.families.link.tan_2(idata_vm.posterior[\"mu\"])\nax[0].plot(data.distance, posterior_mean.mean((\"chain\", \"draw\")))\naz.plot_hdi(data.distance, posterior_mean, ax=ax[0])\n\nax[0].plot(data.distance, data.direction, \"k.\")\nax[0].set_xlabel(\"Distance travelled (in m)\")\nax[0].set_ylabel(\"Direction of travel (radians)\")\nax[0].set_title(\"VonMises Family\")\n\nposterior_mean = idata_n.posterior[\"mu\"]\nax[1].plot(data.distance, posterior_mean.mean((\"chain\", \"draw\")))\naz.plot_hdi(data.distance, posterior_mean, ax=ax[1])\n\nax[1].plot(data.distance, data.direction, \"k.\")\nax[1].set_xlabel(\"Distance travelled (in m)\")\nax[1].set_title(\"Normal Family\");\n\n\n\n\n\n\n\n\nWe can see that there is a negative relationship between distance and direction. This could be explained as Periwinkles travelling in a direction towards the sea travelled shorter distances than those travelling in directions away from it. From a biological perspective, this could have been due to a propensity of the periwinkles to stop moving once they are close to the sea.\nWe can also see that if inadvertently we had assumed a normal response we would have obtained a fit with higher uncertainty and more importantly the wrong sign for the relationship.\nAs a last step for this example we are going to do a posterior predictive check. In the figure below we have to panels showing the same data, with the only difference that the on the right is using a polar projection and the KDE are computing taking into account the circularity of the data.\nWe can see that our modeling is failing at capturing the bimodality in the data (with mode around 1.6 and \\(\\pm \\pi\\)) and hence the predicted distribution is wider and with a mean closer to \\(\\pm \\pi\\).\n\nfig = plt.figure(figsize=(12, 5))\nax0 = plt.subplot(121)\nax1 = plt.subplot(122, projection=\"polar\")\n\nmodel_vm.predict(idata_vm, kind=\"response\")\npp_samples = az.extract_dataset(idata_vm, group=\"posterior_predictive\", num_samples=200)[\"direction\"]\ncolors = [\"C0\" , \"k\", \"C1\"]\n\nfor ax, circ in zip((ax0, ax1), (False, \"radians\", colors)):\n    for s in pp_samples:\n        az.plot_kde(s.values,  plot_kwargs={\"color\":colors[0], \"alpha\": 0.25}, is_circular=circ, ax=ax)\n    az.plot_kde(idata_vm.observed_data[\"direction\"].values,\n                plot_kwargs={\"color\":colors[1], \"lw\":3}, is_circular=circ, ax=ax)\n    az.plot_kde(idata_vm.posterior_predictive[\"direction\"].values,\n                plot_kwargs={\"color\":colors[2], \"ls\":\"--\", \"lw\":3}, is_circular=circ, ax=ax)\n\ncustom_lines = [Line2D([0], [0], color=c) for c in colors]\n\nax0.legend(custom_lines, [\"posterior_predictive\", \"Observed\", 'mean posterior predictive'])\nax0.set_yticks([])\nfig.suptitle(\"Directions (radians)\", fontsize=18);\n\n/tmp/ipykernel_46393/706974292.py:6: FutureWarning: extract_dataset has been deprecated, please use extract\n  pp_samples = az.extract_dataset(idata_vm, group=\"posterior_predictive\", num_samples=200)[\"direction\"]\n\n\n\n\n\n\n\n\n\nWe have shown an example of regression where the response variable is circular and the covariates are linear. This is sometimes refereed as linear-circular regression in order to distinguish it from other cases. Namely, when the response is linear and the covariates (or at least one of them) is circular the name circular-linear regression is often used. And when both covariates and the response variables are circular, we have a circular-circular regression. When the covariates are circular they are usually modelled with the help of sin and cosine functions. You can read more about this kind of regression and other circular statistical methods in the following books.\n\nCircular statistics in R\nModern directional statistics\nApplied Directional Statistics\nDirectional Statistics\n\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Thu Jul 04 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\npandas    : 2.2.2\nbambi     : 0.13.1.dev45+ge8510ea5.d20240704\nmatplotlib: 3.8.4\nscipy     : 1.13.0\nnumpy     : 1.26.4\narviz     : 0.18.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Circular Regression"
    ]
  },
  {
    "objectID": "notebooks/beta_regression.html",
    "href": "notebooks/beta_regression.html",
    "title": "Beta Regression",
    "section": "",
    "text": "This example has been contributed by Tyler James Burch (@tjburch on GitHub).\nimport arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nfrom scipy.special import expit\naz.style.use(\"arviz-darkgrid\")\nIn this example, we’ll look at using the Beta distribution for regression models. The Beta distribution is a probability distribution bounded on the interval [0, 1], which makes it well-suited to model probabilities or proportions. In fact, in much of the Bayesian literature, the Beta distribution is introduced as a prior distribution for the probability \\(p\\) parameter of the Binomial distribution (in fact, it’s the conjugate prior for the Binomial distribution).",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Beta Regression"
    ]
  },
  {
    "objectID": "notebooks/beta_regression.html#simulated-beta-distribution",
    "href": "notebooks/beta_regression.html#simulated-beta-distribution",
    "title": "Beta Regression",
    "section": "Simulated Beta Distribution",
    "text": "Simulated Beta Distribution\nTo start getting an intuitive sense of the Beta distribution, we’ll model coin flipping probabilities. Say we grab all the coins out of our pocket, we might have some fresh from the mint, but we might also have some old ones. Due to the variation, some may be slightly biased toward heads or tails, and our goal is to model distribution of the probabilities of flipping heads for the coins in our pocket.\nSince we trust the mint, we’ll say the \\(\\alpha\\) and \\(\\beta\\) are both large, we’ll use 1,000 for each, which gives a distribution spanning from 0.45 to 0.55.\n\nalpha = 1_000\nbeta = 1_000\np = np.random.beta(alpha, beta, size=10_000)\naz.plot_kde(p)\nplt.xlabel(\"$p$\");\n\n\n\n\n\n\n\n\nNext, we’ll use Bambi to try to recover the parameters of the Beta distribution. Since we have no predictors, we can do a intercept-only model to try to recover them.\n\ndata = pd.DataFrame({\"probabilities\": p})\nmodel = bmb.Model(\"probabilities ~ 1\", data, family=\"beta\")\nfitted = model.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [kappa, Intercept]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 3 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\naz.plot_trace(fitted);\n\n\n\n\n\n\n\n\n\naz.summary(fitted)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-0.00\n0.000\n-0.001\n0.001\n0.000\n0.000\n2071.0\n1229.0\n1.0\n\n\nkappa\n1986.48\n28.041\n1930.335\n2035.428\n0.588\n0.416\n2268.0\n1656.0\n1.0\n\n\n\n\n\n\n\nThe model fit, but clearly these parameters are not the ones that we used above. For Beta regression, we use a linear model for the mean, so we use the \\(\\mu\\) and \\(\\sigma\\) formulation. To link the two, we use\n\\(\\alpha = \\mu \\kappa\\)\n\\(\\beta = (1-\\mu)\\kappa\\)\nand \\(\\kappa\\) is a function of the mean and variance,\n\\(\\kappa = \\frac{\\mu(1-\\mu)}{\\sigma^2} - 1\\)\nRather than \\(\\sigma\\), you’ll note Bambi returns \\(\\kappa\\). We’ll define a function to retrieve our original parameters.\n\ndef mukappa_to_alphabeta(mu, kappa):\n    # Calculate alpha and beta\n    alpha = mu * kappa\n    beta = (1 - mu) * kappa\n    \n    # Get mean values and 95% HDIs \n    alpha_mean = alpha.mean((\"chain\", \"draw\")).item()\n    alpha_hdi = az.hdi(alpha, hdi_prob=.95)[\"x\"].values\n    beta_mean = beta.mean((\"chain\", \"draw\")).item()\n    beta_hdi = az.hdi(beta, hdi_prob=.95)[\"x\"].values\n    \n    return alpha_mean, alpha_hdi, beta_mean, beta_hdi\n\nalpha, alpha_hdi, beta, beta_hdi = mukappa_to_alphabeta(\n    expit(fitted.posterior[\"Intercept\"]),\n    fitted.posterior[\"kappa\"]\n)\n\nprint(f\"Alpha - mean: {np.round(alpha)}, 95% HDI: {np.round(alpha_hdi[0])} - {np.round(alpha_hdi[1])}\")\nprint(f\"Beta - mean: {np.round(beta)}, 95% HDI: {np.round(beta_hdi[0])} - {np.round(beta_hdi[1])}\")\n\nAlpha - mean: 993.0, 95% HDI: 967.0 - 1022.0\nBeta - mean: 993.0, 95% HDI: 967.0 - 1022.0\n\n\nWe’ve managed to recover our parameters with an intercept-only model.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Beta Regression"
    ]
  },
  {
    "objectID": "notebooks/beta_regression.html#beta-regression-with-predictors",
    "href": "notebooks/beta_regression.html#beta-regression-with-predictors",
    "title": "Beta Regression",
    "section": "Beta Regression with Predictors",
    "text": "Beta Regression with Predictors\nPerhaps we have a little more information on the coins in our pocket. We notice that the coins have accumulated dirt on either side, which would shift the probability of getting a tails or heads. In reality, we would not know how much the dirt affects the probability distribution, we would like to recover that parameter. We’ll construct this toy example by saying that each micron of dirt shifts the \\(\\alpha\\) parameter by 5.0. Further, the amount of dirt is distributed according to a Half Normal distribution with a standard deviation of 25 per side.\nWe’ll start by looking at the difference in probability for a coin with a lot of dirt on either side.\n\neffect_per_micron = 5.0\n\n# Clean Coin\nalpha = 1_000\nbeta = 1_000\np = np.random.beta(alpha, beta, size=10_000)\n\n# Add two std to tails side (heads more likely)\np_heads = np.random.beta(alpha + 50 * effect_per_micron, beta, size=10_000)\n# Add two std to heads side (tails more likely)\np_tails = np.random.beta(alpha - 50 * effect_per_micron, beta, size=10_000)\n\naz.plot_kde(p, label=\"Clean Coin\")\naz.plot_kde(p_heads, label=\"Biased toward heads\", plot_kwargs={\"color\":\"C1\"})\naz.plot_kde(p_tails, label=\"Biased toward tails\", plot_kwargs={\"color\":\"C2\"})\nplt.xlabel(\"$p$\")\nplt.ylim(top=plt.ylim()[1]*1.25);\n\n\n\n\n\n\n\n\nNext, we’ll generate a toy dataset according to our specifications above. As an added foil, we will also assume that we’re limited in our measuring equipment, that we can only measure correctly to the nearest integer micron.\n\n# Create amount of dirt on top and bottom\nheads_bias_dirt = stats.halfnorm(loc=0, scale=25).rvs(size=1_000)\ntails_bias_dirt = stats.halfnorm(loc=0, scale=25).rvs(size=1_000)\n\n# Create the probability per coin\nalpha = np.repeat(1_000, 1_000)\nalpha = alpha + effect_per_micron * heads_bias_dirt - effect_per_micron * tails_bias_dirt\nbeta = np.repeat(1_000, 1_000)\n\np = np.random.beta(alpha, beta)\n\ndf = pd.DataFrame({\n    \"p\" : p,\n    \"heads_bias_dirt\" : heads_bias_dirt.round(),\n    \"tails_bias_dirt\" : tails_bias_dirt.round()\n})\ndf.head()\n\n\n\n\n\n\n\n\np\nheads_bias_dirt\ntails_bias_dirt\n\n\n\n\n0\n0.500848\n8.0\n1.0\n\n\n1\n0.492925\n4.0\n14.0\n\n\n2\n0.469713\n14.0\n44.0\n\n\n3\n0.474854\n9.0\n32.0\n\n\n4\n0.526697\n23.0\n1.0\n\n\n\n\n\n\n\nTaking a look at our new dataset:\n\nfig,ax = plt.subplots(1,3, figsize=(16,5))\n\ndf[\"p\"].plot.kde(ax=ax[0])\nax[0].set_xlabel(\"$p$\")\n\ndf[\"heads_bias_dirt\"].plot.hist(ax=ax[1], bins=np.arange(0,df[\"heads_bias_dirt\"].max()))\nax[1].set_xlabel(\"Measured Dirt Biasing Toward Heads ($\\mu m$)\")\ndf[\"tails_bias_dirt\"].plot.hist(ax=ax[2], bins=np.arange(0,df[\"tails_bias_dirt\"].max()))\nax[2].set_xlabel(\"Measured Dirt Biasing Toward Tails ($\\mu m$)\");\n\n\n\n\n\n\n\n\nNext we want to make a model to recover the effect per micron of dirt per side. So far, we’ve considered the biasing toward one side or another independently. A linear model might look something like this:\n\\[\n\\begin{aligned}\np &\\sim \\text{Beta}(\\mu, \\sigma) \\\\\n\\text{logit}(\\mu) &= \\text{ Normal}( \\alpha + \\beta_h d_h + \\beta_t d_t)\n\\end{aligned}\n\\]\nWhere \\(d_h\\) and \\(d_t\\) are the measured dirt (in microns) biasing the probability toward heads and tails respectively, \\(\\beta_h\\) and \\(\\beta_t\\) are coefficients for how much a micron of dirt affects each independent side, and \\(\\alpha\\) is the intercept. Also note the logit link function used here, since our outcome is on the scale of 0-1, it makes sense that the link must also put our mean on that scale. Logit is the default link function, however Bambi supports the identity, probit, and cloglog links as well.\nIn this toy example, we’ve constructed it such that dirt should not affect one side differently from another, so we can wrap those into one coefficient: \\(\\beta = \\beta_h = -\\beta_t\\). This makes the last line of the model:\n\\[\n\\text{logit}(\\mu) = \\text{ Normal}( \\alpha + \\beta \\Delta d)\n\\]\nwhere \\(\\Delta d = d_h - d_t\\).\nPutting that into our dataset, then constructing this model in Bambi,\n\ndf[\"delta_d\"] = df[\"heads_bias_dirt\"] - df[\"tails_bias_dirt\"]\ndirt_model = bmb.Model(\"p ~ delta_d\", df, family=\"beta\")\ndirt_fitted = dirt_model.fit()\ndirt_model.predict(dirt_fitted, kind=\"response\")\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [kappa, Intercept, delta_d]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 4 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\naz.summary(dirt_fitted)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-0.006\n0.002\n-0.009\n-0.003\n0.000\n0.000\n3212.0\n1464.0\n1.01\n\n\ndelta_d\n0.005\n0.000\n0.005\n0.005\n0.000\n0.000\n2652.0\n1269.0\n1.00\n\n\nkappa\n1803.768\n79.957\n1644.702\n1949.191\n1.446\n1.022\n3094.0\n1373.0\n1.00\n\n\nmu[0]\n0.508\n0.000\n0.507\n0.508\n0.000\n0.000\n3137.0\n1430.0\n1.00\n\n\nmu[1]\n0.486\n0.000\n0.485\n0.486\n0.000\n0.000\n3172.0\n1700.0\n1.00\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nmu[995]\n0.484\n0.000\n0.483\n0.485\n0.000\n0.000\n3149.0\n1728.0\n1.00\n\n\nmu[996]\n0.489\n0.000\n0.489\n0.490\n0.000\n0.000\n3252.0\n1624.0\n1.00\n\n\nmu[997]\n0.531\n0.001\n0.530\n0.532\n0.000\n0.000\n3007.0\n1627.0\n1.00\n\n\nmu[998]\n0.546\n0.001\n0.545\n0.548\n0.000\n0.000\n2921.0\n1584.0\n1.00\n\n\nmu[999]\n0.528\n0.001\n0.527\n0.529\n0.000\n0.000\n3033.0\n1627.0\n1.00\n\n\n\n\n1003 rows × 9 columns\n\n\n\n\naz.plot_ppc(dirt_fitted);\n\n\n\n\n\n\n\n\nNext, we’ll see if we can in fact recover the effect on \\(\\alpha\\). Remember that in order to return to \\(\\alpha\\), \\(\\beta\\) space, the linear equation passes through an inverse logit transformation, so we must apply this to the coefficient on \\(\\Delta d\\) to get the effect on \\(\\alpha\\). The inverse logit is nicely defined in scipy.special as expit.\n\nmean_effect = expit(dirt_fitted.posterior.delta_d.mean())\nhdi = az.hdi(dirt_fitted.posterior.delta_d, hdi_prob=.95)\nlower = expit(hdi.delta_d[0])\nupper = expit(hdi.delta_d[1])\nprint(f\"Mean effect: {mean_effect.item():.4f}\")\nprint(f\"95% interval {lower.item():.4f} - {upper.item():.4f}\")\n\nMean effect: 0.5013\n95% interval 0.5013 - 0.5013\n\n\nThe recovered effect is very close to the true effect of 0.5.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Beta Regression"
    ]
  },
  {
    "objectID": "notebooks/beta_regression.html#example---revisiting-baseball-data",
    "href": "notebooks/beta_regression.html#example---revisiting-baseball-data",
    "title": "Beta Regression",
    "section": "Example - Revisiting Baseball Data",
    "text": "Example - Revisiting Baseball Data\nIn the Hierarchical Logistic regression with Binomial family notebook, we modeled baseball batting averages (times a player reached first via a hit per times at bat) via a Hierarchical Logisitic regression model. If we’re interested in league-wide effects, we could look at a Beta regression. We work off the assumption that the league-wide batting average follows a Beta distribution, and that individual player’s batting averages are samples from that distribution.\nFirst, load the Batting dataset again, and re-calculate batting average as hits/at-bat. In order to make sure that we have a sufficient sample, we’ll require at least 100 at-bats in order consider a batter. Last, we’ll focus on 1990-2018.\n\nbatting = bmb.load_data(\"batting\")\n\n\nbatting[\"batting_avg\"] = batting[\"H\"] / batting[\"AB\"]\nbatting = batting[batting[\"AB\"] &gt; 100]\ndf = batting[ (batting[\"yearID\"] &gt; 1990) & (batting[\"yearID\"] &lt; 2018) ]\n\n\ndf.batting_avg.hist(bins=30)\nplt.xlabel(\"Batting Average\")\nplt.ylabel(\"Count\");\n\n\n\n\n\n\n\n\nIf we’re interested in modeling the distribution of batting averages, we can start with an intercept-only model.\n\nmodel_avg = bmb.Model(\"batting_avg ~ 1\", df, family=\"beta\")\navg_fitted = model_avg.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [kappa, Intercept]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 3 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\naz.summary(avg_fitted)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-1.038\n0.002\n-1.041\n-1.035\n0.000\n0.000\n1903.0\n1395.0\n1.0\n\n\nkappa\n152.503\n2.062\n148.731\n156.325\n0.046\n0.033\n2012.0\n1219.0\n1.0\n\n\n\n\n\n\n\nLooking at the posterior predictive,\n\nposterior_predictive = model_avg.predict(avg_fitted, kind=\"response\")\n\n\naz.plot_ppc(avg_fitted);\n\n\n\n\n\n\n\n\nThis appears to fit reasonably well. If, for example, we were interested in simulating players, we could sample from this distribution.\nHowever, we can take this further. Say we’re interested in understanding how this distribution shifts if we know a player’s batting average in a previous year. We can condition the model on a player’s n-1 year, and use Beta regrssion to model that. Let’s construct that variable, and for sake of ease, we will ignore players without previous seasons.\n\n# Add the player's batting average in the n-1 year\nbatting[\"batting_avg_shift\"] = np.where(\n    batting[\"playerID\"] == batting[\"playerID\"].shift(),\n    batting[\"batting_avg\"].shift(),\n    np.nan\n)\ndf_shift = batting[ (batting[\"yearID\"] &gt; 1990) & (batting[\"yearID\"] &lt; 2018) ]\ndf_shift = df_shift[~df_shift[\"batting_avg_shift\"].isna()]\ndf_shift[[\"batting_avg_shift\",\"batting_avg\"]].corr()\n\n\n\n\n\n\n\n\nbatting_avg_shift\nbatting_avg\n\n\n\n\nbatting_avg_shift\n1.000000\n0.229774\n\n\nbatting_avg\n0.229774\n1.000000\n\n\n\n\n\n\n\nThere is a lot of variance in year-to-year batting averages, it’s not known to be incredibly predictive, and we see that here. A correlation coefficient of 0.23 is only lightly predictive. However, we can still use it in our model to get a better understanding. We’ll fit two models. First, we’ll refit the previous, intercept-only, model using this updated dataset so we have an apples-to-apples comparison. Then, we’ll fit a model using the previous year’s batting average as a predictor.\nNotice we need to explicitly ask for the inclusion of the log-likelihood values into the inference data object.\n\nmodel_avg = bmb.Model(\"batting_avg ~ 1\", df_shift, family=\"beta\")\navg_fitted = model_avg.fit(idata_kwargs={\"log_likelihood\": True})\n\nmodel_lag = bmb.Model(\"batting_avg ~ batting_avg_shift\", df_shift, family=\"beta\")\nlag_fitted = model_lag.fit(idata_kwargs={\"log_likelihood\": True})\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [kappa, Intercept]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 2 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [kappa, Intercept, batting_avg_shift]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 3 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\naz.summary(lag_fitted)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-1.377\n0.073\n-1.521\n-1.250\n0.001\n0.001\n2593.0\n1287.0\n1.0\n\n\nbatting_avg_shift\n1.359\n0.278\n0.873\n1.887\n0.005\n0.004\n2592.0\n1365.0\n1.0\n\n\nkappa\n135.954\n8.722\n119.751\n151.394\n0.169\n0.121\n2658.0\n1685.0\n1.0\n\n\n\n\n\n\n\n\naz.compare({\n    \"intercept-only\" : avg_fitted,\n    \"lag-model\": lag_fitted\n})\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nlag-model\n0\n785.126819\n2.909173\n0.000000\n0.99836\n14.540186\n0.000000\nFalse\nlog\n\n\nintercept-only\n1\n774.161032\n2.067113\n10.965787\n0.00164\n15.314248\n4.651392\nFalse\nlog\n\n\n\n\n\n\n\nAdding the predictor results in a higher loo than the intercept-only model.\n\nppc= model_lag.predict(lag_fitted, kind=\"response\")\naz.plot_ppc(lag_fitted);\n\n\n\n\n\n\n\n\nThe biggest question this helps us understand is, for each point of batting average in the previous year, how much better do we expect a player to be in the current year?\n\nmean_effect = lag_fitted.posterior.batting_avg_shift.mean().item()\nhdi = az.hdi(lag_fitted.posterior.batting_avg_shift, hdi_prob=.95)\n\nlower = expit(hdi.batting_avg_shift[0]).item()\nupper = expit(hdi.batting_avg_shift[1]).item()\nprint(f\"Mean effect: {expit(mean_effect):.4f}\")\nprint(f\"95% interval {lower:.4f} - {upper:.4f}\")\n\nMean effect: 0.7956\n95% interval 0.6944 - 0.8679\n\n\n\naz.plot_hdi(df_shift.batting_avg_shift, lag_fitted.posterior_predictive.batting_avg, hdi_prob=0.95, color=\"goldenrod\", fill_kwargs={\"alpha\":0.8})\naz.plot_hdi(df_shift.batting_avg_shift, lag_fitted.posterior_predictive.batting_avg, hdi_prob=.68, color=\"forestgreen\", fill_kwargs={\"alpha\":0.8})\n\nintercept = lag_fitted.posterior.Intercept.values.mean()\nx = np.linspace(df_shift.batting_avg_shift.min(), df_shift.batting_avg_shift.max(),100)\nlinear = mean_effect * x + intercept\nplt.plot(x, expit(linear), c=\"black\")\nplt.xlabel(\"Previous Year's Batting Average\")\nplt.ylabel(\"Batting Average\");\n\n\n\n\n\n\n\n\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sat May 25 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\npandas    : 2.2.2\nmatplotlib: 3.8.4\nnumpy     : 1.26.4\nscipy     : 1.13.1\narviz     : 0.18.0\nbambi     : 0.13.1.dev37+g2a54df76.d20240525\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Beta Regression"
    ]
  },
  {
    "objectID": "notebooks/alternative_links_binary.html",
    "href": "notebooks/alternative_links_binary.html",
    "title": "Regression for Binary responses: Alternative link functions",
    "section": "",
    "text": "In this example we use a simple dataset to fit a Generalized Linear Model for a binary response using different link functions.\nimport arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom scipy.special import expit as invlogit\nfrom scipy.stats import norm\naz.style.use(\"arviz-darkgrid\")\nnp.random.seed(1234)",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Regression for Binary responses: Alternative link functions"
    ]
  },
  {
    "objectID": "notebooks/alternative_links_binary.html#generalized-linear-models-for-binary-response",
    "href": "notebooks/alternative_links_binary.html#generalized-linear-models-for-binary-response",
    "title": "Regression for Binary responses: Alternative link functions",
    "section": "Generalized linear models for binary response",
    "text": "Generalized linear models for binary response\nFirst of all, let’s review some concepts. A Generalized Linear Model (GLM) is made of three components.\n1. Random component\nA set of independent and identically distributed random variables \\(Y_i\\). Their (conditional) probability distribution belongs to the same family \\(f\\) with a mean given by \\(\\mu_i\\).\n2. Systematic component (a.k.a linear predictor)\nConstructed by a linear combination of the parameters \\(\\beta_j\\) and explanatory variables \\(x_j\\), represented by \\(\\eta_i\\)\n\\[\n\\eta_i = \\mathbf{x}_i^T\\mathbf{\\beta} = x_{i1}\\beta_1 + x_{i2}\\beta_2 + \\cdots + x_{ip}\\beta_p\n\\]\n3. Link function\nA monotone and differentiable function \\(g\\) such that\n\\[\ng(\\mu_i) = \\eta_i = \\mathbf{x}_i^T\\mathbf{\\beta}\n\\] where \\(\\mu_i = E(Y_i)\\)\nAs we can see, this function specifies the link between the random and the systematic components of the model.\nAn important feature of GLMs is that no matter we are modeling a function of \\(\\mu\\) (and not just \\(\\mu\\), unless \\(g\\) is the identity function) is that we can show predictions in terms of the mean \\(\\mu\\) by using the inverse of \\(g\\) on the linear predictor \\(\\eta_i\\)\n\\[\ng^{-1}(\\eta_i) = g^{-1}(\\mathbf{x}_i^T\\mathbf{\\beta}) = \\mu_i\n\\]\nIn Bambi, we can use family=\"bernoulli\" to tell we are modeling a binary variable that follows a Bernoulli distribution and our random component is of the form\n\\[\nY_i =\n\\left\\{\n    \\begin{array}{ll}\n        1 & \\textrm{with probability } \\pi_i \\\\\n        0 & \\textrm{with probability } 1 - \\pi_i\n    \\end{array}\n\\right.\n\\]\nthat has a mean \\(\\mu_i\\) equal to the probability of success \\(\\pi_i\\).\nBy default, this family implies \\(g\\) is the logit function.\n\\[\n\\begin{array}{lcr}    \n    \\displaystyle \\text{logit}(\\pi_i) = \\log{\\left( \\frac{\\pi_i}{1 - \\pi_i} \\right)} = \\eta_i &\n    \\text{ with } &\n    \\displaystyle g^{-1}(\\eta) = \\frac{1}{1 + e^{-\\eta}} = \\pi_i\n\\end{array}\n\\]\nBut there are other options available, like the probit and the cloglog link functions.\nThe probit function is the inverse of the cumulative density function of a standard Gaussian distribution\n\\[\n\\begin{array}{lcr}    \n    \\displaystyle \\text{probit}(\\pi_i) = \\Phi^{-1}(\\pi_i) = \\eta_i &\n    \\text{ with } &\n    \\displaystyle g^{-1}(\\eta) = \\Phi(\\eta_i) = \\pi_i\n\\end{array}\n\\]\nAnd with the cloglog link function we have\n\\[\n\\begin{array}{lcr}    \n    \\displaystyle \\text{cloglog}(\\pi_i) = \\log(-\\log(1 - \\pi)) = \\eta_i &\n    \\text{ with } &\n    \\displaystyle g^{-1}(\\eta) = 1 - \\exp(-\\exp(\\eta_i)) = \\pi_i\n\\end{array}\n\\]\ncloglog stands for complementary log-log and \\(g^{-1}\\) is the cumulative density function of the extreme minimum value distribution.\nLet’s plot them to better understand the implications of what we’re saying.\n\ndef invcloglog(x):\n    return 1 - np.exp(-np.exp(x))\n\n\nx = np.linspace(-5, 5, num=200)\n\n# inverse of the logit function\nlogit = invlogit(x)\n\n# cumulative density function of standard gaussian\nprobit = norm.cdf(x)\n\n# inverse of the cloglog function\ncloglog = invcloglog(x)\n\nplt.plot(x, logit, color=\"C0\", lw=2, label=\"Logit\")\nplt.plot(x, probit, color=\"C1\", lw=2, label=\"Probit\")\nplt.plot(x, cloglog, color=\"C2\", lw=2, label=\"CLogLog\")\nplt.axvline(0, c=\"k\", alpha=0.5, ls=\"--\")\nplt.axhline(0.5, c=\"k\", alpha=0.5, ls=\"--\")\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$\\pi$\")\nplt.legend();\n\n\n\n\n\n\n\n\nIn the plot above we can see both the logit and the probit links are symmetric in terms of their slopes at \\(-x\\) and \\(x\\). We can say the function approaches \\(\\pi = 0.5\\) at the same rate as it moves away from it. However, these two functions differ in their tails. The probit link approaches 0 and 1 faster than the logit link as we move away from \\(x=0\\). Just see the orange line is below the blue one for \\(x &lt; 0\\) and it is above for \\(x &gt; 0\\). In other words, the logit function has heavier tails than the probit.\nOn the other hand, the cloglog does not present this symmetry, and we can clearly see it since the green line does not cross the point (0, 0.5). This function approaches faster the 1 than 0 as we move away from \\(x=0\\).",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Regression for Binary responses: Alternative link functions"
    ]
  },
  {
    "objectID": "notebooks/alternative_links_binary.html#load-data",
    "href": "notebooks/alternative_links_binary.html#load-data",
    "title": "Regression for Binary responses: Alternative link functions",
    "section": "Load data",
    "text": "Load data\nWe use a data set consisting of the numbers of beetles dead after five hours of exposure to gaseous carbon disulphide at various concentrations. This data can be found in An Introduction to Generalized Linear Models by A. J. Dobson and A. G. Barnett, but the original source is (Bliss, 1935).\n\n\n\n\n\n\n\n\nDose, \\(x_i\\) (\\(\\log_{10}\\text{CS}_2\\text{mgl}^{-1}\\))\nNumber of beetles, \\(n_i\\)\nNumber killed, \\(y_i\\)\n\n\n\n\n1.6907\n59\n6\n\n\n1.7242\n60\n13\n\n\n1.7552\n62\n18\n\n\n1.7842\n56\n28\n\n\n1.8113\n63\n52\n\n\n1.8369\n59\n53\n\n\n1.8610\n62\n61\n\n\n1.8839\n60\n60\n\n\n\nWe create a data frame where the data is in long format (i.e. each row is an observation with a 0-1 outcome).\n\nx = np.array([1.6907, 1.7242, 1.7552, 1.7842, 1.8113, 1.8369, 1.8610, 1.8839])\nn = np.array([59, 60, 62, 56, 63, 59, 62, 60])\ny = np.array([6, 13, 18, 28, 52, 53, 61, 60])\n\ndata = pd.DataFrame({\"x\": x, \"n\": n, \"y\": y})",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Regression for Binary responses: Alternative link functions"
    ]
  },
  {
    "objectID": "notebooks/alternative_links_binary.html#build-the-models",
    "href": "notebooks/alternative_links_binary.html#build-the-models",
    "title": "Regression for Binary responses: Alternative link functions",
    "section": "Build the models",
    "text": "Build the models\nBambi has two families to model binary data: Bernoulli and Binomial. The first one can be used when each row represents a single observation with a column containing the binary outcome, while the second is used when each row represents a group of observations or realizations and there’s one column for the number of successes and another column for the number of trials.\nSince we have aggregated data, we’re going to use the Binomial family. This family requires using the function proportion(y, n) on the left side of the model formula to indicate we want to model the proportion between two variables. This function can be replaced by any of its aliases prop(y, n) or p(y, n). Let’s use the shortest one here.\n\nformula = \"p(y, n) ~ x\"\n\n\nLogit link\nThe logit link is the default link when we say family=\"binomial\", so there’s no need to add it.\n\nmodel_logit = bmb.Model(formula, data, family=\"binomial\")\nidata_logit = model_logit.fit(draws=2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Intercept, x]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 7 seconds.\n\n\n\n\nProbit link\n\nmodel_probit = bmb.Model(formula, data, family=\"binomial\", link=\"probit\")\nidata_probit = model_probit.fit(draws=2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Intercept, x]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 7 seconds.\n\n\n\nmodel_probit\n\n       Formula: p(y, n) ~ x\n        Family: binomial\n          Link: p = probit\n  Observations: 8\n        Priors: \n    target = p\n        Common-level effects\n            Intercept ~ Normal(mu: 0.0, sigma: 1.5)\n            x ~ Normal(mu: 0.0, sigma: 15.848)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\n\n\nCloglog link\n\nmodel_cloglog = bmb.Model(formula, data, family=\"binomial\", link=\"cloglog\")\nidata_cloglog = model_cloglog.fit(draws=2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Intercept, x]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 5 seconds.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Regression for Binary responses: Alternative link functions"
    ]
  },
  {
    "objectID": "notebooks/alternative_links_binary.html#results",
    "href": "notebooks/alternative_links_binary.html#results",
    "title": "Regression for Binary responses: Alternative link functions",
    "section": "Results",
    "text": "Results\nWe can use the samples from the posteriors to see the mean estimate for the probability of dying at each concentration level. To do so, we use a little helper function that will help us to write less code. This function leverages the power of the new Model.predict() method that is helpful to obtain both in-sample and out-of-sample predictions.\n\ndef get_predictions(model, idata, seq):\n    # Create a data frame with the new data\n    new_data = pd.DataFrame({\"x\": seq})\n    \n    # Predict probability of dying using out of sample data\n    model.predict(idata, data=new_data)\n    \n    # Get posterior mean across all chains and draws\n    mu = idata.posterior[\"p\"].mean((\"chain\", \"draw\"))\n    return mu\n\n\nx_seq = np.linspace(1.6, 2, num=200)\n\nmu_logit = get_predictions(model_logit, idata_logit, x_seq)\nmu_probit = get_predictions(model_probit, idata_probit, x_seq)\nmu_cloglog = get_predictions(model_cloglog, idata_cloglog, x_seq)\n\n\nplt.scatter(x, y / n, c = \"white\", edgecolors = \"black\", s=100)\nplt.plot(x_seq, mu_logit, lw=2, label=\"Logit\")\nplt.plot(x_seq, mu_probit, lw=2, label=\"Probit\")\nplt.plot(x_seq, mu_cloglog, lw=2, label=\"CLogLog\")\nplt.axhline(0.5, c=\"k\", alpha=0.5, ls=\"--\")\nplt.xlabel(r\"Dose $\\log_{10}CS_2mgl^{-1}$\")\nplt.ylabel(\"Probability of death\")\nplt.legend();\n\n\n\n\n\n\n\n\nIn this example, we can see the models using the logit and probit link functions present very similar estimations. With these particular data, all the three link functions fit the data well and the results do not differ significantly. However, there can be scenarios where the results are more sensitive to the choice of the link function.\nReferences\nBliss, C. I. (1935). The calculation of the dose-mortality curve. Annals of Applied Biology 22, 134–167\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Thu Aug 15 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\npandas    : 2.2.2\nmatplotlib: 3.8.4\narviz     : 0.18.0\nnumpy     : 1.26.4\nbambi     : 0.14.1.dev12+g64e57423.d20240730\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Regression for Binary responses: Alternative link functions"
    ]
  },
  {
    "objectID": "notebooks/ESCS_multiple_regression.html",
    "href": "notebooks/ESCS_multiple_regression.html",
    "title": "Multiple linear regression",
    "section": "",
    "text": "import arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nimport xarray as xr\naz.style.use(\"arviz-darkgrid\")\nSEED = 7355608",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Multiple linear regression"
    ]
  },
  {
    "objectID": "notebooks/ESCS_multiple_regression.html#load-and-examine-eugene-springfield-community-sample-data",
    "href": "notebooks/ESCS_multiple_regression.html#load-and-examine-eugene-springfield-community-sample-data",
    "title": "Multiple linear regression",
    "section": "Load and examine Eugene-Springfield community sample data",
    "text": "Load and examine Eugene-Springfield community sample data\nBambi comes with several datasets. These can be accessed via the load_data() function.\n\ndata = bmb.load_data(\"ESCS\")\nnp.round(data.describe(), 2)\n\n\n\n\n\n\n\n\ndrugs\nn\ne\no\na\nc\nhones\nemoti\nextra\nagree\nconsc\nopenn\n\n\n\n\ncount\n604.00\n604.00\n604.00\n604.00\n604.00\n604.00\n604.00\n604.00\n604.00\n604.00\n604.00\n604.00\n\n\nmean\n2.21\n80.04\n106.52\n113.87\n124.63\n124.23\n3.89\n3.18\n3.21\n3.13\n3.57\n3.41\n\n\nstd\n0.65\n23.21\n19.88\n21.12\n16.67\n18.69\n0.45\n0.46\n0.53\n0.47\n0.44\n0.52\n\n\nmin\n1.00\n23.00\n42.00\n51.00\n63.00\n44.00\n2.56\n1.47\n1.62\n1.59\n2.00\n1.28\n\n\n25%\n1.71\n65.75\n93.00\n101.00\n115.00\n113.00\n3.59\n2.88\n2.84\n2.84\n3.31\n3.06\n\n\n50%\n2.14\n76.00\n107.00\n112.00\n126.00\n125.00\n3.88\n3.19\n3.22\n3.16\n3.56\n3.44\n\n\n75%\n2.64\n93.00\n120.00\n129.00\n136.00\n136.00\n4.20\n3.47\n3.56\n3.44\n3.84\n3.75\n\n\nmax\n4.29\n163.00\n158.00\n174.00\n171.00\n180.00\n4.94\n4.62\n4.75\n4.44\n4.75\n4.72\n\n\n\n\n\n\n\nIt’s always a good idea to start off with some basic plotting. Here’s what our outcome variable drugs (some index of self-reported illegal drug use) looks like:\n\ndata[\"drugs\"].hist();\n\n\n\n\n\n\n\n\nThe five numerical predictors that we’ll use are sum-scores measuring participants’ standings on the Big Five personality dimensions. The dimensions are:\n\nO = Openness to experience\nC = Conscientiousness\nE = Extraversion\nA = Agreeableness\nN = Neuroticism\n\nHere’s what our predictors look like:\n\naz.plot_pair(data[[\"o\", \"c\", \"e\", \"a\", \"n\"]].to_dict(\"list\"), marginals=True, textsize=24);\n\n\n\n\n\n\n\n\nWe can easily see all the predictors are more or less symmetrically distributed without outliers and the pairwise correlations between them are not strong.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Multiple linear regression"
    ]
  },
  {
    "objectID": "notebooks/ESCS_multiple_regression.html#specify-model-and-examine-priors",
    "href": "notebooks/ESCS_multiple_regression.html#specify-model-and-examine-priors",
    "title": "Multiple linear regression",
    "section": "Specify model and examine priors",
    "text": "Specify model and examine priors\nWe’re going to fit a pretty straightforward additive multiple regression model predicting drug index from all 5 personality dimension scores. It’s simple to specify the model using a familiar formula interface. Here we also tell Bambi to run two parallel Markov Chain Monte Carlo (MCMC) chains, each one with 2000 draws. The first 1000 draws are tuning steps that we discard and the last 1000 draws are considered to be taken from the joint posterior distribution of all the parameters (to be confirmed when we analyze the convergence of the chains).\n\nmodel = bmb.Model(\"drugs ~ o + c + e + a + n\", data)\nfitted = model.fit(tune=2000, draws=2000, init=\"adapt_diag\", random_seed=SEED)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, o, c, e, a, n]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 2_000 tune and 2_000 draw iterations (4_000 + 4_000 draws total) took 8 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nGreat! But this is a Bayesian model, right? What about the priors? If no priors are given explicitly by the user, then Bambi chooses smart default priors for all parameters of the model based on the implied partial correlations between the outcome and the predictors. Here’s what the default priors look like in this case – the plots below show 1000 draws from each prior distribution:\n\nmodel.plot_priors();\n\nSampling: [Intercept, a, c, e, n, o, sigma]\n\n\n\n\n\n\n\n\n\n\n# Normal priors on the coefficients\n{x.name: x.prior.args for x in model.components[\"mu\"].terms.values()}\n\n{'Intercept': {'mu': array(2.21014664), 'sigma': array(21.19375074)},\n 'o': {'mu': array(0.), 'sigma': array(0.0768135)},\n 'c': {'mu': array(0.), 'sigma': array(0.08679683)},\n 'e': {'mu': array(0.), 'sigma': array(0.0815892)},\n 'a': {'mu': array(0.), 'sigma': array(0.09727366)},\n 'n': {'mu': array(0.), 'sigma': array(0.06987412)}}\n\n\n\n# HalfStudentT prior on the residual standard deviation\nfor name, component in model.constant_components.items():\n    print(f\"{name}: {component.prior}\")\n\nsigma: HalfStudentT(nu: 4.0, sigma: 0.6482)\n\n\nYou could also just print the model and see it also contains the same information about the priors\n\nmodel\n\n       Formula: drugs ~ o + c + e + a + n\n        Family: gaussian\n          Link: mu = identity\n  Observations: 604\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 2.2101, sigma: 21.1938)\n            o ~ Normal(mu: 0.0, sigma: 0.0768)\n            c ~ Normal(mu: 0.0, sigma: 0.0868)\n            e ~ Normal(mu: 0.0, sigma: 0.0816)\n            a ~ Normal(mu: 0.0, sigma: 0.0973)\n            n ~ Normal(mu: 0.0, sigma: 0.0699)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 0.6482)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\nSome more info about the default prior distributions can be found in this technical paper.\nNotice the apparently small SDs of the slope priors. This is due to the relative scales of the outcome and the predictors: remember from the plots above that the outcome, drugs, ranges from 1 to about 4, while the predictors all range from about 20 to 180 or so. A one-unit change in any of the predictors – which is a trivial increase on the scale of the predictors – is likely to lead to a very small absolute change in the outcome. Believe it or not, these priors are actually quite wide on the partial correlation scale!",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Multiple linear regression"
    ]
  },
  {
    "objectID": "notebooks/ESCS_multiple_regression.html#examine-the-model-results",
    "href": "notebooks/ESCS_multiple_regression.html#examine-the-model-results",
    "title": "Multiple linear regression",
    "section": "Examine the model results",
    "text": "Examine the model results\nLet’s start with a pretty picture of the parameter estimates!\n\naz.plot_trace(fitted);\n\n\n\n\n\n\n\n\nThe left panels show the marginal posterior distributions for all of the model’s parameters, which summarize the most plausible values of the regression coefficients, given the data we have now observed. These posterior density plots show two overlaid distributions because we ran two MCMC chains. The panels on the right are “trace plots” showing the sampling paths of the two MCMC chains as they wander through the parameter space. If any of these paths exhibited a pattern other than white noise we would be concerned about the convergence of the chains.\nA much more succinct (non-graphical) summary of the parameter estimates can be found like so:\n\naz.summary(fitted)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n3.306\n0.357\n2.599\n3.934\n0.006\n0.004\n3401.0\n3494.0\n1.0\n\n\na\n-0.012\n0.001\n-0.015\n-0.010\n0.000\n0.000\n4468.0\n3384.0\n1.0\n\n\nc\n-0.004\n0.001\n-0.007\n-0.001\n0.000\n0.000\n3815.0\n2844.0\n1.0\n\n\ne\n0.003\n0.001\n0.001\n0.006\n0.000\n0.000\n4078.0\n2890.0\n1.0\n\n\nn\n-0.002\n0.001\n-0.004\n0.001\n0.000\n0.000\n3426.0\n3178.0\n1.0\n\n\no\n0.006\n0.001\n0.004\n0.008\n0.000\n0.000\n4585.0\n3503.0\n1.0\n\n\nsigma\n0.592\n0.017\n0.561\n0.625\n0.000\n0.000\n4284.0\n3008.0\n1.0\n\n\n\n\n\n\n\nWhen there are multiple MCMC chains, the default summary output includes some basic convergence diagnostic info (the effective MCMC sample sizes and the Gelman-Rubin “R-hat” statistics), although in this case it’s pretty clear from the trace plots above that the chains have converged just fine.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Multiple linear regression"
    ]
  },
  {
    "objectID": "notebooks/ESCS_multiple_regression.html#summarize-effects-on-partial-correlation-scale",
    "href": "notebooks/ESCS_multiple_regression.html#summarize-effects-on-partial-correlation-scale",
    "title": "Multiple linear regression",
    "section": "Summarize effects on partial correlation scale",
    "text": "Summarize effects on partial correlation scale\n\nsamples = fitted.posterior\n\nIt turns out that we can convert each regression coefficient into a partial correlation by multiplying it by a constant that depends on (1) the SD of the predictor, (2) the SD of the outcome, and (3) the degree of multicollinearity with the set of other predictors. Two of these statistics are actually already computed and stored in the fitted model object, in a dictionary called dm_statistics (for design matrix statistics), because they are used internally. We will compute the others manually.\nSome information about the relationship between linear regression parameters and partial correlation can be found here.\n\n# the names of the predictors\nvarnames = ['o', 'c', 'e', 'a', 'n']\n\n# compute the needed statistics like R-squared when each predictor is response and all the \n# other predictors are the predictor\n\n# x_matrix = common effects design matrix (excluding intercept/constant term)\nterms = [t for t in model.components[\"mu\"].common_terms.values() if t.name != \"Intercept\"]\nx_matrix = [pd.DataFrame(x.data, columns=x.levels) for x in terms]\nx_matrix = pd.concat(x_matrix, axis=1)\nx_matrix.columns = varnames\n\ndm_statistics = {\n    'r2_x': pd.Series(\n        {\n            x: sm.OLS(\n                endog=x_matrix[x],\n                exog=sm.add_constant(x_matrix.drop(x, axis=1))\n                if \"Intercept\" in model.components[\"mu\"].terms\n                else x_matrix.drop(x, axis=1),\n            )\n            .fit()\n            .rsquared\n            for x in list(x_matrix.columns)\n        }\n    ),\n    'sigma_x': x_matrix.std(),\n    'mean_x': x_matrix.mean(axis=0),\n}\n\nr2_x = dm_statistics['r2_x']\nsd_x = dm_statistics['sigma_x']\nr2_y = pd.Series([sm.OLS(endog=data['drugs'],\n                         exog=sm.add_constant(data[[p for p in varnames if p != x]])).fit().rsquared\n                  for x in varnames], index=varnames)\nsd_y = data['drugs'].std()\n\n# compute the products to multiply each slope with to produce the partial correlations\nslope_constant = (sd_x[varnames] / sd_y) * ((1 - r2_x[varnames]) / (1 - r2_y)) ** 0.5\nslope_constant\n\no    32.392557\nc    27.674284\ne    30.305117\na    26.113299\nn    34.130431\ndtype: float64\n\n\nNow we just multiply each sampled regression coefficient by its corresponding slope_constant to transform it into a sample partial correlation coefficient.\n\npcorr_samples = (samples[varnames] * slope_constant)\n\nAnd voilà! We now have a joint posterior distribution for the partial correlation coefficients. Let’s plot the marginal posterior distributions:\n\n# Pass the same axes to az.plot_kde to have all the densities in the same plot\n_, ax = plt.subplots()\nfor idx, (k, v) in enumerate(pcorr_samples.items()):\n    az.plot_dist(v, label=k, plot_kwargs={'color':f'C{idx}'}, ax=ax)\nax.axvline(x=0, color='k', linestyle='--');\n\n\n\n\n\n\n\n\nThe means of these distributions serve as good point estimates of the partial correlations:\n\npcorr_samples.mean()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 40B\nDimensions:  ()\nData variables:\n    o        float64 8B 0.1955\n    c        float64 8B -0.1053\n    e        float64 8B 0.1025\n    a        float64 8B -0.3248\n    n        float64 8B -0.05135xarray.DatasetDimensions:Coordinates: (0)Data variables: (5)o()float640.1955array(0.19545731)c()float64-0.1053array(-0.10533249)e()float640.1025array(0.10253546)a()float64-0.3248array(-0.3248134)n()float64-0.05135array(-0.05135457)Indexes: (0)Attributes: (0)",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Multiple linear regression"
    ]
  },
  {
    "objectID": "notebooks/ESCS_multiple_regression.html#relative-importance-which-predictors-have-the-strongest-effects-defined-in-terms-of-squared-partial-correlation",
    "href": "notebooks/ESCS_multiple_regression.html#relative-importance-which-predictors-have-the-strongest-effects-defined-in-terms-of-squared-partial-correlation",
    "title": "Multiple linear regression",
    "section": "Relative importance: Which predictors have the strongest effects (defined in terms of squared partial correlation?",
    "text": "Relative importance: Which predictors have the strongest effects (defined in terms of squared partial correlation?\nWe just take the square of the partial correlation coefficients, so it’s easy to get posteriors on that scale too:\n\n_, ax = plt.subplots()\nfor idx, (k, v) in enumerate(pcorr_samples.items()):\n    az.plot_dist(v ** 2, label=k, plot_kwargs={'color':f'C{idx}'}, ax=ax)\nax.set_ylim(0, 80);\n\n\n\n\n\n\n\n\nWith these posteriors we can ask: What is the probability that the squared partial correlation for Openness (blue) is greater than the squared partial correlation for Conscientiousness (orange)?\n\n(pcorr_samples['o'] ** 2 &gt; pcorr_samples['c'] ** 2).mean().item()\n\n0.92475\n\n\nIf we contrast this result with the plot we’ve just shown, we may think the probability is too high when looking at the overlap between the blue and orange curves. However, the previous plot is only showing marginal posteriors, which don’t account for correlations between the coefficients. In our Bayesian world, our model parameters’ are random variables (and consequently, any combination of them are too). As such, squared partial correlation have a joint distribution. When computing probabilities involving at least two of these parameters, one has to use the joint distribution. Otherwise, if we choose to work only with marginals, we are implicitly assuming independence.\nLet’s check the joint distribution of the squared partial correlation for Openness and Conscientiousness. We highlight with a blue color the draws where the coefficient for Openness is greater than the coefficient for Conscientiousness.\n\nsq_partial_c = pcorr_samples['c'] ** 2\nsq_partial_o = pcorr_samples['o'] ** 2\n\n\ncolors = np.where(sq_partial_c &gt; sq_partial_o, \"C1\", \"C0\").flatten().tolist()\n\nplt.scatter(sq_partial_o, sq_partial_c, c=colors)\nplt.xlabel(\"Openness to experience\")\nplt.ylabel(\"Conscientiousness\");\n\n\n\n\n\n\n\n\nWe can see that in the great majority of the draws (92.8%) the squared partial correlation for Openness is greater than the one for Conscientiousness. In fact, we can check the correlation between them is\n\nxr.corr(sq_partial_c, sq_partial_o).item()\n\n-0.17083046946181768\n\n\nwhich explains why ony looking at the marginal posteriors (i.e. assuming independence) is not the best approach here.\nFor each predictor, what is the probability that it has the largest squared partial correlation?\n\npc_df = pcorr_samples.to_dataframe()\n(pc_df**2).idxmax(axis=1).value_counts() / len(pc_df.index)\n\na    0.9915\no    0.0085\nName: count, dtype: float64\n\n\nAgreeableness is clearly the strongest predictor of drug use among the Big Five personality traits in terms of partial correlation, but it’s still not a particularly strong predictor in an absolute sense. Walter Mischel famously claimed that it is rare to see correlations between personality measure and relevant behavioral outcomes exceed 0.3. In this case, the probability that the agreeableness partial correlation exceeds 0.3 is:\n\n(np.abs(pcorr_samples['a']) &gt; 0.3).mean().item()\n\n0.75325",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Multiple linear regression"
    ]
  },
  {
    "objectID": "notebooks/ESCS_multiple_regression.html#posterior-predictive",
    "href": "notebooks/ESCS_multiple_regression.html#posterior-predictive",
    "title": "Multiple linear regression",
    "section": "Posterior Predictive",
    "text": "Posterior Predictive\nOnce we have computed the posterior distribution, we can use it to compute the posterior predictive distribution. As the name implies, these are predictions assuming the model’s parameter are distributed as the posterior. Thus, the posterior predictive includes the uncertainty about the parameters.\nWith bambi we can use the model’s predict() method with the fitted az.InferenceData to generate a posterior predictive samples, which are then automatically added to the az.InferenceData object\n\nmodel.predict(fitted, kind=\"response\")\nfitted\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 20MB\nDimensions:    (chain: 2, draw: 2000, __obs__: 604)\nCoordinates:\n  * chain      (chain) int64 16B 0 1\n  * draw       (draw) int64 16kB 0 1 2 3 4 5 6 ... 1994 1995 1996 1997 1998 1999\n  * __obs__    (__obs__) int64 5kB 0 1 2 3 4 5 6 ... 597 598 599 600 601 602 603\nData variables:\n    Intercept  (chain, draw) float64 32kB 3.633 2.935 3.971 ... 3.607 3.041\n    a          (chain, draw) float64 32kB -0.0138 -0.01134 ... -0.0115 -0.01258\n    c          (chain, draw) float64 32kB -0.004017 -0.001958 ... -0.001852\n    e          (chain, draw) float64 32kB 8.115e-05 0.00462 ... 0.002352\n    n          (chain, draw) float64 32kB -0.001429 -0.001813 ... -0.0009052\n    o          (chain, draw) float64 32kB 0.007907 0.005217 ... 0.007043\n    sigma      (chain, draw) float64 32kB 0.5625 0.6174 0.5599 ... 0.5916 0.5892\n    mu         (chain, draw, __obs__) float64 19MB 2.494 2.202 ... 2.429 2.128\nAttributes:\n    created_at:                  2024-05-25T21:33:53.557979+00:00\n    arviz_version:               0.18.0\n    inference_library:           pymc\n    inference_library_version:   5.15.0+23.g19be124e\n    sampling_time:               7.535887002944946\n    tuning_steps:                2000\n    modeling_interface:          bambi\n    modeling_interface_version:  0.13.1.dev37+g2a54df76.d20240525xarray.DatasetDimensions:chain: 2draw: 2000__obs__: 604Coordinates: (3)chain(chain)int640 1array([0, 1])draw(draw)int640 1 2 3 4 ... 1996 1997 1998 1999array([   0,    1,    2, ..., 1997, 1998, 1999])__obs__(__obs__)int640 1 2 3 4 5 ... 599 600 601 602 603array([  0,   1,   2, ..., 601, 602, 603])Data variables: (8)Intercept(chain, draw)float643.633 2.935 3.971 ... 3.607 3.041array([[3.6329393 , 2.93512374, 3.97121306, ..., 3.50023377, 2.96577152,\n        2.82846514],\n       [3.32408442, 3.24550446, 3.51617666, ..., 3.8963827 , 3.60688917,\n        3.04067082]])a(chain, draw)float64-0.0138 -0.01134 ... -0.01258array([[-0.01380465, -0.01134066, -0.0138804 , ..., -0.011867  ,\n        -0.01156186, -0.01025029],\n       [-0.01043387, -0.01063322, -0.01264349, ..., -0.01523829,\n        -0.01149513, -0.01257686]])c(chain, draw)float64-0.004017 -0.001958 ... -0.001852array([[-0.00401651, -0.00195821, -0.00718886, ..., -0.00518897,\n        -0.00316521, -0.00289915],\n       [-0.00539555, -0.00528656, -0.00399556, ..., -0.00514617,\n        -0.00553956, -0.0018519 ]])e(chain, draw)float648.115e-05 0.00462 ... 0.002352array([[8.11506145e-05, 4.62005732e-03, 2.66258450e-03, ...,\n        3.44245100e-03, 4.41737030e-03, 3.03478699e-03],\n       [2.58312349e-03, 3.97916231e-03, 2.10409625e-03, ...,\n        5.09450873e-03, 3.03598584e-03, 2.35222585e-03]])n(chain, draw)float64-0.001429 -0.001813 ... -0.0009052array([[-1.42927959e-03, -1.81253157e-03, -1.32845192e-03, ...,\n        -3.36136863e-03,  9.54065510e-04, -2.47044880e-05],\n       [-6.13597553e-05, -1.11939238e-03, -2.22216469e-03, ...,\n        -2.25085013e-03, -2.87956289e-03, -9.05156411e-04]])o(chain, draw)float640.007907 0.005217 ... 0.007043array([[0.00790717, 0.00521671, 0.00593912, ..., 0.00648975, 0.00458774,\n        0.00562242],\n       [0.00543892, 0.00544424, 0.00639954, ..., 0.00437252, 0.00544206,\n        0.00704307]])sigma(chain, draw)float640.5625 0.6174 ... 0.5916 0.5892array([[0.56247986, 0.61743819, 0.55987967, ..., 0.60619971, 0.58680083,\n        0.58714154],\n       [0.59198085, 0.58416584, 0.62477611, ..., 0.59223478, 0.59156901,\n        0.589219  ]])mu(chain, draw, __obs__)float642.494 2.202 1.73 ... 2.429 2.128array([[[2.49366104, 2.20177204, 1.72970898, ..., 1.954899  ,\n         2.33667376, 2.14913161],\n        [2.35228558, 2.12970111, 1.86985179, ..., 2.0051542 ,\n         2.51236666, 2.08766712],\n        [2.57588625, 2.07567763, 1.54537657, ..., 2.04584617,\n         2.33858918, 2.21281759],\n        ...,\n        [2.42331023, 2.16022583, 1.7212804 , ..., 1.93100172,\n         2.57961568, 2.08777559],\n        [2.47635519, 2.05299057, 1.75578497, ..., 2.15807941,\n         2.308892  , 2.2161822 ],\n        [2.38424973, 2.08661519, 1.77250028, ..., 2.0385047 ,\n         2.33715667, 2.12598845]],\n\n       [[2.56383226, 2.15686902, 1.73945554, ..., 2.16202639,\n         2.39026582, 2.27587797],\n        [2.49128282, 2.12095411, 1.71884587, ..., 2.08527578,\n         2.48088674, 2.1926459 ],\n        [2.44193843, 2.16765577, 1.76163829, ..., 1.96859016,\n         2.43362137, 2.12482053],\n        ...,\n        [2.47570855, 2.0180122 , 1.62165052, ..., 2.0142066 ,\n         2.3877961 , 2.13747292],\n        [2.42862188, 2.11974305, 1.69193249, ..., 1.96510932,\n         2.46981787, 2.11398399],\n        [2.42279127, 2.1895248 , 1.85807537, ..., 2.00305776,\n         2.42889787, 2.12760939]]])Indexes: (3)chainPandasIndexPandasIndex(Index([0, 1], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999],\n      dtype='int64', name='draw', length=2000))__obs__PandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       594, 595, 596, 597, 598, 599, 600, 601, 602, 603],\n      dtype='int64', name='__obs__', length=604))Attributes: (8)created_at :2024-05-25T21:33:53.557979+00:00arviz_version :0.18.0inference_library :pymcinference_library_version :5.15.0+23.g19be124esampling_time :7.535887002944946tuning_steps :2000modeling_interface :bambimodeling_interface_version :0.13.1.dev37+g2a54df76.d20240525\n                      \n                  \n            \n            \n            \n                  \n                  posterior_predictive\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 19MB\nDimensions:  (chain: 2, draw: 2000, __obs__: 604)\nCoordinates:\n  * chain    (chain) int64 16B 0 1\n  * draw     (draw) int64 16kB 0 1 2 3 4 5 6 ... 1994 1995 1996 1997 1998 1999\n  * __obs__  (__obs__) int64 5kB 0 1 2 3 4 5 6 7 ... 597 598 599 600 601 602 603\nData variables:\n    drugs    (chain, draw, __obs__) float64 19MB 2.451 2.123 1.484 ... 3.417 2.3\nAttributes:\n    modeling_interface:          bambi\n    modeling_interface_version:  0.13.1.dev37+g2a54df76.d20240525xarray.DatasetDimensions:chain: 2draw: 2000__obs__: 604Coordinates: (3)chain(chain)int640 1array([0, 1])draw(draw)int640 1 2 3 4 ... 1996 1997 1998 1999array([   0,    1,    2, ..., 1997, 1998, 1999])__obs__(__obs__)int640 1 2 3 4 5 ... 599 600 601 602 603array([  0,   1,   2, ..., 601, 602, 603])Data variables: (1)drugs(chain, draw, __obs__)float642.451 2.123 1.484 ... 3.417 2.3array([[[2.45128399, 2.12267585, 1.4842515 , ..., 1.66121515,\n         2.68146344, 2.27421321],\n        [2.07408608, 0.95317809, 2.80333651, ..., 2.51233449,\n         3.87317479, 2.58879397],\n        [2.03408037, 1.59423868, 2.28393395, ..., 2.2029466 ,\n         1.63566635, 2.69141331],\n        ...,\n        [2.15060158, 1.99611564, 1.84197085, ..., 2.38735067,\n         2.41601049, 2.41561515],\n        [2.1354205 , 2.07318294, 1.631507  , ..., 0.98701975,\n         2.34323492, 2.31605112],\n        [2.80055089, 2.34670462, 0.71701933, ..., 2.07977391,\n         2.94510999, 1.86065733]],\n\n       [[2.60671295, 1.38981679, 1.88710075, ..., 2.77522384,\n         2.64275341, 2.62620417],\n        [2.50806646, 1.9423765 , 1.63703418, ..., 1.80475941,\n         1.82928932, 2.25385632],\n        [3.15816737, 2.2187811 , 1.36302458, ..., 1.88239477,\n         2.41895537, 2.68465772],\n        ...,\n        [2.491626  , 1.67804507, 2.41272414, ..., 1.22826667,\n         2.80298923, 1.86701735],\n        [2.62854851, 2.62544876, 1.44705075, ..., 1.26111086,\n         2.28048644, 2.10755881],\n        [3.08338678, 2.15673753, 1.47119636, ..., 2.25117326,\n         3.41705719, 2.30045749]]])Indexes: (3)chainPandasIndexPandasIndex(Index([0, 1], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999],\n      dtype='int64', name='draw', length=2000))__obs__PandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       594, 595, 596, 597, 598, 599, 600, 601, 602, 603],\n      dtype='int64', name='__obs__', length=604))Attributes: (2)modeling_interface :bambimodeling_interface_version :0.13.1.dev37+g2a54df76.d20240525\n                      \n                  \n            \n            \n            \n                  \n                  sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 504kB\nDimensions:                (chain: 2, draw: 2000)\nCoordinates:\n  * chain                  (chain) int64 16B 0 1\n  * draw                   (draw) int64 16kB 0 1 2 3 4 ... 1996 1997 1998 1999\nData variables: (12/17)\n    acceptance_rate        (chain, draw) float64 32kB 0.7922 0.963 ... 0.8874\n    diverging              (chain, draw) bool 4kB False False ... False False\n    energy                 (chain, draw) float64 32kB 541.8 543.4 ... 537.1\n    energy_error           (chain, draw) float64 32kB 0.2763 ... -0.06115\n    index_in_trajectory    (chain, draw) int64 32kB -1 4 -3 -2 2 ... 1 -6 -2 5\n    largest_eigval         (chain, draw) float64 32kB nan nan nan ... nan nan\n    ...                     ...\n    process_time_diff      (chain, draw) float64 32kB 0.0007453 ... 0.001465\n    reached_max_treedepth  (chain, draw) bool 4kB False False ... False False\n    smallest_eigval        (chain, draw) float64 32kB nan nan nan ... nan nan\n    step_size              (chain, draw) float64 32kB 0.9536 0.9536 ... 0.7853\n    step_size_bar          (chain, draw) float64 32kB 0.8253 0.8253 ... 0.8255\n    tree_depth             (chain, draw) int64 32kB 2 3 3 2 2 3 ... 2 3 2 3 3 3\nAttributes:\n    created_at:                  2024-05-25T21:33:53.575429+00:00\n    arviz_version:               0.18.0\n    inference_library:           pymc\n    inference_library_version:   5.15.0+23.g19be124e\n    sampling_time:               7.535887002944946\n    tuning_steps:                2000\n    modeling_interface:          bambi\n    modeling_interface_version:  0.13.1.dev37+g2a54df76.d20240525xarray.DatasetDimensions:chain: 2draw: 2000Coordinates: (2)chain(chain)int640 1array([0, 1])draw(draw)int640 1 2 3 4 ... 1996 1997 1998 1999array([   0,    1,    2, ..., 1997, 1998, 1999])Data variables: (17)acceptance_rate(chain, draw)float640.7922 0.963 0.757 ... 1.0 0.8874array([[0.79217087, 0.96296416, 0.75701468, ..., 0.98668331, 0.86355019,\n        0.61305026],\n       [0.79559636, 1.        , 0.81971943, ..., 0.90197869, 1.        ,\n        0.8874015 ]])diverging(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])energy(chain, draw)float64541.8 543.4 542.1 ... 537.6 537.1array([[541.7974481 , 543.4002226 , 542.1182287 , ..., 539.29211328,\n        538.90537453, 541.84797599],\n       [542.2896245 , 538.26746448, 538.24805993, ..., 541.60600683,\n        537.58681471, 537.07203933]])energy_error(chain, draw)float640.2763 -0.1946 ... -0.3255 -0.06115array([[ 0.27629936, -0.19463963,  0.93448443, ..., -0.51369845,\n         0.09106047,  0.4483619 ],\n       [ 0.21408092, -0.84575278,  0.17284166, ..., -0.1160746 ,\n        -0.32549149, -0.06115012]])index_in_trajectory(chain, draw)int64-1 4 -3 -2 2 3 ... -1 -1 1 -6 -2 5array([[-1,  4, -3, ..., -1, -3, -1],\n       [-1,  1,  6, ..., -6, -2,  5]])largest_eigval(chain, draw)float64nan nan nan nan ... nan nan nan nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]])lp(chain, draw)float64-539.7 -537.6 ... -535.2 -535.0array([[-539.68673086, -537.59493057, -540.90647689, ..., -535.7951793 ,\n        -536.73462993, -538.49969674],\n       [-538.19535188, -535.18640368, -536.31460292, ..., -537.15037153,\n        -535.17462544, -534.96292355]])max_energy_error(chain, draw)float640.2763 -0.6461 ... -0.4432 0.2071array([[ 0.27629936, -0.64610211,  0.93448443, ..., -0.51369845,\n         0.49173388,  0.68899993],\n       [ 0.46226242, -0.84575278,  0.30507806, ...,  0.27077741,\n        -0.44323455,  0.20707454]])n_steps(chain, draw)float643.0 7.0 7.0 3.0 ... 3.0 7.0 7.0 7.0array([[3., 7., 7., ..., 3., 7., 3.],\n       [7., 3., 7., ..., 7., 7., 7.]])perf_counter_diff(chain, draw)float640.0007441 0.001429 ... 0.001465array([[0.00074406, 0.00142912, 0.00146449, ..., 0.00177373, 0.0017067 ,\n        0.00075063],\n       [0.00145907, 0.0007567 , 0.00150751, ..., 0.00144749, 0.00143305,\n        0.00146469]])perf_counter_start(chain, draw)float642.877e+04 2.877e+04 ... 2.877e+04array([[28768.4524951 , 28768.45340557, 28768.45499683, ...,\n        28771.46269002, 28771.46474862, 28771.46664582],\n       [28768.37680723, 28768.37845389, 28768.37936989, ...,\n        28771.43566363, 28771.43727098, 28771.43887808]])process_time_diff(chain, draw)float640.0007453 0.00143 ... 0.001465array([[0.0007453 , 0.00143047, 0.00146615, ..., 0.00177358, 0.00170805,\n        0.00075126],\n       [0.00146063, 0.0007585 , 0.00147464, ..., 0.00144826, 0.00143367,\n        0.00146505]])reached_max_treedepth(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])smallest_eigval(chain, draw)float64nan nan nan nan ... nan nan nan nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]])step_size(chain, draw)float640.9536 0.9536 ... 0.7853 0.7853array([[0.95361789, 0.95361789, 0.95361789, ..., 0.95361789, 0.95361789,\n        0.95361789],\n       [0.78533542, 0.78533542, 0.78533542, ..., 0.78533542, 0.78533542,\n        0.78533542]])step_size_bar(chain, draw)float640.8253 0.8253 ... 0.8255 0.8255array([[0.82528119, 0.82528119, 0.82528119, ..., 0.82528119, 0.82528119,\n        0.82528119],\n       [0.82551435, 0.82551435, 0.82551435, ..., 0.82551435, 0.82551435,\n        0.82551435]])tree_depth(chain, draw)int642 3 3 2 2 3 2 2 ... 2 2 2 3 2 3 3 3array([[2, 3, 3, ..., 2, 3, 2],\n       [3, 2, 3, ..., 3, 3, 3]])Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999],\n      dtype='int64', name='draw', length=2000))Attributes: (8)created_at :2024-05-25T21:33:53.575429+00:00arviz_version :0.18.0inference_library :pymcinference_library_version :5.15.0+23.g19be124esampling_time :7.535887002944946tuning_steps :2000modeling_interface :bambimodeling_interface_version :0.13.1.dev37+g2a54df76.d20240525\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 10kB\nDimensions:  (__obs__: 604)\nCoordinates:\n  * __obs__  (__obs__) int64 5kB 0 1 2 3 4 5 6 7 ... 597 598 599 600 601 602 603\nData variables:\n    drugs    (__obs__) float64 5kB 1.857 3.071 1.571 2.214 ... 1.5 2.5 3.357\nAttributes:\n    created_at:                  2024-05-25T21:33:53.580244+00:00\n    arviz_version:               0.18.0\n    inference_library:           pymc\n    inference_library_version:   5.15.0+23.g19be124e\n    modeling_interface:          bambi\n    modeling_interface_version:  0.13.1.dev37+g2a54df76.d20240525xarray.DatasetDimensions:__obs__: 604Coordinates: (1)__obs__(__obs__)int640 1 2 3 4 5 ... 599 600 601 602 603array([  0,   1,   2, ..., 601, 602, 603])Data variables: (1)drugs(__obs__)float641.857 3.071 1.571 ... 1.5 2.5 3.357array([1.85714286, 3.07142857, 1.57142857, 2.21428571, 1.07142857,\n       1.42857143, 1.14285714, 2.14285714, 2.14285714, 1.07142857,\n       1.85714286, 2.5       , 1.85714286, 2.71428571, 1.42857143,\n       1.71428571, 1.71428571, 3.14285714, 2.71428571, 1.92857143,\n       2.71428571, 2.28571429, 2.35714286, 1.71428571, 2.        ,\n       2.92857143, 2.5       , 2.92857143, 2.64285714, 2.21428571,\n       2.78571429, 2.71428571, 3.07142857, 2.        , 3.        ,\n       1.92857143, 3.07142857, 2.57142857, 2.71428571, 3.07142857,\n       1.78571429, 1.78571429, 3.57142857, 2.28571429, 2.78571429,\n       2.14285714, 2.71428571, 2.71428571, 2.35714286, 2.28571429,\n       1.85714286, 2.57142857, 2.14285714, 3.07142857, 2.07142857,\n       3.5       , 1.71428571, 2.5       , 2.14285714, 1.14285714,\n       3.5       , 1.85714286, 3.28571429, 2.64285714, 2.        ,\n       1.85714286, 2.35714286, 2.21428571, 3.14285714, 2.64285714,\n       1.28571429, 1.64285714, 2.64285714, 2.07142857, 2.21428571,\n       3.07142857, 2.42857143, 3.21428571, 2.71428571, 2.07142857,\n       2.42857143, 2.07142857, 2.92857143, 3.42857143, 1.92857143,\n       2.57142857, 1.        , 2.42857143, 2.14285714, 1.71428571,\n       1.78571429, 3.35714286, 1.71428571, 1.85714286, 2.07142857,\n       2.71428571, 1.5       , 1.57142857, 1.14285714, 1.        ,\n...\n       1.35714286, 3.07142857, 1.42857143, 2.64285714, 1.35714286,\n       2.07142857, 3.        , 1.35714286, 1.85714286, 1.42857143,\n       1.78571429, 2.        , 2.42857143, 1.42857143, 2.        ,\n       3.07142857, 1.5       , 2.        , 2.42857143, 2.        ,\n       2.64285714, 3.92857143, 2.42857143, 2.        , 1.71428571,\n       1.42857143, 2.        , 1.78571429, 1.85714286, 2.78571429,\n       1.14285714, 1.42857143, 2.21428571, 2.07142857, 1.42857143,\n       1.85714286, 2.64285714, 3.5       , 2.        , 2.        ,\n       2.92857143, 1.71428571, 2.57142857, 2.28571429, 1.21428571,\n       2.64285714, 1.21428571, 1.92857143, 1.85714286, 1.5       ,\n       1.5       , 1.        , 1.85714286, 2.28571429, 2.28571429,\n       2.        , 2.85714286, 1.21428571, 2.14285714, 1.71428571,\n       1.42857143, 2.64285714, 1.64285714, 1.57142857, 1.64285714,\n       1.57142857, 1.07142857, 2.07142857, 1.42857143, 2.35714286,\n       2.42857143, 2.42857143, 2.28571429, 1.85714286, 1.42857143,\n       1.78571429, 1.64285714, 1.64285714, 1.07142857, 3.71428571,\n       3.07142857, 2.21428571, 2.14285714, 1.78571429, 2.        ,\n       2.14285714, 3.85714286, 1.64285714, 3.        , 2.64285714,\n       1.71428571, 2.78571429, 1.85714286, 3.14285714, 2.42857143,\n       1.57142857, 1.5       , 2.5       , 3.35714286])Indexes: (1)__obs__PandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       594, 595, 596, 597, 598, 599, 600, 601, 602, 603],\n      dtype='int64', name='__obs__', length=604))Attributes: (6)created_at :2024-05-25T21:33:53.580244+00:00arviz_version :0.18.0inference_library :pymcinference_library_version :5.15.0+23.g19be124emodeling_interface :bambimodeling_interface_version :0.13.1.dev37+g2a54df76.d20240525\n                      \n                  \n            \n            \n              \n            \n            \n\n\nOne use of the posterior predictive is as a diagnostic tool, shown below using az.plot_ppc().The blue lines represent the posterior predictive distribution estimates, and the black line represents the observed data. Our posterior predictions seems perform an adequately good job representing the observed data in all regions except near the value of 1, where the observed data and posterior estimates diverge.\n\naz.plot_ppc(fitted);\n\n\n\n\n\n\n\n\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sat May 25 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\nnumpy      : 1.26.4\narviz      : 0.18.0\nbambi      : 0.13.1.dev37+g2a54df76.d20240525\nmatplotlib : 3.8.4\npandas     : 2.2.2\nxarray     : 2024.5.0\nstatsmodels: 0.14.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Multiple linear regression"
    ]
  },
  {
    "objectID": "notebooks/Strack_RRR_re_analysis.html",
    "href": "notebooks/Strack_RRR_re_analysis.html",
    "title": "Bayesian Workflow (Strack RRR Analysis Replication)",
    "section": "",
    "text": "from glob import glob\nfrom os.path import basename\n\nimport arviz as az\nimport bambi as bmb\nimport numpy as np\nimport pandas as pd\naz.style.use(\"arviz-darkgrid\")\nIn this Jupyter notebook, we do a Bayesian reanalysis of the data reported in the recent registered replication report (RRR) of a famous study by Strack, Martin & Stepper (1988). The original Strack et al. study tested a facial feedback hypothesis arguing that emotional responses are, in part, driven by facial expressions (rather than expressions always following from emotions). Strack and colleagues reported that participants rated cartoons as more funny when the participants held a pen in their teeth (unknowingly inducing a smile) than when they held a pen between their lips (unknowingly inducing a pout). The article has been cited over 1,400 times, and has been enormously influential in popularizing the view that affective experiences and outward expressions of affective experiences can both influence each other (instead of the relationship being a one-way street from experience to expression). In 2016, a Registered Replication Report led by Wagenmakers and colleagues attempted to replicate Study 1 from Strack, Martin, & Stepper (1988) in 17 independent experiments comprising over 2,500 participants. The RRR reported no evidence in support of the effect.\nBecause the emphasis here is on fitting models in Bambi, we spend very little time on quality control and data exploration; our goal is simply to show how one can replicate and extend the primary analysis reported in the RRR in a few lines of Bambi code.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Bayesian Workflow (Strack RRR Analysis Replication)"
    ]
  },
  {
    "objectID": "notebooks/Strack_RRR_re_analysis.html#reading-in-the-data",
    "href": "notebooks/Strack_RRR_re_analysis.html#reading-in-the-data",
    "title": "Bayesian Workflow (Strack RRR Analysis Replication)",
    "section": "Reading in the data",
    "text": "Reading in the data\nThe data for the RRR of Strack, Martin, & Stepper (henceforth SMS) is available as a set of CSV files from the project’s repository on the Open Science Framework. For the sake of completeness, we’ll show how to go from the raw CSV to the “long” data format that Bambi can use.\nOne slightly annoying thing about these 17 CSV files–each of which represents a different replication site–is that they don’t all contain exactly the same columns. Some labs added a column or two at the end (mostly for notes). To keep things simple, we’ll just truncate each dataset to only the first 22 columns. Because the variable names are structured in a bit of a confusing way, we’ll also just drop the first two rows in each file, and manually set the column names for all 22 variables. Once we’ve done that, we can simply concatenate all of the 17 datasets along the row axis to create one big dataset.\n\nDL_PATH = 'data/facial_feedback/*csv'\n\ndfs = []\ncolumns = ['subject', 'cond_id', 'condition', 'correct_c1', 'correct_c2', 'correct_c3', 'correct_c4',\n           'correct_total', 'rating_t1', 'rating_t2', 'rating_c1', 'rating_c2', 'rating_c3',\n           'rating_c4', 'self_perf', 'comprehension', 'awareness', 'transcript', 'age', 'gender',\n           'student', 'occupation']\n\ncount = 0\nfor idx, study in enumerate(glob(DL_PATH)):\n    data = pd.read_csv(study, encoding='latin1', skiprows=2, header=None, index_col=False).iloc[:, :22]\n    data.columns = columns\n    # Add study name\n    data['study'] = idx\n    # Some sites used the same subject id numbering schemes, so prepend with study to create unique ids.\n    # Note that if we don't do this, Bambi would have no way of distinguishing two subjects who share\n    # the same id, which would hose our results.\n    data['uid'] = data['subject'].astype(float) + count\n    dfs.append(data)\ndata = pd.concat(dfs, axis=0).apply(pd.to_numeric,  errors='coerce', axis=1)\n\nLet’s see what the first few rows look like…\n\ndata.head()\n\n\n\n\n\n\n\n\nsubject\ncond_id\ncondition\ncorrect_c1\ncorrect_c2\ncorrect_c3\ncorrect_c4\ncorrect_total\nrating_t1\nrating_t2\n...\nself_perf\ncomprehension\nawareness\ntranscript\nage\ngender\nstudent\noccupation\nstudy\nuid\n\n\n\n\n0\n1.0\n1.0\n0.0\n1.0\n1.0\n1.0\n1.0\n4.0\n7.0\n2.0\n...\n5.0\n1.0\n0.0\nNaN\n22.0\n1.0\n1.0\nNaN\n0.0\n1.0\n\n\n1\n2.0\n2.0\n0.0\n1.0\n1.0\n1.0\n1.0\n4.0\n7.0\n6.0\n...\n5.0\n1.0\n0.0\nNaN\n20.0\n0.0\n1.0\nNaN\n0.0\n2.0\n\n\n2\n3.0\n3.0\n1.0\n1.0\n1.0\n1.0\n0.0\n3.0\n4.0\n7.0\n...\n4.0\n1.0\n0.0\nNaN\n20.0\n0.0\n1.0\nNaN\n0.0\n3.0\n\n\n3\n4.0\n4.0\n1.0\n1.0\n1.0\n1.0\n1.0\n4.0\n6.0\n3.0\n...\n2.0\n1.0\n0.0\nNaN\n20.0\n0.0\n1.0\nNaN\n0.0\n4.0\n\n\n4\n5.0\n5.0\n0.0\n1.0\n1.0\n1.0\n1.0\n4.0\n7.0\n6.0\n...\n5.0\n1.0\n0.0\nNaN\n20.0\n1.0\n1.0\nNaN\n0.0\n5.0\n\n\n\n\n5 rows × 24 columns",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Bayesian Workflow (Strack RRR Analysis Replication)"
    ]
  },
  {
    "objectID": "notebooks/Strack_RRR_re_analysis.html#reshaping-the-data",
    "href": "notebooks/Strack_RRR_re_analysis.html#reshaping-the-data",
    "title": "Bayesian Workflow (Strack RRR Analysis Replication)",
    "section": "Reshaping the data",
    "text": "Reshaping the data\nAt this point we have our data in a pandas DataFrame with shape of (2612, 24). Unfortunately, we can’t use the data in this form. We’ll need to (a) conduct some basic quality control, and (b) “melt” the dataset–currently in so-called “wide” format, with each subject in a separate row–into long format, where each row is a single trial. Fortunately, we can do this easily in pandas:\n\n# Keep only subjects who (i) respond appropriately on all trials,\n# (ii) understand the cartoons, and (iii) don't report any awareness\n# of the hypothesis or underlying theory.\nvalid = data.query('correct_total==4 and comprehension==1 and awareness==0')\nlong = pd.melt(valid, ['uid', 'condition', 'gender', 'age', 'study', 'self_perf'],\n               ['rating_c1', 'rating_c2', 'rating_c3', 'rating_c4'], var_name='stimulus')\n\n\nlong\n\n\n\n\n\n\n\n\nuid\ncondition\ngender\nage\nstudy\nself_perf\nstimulus\nvalue\n\n\n\n\n0\n1.0\n0.0\n1.0\n22.0\n0.0\n5.0\nrating_c1\n2.0\n\n\n1\n2.0\n0.0\n0.0\n20.0\n0.0\n5.0\nrating_c1\n1.0\n\n\n2\n4.0\n1.0\n0.0\n20.0\n0.0\n2.0\nrating_c1\n8.0\n\n\n3\n5.0\n0.0\n1.0\n20.0\n0.0\n5.0\nrating_c1\n6.0\n\n\n4\n7.0\n1.0\n1.0\n20.0\n0.0\n6.0\nrating_c1\n2.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n6935\n145.0\n0.0\n0.0\n20.0\n16.0\nNaN\nrating_c4\n3.0\n\n\n6936\n146.0\n1.0\n1.0\n19.0\n16.0\nNaN\nrating_c4\n5.0\n\n\n6937\n150.0\n1.0\n0.0\n20.0\n16.0\nNaN\nrating_c4\n8.0\n\n\n6938\n151.0\n0.0\n0.0\n20.0\n16.0\nNaN\nrating_c4\n1.0\n\n\n6939\n152.0\n1.0\n0.0\n21.0\n16.0\nNaN\nrating_c4\n6.0\n\n\n\n\n6940 rows × 8 columns\n\n\n\nNotice that in the melt() call above, we’re treating not only the unique subject ID (uid) as an identifying variable, but also gender, experimental condition, age, and study name. Since these are all between-subject variables, these columns are all completely redundant with uid, and adding them does nothing to change the structure of our data. The point of explicitly listing them is just to keep them around in the dataset, so that we can easily add them to our models.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Bayesian Workflow (Strack RRR Analysis Replication)"
    ]
  },
  {
    "objectID": "notebooks/Strack_RRR_re_analysis.html#fitting-the-model",
    "href": "notebooks/Strack_RRR_re_analysis.html#fitting-the-model",
    "title": "Bayesian Workflow (Strack RRR Analysis Replication)",
    "section": "Fitting the model",
    "text": "Fitting the model\nNow that we’re all done with our (minimal) preprocessing, it’s time to fit the model! This turns out to be a snap in Bambi. We’ll begin with a very naive (and, as we’ll see later, incorrect) model that includes only the following terms:\n\nAn overall (common) intercept.\nThe common effect of experimental condition (“smiling” by holding a pen in one’s teeth vs. “pouting” by holding a pen in one’s lips). This is the primary variable of interest in the study.\nA group specific intercept for each of the 1,728 subjects in the ‘long’ dataset. (There were 2,576 subjects in the original dataset, but about 25% were excluded for various reasons, and we’re further excluding all subjects who lack complete data. As an exercise, you can try relaxing some of these criteria and re-fitting the models, though you’ll probably find that it makes no meaningful difference to the results.)\n\nWe’ll create a Bambi model, fit it, and store the results in a new object–which we can then interrogate in various ways.\n\n# Initialize the model, passing in the dataset we want to use.\nmodel = bmb.Model(\"value ~ condition + (1|uid)\", long, dropna=True)\n\n# Set a custom prior on group specific factor variances—just for illustration\ngroup_specific_sd = bmb.Prior(\"HalfNormal\", sigma=10)\ngroup_specific_prior = bmb.Prior(\"Normal\", mu=0, sigma=group_specific_sd)\nmodel.set_priors(group_specific=group_specific_prior)\n\n# Fit the model, drawing 1,000 MCMC draws per chain\nresults = model.fit(draws=1000)\n\nAutomatically removing 9/6940 rows from the dataset.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, condition, 1|uid_sigma, 1|uid_offset]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 23 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n\n\nNotice that, in Bambi, the common and group specific effects are specified in the same formula. This is the same convention used by other similar packages like brms.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Bayesian Workflow (Strack RRR Analysis Replication)"
    ]
  },
  {
    "objectID": "notebooks/Strack_RRR_re_analysis.html#inspecting-results",
    "href": "notebooks/Strack_RRR_re_analysis.html#inspecting-results",
    "title": "Bayesian Workflow (Strack RRR Analysis Replication)",
    "section": "Inspecting results",
    "text": "Inspecting results\nWe can plot the prior distributions for all parameters with a call to the plot_priors() method.\n\nmodel.plot_priors();\n\nSampling: [1|uid_sigma, Intercept, condition, sigma]\n\n\n\n\n\n\n\n\n\nAnd we can easily get the posterior distributions with az.plot_trace(). We can select a subset of the parameters with the var_names arguments, like in the following cell. Or alternative by negating variables like var_names=\"~1|uid\".\n\naz.plot_trace(\n    results,\n    var_names=[\"Intercept\", \"condition\", \"sigma\", \"1|uid_sigma\"],\n    compact=False,\n);\n\n\n\n\n\n\n\n\nIf we want a numerical summary of the results, we just pass the results object to az.summary(). By default, summary shows the mean, standard deviation, and 94% highest density interval for the posterior. Summary also includes the Monte Carlo standard error, the effective sample size and the R-hat statistic.\n\naz.summary(results, var_names=['Intercept', 'condition', 'sigma', '1|uid_sigma'])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n4.563\n0.046\n4.476\n4.649\n0.001\n0.001\n1625.0\n1491.0\n1.0\n\n\ncondition\n-0.030\n0.059\n-0.138\n0.087\n0.001\n0.001\n2346.0\n1297.0\n1.0\n\n\nsigma\n2.401\n0.020\n2.365\n2.439\n0.000\n0.000\n2800.0\n1520.0\n1.0\n\n\n1|uid_sigma\n0.305\n0.045\n0.219\n0.389\n0.002\n0.001\n694.0\n1123.0\n1.0",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Bayesian Workflow (Strack RRR Analysis Replication)"
    ]
  },
  {
    "objectID": "notebooks/Strack_RRR_re_analysis.html#expanding-the-model",
    "href": "notebooks/Strack_RRR_re_analysis.html#expanding-the-model",
    "title": "Bayesian Workflow (Strack RRR Analysis Replication)",
    "section": "Expanding the model",
    "text": "Expanding the model\nLooking at the parameter estimates produced by our model, it seems pretty clear that there’s no meaningful effect of condition. The posterior distribution is centered almost exactly on 0, with most of the probability mass on very small values. The 94% HDI spans from \\(\\approx -0.14\\) to \\(\\approx 0.08\\)–in other words, the plausible effect of the experimental manipulation is, at best, to produce a change of &lt; 0.2 on cartoon ratings made on a 10-point scale. For perspective, the variation between subjects is enormous in comparison–the standard deviation for group specific effects 1|uid_sigma is around 0.3. We can also see that the model is behaving well, and the sampler seems to have converged nicely (the traces for all parameters look stationary).\nUnfortunately, our first model has at least two pretty serious problems. First, it gives no consideration to between-study variation–we’re simply lumping all 1,728 subjects together, as if they came from the same study. A better model would properly account for study-level variation. We could model study as either a common or a group specific factor in this case–both choices are defensible, depending on whether we want to think of the 17 studies in this dataset as the only sites of interest, or as if they’re just 17 random sites drawn from some much larger population that have particular characteristics we want to account for.\nFor present purposes, we’ll adopt the latter strategy (as an exercise, you can modify the the code below and re-run the model with study as a common factor). We’ll “keep it maximal” by adding both group specific study intercepts and group specific study slopes to the model. That is, we’ll assume that the subjects at each research site have a different baseline appreciation of the cartoons (some find the cartoons funnier than others), and that the effect of condition also varies across sites.\nSecond, our model also fails to explicitly model variation in cartoon ratings that should properly be attributed to the 4 stimuli. In principle, our estimate of the common effect of condition could change somewhat once we correctly account for stimulus variability (though in practice, the net effect is almost always to reduce effects, not increase them–so in this case, it’s very unlikely that adding group specific stimulus effects will produce a meaningful effect of condition). So we’ll deal with this by adding specific intercepts for the 4 stimuli. We’ll model the stimuli as group specific effect, rather than common, because it wouldn’t make sense to think of these particular cartoons as exhausting the universe of stimuli we care about (i.e., we wouldn’t really care about the facial-feedback effect if we knew that it only applied to 4 specific Far Side cartoons, and no other stimuli).\nLastly, just for fun, we can throw in some additional covariates, since they’re readily available in the dataset, and may be of interest even if they don’t directly inform the core hypothesis. Specifically, we’ll add common effects of gender and age to the model, which will let us estimate the degree to which participants’ ratings of the cartoons varies as a function of these background variables.\nOnce we’ve done all that, we end up with a model that’s in a good position to answer the question we care about–namely, whether the smiling/pouting manipulation has an effect on cartoon ratings that generalizes across the subjects, studies, and stimuli found in the RRR dataset.\n\nmodel = bmb.Model(\n    \"value ~ condition + age + gender + (1|uid) + (condition|study) + (condition|stimulus)\",\n    long,\n    dropna=True,\n)\n\ngroup_specific_sd = bmb.Prior(\"HalfNormal\", sigma=10)\ngroup_specific_prior = bmb.Prior(\"Normal\", mu=0, sigma=group_specific_sd)\nmodel.set_priors(group_specific=group_specific_prior)\n\n# Not we use 2000 samples for tuning and increase the taget_accept to 0.99.\n# The default values result in divergences.\nresults = model.fit(draws=1000, tune=2000, target_accept=0.99)\n\nAutomatically removing 33/6940 rows from the dataset.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, condition, age, gender, 1|uid_sigma, 1|uid_offset, 1|study_sigma, 1|study_offset, condition|study_sigma, condition|study_offset, 1|stimulus_sigma, 1|stimulus_offset, condition|stimulus_sigma, condition|stimulus_offset]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 2_000 tune and 1_000 draw iterations (4_000 + 2_000 draws total) took 1575 seconds.\nThere were 2 divergences after tuning. Increase `target_accept` or reparameterize.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n\n\n\naz.plot_trace(\n    results, \n    var_names=[\n        'Intercept', 'age', 'gender', 'condition', 'sigma', \n        '1|study', '1|stimulus', 'condition|study', 'condition|stimulus',\n        '1|study_sigma', '1|stimulus_sigma', 'condition|study_sigma', \n    ],\n    compact=True\n);",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Bayesian Workflow (Strack RRR Analysis Replication)"
    ]
  },
  {
    "objectID": "notebooks/Strack_RRR_re_analysis.html#and-the-answer-is",
    "href": "notebooks/Strack_RRR_re_analysis.html#and-the-answer-is",
    "title": "Bayesian Workflow (Strack RRR Analysis Replication)",
    "section": "And the answer is…",
    "text": "And the answer is…\nNo. There’s still no discernible effect. Modeling the data using a mixed-effects model does highlight a number of other interesting features, however: * The stimulus-level standard deviation 1|stimulus_sigma is quite large compared to the other factors. This is potentially problematic, because it suggests that a more conventional analysis that left individual stimulus effects out of the model could potentially run a high false positive rate. Note that this is a problem that affects both the RRR and the original Strack study equally; the moral of the story is to deliberately sample large numbers of stimuli and explicitly model their influence. * Older people seem to rate cartoons as being (a little bit) funnier. * The variation across sites is surprisingly small–in terms of both the group specific intercepts (1|study) and the group specific slopes (condition|study). In other words, the constitution of the sample, the gender of the experimenter, or any of the hundreds of others of between-site differences that one might conceivably have expected to matter, don’t really seem to make much of a difference to participants’ ratings of the cartoons.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sun May 26 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\narviz : 0.18.0\npandas: 2.2.2\nnumpy : 1.26.4\nbambi : 0.13.1.dev39+gb7d6a6cb\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Bayesian Workflow (Strack RRR Analysis Replication)"
    ]
  },
  {
    "objectID": "notebooks/alternative_samplers.html",
    "href": "notebooks/alternative_samplers.html",
    "title": "Alternative sampling backends",
    "section": "",
    "text": "In Bambi, the sampler used is automatically selected given the type of variables used in the model. For inference, Bambi supports both MCMC and variational inference. By default, Bambi uses PyMC’s implementation of the adaptive Hamiltonian Monte Carlo (HMC) algorithm for sampling. Also known as the No-U-Turn Sampler (NUTS). This sampler is a good choice for many models. However, it is not the only sampling method, nor is PyMC the only library implementing NUTS.\nTo this extent, Bambi supports multiple backends for MCMC sampling such as NumPyro and Blackjax. This notebook will cover how to use such alternatives in Bambi.\nNote: Bambi utilizes bayeux to access a variety of sampling backends. Thus, you will need to install the optional dependencies in the Bambi pyproject.toml file to use these backends.\nimport arviz as az\nimport bambi as bmb\nimport numpy as np\nimport pandas as pd",
    "crumbs": [
      "Examples",
      "Alternative sampling backends",
      "Alternative sampling backends"
    ]
  },
  {
    "objectID": "notebooks/alternative_samplers.html#bayeux",
    "href": "notebooks/alternative_samplers.html#bayeux",
    "title": "Alternative sampling backends",
    "section": "Bayeux",
    "text": "Bayeux\nBambi leverages bayeux to access different sampling backends. In short, bayeux lets you write a probabilistic model in JAX and immediately have access to state-of-the-art inference methods.\nSince the underlying Bambi model is a PyMC model, this PyMC model can be “given” to bayeux. Then, we can choose from a variety of MCMC methods to perform inference.\nTo demonstrate the available backends, we will fist simulate data and build a model.\n\nnum_samples = 100\nnum_features = 1\nnoise_std = 1.0\nrandom_seed = 42\n\nrng = np.random.default_rng(random_seed)\n\ncoefficients = rng.normal(size=num_features)\nX = rng.normal(size=(num_samples, num_features))\nerror = rng.normal(scale=noise_std, size=num_samples)\ny = X @ coefficients + error\n\ndata = pd.DataFrame({\"y\": y, \"x\": X.flatten()})\n\n\nmodel = bmb.Model(\"y ~ x\", data)\nmodel.build()\n\nWe can call bmb.inference_methods.names that returns a nested dictionary of the backends and list of inference methods.\n\nmethods = bmb.inference_methods.names\nmethods\n\n{'pymc': {'mcmc': ['mcmc'], 'vi': ['vi']},\n 'bayeux': {'mcmc': ['tfp_hmc',\n   'tfp_nuts',\n   'tfp_snaper_hmc',\n   'blackjax_hmc',\n   'blackjax_chees_hmc',\n   'blackjax_meads_hmc',\n   'blackjax_nuts',\n   'blackjax_hmc_pathfinder',\n   'blackjax_nuts_pathfinder',\n   'flowmc_rqspline_hmc',\n   'flowmc_rqspline_mala',\n   'flowmc_realnvp_hmc',\n   'flowmc_realnvp_mala',\n   'numpyro_hmc',\n   'numpyro_nuts',\n   'nutpie']}}\n\n\nWith the PyMC backend, we have access to their implementation of the NUTS sampler and mean-field variational inference.\n\nmethods[\"pymc\"]\n\n{'mcmc': ['mcmc'], 'vi': ['vi']}\n\n\nbayeux lets us have access to Tensorflow probability, Blackjax, FlowMC, and NumPyro backends.\n\nmethods[\"bayeux\"]\n\n{'mcmc': ['tfp_hmc',\n  'tfp_nuts',\n  'tfp_snaper_hmc',\n  'blackjax_hmc',\n  'blackjax_chees_hmc',\n  'blackjax_meads_hmc',\n  'blackjax_nuts',\n  'blackjax_hmc_pathfinder',\n  'blackjax_nuts_pathfinder',\n  'flowmc_rqspline_hmc',\n  'flowmc_rqspline_mala',\n  'flowmc_realnvp_hmc',\n  'flowmc_realnvp_mala',\n  'numpyro_hmc',\n  'numpyro_nuts',\n  'nutpie']}\n\n\nThe values of the MCMC and VI keys in the dictionary are the names of the argument you would pass to inference_method in model.fit. This is shown in the section below.",
    "crumbs": [
      "Examples",
      "Alternative sampling backends",
      "Alternative sampling backends"
    ]
  },
  {
    "objectID": "notebooks/alternative_samplers.html#specifying-an-inference_method",
    "href": "notebooks/alternative_samplers.html#specifying-an-inference_method",
    "title": "Alternative sampling backends",
    "section": "Specifying an inference_method",
    "text": "Specifying an inference_method\nBy default, Bambi uses the PyMC NUTS implementation. To use a different backend, pass the name of the bayeux MCMC method to the inference_method parameter of the fit method.\n\nBlackjax\n\nblackjax_nuts_idata = model.fit(inference_method=\"blackjax_nuts\")\nblackjax_nuts_idata\n\nWARNING:2024-12-21 13:43:24,702:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 100kB\nDimensions:    (chain: 8, draw: 500)\nCoordinates:\n  * draw       (draw) int64 4kB 0 1 2 3 4 5 6 7 ... 493 494 495 496 497 498 499\n  * chain      (chain) int64 64B 0 1 2 3 4 5 6 7\nData variables:\n    Intercept  (chain, draw) float64 32kB -0.02658 0.09092 ... 0.06874 0.01924\n    sigma      (chain, draw) float64 32kB 1.083 0.9101 0.9074 ... 0.9316 1.088\n    x          (chain, draw) float64 32kB 0.2574 0.5978 0.2478 ... 0.5018 0.6094\nAttributes:\n    created_at:                  2024-12-21T16:43:32.789194+00:00\n    arviz_version:               0.19.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:chain: 8draw: 500Coordinates: (2)draw(draw)int640 1 2 3 4 5 ... 495 496 497 498 499array([  0,   1,   2, ..., 497, 498, 499])chain(chain)int640 1 2 3 4 5 6 7array([0, 1, 2, 3, 4, 5, 6, 7])Data variables: (3)Intercept(chain, draw)float64-0.02658 0.09092 ... 0.01924array([[-0.02658111,  0.09092311,  0.11795115, ..., -0.06640127,\n        -0.07304943, -0.07304943],\n       [ 0.01155273,  0.05560022,  0.05645374, ..., -0.11902965,\n         0.15598449,  0.05305681],\n       [ 0.01325056, -0.09258721, -0.12564707, ..., -0.1270452 ,\n         0.0226572 , -0.13311911],\n       ...,\n       [ 0.00654733,  0.1162016 ,  0.1162016 , ...,  0.17542573,\n        -0.10504741,  0.13413861],\n       [-0.07104718, -0.08145941,  0.09747892, ..., -0.11062677,\n        -0.14297176, -0.13000677],\n       [ 0.0647134 , -0.02805274, -0.05086112, ...,  0.06960474,\n         0.06874382,  0.01924388]])sigma(chain, draw)float641.083 0.9101 ... 0.9316 1.088array([[1.08286755, 0.91009683, 0.90740154, ..., 1.04084804, 0.9122751 ,\n        0.9122751 ],\n       [0.94534918, 1.13671854, 0.96041739, ..., 0.87811556, 1.09079128,\n        0.94423378],\n       [0.90816757, 1.04812487, 1.06399674, ..., 1.03973046, 1.01010142,\n        0.87700991],\n       ...,\n       [1.12654384, 0.86851728, 0.86851728, ..., 1.07861895, 0.92485308,\n        1.00014413],\n       [0.91526758, 0.89551954, 1.04980028, ..., 0.94360289, 0.95889818,\n        1.007102  ],\n       [0.96186467, 1.02626141, 0.99183226, ..., 0.97610033, 0.93160127,\n        1.08782709]])x(chain, draw)float640.2574 0.5978 ... 0.5018 0.6094array([[0.25738559, 0.59783036, 0.24779006, ..., 0.25177696, 0.4307542 ,\n        0.4307542 ],\n       [0.65370905, 0.40586643, 0.41765398, ..., 0.55844874, 0.4797765 ,\n        0.40513045],\n       [0.56860133, 0.36653944, 0.36446413, ..., 0.19247187, 0.48895635,\n        0.52891685],\n       ...,\n       [0.26910199, 0.5794493 , 0.5794493 , ..., 0.0794695 , 0.57235876,\n        0.25527193],\n       [0.36526813, 0.45110655, 0.46746077, ..., 0.28122244, 0.39524775,\n        0.4660637 ],\n       [0.6341404 , 0.34837756, 0.56736688, ..., 0.3739496 , 0.501771  ,\n        0.60940309]])Indexes: (2)drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       490, 491, 492, 493, 494, 495, 496, 497, 498, 499],\n      dtype='int64', name='draw', length=500))chainPandasIndexPandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7], dtype='int64', name='chain'))Attributes: (4)created_at :2024-12-21T16:43:32.789194+00:00arviz_version :0.19.0modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7\n                      \n                  \n            \n            \n            \n                  \n                  sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 200kB\nDimensions:          (chain: 8, draw: 500)\nCoordinates:\n  * chain            (chain) int64 64B 0 1 2 3 4 5 6 7\n  * draw             (draw) int64 4kB 0 1 2 3 4 5 6 ... 494 495 496 497 498 499\nData variables:\n    acceptance_rate  (chain, draw) float64 32kB 1.0 0.9701 ... 0.9816 0.8413\n    diverging        (chain, draw) bool 4kB False False False ... False False\n    energy           (chain, draw) float64 32kB 146.2 146.9 ... 144.5 146.6\n    lp               (chain, draw) float64 32kB -145.5 -145.6 ... -144.3 -145.8\n    n_steps          (chain, draw) int64 32kB 7 7 7 1 7 1 7 3 ... 3 23 1 3 3 7 7\n    step_size        (chain, draw) float64 32kB 0.6587 0.6587 ... 0.8076 0.8076\n    tree_depth       (chain, draw) int64 32kB 3 3 3 1 3 1 3 2 ... 2 5 1 2 2 3 3\nAttributes:\n    created_at:                  2024-12-21T16:43:32.791248+00:00\n    arviz_version:               0.19.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:chain: 8draw: 500Coordinates: (2)chain(chain)int640 1 2 3 4 5 6 7array([0, 1, 2, 3, 4, 5, 6, 7])draw(draw)int640 1 2 3 4 5 ... 495 496 497 498 499array([  0,   1,   2, ..., 497, 498, 499])Data variables: (7)acceptance_rate(chain, draw)float641.0 0.9701 0.9571 ... 0.9816 0.8413array([[1.        , 0.97006468, 0.95707146, ..., 0.97826123, 0.99044162,\n        0.74222495],\n       [0.95762025, 0.93924226, 0.96338533, ..., 0.73056644, 0.99394205,\n        0.86765568],\n       [0.98994354, 0.96667462, 0.92877089, ..., 0.82934201, 1.        ,\n        0.80614085],\n       ...,\n       [1.        , 0.95773634, 0.62150145, ..., 0.69859751, 0.96819032,\n        1.        ],\n       [0.98803911, 0.97905407, 0.99832213, ..., 0.99941531, 1.        ,\n        1.        ],\n       [0.95319494, 0.98840345, 0.84058548, ..., 0.90845327, 0.9815987 ,\n        0.84128627]])diverging(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       ...,\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])energy(chain, draw)float64146.2 146.9 147.6 ... 144.5 146.6array([[146.20853009, 146.92917848, 147.6360811 , ..., 145.24207867,\n        145.87623618, 147.13081329],\n       [145.59278885, 147.44713994, 146.86936261, ..., 147.43697811,\n        148.16186623, 148.16903208],\n       [145.35673415, 145.6494305 , 145.31892996, ..., 146.61776123,\n        146.06678407, 146.9496078 ],\n       ...,\n       [147.87081823, 148.37233119, 148.61259875, ..., 151.36525088,\n        148.99423831, 146.71758754],\n       [144.87253755, 145.2217807 , 145.34049789, ..., 146.79512891,\n        145.82846494, 145.50485403],\n       [149.3085002 , 145.7621817 , 146.20656758, ..., 147.12749679,\n        144.52686547, 146.60129266]])lp(chain, draw)float64-145.5 -145.6 ... -144.3 -145.8array([[-145.54158492, -145.58663675, -146.23973644, ..., -145.14591989,\n        -144.45271634, -144.45271634],\n       [-145.53580082, -146.08481967, -143.86213268, ..., -146.57279016,\n        -145.98872165, -143.92837743],\n       [-144.91890886, -144.74108265, -145.28654516, ..., -146.26457691,\n        -143.98828585, -146.55042464],\n       ...,\n       [-146.2949621 , -146.70927775, -146.70927775, ..., -149.36892616,\n        -145.50706965, -145.61839596],\n       [-144.47776232, -144.87493115, -144.7184633 , ..., -145.0868909 ,\n        -144.87527493, -144.79194767],\n       [-145.26549283, -144.19282923, -144.56709736, ..., -144.02660067,\n        -144.29201224, -145.78638496]])n_steps(chain, draw)int647 7 7 1 7 1 7 3 ... 3 23 1 3 3 7 7array([[ 7,  7,  7, ...,  3,  7,  3],\n       [ 3,  7,  3, ...,  3,  7,  3],\n       [15,  3,  1, ...,  3,  3,  3],\n       ...,\n       [ 7,  7,  1, ...,  7,  5,  7],\n       [ 7,  3,  7, ...,  7,  7,  7],\n       [ 3,  3,  3, ...,  3,  7,  7]])step_size(chain, draw)float640.6587 0.6587 ... 0.8076 0.8076array([[0.65866895, 0.65866895, 0.65866895, ..., 0.65866895, 0.65866895,\n        0.65866895],\n       [0.81360467, 0.81360467, 0.81360467, ..., 0.81360467, 0.81360467,\n        0.81360467],\n       [0.92484756, 0.92484756, 0.92484756, ..., 0.92484756, 0.92484756,\n        0.92484756],\n       ...,\n       [0.78804737, 0.78804737, 0.78804737, ..., 0.78804737, 0.78804737,\n        0.78804737],\n       [0.66485663, 0.66485663, 0.66485663, ..., 0.66485663, 0.66485663,\n        0.66485663],\n       [0.80764974, 0.80764974, 0.80764974, ..., 0.80764974, 0.80764974,\n        0.80764974]])tree_depth(chain, draw)int643 3 3 1 3 1 3 2 ... 2 2 5 1 2 2 3 3array([[3, 3, 3, ..., 2, 3, 2],\n       [2, 3, 2, ..., 2, 3, 2],\n       [4, 2, 1, ..., 2, 2, 2],\n       ...,\n       [3, 3, 1, ..., 3, 3, 3],\n       [3, 2, 3, ..., 3, 3, 3],\n       [2, 2, 2, ..., 2, 3, 3]])Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       490, 491, 492, 493, 494, 495, 496, 497, 498, 499],\n      dtype='int64', name='draw', length=500))Attributes: (4)created_at :2024-12-21T16:43:32.791248+00:00arviz_version :0.19.0modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 2kB\nDimensions:  (__obs__: 100)\nCoordinates:\n  * __obs__  (__obs__) int64 800B 0 1 2 3 4 5 6 7 8 ... 92 93 94 95 96 97 98 99\nData variables:\n    y        (__obs__) float64 800B 0.9823 -0.1276 1.024 ... -0.4394 0.2223\nAttributes:\n    created_at:                  2024-12-21T16:43:32.789194+00:00\n    arviz_version:               0.19.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:__obs__: 100Coordinates: (1)__obs__(__obs__)int640 1 2 3 4 5 6 ... 94 95 96 97 98 99array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])Data variables: (1)y(__obs__)float640.9823 -0.1276 ... -0.4394 0.2223array([ 0.98232738, -0.12758867,  1.0241217 , -1.52813143, -0.60223389,\n       -0.9110669 , -0.4353976 ,  0.83518854, -1.98725748,  0.70239123,\n        0.47474209, -0.57402927, -1.10256821,  0.21458759, -0.7913338 ,\n        0.34504087, -0.27033576,  1.8694577 , -0.25456891, -1.07982821,\n       -0.02821523,  0.59252591,  1.3120998 ,  0.70459244,  0.24956995,\n        1.62550659, -1.07740601, -0.51398486, -0.79529742,  0.2627868 ,\n       -1.50052774,  0.47906184, -0.47019315, -1.28310684, -0.67156194,\n        0.27879211,  0.58211654,  1.74549738,  3.1121092 ,  0.64089167,\n       -0.82402974, -2.33483846,  0.33845498, -0.77738494, -0.34871911,\n       -0.34655757, -0.0726575 ,  1.27285679,  0.17764106, -0.07053522,\n       -0.84328945, -2.11870321, -0.58371719, -0.19711313,  1.57325292,\n        0.04643398,  1.43827366, -0.76312913, -0.88989281, -1.47791592,\n       -0.82727125,  2.17806337, -0.64275472,  1.05521209, -0.66118073,\n        0.82531053,  0.24406448,  0.10480201, -0.09905622, -1.04351111,\n        0.10074023, -0.7351563 , -1.07411239, -1.23453802,  0.3829906 ,\n        1.44890008,  0.20830137,  0.07198975,  0.19156297,  1.44518896,\n        0.01768236, -0.52155594,  0.98996665,  0.06436367,  1.68414482,\n        0.04019953, -1.22066186, -1.22166748,  1.78699361,  1.92641993,\n       -0.20952942, -0.51217355,  1.43715279, -1.6212053 , -1.33568691,\n        0.24027763, -0.69848326,  0.11669617, -0.43935783,  0.22234196])Indexes: (1)__obs__PandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n       90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n      dtype='int64', name='__obs__'))Attributes: (4)created_at :2024-12-21T16:43:32.789194+00:00arviz_version :0.19.0modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7\n                      \n                  \n            \n            \n              \n            \n            \n\n\nDifferent backends have different naming conventions for the parameters specific to that MCMC method. Thus, to specify backend-specific parameters, pass your own kwargs to the fit method.\nThe following can be performend to identify the kwargs specific to each method.\n\nbmb.inference_methods.get_kwargs(\"blackjax_nuts\")\n\n{&lt;function blackjax.adaptation.window_adaptation.window_adaptation(algorithm, logdensity_fn: Callable, is_mass_matrix_diagonal: bool = True, initial_step_size: float = 1.0, target_acceptance_rate: float = 0.8, progress_bar: bool = False, adaptation_info_fn: Callable = &lt;function return_all_adapt_info at 0x7f164c18d120&gt;, integrator=&lt;function generate_euclidean_integrator.&lt;locals&gt;.euclidean_integrator at 0x7f164c15c680&gt;, **extra_parameters) -&gt; blackjax.base.AdaptationAlgorithm&gt;: {'logdensity_fn': &lt;function bayeux._src.shared.constrain.&lt;locals&gt;.wrap_log_density.&lt;locals&gt;.wrapped(args)&gt;,\n  'is_mass_matrix_diagonal': True,\n  'initial_step_size': 1.0,\n  'target_acceptance_rate': 0.8,\n  'progress_bar': False,\n  'adaptation_info_fn': &lt;function blackjax.adaptation.base.return_all_adapt_info(state, info, adaptation_state)&gt;,\n  'algorithm': GenerateSamplingAPI(differentiable=&lt;function as_top_level_api at 0x7f164c16a7a0&gt;, init=&lt;function init at 0x7f164c133380&gt;, build_kernel=&lt;function build_kernel at 0x7f164c169e40&gt;)},\n 'adapt.run': {'num_steps': 500},\n &lt;function blackjax.mcmc.nuts.as_top_level_api(logdensity_fn: Callable, step_size: float, inverse_mass_matrix: Union[blackjax.mcmc.metrics.Metric, jax.Array, Callable[[Union[jax.Array, numpy.ndarray, numpy.bool_, numpy.number, bool, int, float, complex, Iterable[ForwardRef('ArrayLikeTree')], Mapping[Any, ForwardRef('ArrayLikeTree')]]], jax.Array]], *, max_num_doublings: int = 10, divergence_threshold: int = 1000, integrator: Callable = &lt;function generate_euclidean_integrator.&lt;locals&gt;.euclidean_integrator at 0x7f164c15c680&gt;) -&gt; blackjax.base.SamplingAlgorithm&gt;: {'max_num_doublings': 10,\n  'divergence_threshold': 1000,\n  'integrator': &lt;function blackjax.mcmc.integrators.generate_euclidean_integrator.&lt;locals&gt;.euclidean_integrator(logdensity_fn: Callable, kinetic_energy_fn: blackjax.mcmc.metrics.KineticEnergy) -&gt; Callable[[blackjax.mcmc.integrators.IntegratorState, float], blackjax.mcmc.integrators.IntegratorState]&gt;,\n  'logdensity_fn': &lt;function bayeux._src.shared.constrain.&lt;locals&gt;.wrap_log_density.&lt;locals&gt;.wrapped(args)&gt;,\n  'step_size': 0.5},\n 'extra_parameters': {'chain_method': 'vectorized',\n  'num_chains': 8,\n  'num_draws': 500,\n  'num_adapt_draws': 500,\n  'return_pytree': False}}\n\n\nNow, we can identify the kwargs we would like to change and pass to the fit method.\n\nkwargs = {\n    \"adapt.run\": {\"num_steps\": 500},\n    \"num_chains\": 4,\n    \"num_draws\": 250,\n    \"num_adapt_draws\": 250,\n}\n\nblackjax_nuts_idata = model.fit(inference_method=\"blackjax_nuts\", **kwargs)\nblackjax_nuts_idata\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 26kB\nDimensions:    (chain: 4, draw: 250)\nCoordinates:\n  * draw       (draw) int64 2kB 0 1 2 3 4 5 6 7 ... 243 244 245 246 247 248 249\n  * chain      (chain) int64 32B 0 1 2 3\nData variables:\n    Intercept  (chain, draw) float64 8kB -0.1701 0.1002 ... 0.09008 -0.07872\n    sigma      (chain, draw) float64 8kB 1.024 0.9962 0.9826 ... 0.9153 1.042\n    x          (chain, draw) float64 8kB 0.468 0.5335 0.4088 ... 0.5823 0.2556\nAttributes:\n    created_at:                  2024-12-21T16:43:38.392870+00:00\n    arviz_version:               0.19.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:chain: 4draw: 250Coordinates: (2)draw(draw)int640 1 2 3 4 5 ... 245 246 247 248 249array([  0,   1,   2, ..., 247, 248, 249])chain(chain)int640 1 2 3array([0, 1, 2, 3])Data variables: (3)Intercept(chain, draw)float64-0.1701 0.1002 ... 0.09008 -0.07872array([[-1.70069061e-01,  1.00151717e-01, -9.48571933e-03,\n        -5.66264519e-02, -7.66510611e-03,  5.39426100e-02,\n        -1.09270112e-02,  6.56760967e-02, -1.34513509e-01,\n         4.93264686e-02, -9.91200889e-03, -2.24930661e-02,\n        -2.30427571e-02,  8.76013277e-02,  1.42677165e-01,\n        -2.08639782e-02,  1.04208094e-01, -4.39398906e-02,\n        -1.07140992e-01,  3.19942450e-02,  6.86301614e-02,\n         2.51698739e-01, -9.42185626e-02, -6.04145532e-02,\n         6.97358772e-02,  1.10177123e-01, -2.32385340e-02,\n         2.21802887e-02, -7.76058326e-03,  3.92096624e-02,\n        -6.87456028e-02,  8.80249035e-02,  8.73124503e-02,\n        -1.41811769e-02, -1.10359746e-01,  1.44491167e-01,\n         1.96460999e-01,  1.33850437e-02, -3.27182929e-02,\n         5.62014630e-02, -1.10907295e-01,  1.21171584e-01,\n         1.36654035e-01, -6.21069028e-02, -5.59068694e-02,\n        -1.63455765e-01,  1.68612503e-01, -2.16739685e-01,\n        -2.00362815e-02, -4.02794947e-02, -4.84263601e-02,\n         1.60954315e-01, -1.55422612e-02, -1.99040695e-01,\n        -1.30941126e-01, -5.41326918e-04, -1.30929429e-02,\n         3.84735942e-02,  5.94728562e-02, -6.48670121e-02,\n...\n        -5.41033762e-02,  1.36199040e-02,  6.18837870e-02,\n         1.49949824e-01, -1.67486676e-01, -1.70986979e-01,\n         4.16211973e-02, -1.21679214e-01,  8.47262737e-02,\n        -1.02449823e-01, -7.48811099e-02, -1.31527361e-01,\n         7.37864764e-02, -5.26510000e-02, -6.78089625e-02,\n         5.36730538e-02, -5.18914219e-03, -6.60723995e-02,\n         1.91736086e-01,  1.53911781e-01, -2.55052091e-01,\n        -3.98374120e-02,  5.85495651e-02, -7.49019017e-02,\n         2.27165332e-02,  3.03672899e-02, -1.56537015e-02,\n         7.56850084e-02,  4.75837954e-03, -6.83049512e-02,\n        -2.85313144e-02, -1.64067667e-01, -2.08476638e-01,\n        -2.26712429e-01,  2.04192317e-01,  1.82469636e-01,\n        -8.81434188e-02, -8.02606217e-02, -5.01482267e-02,\n         2.90771939e-02, -4.98103239e-02, -9.61837158e-02,\n        -2.98989363e-02, -6.24376661e-03, -4.07107749e-02,\n        -3.90179504e-03, -1.02480442e-01, -8.74778894e-02,\n        -3.71899115e-03,  1.60236331e-01,  5.96701113e-02,\n        -1.54265715e-01,  1.21419988e-01,  1.04888537e-01,\n         7.00015952e-02, -1.30581971e-01,  9.00761635e-02,\n        -7.87242665e-02]])sigma(chain, draw)float641.024 0.9962 ... 0.9153 1.042array([[1.02399554, 0.99618345, 0.98263019, 0.99740166, 0.9624323 ,\n        0.99195017, 0.90995056, 1.12153711, 0.96724986, 0.92496777,\n        0.89158961, 1.0234767 , 0.97485344, 0.94890488, 0.94470273,\n        1.07659094, 1.0459875 , 0.96642688, 0.98858994, 0.98950078,\n        0.99893284, 1.03758011, 1.12455104, 1.12560157, 0.89151676,\n        0.85577524, 1.12327744, 0.89833972, 1.10025857, 0.91364742,\n        1.05514578, 1.07917937, 1.13084916, 1.15463615, 0.92235556,\n        1.03771077, 1.09613145, 0.9748313 , 0.99577541, 0.95290407,\n        1.01991248, 0.98370166, 0.86606544, 1.09522386, 1.07838295,\n        1.0400244 , 0.95386411, 1.01687705, 1.06060157, 1.00644701,\n        0.89890209, 0.89654922, 0.96861677, 0.94053149, 1.00249698,\n        0.88857924, 0.8355495 , 1.16944166, 1.15127614, 0.9492957 ,\n        0.94470807, 0.89529218, 0.85104904, 0.82031253, 0.82573236,\n        1.0721279 , 1.08112977, 1.02147852, 1.02240714, 0.8839768 ,\n        0.8839768 , 0.92113385, 0.96852991, 1.05534858, 0.98716332,\n        1.0632634 , 0.94571803, 1.02629484, 1.09395491, 0.94150007,\n        0.899342  , 1.07483519, 0.94423974, 1.03590878, 0.95174486,\n        0.88754929, 1.04345059, 0.96778658, 0.96002373, 0.93763471,\n        1.04903538, 1.05152944, 1.06395446, 0.97025949, 0.96482176,\n        0.98567836, 0.97371753, 0.95944523, 1.0216735 , 1.00287471,\n...\n        0.95897003, 0.9680127 , 1.02185514, 1.07143328, 0.99661839,\n        0.99715746, 0.8981794 , 1.09983336, 0.90285392, 1.09519883,\n        1.03580205, 0.94549069, 0.93962845, 0.95641947, 0.90504108,\n        0.93842995, 0.95207231, 0.95612619, 0.9902147 , 0.98172805,\n        1.06561426, 0.96642849, 1.09698447, 0.93227248, 0.96928407,\n        1.00240463, 0.92921373, 0.95040303, 1.03173147, 0.93158648,\n        1.14204583, 0.88253619, 0.93251834, 1.0283527 , 0.93452874,\n        0.97159728, 0.94509273, 0.97599144, 0.96810784, 1.02546515,\n        1.00607533, 0.89456675, 0.86131561, 0.96695929, 1.06079086,\n        0.90904656, 1.07446648, 1.0394921 , 0.96964756, 0.90374939,\n        0.90679797, 1.05227513, 0.97423313, 0.96706764, 1.00271252,\n        0.96229385, 0.92194917, 1.07628351, 0.90818296, 1.03344632,\n        0.96717024, 0.9147238 , 1.03448556, 0.95193652, 1.01246045,\n        0.85323302, 1.10845644, 0.98895879, 0.92933126, 0.99654285,\n        1.04932968, 0.94563071, 0.93945178, 0.98790823, 1.06480279,\n        1.09379232, 0.95675793, 0.96219281, 1.09095606, 0.99714155,\n        0.9193868 , 0.90923137, 1.09562631, 0.94774449, 0.93792541,\n        0.96879722, 1.00595223, 0.8656108 , 1.18189528, 0.96664037,\n        1.03078492, 0.92146894, 0.96430373, 1.00066357, 0.96329536,\n        0.95989397, 1.00750482, 1.01051458, 0.9152898 , 1.04203015]])x(chain, draw)float640.468 0.5335 ... 0.5823 0.2556array([[0.46800586, 0.53349183, 0.4088409 , 0.37521013, 0.43717575,\n        0.3832035 , 0.21140898, 0.55448817, 0.1711821 , 0.35688661,\n        0.43822726, 0.33735265, 0.16561344, 0.67699918, 0.45422667,\n        0.47178428, 0.46508591, 0.40837796, 0.2101566 , 0.47458809,\n        0.48962153, 0.70202638, 0.37017146, 0.34851642, 0.51916013,\n        0.35651803, 0.4381548 , 0.45203473, 0.48434229, 0.29749362,\n        0.515871  , 0.46371454, 0.46856633, 0.43580705, 0.28317073,\n        0.5385999 , 0.53054664, 0.49125902, 0.34369147, 0.49371215,\n        0.46446401, 0.42732375, 0.36155887, 0.42573094, 0.44892402,\n        0.41812373, 0.5626904 , 0.52362686, 0.54207493, 0.52779595,\n        0.37978216, 0.36241897, 0.39519959, 0.18887748, 0.45953421,\n        0.37953675, 0.12676415, 0.80772978, 0.56050793, 0.35300676,\n        0.36029395, 0.43004195, 0.50086254, 0.50316126, 0.50700983,\n        0.44730184, 0.46993672, 0.16229443, 0.4708801 , 0.45681139,\n        0.45681139, 0.41432321, 0.55174925, 0.67505524, 0.58785653,\n        0.30591471, 0.37007726, 0.44209737, 0.37308069, 0.38768251,\n        0.40982001, 0.49554139, 0.33027965, 0.44829602, 0.29485496,\n        0.24089589, 0.57888589, 0.32744555, 0.22130569, 0.54324738,\n        0.56193907, 0.54501603, 0.55910209, 0.32386995, 0.54059668,\n        0.31615273, 0.54903698, 0.51587335, 0.36294404, 0.51472186,\n...\n        0.47098906, 0.57807822, 0.41782348, 0.38082894, 0.598839  ,\n        0.28582131, 0.43897772, 0.47030186, 0.49756787, 0.50881817,\n        0.49218722, 0.31837187, 0.49070988, 0.36480284, 0.36048507,\n        0.43283685, 0.28792998, 0.54390732, 0.2560028 , 0.30281095,\n        0.28430704, 0.3409292 , 0.464392  , 0.33323525, 0.48930828,\n        0.37404571, 0.19651709, 0.61334568, 0.24632981, 0.64574153,\n        0.34629601, 0.53377864, 0.41677576, 0.4450463 , 0.48055301,\n        0.3773017 , 0.39729327, 0.44056334, 0.3974933 , 0.51845204,\n        0.54942556, 0.4265995 , 0.56770408, 0.54392126, 0.2638794 ,\n        0.59291187, 0.28143342, 0.43882727, 0.49052401, 0.37245527,\n        0.47884013, 0.36824753, 0.35245361, 0.34835847, 0.65365594,\n        0.18200426, 0.1229928 , 0.73104394, 0.28958726, 0.50304965,\n        0.38370283, 0.40925073, 0.37520302, 0.31518738, 0.31079615,\n        0.19531552, 0.46179129, 0.47102367, 0.39390833, 0.54685681,\n        0.54344871, 0.1425032 , 0.29892226, 0.27632147, 0.42930704,\n        0.42375233, 0.28049368, 0.46458036, 0.5612849 , 0.37934858,\n        0.23479622, 0.59712043, 0.3248167 , 0.32381177, 0.35358029,\n        0.51104295, 0.22102055, 0.52387545, 0.3960171 , 0.64140278,\n        0.38078932, 0.33168525, 0.35080479, 0.49506784, 0.46573925,\n        0.5437958 , 0.4413925 , 0.38373482, 0.58225231, 0.25562624]])Indexes: (2)drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       240, 241, 242, 243, 244, 245, 246, 247, 248, 249],\n      dtype='int64', name='draw', length=250))chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))Attributes: (4)created_at :2024-12-21T16:43:38.392870+00:00arviz_version :0.19.0modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7\n                      \n                  \n            \n            \n            \n                  \n                  sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 51kB\nDimensions:          (chain: 4, draw: 250)\nCoordinates:\n  * chain            (chain) int64 32B 0 1 2 3\n  * draw             (draw) int64 2kB 0 1 2 3 4 5 6 ... 244 245 246 247 248 249\nData variables:\n    acceptance_rate  (chain, draw) float64 8kB 0.972 0.993 0.9295 ... 0.94 1.0\n    diverging        (chain, draw) bool 1kB False False False ... False False\n    energy           (chain, draw) float64 8kB 145.9 145.9 145.6 ... 146.0 145.4\n    lp               (chain, draw) float64 8kB -145.5 -144.5 ... -145.3 -145.2\n    n_steps          (chain, draw) int64 8kB 7 3 3 3 3 3 7 7 ... 7 3 3 3 3 3 3 7\n    step_size        (chain, draw) float64 8kB 0.8512 0.8512 ... 0.8232 0.8232\n    tree_depth       (chain, draw) int64 8kB 3 2 2 2 2 2 3 3 ... 3 2 2 2 2 2 2 3\nAttributes:\n    created_at:                  2024-12-21T16:43:38.394782+00:00\n    arviz_version:               0.19.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:chain: 4draw: 250Coordinates: (2)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 245 246 247 248 249array([  0,   1,   2, ..., 247, 248, 249])Data variables: (7)acceptance_rate(chain, draw)float640.972 0.993 0.9295 ... 0.94 1.0array([[0.9720433 , 0.99303478, 0.9295272 , 0.92986998, 0.97901831,\n        0.96581174, 0.90383675, 0.97116927, 0.98724624, 1.        ,\n        0.9690074 , 0.9755437 , 0.89704634, 0.98685252, 0.94992695,\n        0.97890341, 0.98846335, 1.        , 0.83486528, 0.9993348 ,\n        0.90529922, 0.5741795 , 0.98243449, 1.        , 0.98139272,\n        0.74795716, 0.99654441, 0.99482358, 0.89329045, 0.99927984,\n        0.98997529, 0.97672318, 0.96394141, 0.9786796 , 0.98751797,\n        0.97848863, 0.93229617, 0.9555814 , 0.8877351 , 0.98180158,\n        0.90618543, 0.9763756 , 0.74380358, 1.        , 1.        ,\n        0.95470967, 0.95775845, 0.94137267, 0.99470761, 0.99809095,\n        0.96232196, 0.80277833, 1.        , 0.704677  , 0.98746569,\n        0.81493283, 0.51930375, 1.        , 0.92616214, 0.98819177,\n        0.97529459, 0.92422593, 0.72827975, 0.93264438, 1.        ,\n        0.87992617, 0.99404592, 0.86031603, 0.98558005, 0.90021857,\n        0.47290181, 0.9765392 , 0.8391316 , 0.91941677, 1.        ,\n        0.86539454, 0.97566959, 0.97605092, 0.90341389, 1.        ,\n        0.9803974 , 0.89206904, 0.73603399, 1.        , 0.79677445,\n        0.99068062, 0.90256535, 0.91019282, 0.98342346, 0.97818158,\n        0.77228611, 1.        , 0.99869603, 0.99092063, 0.7137078 ,\n        0.9728895 , 0.97314328, 0.97850007, 0.88820915, 1.        ,\n...\n        0.99431701, 0.91674077, 0.9091222 , 0.94089423, 0.92084418,\n        0.7375471 , 0.96985072, 0.96330501, 1.        , 0.87310539,\n        0.97512529, 0.99480611, 1.        , 0.87350268, 0.92078778,\n        0.99790025, 0.91490546, 0.97240355, 0.96107284, 0.9941977 ,\n        0.89998592, 0.80240597, 0.99535414, 0.94061673, 1.        ,\n        0.72650835, 0.78398942, 1.        , 0.94325819, 0.88799857,\n        0.90477998, 0.96667412, 1.        , 0.9017629 , 0.97138839,\n        0.99029645, 0.93946412, 0.99742733, 0.99609774, 0.60428783,\n        0.97446119, 0.96015555, 0.75938424, 0.94223928, 0.84103807,\n        0.82199603, 1.        , 1.        , 1.        , 0.90426692,\n        0.99876509, 0.9844627 , 0.99487014, 0.95889242, 0.80693499,\n        0.99331301, 0.68126783, 0.98251729, 0.98048657, 0.94670271,\n        0.87281639, 0.99386622, 0.80497022, 1.        , 0.9708809 ,\n        0.67042334, 0.99111389, 0.96220115, 0.98371599, 0.73690286,\n        0.88006246, 0.81505355, 1.        , 0.82647808, 0.9112207 ,\n        0.93830167, 0.88548941, 1.        , 0.90949821, 0.944067  ,\n        0.84503657, 0.73559992, 0.92898106, 0.8933631 , 1.        ,\n        0.91003842, 0.86277041, 0.94861289, 0.84530157, 0.96950238,\n        0.7543196 , 0.88983454, 0.95395081, 0.58772853, 0.99200676,\n        0.9889097 , 0.98534041, 0.88202601, 0.93997294, 1.        ]])diverging(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n...\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False]])energy(chain, draw)float64145.9 145.9 145.6 ... 146.0 145.4array([[145.91772704, 145.91883587, 145.58143403, 144.40337055,\n        144.36974872, 144.04406778, 145.91605242, 148.11161033,\n        148.19347032, 146.70797434, 144.95316733, 145.01236326,\n        145.96126427, 147.00481142, 147.35457438, 146.50356288,\n        145.43292515, 144.7314781 , 146.76377146, 145.69947555,\n        144.85961646, 151.57981171, 150.33384151, 146.37510938,\n        147.03432717, 148.50654397, 147.48051466, 145.55058968,\n        146.28281033, 146.23485176, 145.56719232, 145.81714488,\n        146.28924297, 147.29064021, 147.68928723, 145.94598641,\n        147.05988736, 147.69703615, 145.29908406, 144.34429562,\n        145.35631333, 145.54803578, 148.39377431, 147.11213505,\n        145.28019303, 146.23983754, 147.32897508, 147.98840563,\n        146.95852787, 145.0691263 , 145.20401136, 146.8799089 ,\n        145.77094868, 147.86647334, 148.70329979, 148.15932753,\n        151.66278519, 151.76839145, 152.48402924, 147.29835162,\n        144.58885   , 145.85631312, 147.61644847, 148.21038457,\n        148.5591529 , 149.46950883, 145.10488352, 147.97950943,\n        147.20698232, 145.89314732, 152.63892764, 146.83581065,\n        146.42231815, 146.88570122, 146.53130249, 146.78365731,\n        147.98503747, 145.7452399 , 145.70769099, 145.54740687,\n...\n        147.45548501, 146.83407801, 145.92723882, 146.67244693,\n        147.31926775, 146.77702603, 146.01406677, 147.16635779,\n        147.97434509, 147.14810844, 145.36972994, 145.15433309,\n        144.84625113, 144.7768379 , 144.60706204, 143.93720862,\n        143.86303629, 148.83474176, 144.76648764, 145.27320396,\n        147.78080305, 147.15315762, 145.87225857, 148.83257242,\n        147.27851834, 147.18452807, 145.47961258, 145.36414792,\n        146.00391405, 145.12152786, 145.11394721, 144.82662392,\n        147.63012865, 146.01007151, 147.48621524, 148.89046776,\n        147.50239657, 146.03455429, 146.43060907, 147.00829367,\n        149.1757429 , 147.34321079, 144.87592362, 150.82948882,\n        148.59157317, 146.0499724 , 144.09389628, 147.03464404,\n        146.21292494, 147.62647473, 146.41985609, 146.60151842,\n        147.94423624, 147.38321269, 151.34090195, 147.53438733,\n        147.22948968, 147.11826796, 145.91995947, 149.70053853,\n        147.38514828, 147.44150499, 144.62859758, 145.09094516,\n        145.50349569, 146.54998256, 148.20815365, 149.34747541,\n        148.16991633, 146.05970861, 146.32358621, 148.52740743,\n        145.81575221, 144.95519911, 145.02048293, 145.35047359,\n        146.02587089, 145.44887936]])lp(chain, draw)float64-145.5 -144.5 ... -145.3 -145.2array([[-145.5084443 , -144.53929191, -143.72417165, -144.00347398,\n        -143.71502073, -143.934253  , -145.75877746, -146.14137985,\n        -146.54795923, -144.23617   , -144.48149358, -144.20227724,\n        -145.79843417, -146.14710436, -144.86269727, -144.79868676,\n        -144.72369825, -143.81924668, -145.61747478, -143.84503074,\n        -144.09732777, -148.79212392, -146.10267782, -145.97829011,\n        -145.03888713, -146.45148457, -145.68767272, -144.37571595,\n        -145.25637452, -144.75888247, -144.85878585, -145.08673494,\n        -146.13528712, -146.42886007, -145.31551219, -145.33636793,\n        -146.8168436 , -143.84225906, -144.00268552, -144.02188135,\n        -144.63668916, -144.42936233, -146.5084853 , -145.23475179,\n        -144.91403424, -145.4387337 , -145.72229782, -146.66475767,\n        -144.85697931, -144.26599567, -144.53898228, -146.11871324,\n        -143.73669152, -147.68001862, -144.76223619, -144.59965661,\n        -149.96949534, -150.03859599, -146.83959537, -144.1389861 ,\n        -144.54787836, -144.48104832, -146.6483268 , -147.85824709,\n        -147.72516603, -144.845782  , -144.89568586, -146.97420856,\n        -144.14878426, -145.56175333, -145.56175333, -144.14973997,\n        -144.77478786, -146.26419733, -144.75745707, -145.98434854,\n        -145.09629025, -144.00757721, -145.13921826, -144.40197073,\n...\n        -145.27175917, -145.78576118, -143.98425046, -144.58320035,\n        -145.86141507, -145.15346915, -144.94100192, -146.09912375,\n        -146.23976638, -145.24906103, -143.99423569, -144.17118272,\n        -144.41558012, -144.00985162, -143.83256805, -143.78035095,\n        -143.78209626, -144.26834705, -144.31656292, -144.7739249 ,\n        -146.37365001, -144.15872782, -145.32770818, -146.31617929,\n        -146.3416362 , -145.57696561, -143.90004435, -145.24066775,\n        -144.66350549, -144.87820377, -144.14575514, -144.78965811,\n        -145.53628622, -145.68361419, -147.32103649, -147.18919701,\n        -144.81065027, -144.50888214, -145.693528  , -145.44102051,\n        -147.21085806, -144.19662696, -144.42698962, -147.95121443,\n        -145.37441741, -143.8287251 , -143.93752843, -144.43602194,\n        -144.6693352 , -146.57983153, -144.36561704, -145.68754173,\n        -146.4978727 , -147.24257259, -146.77536963, -145.44691559,\n        -145.86386805, -144.15683987, -145.37054438, -145.24370133,\n        -145.39996683, -144.57479704, -144.03050776, -143.94924548,\n        -145.08595998, -145.52774857, -147.54798815, -145.78351401,\n        -144.09844833, -145.82381246, -144.06671543, -145.2461415 ,\n        -144.47951699, -144.66225608, -144.05405028, -144.75064556,\n        -145.31097232, -145.19928554]])n_steps(chain, draw)int647 3 3 3 3 3 7 7 ... 7 3 3 3 3 3 3 7array([[ 7,  3,  3,  3,  3,  3,  7,  7,  7,  3,  3,  7,  3,  7,  3,  7,\n         3,  3,  7,  3,  3,  5,  7,  3,  7,  7,  7,  5,  7,  7,  7,  7,\n         7,  7,  7,  7,  3,  3,  3,  7,  7,  7,  3,  7,  1,  7,  7,  7,\n         7,  3,  7,  3,  3,  3,  7,  3,  3,  7,  7,  3,  3,  7,  3,  3,\n         1,  3,  7,  3,  3,  7,  3,  7,  3,  3,  3,  7,  7,  7,  3,  7,\n         3,  5,  3,  3,  3,  7,  7,  7,  7,  3,  3,  3,  7,  7,  3,  7,\n         7,  3,  7,  3,  3,  7,  7,  3,  3,  3,  3,  3,  3,  7,  3,  7,\n         3,  7,  3,  7,  7,  7,  3,  7,  7,  7,  7,  7,  7,  7,  7,  3,\n         3,  3,  7,  7,  7,  3,  3,  3,  3,  7,  3,  3,  7,  3,  3,  7,\n         7,  3,  3,  7,  3,  3,  3,  7,  7,  3,  3,  3,  3,  7,  3,  7,\n         3,  3,  7,  3,  7,  7,  7,  3,  7,  7,  3,  7,  3,  3,  3,  7,\n         7,  7,  3,  7,  3,  7,  7,  7,  3,  3,  3,  7,  7,  3,  7,  3,\n         7,  7,  3,  7,  7,  5,  3,  3,  3,  3,  7,  7,  3,  3,  7,  7,\n         3,  7,  7,  7,  7,  3,  7,  7,  3,  3,  3,  7,  7,  7,  7,  3,\n         7,  7,  3,  7,  3,  7,  7,  3,  7,  7,  7,  3,  7,  3,  3,  3,\n         3,  7,  7,  7,  7,  3,  3,  7,  7,  3],\n       [ 3,  7,  3,  7,  3,  3,  7,  3,  7,  7,  7,  7,  7,  7,  3,  7,\n         7,  3,  7,  7,  3,  3,  3,  7,  7,  3,  3,  7,  3,  7,  3,  7,\n         3,  3,  7,  3,  7,  1,  7,  7,  7,  7,  7,  3,  3,  3,  7,  7,\n         7,  7,  3,  7,  7,  7,  3,  7,  7,  7,  3,  3,  7,  7,  7,  7,\n...\n         7,  7,  3,  3,  3,  7,  7,  3,  3,  3,  3,  7,  3,  7,  3,  7,\n         3,  7,  7,  3,  7,  7,  3,  7,  3,  3,  7,  3,  3,  7,  3,  7,\n         3,  3,  7,  7,  3,  7,  7,  7,  7,  3,  3,  3,  3,  3,  7,  1,\n         3,  3,  3,  7,  3,  7,  3,  7,  3,  3],\n       [ 3,  3,  7,  3,  3,  3,  3,  3,  7,  3,  7,  7,  3,  3,  3,  3,\n         3,  3,  3,  7,  7,  3,  7,  7,  7,  7,  3,  3,  7,  7,  3,  3,\n         3,  1,  3,  3,  3,  3,  3,  3,  3,  3,  3,  7,  3,  3,  3,  3,\n         3,  3,  7,  3,  3,  3,  7,  7,  7,  3,  7,  3,  7,  3,  3,  7,\n         3,  7,  7,  7,  3,  3,  7,  3,  1,  7,  7,  7,  3,  3,  3,  7,\n         7,  7,  3,  3,  7,  7,  7,  3,  7,  7,  3,  7,  7,  7,  7,  3,\n         7,  7,  3,  3,  3,  3,  3,  3,  3,  3,  3,  7,  7,  7,  3,  3,\n         7,  7,  3,  3,  3,  3,  3,  3,  3,  3,  3,  7,  7,  7,  3,  7,\n         3,  7,  7,  3,  3,  3,  3,  3,  3,  3,  3,  7,  3,  7,  7,  7,\n         7,  3,  3,  3,  3,  7,  3,  3,  3,  7,  7,  3,  7,  7,  7,  7,\n         7,  7,  3,  7,  3,  3,  3,  3,  3,  7,  3,  3,  7,  3,  3,  3,\n         3,  3,  3,  7,  3,  3,  3,  7,  3,  3,  7,  3,  3,  7,  3,  3,\n         3,  3,  3,  7,  7,  7,  3,  3,  7,  7,  3,  3,  3,  7,  1,  7,\n         3,  3,  3,  7,  3,  3,  7,  3,  7,  3,  3,  3,  7,  3,  3,  3,\n         3,  1,  7,  3,  7,  7,  3,  3,  7,  3,  3,  3,  7,  3,  7,  7,\n         3,  3,  7,  3,  3,  3,  3,  3,  3,  7]])step_size(chain, draw)float640.8512 0.8512 ... 0.8232 0.8232array([[0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n        0.85120724, 0.85120724, 0.85120724, 0.85120724, 0.85120724,\n...\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403,\n        0.82316403, 0.82316403, 0.82316403, 0.82316403, 0.82316403]])tree_depth(chain, draw)int643 2 2 2 2 2 3 3 ... 3 2 2 2 2 2 2 3array([[3, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 3, 2, 3, 2, 3, 2, 2, 3, 2, 2, 3,\n        3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 2, 3,\n        1, 3, 3, 3, 3, 2, 3, 2, 2, 2, 3, 2, 2, 3, 3, 2, 2, 3, 2, 2, 1, 2,\n        3, 2, 2, 3, 2, 3, 2, 2, 2, 3, 3, 3, 2, 3, 2, 3, 2, 2, 2, 3, 3, 3,\n        3, 2, 2, 2, 3, 3, 2, 3, 3, 2, 3, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 3,\n        2, 3, 2, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 3,\n        3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 3, 3, 2, 2, 3, 2, 2, 2, 3, 3, 2,\n        2, 2, 2, 3, 2, 3, 2, 2, 3, 2, 3, 3, 3, 2, 3, 3, 2, 3, 2, 2, 2, 3,\n        3, 3, 2, 3, 2, 3, 3, 3, 2, 2, 2, 3, 3, 2, 3, 2, 3, 3, 2, 3, 3, 3,\n        2, 2, 2, 2, 3, 3, 2, 2, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 2, 2, 2, 3,\n        3, 3, 3, 2, 3, 3, 2, 3, 2, 3, 3, 2, 3, 3, 3, 2, 3, 2, 2, 2, 2, 3,\n        3, 3, 3, 2, 2, 3, 3, 2],\n       [2, 3, 2, 3, 2, 2, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 2, 2,\n        2, 3, 3, 2, 2, 3, 2, 3, 2, 3, 2, 2, 3, 2, 3, 1, 3, 3, 3, 3, 3, 2,\n        2, 2, 3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 2, 2, 3, 3, 3, 3, 2, 3,\n        3, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 2,\n        3, 3, 2, 2, 3, 2, 2, 2, 3, 2, 3, 3, 2, 2, 3, 3, 3, 2, 3, 3, 2, 3,\n        2, 3, 2, 3, 2, 3, 2, 2, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 2, 3, 2,\n        2, 3, 2, 2, 3, 2, 2, 3, 3, 3, 2, 3, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2,\n        3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 2, 3, 2, 3, 2,\n...\n        3, 2, 2, 3, 3, 2, 2, 3, 3, 3, 3, 2, 2, 3, 2, 2, 2, 2, 3, 2, 3, 3,\n        2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 2, 2,\n        1, 1, 2, 2, 2, 3, 2, 3, 2, 2, 2, 3, 2, 2, 3, 3, 3, 2, 2, 2, 2, 3,\n        3, 2, 2, 2, 2, 3, 2, 3, 2, 2, 2, 3, 2, 3, 2, 2, 3, 3, 2, 3, 3, 3,\n        3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 4, 1, 3, 3, 3, 2, 3, 3, 2, 2, 2, 3,\n        3, 2, 2, 2, 2, 3, 2, 3, 2, 3, 2, 3, 3, 2, 3, 3, 2, 3, 2, 2, 3, 2,\n        2, 3, 2, 3, 2, 2, 3, 3, 2, 3, 3, 3, 3, 2, 2, 2, 2, 2, 3, 1, 2, 2,\n        2, 3, 2, 3, 2, 3, 2, 2],\n       [2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2,\n        3, 3, 3, 3, 2, 2, 3, 3, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3,\n        2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 3, 3, 2, 3, 2, 3, 2, 2, 3, 2, 3,\n        3, 3, 2, 2, 3, 2, 1, 3, 3, 3, 2, 2, 2, 3, 3, 3, 2, 2, 3, 3, 3, 2,\n        3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n        2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 3, 2, 3, 3, 2,\n        2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 3, 3, 3, 2, 2, 2, 2, 3, 2, 2, 2, 3,\n        3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2,\n        2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 3, 3, 3,\n        2, 2, 3, 3, 2, 2, 2, 3, 1, 3, 2, 2, 2, 3, 2, 2, 3, 2, 3, 2, 2, 2,\n        3, 2, 2, 2, 2, 1, 3, 2, 3, 3, 2, 2, 3, 2, 2, 2, 3, 2, 3, 3, 2, 2,\n        3, 2, 2, 2, 2, 2, 2, 3]])Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       240, 241, 242, 243, 244, 245, 246, 247, 248, 249],\n      dtype='int64', name='draw', length=250))Attributes: (4)created_at :2024-12-21T16:43:38.394782+00:00arviz_version :0.19.0modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 2kB\nDimensions:  (__obs__: 100)\nCoordinates:\n  * __obs__  (__obs__) int64 800B 0 1 2 3 4 5 6 7 8 ... 92 93 94 95 96 97 98 99\nData variables:\n    y        (__obs__) float64 800B 0.9823 -0.1276 1.024 ... -0.4394 0.2223\nAttributes:\n    created_at:                  2024-12-21T16:43:38.392870+00:00\n    arviz_version:               0.19.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:__obs__: 100Coordinates: (1)__obs__(__obs__)int640 1 2 3 4 5 6 ... 94 95 96 97 98 99array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])Data variables: (1)y(__obs__)float640.9823 -0.1276 ... -0.4394 0.2223array([ 0.98232738, -0.12758867,  1.0241217 , -1.52813143, -0.60223389,\n       -0.9110669 , -0.4353976 ,  0.83518854, -1.98725748,  0.70239123,\n        0.47474209, -0.57402927, -1.10256821,  0.21458759, -0.7913338 ,\n        0.34504087, -0.27033576,  1.8694577 , -0.25456891, -1.07982821,\n       -0.02821523,  0.59252591,  1.3120998 ,  0.70459244,  0.24956995,\n        1.62550659, -1.07740601, -0.51398486, -0.79529742,  0.2627868 ,\n       -1.50052774,  0.47906184, -0.47019315, -1.28310684, -0.67156194,\n        0.27879211,  0.58211654,  1.74549738,  3.1121092 ,  0.64089167,\n       -0.82402974, -2.33483846,  0.33845498, -0.77738494, -0.34871911,\n       -0.34655757, -0.0726575 ,  1.27285679,  0.17764106, -0.07053522,\n       -0.84328945, -2.11870321, -0.58371719, -0.19711313,  1.57325292,\n        0.04643398,  1.43827366, -0.76312913, -0.88989281, -1.47791592,\n       -0.82727125,  2.17806337, -0.64275472,  1.05521209, -0.66118073,\n        0.82531053,  0.24406448,  0.10480201, -0.09905622, -1.04351111,\n        0.10074023, -0.7351563 , -1.07411239, -1.23453802,  0.3829906 ,\n        1.44890008,  0.20830137,  0.07198975,  0.19156297,  1.44518896,\n        0.01768236, -0.52155594,  0.98996665,  0.06436367,  1.68414482,\n        0.04019953, -1.22066186, -1.22166748,  1.78699361,  1.92641993,\n       -0.20952942, -0.51217355,  1.43715279, -1.6212053 , -1.33568691,\n        0.24027763, -0.69848326,  0.11669617, -0.43935783,  0.22234196])Indexes: (1)__obs__PandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n       90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n      dtype='int64', name='__obs__'))Attributes: (4)created_at :2024-12-21T16:43:38.392870+00:00arviz_version :0.19.0modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7\n                      \n                  \n            \n            \n              \n            \n            \n\n\n\n\nTensorflow probability\n\ntfp_nuts_idata = model.fit(inference_method=\"tfp_nuts\")\ntfp_nuts_idata\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 200kB\nDimensions:    (chain: 8, draw: 1000)\nCoordinates:\n  * draw       (draw) int64 8kB 0 1 2 3 4 5 6 7 ... 993 994 995 996 997 998 999\n  * chain      (chain) int64 64B 0 1 2 3 4 5 6 7\nData variables:\n    Intercept  (chain, draw) float64 64kB -0.06265 -0.06601 ... 0.08766 0.08766\n    sigma      (chain, draw) float64 64kB 0.9457 0.9487 0.9521 ... 0.9434 0.9434\n    x          (chain, draw) float64 64kB 0.3832 0.3474 0.276 ... 0.395 0.395\nAttributes:\n    created_at:                  2024-12-21T16:43:45.717159+00:00\n    arviz_version:               0.19.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:chain: 8draw: 1000Coordinates: (2)draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])chain(chain)int640 1 2 3 4 5 6 7array([0, 1, 2, 3, 4, 5, 6, 7])Data variables: (3)Intercept(chain, draw)float64-0.06265 -0.06601 ... 0.08766array([[-0.06264747, -0.0660125 , -0.01700844, ..., -0.08872791,\n         0.0941666 ,  0.01386138],\n       [-0.18189931, -0.06907472,  0.07860264, ..., -0.07688109,\n         0.21829021, -0.2126967 ],\n       [-0.03662729,  0.19079907,  0.23640799, ...,  0.08294682,\n         0.00513439,  0.02323765],\n       ...,\n       [ 0.01011986,  0.01753744, -0.03716693, ...,  0.02074494,\n         0.0848427 ,  0.08626771],\n       [ 0.17615389,  0.19552985,  0.11106452, ..., -0.08082757,\n         0.18760393, -0.14670461],\n       [-0.18970417,  0.02871667,  0.08781545, ..., -0.03420375,\n         0.08766422,  0.08766422]])sigma(chain, draw)float640.9457 0.9487 ... 0.9434 0.9434array([[0.94569485, 0.94870284, 0.95213973, ..., 0.93440049, 1.01812406,\n        1.04291367],\n       [1.04315269, 0.99276636, 1.01059094, ..., 1.14475339, 1.02881064,\n        1.04892393],\n       [0.93984991, 1.10522002, 1.06861672, ..., 0.92906162, 1.02390631,\n        0.92916676],\n       ...,\n       [1.03252984, 0.94501844, 0.91377664, ..., 0.89307866, 1.06423366,\n        0.89421931],\n       [1.13593225, 1.15496002, 0.97117364, ..., 0.89220192, 1.11541603,\n        0.91919422],\n       [1.01651393, 1.07249994, 0.92996479, ..., 0.99630479, 0.94338243,\n        0.94338243]])x(chain, draw)float640.3832 0.3474 0.276 ... 0.395 0.395array([[0.38316677, 0.34740813, 0.27595292, ..., 0.44392909, 0.47445609,\n        0.1554849 ],\n       [0.47191021, 0.53930882, 0.31983663, ..., 0.28736472, 0.64850478,\n        0.19784962],\n       [0.385989  , 0.64137192, 0.56873759, ..., 0.38337526, 0.3505215 ,\n        0.48127725],\n       ...,\n       [0.44651539, 0.43971577, 0.38104135, ..., 0.4976736 , 0.44335065,\n        0.31018728],\n       [0.29970792, 0.26045941, 0.33981284, ..., 0.49286072, 0.63469791,\n        0.21232564],\n       [0.30200621, 0.46201128, 0.48143039, ..., 0.37886645, 0.39497688,\n        0.39497688]])Indexes: (2)drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))chainPandasIndexPandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7], dtype='int64', name='chain'))Attributes: (4)created_at :2024-12-21T16:43:45.717159+00:00arviz_version :0.19.0modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7\n                      \n                  \n            \n            \n            \n                  \n                  sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 312kB\nDimensions:          (chain: 8, draw: 1000)\nCoordinates:\n  * chain            (chain) int64 64B 0 1 2 3 4 5 6 7\n  * draw             (draw) int64 8kB 0 1 2 3 4 5 6 ... 994 995 996 997 998 999\nData variables:\n    accept_ratio     (chain, draw) float64 64kB 0.9721 0.9725 ... 0.9694 0.8617\n    diverging        (chain, draw) bool 8kB False False False ... False False\n    is_accepted      (chain, draw) bool 8kB True True True ... True True False\n    n_steps          (chain, draw) int32 32kB 7 3 7 3 7 7 7 7 ... 7 3 3 3 3 3 7\n    step_size        (chain, draw) float64 64kB 0.563 0.563 0.563 ... nan nan\n    target_log_prob  (chain, draw) float64 64kB -144.0 -144.2 ... -144.2 -144.2\n    tune             (chain, draw) float64 64kB 0.0 0.0 0.0 0.0 ... nan nan nan\nAttributes:\n    created_at:                  2024-12-21T16:43:45.718997+00:00\n    arviz_version:               0.19.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:chain: 8draw: 1000Coordinates: (2)chain(chain)int640 1 2 3 4 5 6 7array([0, 1, 2, 3, 4, 5, 6, 7])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])Data variables: (7)accept_ratio(chain, draw)float640.9721 0.9725 ... 0.9694 0.8617array([[0.97205693, 0.97247584, 0.96821983, ..., 1.        , 0.99997408,\n        0.89420381],\n       [0.95607167, 0.98035862, 0.88295863, ..., 0.98237237, 0.90617221,\n        0.8622873 ],\n       [1.        , 0.75172571, 0.97348348, ..., 0.99137916, 0.99708924,\n        0.924119  ],\n       ...,\n       [0.9407456 , 1.        , 0.92484625, ..., 0.97215578, 0.99863597,\n        0.94694559],\n       [0.9799534 , 0.97789566, 0.96244261, ..., 0.9141886 , 0.84339419,\n        0.92260937],\n       [0.93528097, 0.91592569, 0.99518055, ..., 0.93995238, 0.96942414,\n        0.86173663]])diverging(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       ...,\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])is_accepted(chain, draw)boolTrue True True ... True True Falsearray([[ True,  True,  True, ...,  True,  True,  True],\n       [ True,  True,  True, ...,  True,  True,  True],\n       [ True,  True,  True, ...,  True,  True,  True],\n       ...,\n       [ True,  True,  True, ...,  True,  True,  True],\n       [ True,  True,  True, ...,  True,  True,  True],\n       [ True,  True,  True, ...,  True,  True, False]])n_steps(chain, draw)int327 3 7 3 7 7 7 7 ... 3 7 3 3 3 3 3 7array([[7, 3, 7, ..., 7, 7, 7],\n       [7, 7, 7, ..., 7, 7, 7],\n       [3, 7, 3, ..., 7, 3, 7],\n       ...,\n       [3, 3, 5, ..., 7, 7, 7],\n       [7, 3, 3, ..., 7, 3, 7],\n       [7, 7, 3, ..., 3, 3, 7]], dtype=int32)step_size(chain, draw)float640.563 0.563 0.563 ... nan nan nanarray([[0.56300945, 0.56300945, 0.56300945, ..., 0.56300945, 0.56300945,\n        0.56300945],\n       [       nan,        nan,        nan, ...,        nan,        nan,\n               nan],\n       [       nan,        nan,        nan, ...,        nan,        nan,\n               nan],\n       ...,\n       [       nan,        nan,        nan, ...,        nan,        nan,\n               nan],\n       [       nan,        nan,        nan, ...,        nan,        nan,\n               nan],\n       [       nan,        nan,        nan, ...,        nan,        nan,\n               nan]])target_log_prob(chain, draw)float64-144.0 -144.2 ... -144.2 -144.2array([[-144.04512961, -144.17562995, -144.45945005, ..., -144.35517824,\n        -144.36652737, -146.19839882],\n       [-145.88522923, -144.46827215, -144.49383644, ..., -146.78685305,\n        -147.38609161, -147.5349841 ],\n       [-143.92977045, -147.67713931, -147.34003549, ..., -144.33785214,\n        -144.12740038, -144.02173211],\n       ...,\n       [-144.08161023, -143.78573543, -144.22702771, ..., -144.64604162,\n        -144.79653201, -145.39035949],\n       [-147.56032147, -148.54226605, -144.589887  , ..., -145.11571835,\n        -147.74366413, -146.71150101],\n       [-146.00994179, -144.69852178, -144.38002703, ..., -143.88469791,\n        -144.22077796, -144.22077796]])tune(chain, draw)float640.0 0.0 0.0 0.0 ... nan nan nan nanarray([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]])Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Attributes: (4)created_at :2024-12-21T16:43:45.718997+00:00arviz_version :0.19.0modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 2kB\nDimensions:  (__obs__: 100)\nCoordinates:\n  * __obs__  (__obs__) int64 800B 0 1 2 3 4 5 6 7 8 ... 92 93 94 95 96 97 98 99\nData variables:\n    y        (__obs__) float64 800B 0.9823 -0.1276 1.024 ... -0.4394 0.2223\nAttributes:\n    created_at:                  2024-12-21T16:43:45.717159+00:00\n    arviz_version:               0.19.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:__obs__: 100Coordinates: (1)__obs__(__obs__)int640 1 2 3 4 5 6 ... 94 95 96 97 98 99array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])Data variables: (1)y(__obs__)float640.9823 -0.1276 ... -0.4394 0.2223array([ 0.98232738, -0.12758867,  1.0241217 , -1.52813143, -0.60223389,\n       -0.9110669 , -0.4353976 ,  0.83518854, -1.98725748,  0.70239123,\n        0.47474209, -0.57402927, -1.10256821,  0.21458759, -0.7913338 ,\n        0.34504087, -0.27033576,  1.8694577 , -0.25456891, -1.07982821,\n       -0.02821523,  0.59252591,  1.3120998 ,  0.70459244,  0.24956995,\n        1.62550659, -1.07740601, -0.51398486, -0.79529742,  0.2627868 ,\n       -1.50052774,  0.47906184, -0.47019315, -1.28310684, -0.67156194,\n        0.27879211,  0.58211654,  1.74549738,  3.1121092 ,  0.64089167,\n       -0.82402974, -2.33483846,  0.33845498, -0.77738494, -0.34871911,\n       -0.34655757, -0.0726575 ,  1.27285679,  0.17764106, -0.07053522,\n       -0.84328945, -2.11870321, -0.58371719, -0.19711313,  1.57325292,\n        0.04643398,  1.43827366, -0.76312913, -0.88989281, -1.47791592,\n       -0.82727125,  2.17806337, -0.64275472,  1.05521209, -0.66118073,\n        0.82531053,  0.24406448,  0.10480201, -0.09905622, -1.04351111,\n        0.10074023, -0.7351563 , -1.07411239, -1.23453802,  0.3829906 ,\n        1.44890008,  0.20830137,  0.07198975,  0.19156297,  1.44518896,\n        0.01768236, -0.52155594,  0.98996665,  0.06436367,  1.68414482,\n        0.04019953, -1.22066186, -1.22166748,  1.78699361,  1.92641993,\n       -0.20952942, -0.51217355,  1.43715279, -1.6212053 , -1.33568691,\n        0.24027763, -0.69848326,  0.11669617, -0.43935783,  0.22234196])Indexes: (1)__obs__PandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n       90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n      dtype='int64', name='__obs__'))Attributes: (4)created_at :2024-12-21T16:43:45.717159+00:00arviz_version :0.19.0modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7\n                      \n                  \n            \n            \n              \n            \n            \n\n\n\n\nNumPyro\n\nnumpyro_nuts_idata = model.fit(inference_method=\"numpyro_nuts\")\nnumpyro_nuts_idata\n\nsample: 100%|██████████| 1500/1500 [00:03&lt;00:00, 386.97it/s]\n\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 200kB\nDimensions:    (chain: 8, draw: 1000)\nCoordinates:\n  * draw       (draw) int64 8kB 0 1 2 3 4 5 6 7 ... 993 994 995 996 997 998 999\n  * chain      (chain) int64 64B 0 1 2 3 4 5 6 7\nData variables:\n    Intercept  (chain, draw) float64 64kB 0.04368 -0.1021 ... -0.00282 0.1476\n    sigma      (chain, draw) float64 64kB 0.9309 0.9906 0.9233 ... 0.9424 0.9128\n    x          (chain, draw) float64 64kB 0.6003 0.3584 0.5494 ... 0.3202 0.2671\nAttributes:\n    created_at:                  2024-12-21T16:43:50.477087+00:00\n    arviz_version:               0.19.0\n    inference_library:           numpyro\n    inference_library_version:   0.15.3\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:chain: 8draw: 1000Coordinates: (2)draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])chain(chain)int640 1 2 3 4 5 6 7array([0, 1, 2, 3, 4, 5, 6, 7])Data variables: (3)Intercept(chain, draw)float640.04368 -0.1021 ... -0.00282 0.1476array([[ 4.36780278e-02, -1.02060312e-01, -1.21861930e-02, ...,\n         8.30274083e-02,  5.10005372e-02,  1.74599096e-01],\n       [ 7.82617979e-02, -2.27029421e-02,  6.36873908e-02, ...,\n        -1.66003675e-01,  2.02171570e-02, -5.17846611e-02],\n       [ 8.80685267e-02, -5.44188543e-02, -3.85344553e-02, ...,\n         7.00181050e-02, -4.62349285e-02, -1.52577362e-01],\n       ...,\n       [-2.17430039e-01, -2.71966853e-01,  8.51352582e-02, ...,\n         5.63802528e-02,  1.25022945e-01, -1.35365289e-01],\n       [-4.66478338e-02, -2.42427856e-01, -3.74597633e-02, ...,\n        -8.64507662e-02,  9.29543008e-02,  2.69365668e-02],\n       [ 1.12906738e-01, -1.01347091e-04, -3.65058149e-02, ...,\n        -1.82585997e-01, -2.82035114e-03,  1.47629599e-01]])sigma(chain, draw)float640.9309 0.9906 ... 0.9424 0.9128array([[0.93087713, 0.9905813 , 0.92325779, ..., 1.01290249, 1.03051213,\n        1.08534419],\n       [0.98206922, 1.01252744, 1.01145341, ..., 0.93090174, 0.96102381,\n        1.00969021],\n       [1.02077691, 0.9220789 , 0.94240637, ..., 1.005969  , 0.93181947,\n        0.99773282],\n       ...,\n       [1.21197842, 1.1400143 , 0.9979225 , ..., 1.02456416, 1.00217482,\n        1.08937599],\n       [0.93834408, 1.00056445, 1.16074408, ..., 1.04277486, 0.92320912,\n        1.03921296],\n       [0.93827366, 1.04881833, 1.05123346, ..., 0.97864129, 0.94240964,\n        0.91278738]])x(chain, draw)float640.6003 0.3584 ... 0.3202 0.2671array([[0.60033335, 0.35843027, 0.54943257, ..., 0.44116516, 0.42984065,\n        0.42538742],\n       [0.4320444 , 0.45089492, 0.22009901, ..., 0.32191115, 0.23913126,\n        0.44003533],\n       [0.19131094, 0.67575404, 0.62492441, ..., 0.59740821, 0.33966004,\n        0.2793921 ],\n       ...,\n       [0.28354421, 0.49746466, 0.26458896, ..., 0.24744114, 0.76819194,\n        0.10381864],\n       [0.47337232, 0.46249374, 0.41401117, ..., 0.48912723, 0.28341635,\n        0.24593964],\n       [0.2667943 , 0.64555162, 0.61529558, ..., 0.3428897 , 0.3202273 ,\n        0.26705966]])Indexes: (2)drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))chainPandasIndexPandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7], dtype='int64', name='chain'))Attributes: (6)created_at :2024-12-21T16:43:50.477087+00:00arviz_version :0.19.0inference_library :numpyroinference_library_version :0.15.3modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7\n                      \n                  \n            \n            \n            \n                  \n                  sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 400kB\nDimensions:          (chain: 8, draw: 1000)\nCoordinates:\n  * chain            (chain) int64 64B 0 1 2 3 4 5 6 7\n  * draw             (draw) int64 8kB 0 1 2 3 4 5 6 ... 994 995 996 997 998 999\nData variables:\n    acceptance_rate  (chain, draw) float64 64kB 0.9297 0.9775 ... 0.9538 0.7392\n    diverging        (chain, draw) bool 8kB False False False ... False False\n    energy           (chain, draw) float64 64kB 145.1 146.0 ... 147.0 147.1\n    lp               (chain, draw) float64 64kB 145.0 144.4 ... 144.1 146.4\n    n_steps          (chain, draw) int64 64kB 7 7 7 7 3 7 7 7 ... 3 3 3 7 7 3 3\n    step_size        (chain, draw) float64 64kB 0.7792 0.7792 ... 0.703 0.703\n    tree_depth       (chain, draw) int64 64kB 3 3 3 3 2 3 3 3 ... 2 2 2 3 3 2 2\nAttributes:\n    created_at:                  2024-12-21T16:43:50.504626+00:00\n    arviz_version:               0.19.0\n    inference_library:           numpyro\n    inference_library_version:   0.15.3\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:chain: 8draw: 1000Coordinates: (2)chain(chain)int640 1 2 3 4 5 6 7array([0, 1, 2, 3, 4, 5, 6, 7])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])Data variables: (7)acceptance_rate(chain, draw)float640.9297 0.9775 ... 0.9538 0.7392array([[0.92971165, 0.97745798, 0.89489526, ..., 0.95775213, 1.        ,\n        0.79216766],\n       [0.96467116, 0.93659304, 0.77369566, ..., 0.98275057, 0.99997745,\n        1.        ],\n       [1.        , 0.97252342, 1.        , ..., 0.9247111 , 0.98048194,\n        0.77570052],\n       ...,\n       [0.71790695, 1.        , 0.9043856 , ..., 0.89367335, 0.73467986,\n        0.68563792],\n       [0.94285325, 0.60290422, 0.92352065, ..., 0.93394489, 0.96653036,\n        0.88048454],\n       [1.        , 0.99950217, 1.        , ..., 0.78672705, 0.95375978,\n        0.73921353]])diverging(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       ...,\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])energy(chain, draw)float64145.1 146.0 146.1 ... 147.0 147.1array([[145.11704181, 146.03433653, 146.08556601, ..., 147.74680129,\n        144.35818509, 147.34553867],\n       [145.61192107, 144.57386766, 148.1365559 , ..., 147.20510508,\n        146.64076565, 145.15219525],\n       [148.69622366, 146.8008191 , 146.33758151, ..., 144.87943283,\n        145.24254021, 146.4411324 ],\n       ...,\n       [151.56038646, 151.72756949, 149.1285552 , ..., 145.15314433,\n        148.36866062, 154.6806734 ],\n       [145.90196458, 150.09643704, 149.68978029, ..., 147.04933693,\n        146.12668161, 148.17662838],\n       [147.74793365, 146.37445968, 145.81906659, ..., 147.69766753,\n        147.01705089, 147.05161145]])lp(chain, draw)float64145.0 144.4 144.5 ... 144.1 146.4array([[145.00325495, 144.39310937, 144.53809961, ..., 144.18479864,\n        144.14959111, 146.11171705],\n       [143.99864661, 143.9292147 , 145.32604251, ..., 145.77657844,\n        144.8476512 , 144.01029553],\n       [145.95299145, 146.50645417, 145.30612683, ..., 144.87268293,\n        144.22464547, 145.49185334],\n       ...,\n       [149.9532268 , 149.18470347, 144.9461866 , ..., 145.05396377,\n        147.84864272, 148.12910411],\n       [144.05383368, 146.90683621, 146.63334906, ..., 144.71077891,\n        145.20505778, 145.07149705],\n       [145.44745093, 145.62173116, 145.41577479, ..., 145.62356323,\n        144.14371798, 146.38098161]])n_steps(chain, draw)int647 7 7 7 3 7 7 7 ... 7 3 3 3 7 7 3 3array([[7, 7, 7, ..., 3, 7, 3],\n       [3, 7, 7, ..., 7, 3, 3],\n       [7, 7, 1, ..., 1, 3, 3],\n       ...,\n       [3, 7, 7, ..., 3, 7, 7],\n       [7, 3, 7, ..., 3, 7, 7],\n       [3, 7, 3, ..., 7, 3, 3]])step_size(chain, draw)float640.7792 0.7792 ... 0.703 0.703array([[0.77915884, 0.77915884, 0.77915884, ..., 0.77915884, 0.77915884,\n        0.77915884],\n       [0.83435803, 0.83435803, 0.83435803, ..., 0.83435803, 0.83435803,\n        0.83435803],\n       [0.81351828, 0.81351828, 0.81351828, ..., 0.81351828, 0.81351828,\n        0.81351828],\n       ...,\n       [1.0486959 , 1.0486959 , 1.0486959 , ..., 1.0486959 , 1.0486959 ,\n        1.0486959 ],\n       [0.7171523 , 0.7171523 , 0.7171523 , ..., 0.7171523 , 0.7171523 ,\n        0.7171523 ],\n       [0.7030038 , 0.7030038 , 0.7030038 , ..., 0.7030038 , 0.7030038 ,\n        0.7030038 ]])tree_depth(chain, draw)int643 3 3 3 2 3 3 3 ... 3 2 2 2 3 3 2 2array([[3, 3, 3, ..., 2, 3, 2],\n       [2, 3, 3, ..., 3, 2, 2],\n       [3, 3, 1, ..., 1, 2, 2],\n       ...,\n       [2, 3, 3, ..., 2, 3, 3],\n       [3, 2, 3, ..., 2, 3, 3],\n       [2, 3, 2, ..., 3, 2, 2]])Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Attributes: (6)created_at :2024-12-21T16:43:50.504626+00:00arviz_version :0.19.0inference_library :numpyroinference_library_version :0.15.3modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 2kB\nDimensions:  (__obs__: 100)\nCoordinates:\n  * __obs__  (__obs__) int64 800B 0 1 2 3 4 5 6 7 8 ... 92 93 94 95 96 97 98 99\nData variables:\n    y        (__obs__) float64 800B 0.9823 -0.1276 1.024 ... -0.4394 0.2223\nAttributes:\n    created_at:                  2024-12-21T16:43:50.477087+00:00\n    arviz_version:               0.19.0\n    inference_library:           numpyro\n    inference_library_version:   0.15.3\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:__obs__: 100Coordinates: (1)__obs__(__obs__)int640 1 2 3 4 5 6 ... 94 95 96 97 98 99array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])Data variables: (1)y(__obs__)float640.9823 -0.1276 ... -0.4394 0.2223array([ 0.98232738, -0.12758867,  1.0241217 , -1.52813143, -0.60223389,\n       -0.9110669 , -0.4353976 ,  0.83518854, -1.98725748,  0.70239123,\n        0.47474209, -0.57402927, -1.10256821,  0.21458759, -0.7913338 ,\n        0.34504087, -0.27033576,  1.8694577 , -0.25456891, -1.07982821,\n       -0.02821523,  0.59252591,  1.3120998 ,  0.70459244,  0.24956995,\n        1.62550659, -1.07740601, -0.51398486, -0.79529742,  0.2627868 ,\n       -1.50052774,  0.47906184, -0.47019315, -1.28310684, -0.67156194,\n        0.27879211,  0.58211654,  1.74549738,  3.1121092 ,  0.64089167,\n       -0.82402974, -2.33483846,  0.33845498, -0.77738494, -0.34871911,\n       -0.34655757, -0.0726575 ,  1.27285679,  0.17764106, -0.07053522,\n       -0.84328945, -2.11870321, -0.58371719, -0.19711313,  1.57325292,\n        0.04643398,  1.43827366, -0.76312913, -0.88989281, -1.47791592,\n       -0.82727125,  2.17806337, -0.64275472,  1.05521209, -0.66118073,\n        0.82531053,  0.24406448,  0.10480201, -0.09905622, -1.04351111,\n        0.10074023, -0.7351563 , -1.07411239, -1.23453802,  0.3829906 ,\n        1.44890008,  0.20830137,  0.07198975,  0.19156297,  1.44518896,\n        0.01768236, -0.52155594,  0.98996665,  0.06436367,  1.68414482,\n        0.04019953, -1.22066186, -1.22166748,  1.78699361,  1.92641993,\n       -0.20952942, -0.51217355,  1.43715279, -1.6212053 , -1.33568691,\n        0.24027763, -0.69848326,  0.11669617, -0.43935783,  0.22234196])Indexes: (1)__obs__PandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n       90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n      dtype='int64', name='__obs__'))Attributes: (6)created_at :2024-12-21T16:43:50.477087+00:00arviz_version :0.19.0inference_library :numpyroinference_library_version :0.15.3modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7\n                      \n                  \n            \n            \n              \n            \n            \n\n\n\n\nflowMC\n\nflowmc_idata = model.fit(inference_method=\"flowmc_realnvp_hmc\")\nflowmc_idata\n\n['n_dim', 'n_chains', 'n_local_steps', 'n_global_steps', 'n_loop', 'output_thinning', 'verbose']\n\n\nGlobal Tuning: 100%|██████████| 5/5 [00:20&lt;00:00,  4.05s/it]\nGlobal Sampling: 100%|██████████| 5/5 [00:00&lt;00:00, 26.22it/s]\n\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 244kB\nDimensions:    (chain: 20, draw: 500)\nCoordinates:\n  * draw       (draw) int64 4kB 0 1 2 3 4 5 6 7 ... 493 494 495 496 497 498 499\n  * chain      (chain) int64 160B 0 1 2 3 4 5 6 7 8 ... 12 13 14 15 16 17 18 19\nData variables:\n    Intercept  (chain, draw) float64 80kB 0.2975 0.2975 ... 0.08134 0.03252\n    sigma      (chain, draw) float64 80kB 0.97 0.97 1.024 ... 0.9849 0.9851\n    x          (chain, draw) float64 80kB 0.5371 0.5371 0.5067 ... 0.4151 0.4007\nAttributes:\n    created_at:                  2024-12-21T16:44:12.534363+00:00\n    arviz_version:               0.19.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:chain: 20draw: 500Coordinates: (2)draw(draw)int640 1 2 3 4 5 ... 495 496 497 498 499array([  0,   1,   2, ..., 497, 498, 499])chain(chain)int640 1 2 3 4 5 6 ... 14 15 16 17 18 19array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19])Data variables: (3)Intercept(chain, draw)float640.2975 0.2975 ... 0.08134 0.03252array([[ 0.29748287,  0.29748287,  0.20412874, ...,  0.10651059,\n         0.05002103,  0.05002103],\n       [-0.04345766, -0.07033399, -0.01827809, ..., -0.03357111,\n        -0.17953483,  0.04185628],\n       [ 0.06892281, -0.04278841, -0.04278841, ..., -0.00819138,\n        -0.00325469, -0.00325469],\n       ...,\n       [ 0.08476461,  0.05130198, -0.10595857, ...,  0.03469424,\n         0.16852237,  0.16852237],\n       [ 0.1015814 , -0.02613308,  0.05469311, ...,  0.02302198,\n         0.01975509,  0.01975509],\n       [ 0.09287518,  0.15573112,  0.05726772, ..., -0.01643258,\n         0.0813396 ,  0.03252254]])sigma(chain, draw)float640.97 0.97 1.024 ... 0.9849 0.9851array([[0.9700181 , 0.9700181 , 1.02416881, ..., 0.88390633, 1.01198967,\n        1.01198967],\n       [0.97172339, 0.87943515, 0.8616251 , ..., 1.00571692, 1.0400462 ,\n        0.91472018],\n       [1.20472422, 1.01106339, 1.01106339, ..., 0.90243256, 0.97105588,\n        0.97105588],\n       ...,\n       [1.0080265 , 1.08869221, 0.972042  , ..., 1.01279497, 0.88843012,\n        0.88843012],\n       [0.91507692, 0.88823903, 0.93696671, ..., 1.00124152, 0.87947138,\n        0.87947138],\n       [0.99197532, 0.95891627, 1.13475845, ..., 0.99780621, 0.98489472,\n        0.98512528]])x(chain, draw)float640.5371 0.5371 ... 0.4151 0.4007array([[0.53709486, 0.53709486, 0.506732  , ..., 0.38066196, 0.14042814,\n        0.14042814],\n       [0.06227666, 0.69916906, 0.15148096, ..., 0.24080569, 0.52297111,\n        0.43349179],\n       [0.64481472, 0.29151227, 0.29151227, ..., 0.33492639, 0.38543645,\n        0.38543645],\n       ...,\n       [0.4253746 , 0.42098853, 0.54155206, ..., 0.725751  , 0.36908541,\n        0.36908541],\n       [0.44289334, 0.38795698, 0.57891486, ..., 0.34892792, 0.59045615,\n        0.59045615],\n       [0.31498303, 0.42620002, 0.42355745, ..., 0.24562306, 0.41513847,\n        0.40065697]])Indexes: (2)drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       490, 491, 492, 493, 494, 495, 496, 497, 498, 499],\n      dtype='int64', name='draw', length=500))chainPandasIndexPandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], dtype='int64', name='chain'))Attributes: (4)created_at :2024-12-21T16:44:12.534363+00:00arviz_version :0.19.0modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 2kB\nDimensions:  (__obs__: 100)\nCoordinates:\n  * __obs__  (__obs__) int64 800B 0 1 2 3 4 5 6 7 8 ... 92 93 94 95 96 97 98 99\nData variables:\n    y        (__obs__) float64 800B 0.9823 -0.1276 1.024 ... -0.4394 0.2223\nAttributes:\n    created_at:                  2024-12-21T16:44:12.534363+00:00\n    arviz_version:               0.19.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:__obs__: 100Coordinates: (1)__obs__(__obs__)int640 1 2 3 4 5 6 ... 94 95 96 97 98 99array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])Data variables: (1)y(__obs__)float640.9823 -0.1276 ... -0.4394 0.2223array([ 0.98232738, -0.12758867,  1.0241217 , -1.52813143, -0.60223389,\n       -0.9110669 , -0.4353976 ,  0.83518854, -1.98725748,  0.70239123,\n        0.47474209, -0.57402927, -1.10256821,  0.21458759, -0.7913338 ,\n        0.34504087, -0.27033576,  1.8694577 , -0.25456891, -1.07982821,\n       -0.02821523,  0.59252591,  1.3120998 ,  0.70459244,  0.24956995,\n        1.62550659, -1.07740601, -0.51398486, -0.79529742,  0.2627868 ,\n       -1.50052774,  0.47906184, -0.47019315, -1.28310684, -0.67156194,\n        0.27879211,  0.58211654,  1.74549738,  3.1121092 ,  0.64089167,\n       -0.82402974, -2.33483846,  0.33845498, -0.77738494, -0.34871911,\n       -0.34655757, -0.0726575 ,  1.27285679,  0.17764106, -0.07053522,\n       -0.84328945, -2.11870321, -0.58371719, -0.19711313,  1.57325292,\n        0.04643398,  1.43827366, -0.76312913, -0.88989281, -1.47791592,\n       -0.82727125,  2.17806337, -0.64275472,  1.05521209, -0.66118073,\n        0.82531053,  0.24406448,  0.10480201, -0.09905622, -1.04351111,\n        0.10074023, -0.7351563 , -1.07411239, -1.23453802,  0.3829906 ,\n        1.44890008,  0.20830137,  0.07198975,  0.19156297,  1.44518896,\n        0.01768236, -0.52155594,  0.98996665,  0.06436367,  1.68414482,\n        0.04019953, -1.22066186, -1.22166748,  1.78699361,  1.92641993,\n       -0.20952942, -0.51217355,  1.43715279, -1.6212053 , -1.33568691,\n        0.24027763, -0.69848326,  0.11669617, -0.43935783,  0.22234196])Indexes: (1)__obs__PandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n       90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n      dtype='int64', name='__obs__'))Attributes: (4)created_at :2024-12-21T16:44:12.534363+00:00arviz_version :0.19.0modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7\n                      \n                  \n            \n            \n              \n            \n            \n\n\n\n\nnutpie\n\nbmb.inference_methods.get_kwargs(\"nutpie\")\n\n{&lt;function nutpie.compiled_pyfunc.from_pyfunc(ndim: int, make_logp_fn: Callable, make_expand_fn: Callable, expanded_dtypes: list[numpy.dtype], expanded_shapes: list[tuple[int, ...]], expanded_names: list[str], *, initial_mean: numpy.ndarray | None = None, coords: dict[str, typing.Any] | None = None, dims: dict[str, tuple[str, ...]] | None = None, shared_data: dict[str, typing.Any] | None = None)&gt;: {'ndim': 1,\n  'make_logp_fn': &lt;function bayeux._src.mcmc.nutpie._NutpieSampler._get_aux.&lt;locals&gt;.make_logp_fn()&gt;,\n  'make_expand_fn': &lt;function bayeux._src.mcmc.nutpie._NutpieSampler.get_kwargs.&lt;locals&gt;.make_expand_fn(*args, **kwargs)&gt;,\n  'expanded_shapes': [(1,)],\n  'expanded_names': ['x'],\n  'expanded_dtypes': [numpy.float64]},\n &lt;function nutpie.sample.sample(compiled_model: nutpie.sample.CompiledModel, *, draws: int = 1000, tune: int = 300, chains: int = 6, cores: Optional[int] = None, seed: Optional[int] = None, save_warmup: bool = True, progress_bar: bool = True, low_rank_modified_mass_matrix: bool = False, init_mean: Optional[numpy.ndarray] = None, return_raw_trace: bool = False, blocking: bool = True, progress_template: Optional[str] = None, progress_style: Optional[str] = None, progress_rate: int = 100, **kwargs) -&gt; arviz.data.inference_data.InferenceData&gt;: {'draws': 1000,\n  'tune': 300,\n  'chains': 8,\n  'cores': 8,\n  'seed': None,\n  'save_warmup': True,\n  'progress_bar': True,\n  'low_rank_modified_mass_matrix': False,\n  'init_mean': None,\n  'return_raw_trace': False,\n  'blocking': True,\n  'progress_template': None,\n  'progress_style': None,\n  'progress_rate': 100},\n 'extra_parameters': {'flatten': &lt;function bayeux._src.mcmc.nutpie._NutpieSampler._get_aux.&lt;locals&gt;.flatten(pytree)&gt;,\n  'unflatten': &lt;jax._src.util.HashablePartial at 0x7f1545283cd0&gt;,\n  'return_pytree': False}}\n\n\n\nnutpie_idata = model.fit(inference_method=\"nutpie\", tune=400, draws=500, chains=3)\nnutpie_idata\n\n\n\n\n\n\n\n    Sampler Progress\n    Total Chains: 3\n    Active Chains: 0\n    \n        Finished Chains:\n        3\n    \n    Sampling for now\n    \n        Estimated Time to Completion:\n        now\n    \n\n    \n    \n    \n        \n            \n                Progress\n                Draws\n                Divergences\n                Step Size\n                Gradients/Draw\n            \n        \n        \n            \n                \n                    \n                        \n                        \n                    \n                    900\n                    0\n                    1.04\n                    3\n                \n            \n                \n                    \n                        \n                        \n                    \n                    900\n                    0\n                    1.02\n                    3\n                \n            \n                \n                    \n                        \n                        \n                    \n                    900\n                    0\n                    0.99\n                    3\n                \n            \n            \n        \n    \n\n\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 40kB\nDimensions:    (chain: 3, draw: 500)\nCoordinates:\n  * draw       (draw) int64 4kB 0 1 2 3 4 5 6 7 ... 493 494 495 496 497 498 499\n  * chain      (chain) int64 24B 0 1 2\nData variables:\n    Intercept  (chain, draw) float64 12kB 0.08496 -0.02695 ... 0.005357 0.1237\n    sigma      (chain, draw) float64 12kB 1.116 0.89 0.8934 ... 0.9256 0.926\n    x          (chain, draw) float64 12kB 0.3081 0.4959 0.3477 ... 0.4546 0.638\nAttributes:\n    created_at:                  2024-12-21T16:44:15.471804+00:00\n    arviz_version:               0.19.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:chain: 3draw: 500Coordinates: (2)draw(draw)int640 1 2 3 4 5 ... 495 496 497 498 499array([  0,   1,   2, ..., 497, 498, 499])chain(chain)int640 1 2array([0, 1, 2])Data variables: (3)Intercept(chain, draw)float640.08496 -0.02695 ... 0.1237array([[ 0.08495626, -0.02694756,  0.04761813, ...,  0.04826587,\n        -0.09547644,  0.06003909],\n       [-0.13172872, -0.13172872, -0.05732306, ..., -0.18458876,\n        -0.00783365,  0.03139188],\n       [-0.22804196, -0.34280014, -0.12318322, ..., -0.01801746,\n         0.00535721,  0.12368312]])sigma(chain, draw)float641.116 0.89 0.8934 ... 0.9256 0.926array([[1.1158858 , 0.89004725, 0.89339945, ..., 0.97595951, 1.05256256,\n        0.94768055],\n       [0.83622004, 0.83622004, 0.86356507, ..., 1.0728143 , 1.00178262,\n        0.98924715],\n       [1.11326286, 1.10151602, 1.05993273, ..., 0.90649939, 0.92558011,\n        0.92597358]])x(chain, draw)float640.3081 0.4959 ... 0.4546 0.638array([[0.30810182, 0.49586739, 0.34773315, ..., 0.17061409, 0.48942307,\n        0.21031244],\n       [0.37021344, 0.37021344, 0.39552654, ..., 0.49092085, 0.60398507,\n        0.30793672],\n       [0.37326579, 0.23681376, 0.37573066, ..., 0.54655074, 0.45460335,\n        0.63799263]])Indexes: (2)drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       490, 491, 492, 493, 494, 495, 496, 497, 498, 499],\n      dtype='int64', name='draw', length=500))chainPandasIndexPandasIndex(Index([0, 1, 2], dtype='int64', name='chain'))Attributes: (4)created_at :2024-12-21T16:44:15.471804+00:00arviz_version :0.19.0modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7\n                      \n                  \n            \n            \n            \n                  \n                  sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 127kB\nDimensions:               (chain: 3, draw: 500)\nCoordinates:\n  * chain                 (chain) int64 24B 0 1 2\n  * draw                  (draw) int64 4kB 0 1 2 3 4 5 ... 495 496 497 498 499\nData variables:\n    depth                 (chain, draw) uint64 12kB 2 2 2 2 2 2 ... 2 2 2 2 2 2\n    diverging             (chain, draw) bool 2kB False False ... False False\n    energy                (chain, draw) float64 12kB 146.6 147.2 ... 144.6 146.6\n    energy_error          (chain, draw) float64 12kB 0.5871 -0.6172 ... 0.704\n    index_in_trajectory   (chain, draw) int64 12kB 2 3 1 -2 -1 ... -2 -1 3 1 -1\n    logp                  (chain, draw) float64 12kB -146.1 -144.8 ... -146.2\n    maxdepth_reached      (chain, draw) bool 2kB False False ... False False\n    mean_tree_accept      (chain, draw) float64 12kB 0.9476 0.5462 ... 1.0 1.0\n    mean_tree_accept_sym  (chain, draw) float64 12kB 0.8644 0.7061 ... 0.8824\n    n_steps               (chain, draw) uint64 12kB 3 3 3 3 3 3 ... 3 3 3 3 3 3\n    step_size             (chain, draw) float64 12kB 1.039 1.039 ... 0.9917\n    step_size_bar         (chain, draw) float64 12kB 1.039 1.039 ... 0.9917\nAttributes:\n    created_at:                  2024-12-21T16:44:15.348609+00:00\n    arviz_version:               0.19.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:chain: 3draw: 500Coordinates: (2)chain(chain)int640 1 2array([0, 1, 2])draw(draw)int640 1 2 3 4 5 ... 495 496 497 498 499array([  0,   1,   2, ..., 497, 498, 499])Data variables: (12)depth(chain, draw)uint642 2 2 2 2 2 2 2 ... 2 2 2 2 2 2 2 2array([[2, 2, 2, ..., 2, 2, 2],\n       [1, 1, 1, ..., 2, 2, 2],\n       [2, 2, 1, ..., 2, 2, 2]], dtype=uint64)diverging(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])energy(chain, draw)float64146.6 147.2 145.5 ... 144.6 146.6array([[146.57457058, 147.16046322, 145.46525944, ..., 146.10295554,\n        146.31953173, 146.06039968],\n       [150.18040459, 150.89710843, 147.15511258, ..., 147.10320246,\n        147.54078436, 145.82985208],\n       [150.23222404, 150.99925011, 150.16072831, ..., 145.41498474,\n        144.58431595, 146.57406298]])energy_error(chain, draw)float640.5871 -0.6172 ... -0.2539 0.704array([[ 0.58705761, -0.61716544,  0.01756805, ...,  0.26662658,\n        -0.25939973,  0.1748119 ],\n       [ 0.        ,  0.        , -0.85939224, ...,  0.52176795,\n        -0.3575971 , -0.23295732],\n       [-0.63405426,  0.50074249, -0.97294914, ..., -0.0021623 ,\n        -0.25392512,  0.70398259]])index_in_trajectory(chain, draw)int642 3 1 -2 -1 -2 ... 3 -2 -1 3 1 -1array([[ 2,  3,  1, ..., -2,  2,  2],\n       [ 0,  0,  1, ...,  2,  2, -3],\n       [-2, -1,  1, ...,  3,  1, -1]])logp(chain, draw)float64-146.1 -144.8 ... -144.0 -146.2array([[-146.12027613, -144.76450443, -144.7888524 , ..., -145.89294843,\n        -144.91590252, -145.53285154],\n       [-147.53415198, -147.53415198, -145.44505253, ..., -146.3599338 ,\n        -144.78543012, -144.20152907],\n       [-147.60083721, -150.68646907, -145.17676015, ..., -144.7825173 ,\n        -143.96135853, -146.20666379]])maxdepth_reached(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])mean_tree_accept(chain, draw)float640.9476 0.5462 0.8713 ... 1.0 1.0array([[0.94764595, 0.54620639, 0.87128658, ..., 0.9648549 , 0.83409475,\n        1.        ],\n       [0.83802168, 0.3704865 , 0.18084125, ..., 0.97002184, 0.59839596,\n        0.93075336],\n       [1.        , 1.        , 0.8686935 , ..., 0.96619102, 1.        ,\n        1.        ]])mean_tree_accept_sym(chain, draw)float640.8644 0.7061 ... 0.9765 0.8824array([[0.86437128, 0.70610338, 0.7505567 , ..., 0.74232527, 0.8776042 ,\n        0.91234673],\n       [0.91187355, 0.54066421, 0.30629223, ..., 0.9240494 , 0.74872853,\n        0.81208005],\n       [0.73145203, 0.66268928, 0.74498843, ..., 0.97871722, 0.9764874 ,\n        0.88242094]])n_steps(chain, draw)uint643 3 3 3 3 3 3 3 ... 3 3 3 3 3 3 3 3array([[3, 3, 3, ..., 3, 3, 3],\n       [1, 1, 1, ..., 3, 3, 3],\n       [3, 3, 3, ..., 3, 3, 3]], dtype=uint64)step_size(chain, draw)float641.039 1.039 1.039 ... 0.9917 0.9917array([[1.03932607, 1.03932607, 1.03932607, ..., 1.03932607, 1.03932607,\n        1.03932607],\n       [1.02168617, 1.02168617, 1.02168617, ..., 1.02168617, 1.02168617,\n        1.02168617],\n       [0.99174921, 0.99174921, 0.99174921, ..., 0.99174921, 0.99174921,\n        0.99174921]])step_size_bar(chain, draw)float641.039 1.039 1.039 ... 0.9917 0.9917array([[1.03932607, 1.03932607, 1.03932607, ..., 1.03932607, 1.03932607,\n        1.03932607],\n       [1.02168617, 1.02168617, 1.02168617, ..., 1.02168617, 1.02168617,\n        1.02168617],\n       [0.99174921, 0.99174921, 0.99174921, ..., 0.99174921, 0.99174921,\n        0.99174921]])Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       490, 491, 492, 493, 494, 495, 496, 497, 498, 499],\n      dtype='int64', name='draw', length=500))Attributes: (4)created_at :2024-12-21T16:44:15.348609+00:00arviz_version :0.19.0modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 2kB\nDimensions:  (__obs__: 100)\nCoordinates:\n  * __obs__  (__obs__) int64 800B 0 1 2 3 4 5 6 7 8 ... 92 93 94 95 96 97 98 99\nData variables:\n    y        (__obs__) float64 800B 0.9823 -0.1276 1.024 ... -0.4394 0.2223\nAttributes:\n    created_at:                  2024-12-21T16:44:15.471804+00:00\n    arviz_version:               0.19.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:__obs__: 100Coordinates: (1)__obs__(__obs__)int640 1 2 3 4 5 6 ... 94 95 96 97 98 99array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])Data variables: (1)y(__obs__)float640.9823 -0.1276 ... -0.4394 0.2223array([ 0.98232738, -0.12758867,  1.0241217 , -1.52813143, -0.60223389,\n       -0.9110669 , -0.4353976 ,  0.83518854, -1.98725748,  0.70239123,\n        0.47474209, -0.57402927, -1.10256821,  0.21458759, -0.7913338 ,\n        0.34504087, -0.27033576,  1.8694577 , -0.25456891, -1.07982821,\n       -0.02821523,  0.59252591,  1.3120998 ,  0.70459244,  0.24956995,\n        1.62550659, -1.07740601, -0.51398486, -0.79529742,  0.2627868 ,\n       -1.50052774,  0.47906184, -0.47019315, -1.28310684, -0.67156194,\n        0.27879211,  0.58211654,  1.74549738,  3.1121092 ,  0.64089167,\n       -0.82402974, -2.33483846,  0.33845498, -0.77738494, -0.34871911,\n       -0.34655757, -0.0726575 ,  1.27285679,  0.17764106, -0.07053522,\n       -0.84328945, -2.11870321, -0.58371719, -0.19711313,  1.57325292,\n        0.04643398,  1.43827366, -0.76312913, -0.88989281, -1.47791592,\n       -0.82727125,  2.17806337, -0.64275472,  1.05521209, -0.66118073,\n        0.82531053,  0.24406448,  0.10480201, -0.09905622, -1.04351111,\n        0.10074023, -0.7351563 , -1.07411239, -1.23453802,  0.3829906 ,\n        1.44890008,  0.20830137,  0.07198975,  0.19156297,  1.44518896,\n        0.01768236, -0.52155594,  0.98996665,  0.06436367,  1.68414482,\n        0.04019953, -1.22066186, -1.22166748,  1.78699361,  1.92641993,\n       -0.20952942, -0.51217355,  1.43715279, -1.6212053 , -1.33568691,\n        0.24027763, -0.69848326,  0.11669617, -0.43935783,  0.22234196])Indexes: (1)__obs__PandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n       90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n      dtype='int64', name='__obs__'))Attributes: (4)created_at :2024-12-21T16:44:15.471804+00:00arviz_version :0.19.0modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7\n                      \n                  \n            \n            \n            \n                  \n                  warmup_posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 32kB\nDimensions:    (chain: 3, draw: 400)\nCoordinates:\n  * chain      (chain) int64 24B 0 1 2\n  * draw       (draw) int64 3kB 0 1 2 3 4 5 6 7 ... 393 394 395 396 397 398 399\nData variables:\n    Intercept  (chain, draw) float64 10kB 0.4285 0.4285 ... 0.05143 0.1415\n    sigma      (chain, draw) float64 10kB 1.157 1.157 0.9778 ... 0.7789 0.8057\n    x          (chain, draw) float64 10kB -0.1518 -0.1518 ... 0.5574 0.378\nAttributes:\n    created_at:                  2024-12-21T16:44:15.473126+00:00\n    arviz_version:               0.19.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:chain: 3draw: 400Coordinates: (2)chain(chain)int640 1 2array([0, 1, 2])draw(draw)int640 1 2 3 4 5 ... 395 396 397 398 399array([  0,   1,   2, ..., 397, 398, 399])Data variables: (3)Intercept(chain, draw)float640.4285 0.4285 ... 0.05143 0.1415array([[ 0.42849679,  0.42849679, -0.04319102, ...,  0.04280365,\n        -0.0528834 ,  0.00821877],\n       [ 0.35478091,  0.35478091,  0.52491017, ..., -0.07888933,\n        -0.1471584 , -0.15286732],\n       [ 0.31884203,  0.31884203,  0.22916411, ..., -0.11524172,\n         0.05142929,  0.14154391]])sigma(chain, draw)float641.157 1.157 ... 0.7789 0.8057array([[1.15651645, 1.15651645, 0.97782966, ..., 1.0874357 , 0.86157526,\n        0.97983836],\n       [3.01888666, 3.01888666, 2.43705693, ..., 0.96097428, 0.85124373,\n        0.83622004],\n       [0.62135292, 0.62135292, 0.65925529, ..., 1.23943536, 0.77891832,\n        0.80567313]])x(chain, draw)float64-0.1518 -0.1518 ... 0.5574 0.378array([[-0.15181112, -0.15181112,  0.13161593, ...,  0.6723258 ,\n         0.50461942,  0.46713512],\n       [-0.48976299, -0.48976299, -0.65443773, ...,  0.51419381,\n         0.37448973,  0.37021344],\n       [ 1.19734819,  1.19734819,  1.17977961, ...,  0.24801949,\n         0.55737312,  0.37795235]])Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       390, 391, 392, 393, 394, 395, 396, 397, 398, 399],\n      dtype='int64', name='draw', length=400))Attributes: (4)created_at :2024-12-21T16:44:15.473126+00:00arviz_version :0.19.0modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7\n                      \n                  \n            \n            \n            \n                  \n                  warmup_sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 102kB\nDimensions:               (chain: 3, draw: 400)\nCoordinates:\n  * chain                 (chain) int64 24B 0 1 2\n  * draw                  (draw) int64 3kB 0 1 2 3 4 5 ... 395 396 397 398 399\nData variables:\n    depth                 (chain, draw) uint64 10kB 2 0 2 1 1 3 ... 2 2 2 2 3 2\n    diverging             (chain, draw) bool 1kB False True ... False False\n    energy                (chain, draw) float64 10kB 191.2 163.4 ... 151.0 153.1\n    energy_error          (chain, draw) float64 10kB -0.388 0.0 ... -0.1098\n    index_in_trajectory   (chain, draw) int64 10kB -3 0 -1 0 0 3 ... -1 -2 2 4 1\n    logp                  (chain, draw) float64 10kB -161.4 -161.4 ... -149.8\n    maxdepth_reached      (chain, draw) bool 1kB False False ... False False\n    mean_tree_accept      (chain, draw) float64 10kB 0.0 0.9011 ... 0.8973\n    mean_tree_accept_sym  (chain, draw) float64 10kB 0.0 0.8825 ... 0.7341\n    n_steps               (chain, draw) uint64 10kB 0 3 1 3 3 2 ... 3 3 3 3 3 7\n    step_size             (chain, draw) float64 10kB 0.4 4.807 ... 0.8206 0.7726\n    step_size_bar         (chain, draw) float64 10kB 0.4 4.807 ... 0.9982 0.9953\nAttributes:\n    created_at:                  2024-12-21T16:44:15.351287+00:00\n    arviz_version:               0.19.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.1.dev17+g25798ce7xarray.DatasetDimensions:chain: 3draw: 400Coordinates: (2)chain(chain)int640 1 2array([0, 1, 2])draw(draw)int640 1 2 3 4 5 ... 395 396 397 398 399array([  0,   1,   2, ..., 397, 398, 399])Data variables: (12)depth(chain, draw)uint642 0 2 1 1 3 3 4 ... 2 2 2 2 2 2 3 2array([[2, 0, 2, ..., 3, 2, 2],\n       [0, 0, 1, ..., 2, 2, 1],\n       [1, 0, 1, ..., 2, 3, 2]], dtype=uint64)diverging(chain, draw)boolFalse True False ... False Falsearray([[False,  True, False, ..., False, False, False],\n       [ True,  True, False, ..., False, False, False],\n       [False,  True, False, ..., False, False, False]])energy(chain, draw)float64191.2 163.4 155.9 ... 151.0 153.1array([[191.23157185, 163.3622523 , 155.87676243, ..., 147.95216505,\n        149.01916812, 146.06499744],\n       [218.45924595, 218.435218  , 219.06354018, ..., 148.14110864,\n        147.31396984, 148.00554111],\n       [233.61446821, 235.48970689, 230.77783113, ..., 152.31433507,\n        150.97707215, 153.05072682]])energy_error(chain, draw)float64-0.388 0.0 ... 0.4326 -0.1098array([[-0.38801388,  0.        , -6.0389153 , ...,  0.18876166,\n        -0.39400422, -0.35352363],\n       [ 0.        ,  0.        , -0.15060317, ...,  0.        ,\n         0.38532503,  0.17671131],\n       [ 0.        ,  0.        , -2.96359591, ...,  0.80505119,\n         0.43263433, -0.10980533]])index_in_trajectory(chain, draw)int64-3 0 -1 0 0 3 -2 ... 1 -1 -2 2 4 1array([[-3,  0, -1, ..., -2,  2,  2],\n       [ 0,  0, -1, ...,  0,  2,  1],\n       [ 0,  0,  1, ...,  2,  4,  1]])logp(chain, draw)float64-161.4 -161.4 ... -150.7 -149.8array([[-161.42484484, -161.42484484, -146.39296452, ..., -146.64178206,\n        -145.5727059 , -143.8066867 ],\n       [-217.149765  , -217.149765  , -202.89830219, ..., -144.15207791,\n        -146.78757092, -147.53415198],\n       [-232.39901681, -232.39901681, -209.91185471, ..., -149.74368692,\n        -150.66260921, -149.78491734]])maxdepth_reached(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])mean_tree_accept(chain, draw)float640.0 0.9011 0.0 ... 0.4232 0.8973array([[0.00000000e+00, 9.01129289e-01, 0.00000000e+00, ...,\n        9.35045146e-01, 8.85736802e-01, 7.31982468e-01],\n       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n        9.79423660e-01, 7.90367614e-03, 8.01897720e-01],\n       [0.00000000e+00, 1.86789958e-17, 0.00000000e+00, ...,\n        8.69324456e-01, 4.23218032e-01, 8.97311135e-01]])mean_tree_accept_sym(chain, draw)float640.0 0.8825 0.0 ... 0.5942 0.7341array([[0.00000000e+00, 8.82472320e-01, 0.00000000e+00, ...,\n        9.50707393e-01, 9.35390284e-01, 7.66685919e-01],\n       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n        9.80937861e-01, 1.54448797e-02, 8.85984744e-01],\n       [0.00000000e+00, 3.73579915e-17, 0.00000000e+00, ...,\n        8.95015782e-01, 5.94161001e-01, 7.34086855e-01]])n_steps(chain, draw)uint640 3 1 3 3 2 7 15 ... 3 3 3 3 3 3 7array([[0, 3, 1, ..., 3, 7, 3],\n       [0, 1, 1, ..., 3, 3, 3],\n       [0, 1, 1, ..., 3, 3, 7]], dtype=uint64)step_size(chain, draw)float640.4 4.807 0.7703 ... 0.8206 0.7726array([[0.4       , 4.80744519, 0.77031196, ..., 0.85196682, 0.97567021,\n        0.94671178],\n       [3.2       , 7.47220733, 0.73675471, ..., 1.50641701, 0.69882598,\n        0.76323218],\n       [1.6       , 3.73610367, 0.36837736, ..., 1.00034356, 0.82058261,\n        0.77257902]])step_size_bar(chain, draw)float640.4 4.807 1.618 ... 0.9982 0.9953array([[0.4       , 4.80744519, 1.61829328, ..., 1.04153154, 1.04076395,\n        1.03965408],\n       [3.2       , 7.47220733, 1.88452898, ..., 1.03173717, 1.02720186,\n        1.02376404],\n       [1.6       , 3.73610367, 0.94226449, ..., 1.00040703, 0.99816802,\n        0.99528607]])Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       390, 391, 392, 393, 394, 395, 396, 397, 398, 399],\n      dtype='int64', name='draw', length=400))Attributes: (4)created_at :2024-12-21T16:44:15.351287+00:00arviz_version :0.19.0modeling_interface :bambimodeling_interface_version :0.14.1.dev17+g25798ce7",
    "crumbs": [
      "Examples",
      "Alternative sampling backends",
      "Alternative sampling backends"
    ]
  },
  {
    "objectID": "notebooks/alternative_samplers.html#sampler-comparisons",
    "href": "notebooks/alternative_samplers.html#sampler-comparisons",
    "title": "Alternative sampling backends",
    "section": "Sampler comparisons",
    "text": "Sampler comparisons\nWith ArviZ, we can compare the inference result summaries of the samplers. Note: We can’t use az.compare as not each inference data object returns the pointwise log-probabilities. Thus, an error would be raised.\n\naz.summary(blackjax_nuts_idata)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-0.000\n0.097\n-0.180\n0.183\n0.003\n0.003\n938.0\n752.0\n1.0\n\n\nsigma\n0.987\n0.073\n0.859\n1.126\n0.002\n0.002\n913.0\n739.0\n1.0\n\n\nx\n0.423\n0.125\n0.151\n0.629\n0.004\n0.003\n1044.0\n820.0\n1.0\n\n\n\n\n\n\n\n\naz.summary(tfp_nuts_idata)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n0.002\n0.099\n-0.183\n0.190\n0.001\n0.001\n6775.0\n5598.0\n1.0\n\n\nsigma\n0.987\n0.071\n0.848\n1.114\n0.001\n0.001\n8338.0\n5715.0\n1.0\n\n\nx\n0.424\n0.127\n0.186\n0.661\n0.002\n0.001\n6244.0\n5267.0\n1.0\n\n\n\n\n\n\n\n\naz.summary(numpyro_nuts_idata)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n0.005\n0.098\n-0.180\n0.188\n0.001\n0.001\n9065.0\n6523.0\n1.0\n\n\nsigma\n0.988\n0.074\n0.856\n1.127\n0.001\n0.001\n7217.0\n5477.0\n1.0\n\n\nx\n0.423\n0.130\n0.179\n0.661\n0.002\n0.001\n7449.0\n6203.0\n1.0\n\n\n\n\n\n\n\n\naz.summary(flowmc_idata)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n0.004\n0.101\n-0.184\n0.193\n0.002\n0.001\n2352.0\n3365.0\n1.01\n\n\nsigma\n0.987\n0.070\n0.861\n1.123\n0.001\n0.001\n4252.0\n4034.0\n1.01\n\n\nx\n0.425\n0.129\n0.171\n0.656\n0.001\n0.001\n7504.0\n3764.0\n1.01\n\n\n\n\n\n\n\n\naz.summary(nutpie_idata)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n0.002\n0.098\n-0.179\n0.181\n0.002\n0.003\n2288.0\n1040.0\n1.0\n\n\nsigma\n0.989\n0.072\n0.857\n1.118\n0.002\n0.001\n2199.0\n1155.0\n1.0\n\n\nx\n0.423\n0.128\n0.176\n0.657\n0.003\n0.002\n1956.0\n1287.0\n1.0",
    "crumbs": [
      "Examples",
      "Alternative sampling backends",
      "Alternative sampling backends"
    ]
  },
  {
    "objectID": "notebooks/alternative_samplers.html#summary",
    "href": "notebooks/alternative_samplers.html#summary",
    "title": "Alternative sampling backends",
    "section": "Summary",
    "text": "Summary\nThanks to bayeux, we can use three different sampling backends and 10+ alternative MCMC methods in Bambi. Using these methods is as simple as passing the inference name to the inference_method of the fit method.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sat Dec 21 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.27.0\n\nbambi : 0.14.1.dev17+g25798ce7\narviz : 0.19.0\npandas: 2.2.3\nnumpy : 1.26.4\n\nWatermark: 2.5.0",
    "crumbs": [
      "Examples",
      "Alternative sampling backends",
      "Alternative sampling backends"
    ]
  },
  {
    "objectID": "notebooks/categorical_regression.html",
    "href": "notebooks/categorical_regression.html",
    "title": "Categorical Regression",
    "section": "",
    "text": "In this example, we will use the categorical family to model outcomes with more than two categories. The examples in this notebook were constructed by Tomás Capretto, and assembled into this example by Tyler James Burch (@tjburch on GitHub).\nimport arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport warnings\n\nfrom matplotlib.lines import Line2D\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\nSEED = 1234\naz.style.use(\"arviz-darkgrid\")\nWhen modeling binary outcomes with Bambi, the Bernoulli family is used. The multivariate generalization of the Bernoulli family is the Categorical family, and with it, we can model an arbitrary number of outcome categories.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Categorical Regression"
    ]
  },
  {
    "objectID": "notebooks/categorical_regression.html#example-with-toy-data",
    "href": "notebooks/categorical_regression.html#example-with-toy-data",
    "title": "Categorical Regression",
    "section": "Example with toy data",
    "text": "Example with toy data\nTo start, we will create a toy dataset with three classes.\n\nrng = np.random.default_rng(SEED)\nx = np.hstack([rng.normal(m, s, size=50) for m, s in zip([-2.5, 0, 2.5], [1.2, 0.5, 1.2])])\ny = np.array([\"A\"] * 50 + [\"B\"] * 50 + [\"C\"] * 50)\n\ncolors = [\"C0\"] * 50 + [\"C1\"] * 50 + [\"C2\"] * 50\nplt.scatter(x, np.random.uniform(size=150), color=colors)\nplt.xlabel(\"x\")\nplt.ylabel(\"y\");\n\n\n\n\n\n\n\n\nHere we have 3 classes, generated from three normal distributions: \\(N(-2.5, 1.2)\\), \\(N(0, 0.5)\\), and \\(N(2.5, 1.2)\\). Creating a model to fit these distributions,\n\ndata = pd.DataFrame({\"y\": y, \"x\": x})\nmodel = bmb.Model(\"y ~ x\", data, family=\"categorical\")\nidata = model.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [Intercept, x]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 4 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nNote that we pass the family=\"categorical\" argument to Bambi’s Model method in order to call the categorical family. Here, the response variable are strings (“A”, “B”, “C”), however they can also be pd.Categorical objects.\nNext we will use posterior predictions to visualize the mean class probability across the \\(x\\) spectrum.\n\nx_new = np.linspace(-5, 5, num=200)\nmodel.predict(idata, data=pd.DataFrame({\"x\": x_new}))\np = idata.posterior[\"p\"].sel(draw=slice(0, None, 10))\n\nfor j, g in enumerate(\"ABC\"):\n   plt.plot(x_new, p.sel({\"y_dim\":g}).stack(samples=(\"chain\", \"draw\")), color=f\"C{j}\", alpha=0.2)\n\nplt.xlabel(\"x\")\nplt.ylabel(\"y\");\n\n\n\n\n\n\n\n\nHere, we can notice that the probability phases between classes from left to right. At all points across \\(x\\), sum of the class probabilities is 1, since in our generative model, it must be one of these three outcomes.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Categorical Regression"
    ]
  },
  {
    "objectID": "notebooks/categorical_regression.html#the-iris-dataset",
    "href": "notebooks/categorical_regression.html#the-iris-dataset",
    "title": "Categorical Regression",
    "section": "The iris dataset",
    "text": "The iris dataset\nNext, we will look at the classic “iris” dataset, which contains samples from 3 different species of iris plants. Using properties of the plant, we will try to model its species.\n\niris = sns.load_dataset(\"iris\")\niris.head(3)\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n\n\n\n\n\nThe dataset includes four different properties of the plants: it’s sepal length, sepal width, petal length, and petal width. There are 3 different class possibilities: setosa, versicolor, and virginica.\n\nsns.pairplot(iris, hue=\"species\");\n\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)\n\n\n\n\n\n\n\n\n\nWe can see the three species have several distinct characteristics, which our linear model can capture to distinguish between them.\n\nmodel = bmb.Model(\n    \"species ~ sepal_length + sepal_width + petal_length + petal_width\", \n    iris, \n    family=\"categorical\",\n)\nidata = model.fit()\naz.summary(idata)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [Intercept, sepal_length, sepal_width, petal_length, petal_width]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 15 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept[versicolor]\n-7.054\n7.937\n-21.843\n7.311\n0.205\n0.156\n1498.0\n1382.0\n1.0\n\n\nIntercept[virginica]\n-22.961\n9.387\n-41.590\n-6.223\n0.234\n0.169\n1603.0\n1433.0\n1.0\n\n\npetal_length[versicolor]\n1.064\n0.922\n-0.670\n2.710\n0.027\n0.021\n1172.0\n1269.0\n1.0\n\n\npetal_length[virginica]\n4.030\n1.088\n1.993\n6.133\n0.028\n0.020\n1543.0\n1350.0\n1.0\n\n\npetal_width[versicolor]\n1.926\n2.040\n-2.077\n5.427\n0.059\n0.043\n1195.0\n1092.0\n1.0\n\n\npetal_width[virginica]\n9.049\n2.263\n4.768\n13.117\n0.061\n0.043\n1365.0\n1118.0\n1.0\n\n\nsepal_length[versicolor]\n3.144\n1.717\n-0.104\n6.211\n0.053\n0.040\n1050.0\n1238.0\n1.0\n\n\nsepal_length[virginica]\n2.341\n1.734\n-0.738\n5.722\n0.054\n0.040\n1029.0\n1234.0\n1.0\n\n\nsepal_width[versicolor]\n-4.674\n1.865\n-8.205\n-1.402\n0.054\n0.038\n1183.0\n1337.0\n1.0\n\n\nsepal_width[virginica]\n-6.554\n2.272\n-10.763\n-2.217\n0.065\n0.046\n1214.0\n1283.0\n1.0\n\n\n\n\n\n\n\n\naz.plot_trace(idata);\n\n\n\n\n\n\n\n\nWe can see that this has fit quite nicely. You’ll notice there are \\(n-1\\) parameters to fit, where \\(n\\) is the number of categories. In the minimal binary case, recall there’s only one parameter set, since it models probability \\(p\\) of being in a class, and probability \\(1-p\\) of being in the other class. Using the categorical distribution, this extends, so we have \\(p_1\\) for class 1, \\(p_2\\) for class 2, and \\(1-(p_1+p_2)\\) for the final class.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Categorical Regression"
    ]
  },
  {
    "objectID": "notebooks/categorical_regression.html#using-numerical-and-categorical-predictors",
    "href": "notebooks/categorical_regression.html#using-numerical-and-categorical-predictors",
    "title": "Categorical Regression",
    "section": "Using numerical and categorical predictors",
    "text": "Using numerical and categorical predictors\nNext we will look at an example from chapter 8 of Alan Agresti’s Categorical Data Analysis, looking at the primary food choice for 64 alligators caught in Lake George, Florida. We will use their length (a continuous variable) and sex (a categorical variable) as predictors to model their food choice.\nFirst, reproducing the dataset,\n\nlength = [\n    1.3, 1.32, 1.32, 1.4, 1.42, 1.42, 1.47, 1.47, 1.5, 1.52, 1.63, 1.65, 1.65, 1.65, 1.65,\n    1.68, 1.7, 1.73, 1.78, 1.78, 1.8, 1.85, 1.93, 1.93, 1.98, 2.03, 2.03, 2.31, 2.36, 2.46,\n    3.25, 3.28, 3.33, 3.56, 3.58, 3.66, 3.68, 3.71, 3.89, 1.24, 1.3, 1.45, 1.45, 1.55, 1.6, \n    1.6, 1.65, 1.78, 1.78, 1.8, 1.88, 2.16, 2.26, 2.31, 2.36, 2.39, 2.41, 2.44, 2.56, 2.67, \n    2.72, 2.79, 2.84\n]\nchoice = [\n    \"I\", \"F\", \"F\", \"F\", \"I\", \"F\", \"I\", \"F\", \"I\", \"I\", \"I\", \"O\", \"O\", \"I\", \"F\", \"F\", \n    \"I\", \"O\", \"F\", \"O\", \"F\", \"F\", \"I\", \"F\", \"I\", \"F\", \"F\", \"F\", \"F\", \"F\", \"O\", \"O\", \n    \"F\", \"F\", \"F\", \"F\", \"O\", \"F\", \"F\", \"I\", \"I\", \"I\", \"O\", \"I\", \"I\", \"I\", \"F\", \"I\", \n    \"O\", \"I\", \"I\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"O\", \"F\", \"I\", \"F\", \"F\"\n]\n\nsex = [\"Male\"] * 32 + [\"Female\"] * 31\ndata = pd.DataFrame({\"choice\": choice, \"length\": length, \"sex\": sex})\ndata[\"choice\"]  = pd.Categorical(\n    data[\"choice\"].map({\"I\": \"Invertebrates\", \"F\": \"Fish\", \"O\": \"Other\"}), \n    [\"Other\", \"Invertebrates\", \"Fish\"], \n    ordered=True\n)\ndata.head(3)\n\n\n\n\n\n\n\n\nchoice\nlength\nsex\n\n\n\n\n0\nInvertebrates\n1.30\nMale\n\n\n1\nFish\n1.32\nMale\n\n\n2\nFish\n1.32\nMale\n\n\n\n\n\n\n\nNext, constructing the model,\n\nmodel = bmb.Model(\"choice ~ length + sex\", data, family=\"categorical\")\nidata = model.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [Intercept, length, sex]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 5 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nUsing bmb.interpret.plot_predictions, we can visualize how the probability of the different response levels varies conditional on a set of predictors. In the plot below, we visualize how the food choices vary by length for both male and female alligators. Note how estimate_dim (the response level) is mapped as the value to the group key.\n\nbmb.interpret.plot_predictions(\n    model,\n    idata,\n    [\"length\", \"sex\"],\n    subplot_kwargs={\"main\": \"length\", \"group\": \"estimate_dim\", \"panel\": \"sex\"},\n    fig_kwargs={\"figsize\": (12, 4)},\n    legend=True\n);\n\nDefault computed for conditional variable: length, sex\n\n\n\n\n\n\n\n\n\nHere we can see that the larger male and female alligators are, the less of a taste they have for invertebrates, and far prefer fish. Additionally, males seem to have a higher propensity to consume “other” foods compared to females at any size. Of note, the posterior means predicted by Bambi contain information about all \\(n\\) categories (despite having only \\(n-1\\) coefficients), so we can directly construct this plot, rather than manually calculating \\(1-(p_1+p_2)\\) for the third class.\nLast, we can make a posterior predictive plot,\n\nmodel.predict(idata, kind=\"pps\")\n\nax = az.plot_ppc(idata)\nax.set_xticks([0.5, 1.5, 2.5])\nax.set_xticklabels(model.response_component.term.levels)\nax.set_xlabel(\"Choice\");\nax.set_ylabel(\"Probability\");\n\n\n\n\n\n\n\n\nwhich depicts posterior predicted probability for each possible food choice for an alligator, which reinforces fish being the most likely food choice, followed by invertebrates.\n\nReferences\nAgresti, A. (2013) Categorical Data Analysis. 3rd Edition, John Wiley & Sons Inc., Hoboken.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sat May 25 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\nbambi     : 0.13.1.dev37+g2a54df76.d20240525\npandas    : 2.2.2\narviz     : 0.18.0\nmatplotlib: 3.8.4\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Categorical Regression"
    ]
  },
  {
    "objectID": "notebooks/count_roaches.html",
    "href": "notebooks/count_roaches.html",
    "title": "Count Regression with Variable Exposure",
    "section": "",
    "text": "import arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom scipy.stats import nbinom\naz.style.use(\"arviz-darkgrid\")\nSEED = 7355608\nThis example is based on the “Roaches” example from Regression and Other Stories by Gelman, Hill, and Vehtari. The example is a count regression model with an offset term.\nThe data is the number of roaches caught in 262 apartments. Some pest control treatment was applied to 158 (treatment=1) of the apartments, and 104 apartments received no treatment (treatment=0). The other columns in the data are:\nroaches = pd.read_csv(\"data/roaches.csv\", index_col=0)\n# rescale \nroaches[\"roach1\"] = roaches[\"roach1\"] / 100\nroaches.head()\n\n\n\n\n\n\n\n\ny\nroach1\ntreatment\nsenior\nexposure2\n\n\n\n\n1\n153\n3.0800\n1\n0\n0.800000\n\n\n2\n127\n3.3125\n1\n0\n0.600000\n\n\n3\n7\n0.0167\n1\n0\n1.000000\n\n\n4\n7\n0.0300\n1\n0\n1.000000\n\n\n5\n0\n0.0200\n1\n0\n1.142857",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Count Regression with Variable Exposure"
    ]
  },
  {
    "objectID": "notebooks/count_roaches.html#poisson-regression",
    "href": "notebooks/count_roaches.html#poisson-regression",
    "title": "Count Regression with Variable Exposure",
    "section": "Poisson regression",
    "text": "Poisson regression\nOne way to model this is to say that there is some rate of roaches per trap-day , and that the number of roaches caught is a Poisson random variable with a rate that is proportional to the number of trap-days (the exposure). That is:\n\\[\n\\begin{align*}\ny_i &\\sim \\text{Poisson}(\\text{exposure2}_i \\times \\rho_i) \\\\\n\\log(\\rho_i) &= \\beta_0 + \\beta_1 \\text{treatment}_i + \\beta_2 \\text{roach1}_i + \\beta_3 \\text{senior}_i\n\\end{align*}\n\\]\nWith a little algebra, we can rewrite this as a generalized linear model:\n\\[\n\\begin{align*}\ny_i &\\sim \\text{Poisson}(\\lambda_i) \\\\\n\\log(\\lambda_i) &= \\beta_0 + \\beta_1 \\text{treatment}_i + \\beta_2 \\text{roach1}_i + \\beta_3 \\text{senior}_i + \\log(\\text{exposure2}_i)\n\\end{align*}\n\\]\nHowever, we don’t want to estimate a coefficient for \\(\\log(\\text{exposure2})\\), we want to simply add it as an offset. In bambi we do this by using the offset function in the formula to specify that a term should not be multiplied by a coefficient to estimate and simply added. The formula for the model is then:\n\"y ~ roach1 + treatment + senior + offset(log(exposure2))\"\nIf you are familiar with R this offset term is the same as the offset term in the glm function.\n\n\n# bambi poisson model\nmodel_1 = bmb.Model(\"y ~ roach1 + treatment  + senior + offset(log(exposure2))\", family = \"poisson\", data = roaches)\nidata_1 = model_1.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Intercept, roach1, treatment, senior]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 18 seconds.\n\n\n\naz.summary(idata_1)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n3.089\n0.020\n3.052\n3.128\n0.000\n0.0\n4436.0\n3676.0\n1.0\n\n\nroach1\n0.698\n0.009\n0.681\n0.714\n0.000\n0.0\n3891.0\n3221.0\n1.0\n\n\nsenior\n-0.381\n0.032\n-0.442\n-0.321\n0.001\n0.0\n3889.0\n3001.0\n1.0\n\n\ntreatment\n-0.517\n0.024\n-0.566\n-0.474\n0.000\n0.0\n4742.0\n3310.0\n1.0\n\n\n\n\n\n\n\nThe sampling seems to have gone well based on ess and r_hat. If this were a real analysis one would also need to check priors, trace plots and other diagnostics. However, lets see if the model predicts the distribution of roaches (y) observed. We can do this by looking at the posterior predictive distribution for the model. We plot the log of y to make the results easier to see.\n\ndef plot_log_posterior_ppc(model, idata):\n    # plot posterior predictive check\n    model.predict(idata, kind='response', inplace=True)\n    var_name = 'log(y+1)'\n    # there is probably a better way\n    idata.posterior_predictive[var_name] = np.log(idata.posterior_predictive['y'] + 1)\n    idata.observed_data[var_name] = np.log(idata.observed_data['y'] + 1)\n    \n    return az.plot_ppc(idata, var_names=[var_name])\n\n\n\nplot_log_posterior_ppc(model_1, idata_1)\n\n\n\n\n\n\n\n\nIt appears that we are drastically under predicting the number of apartments with a small number of roaches. This suggests creating a test statistic measuring the fraction of zeros, both in the observed data and in the simulated replications (posterior predictions). We can then use this to check the model fit.\n\n# check number of zeros in y\n\ndef check_zeros(idata):\n    # flatten over chains:\n    sampled_zeros = (idata.posterior_predictive[\"y\"]==0).mean((\"__obs__\")).values.flatten()\n    print(f\"Fraction of zeros in the observed data: {np.mean(roaches['y']==0)}\")\n    print(f\"Fraction of zeros in the posterior predictive check: {np.mean(sampled_zeros)}\")\n    print(f\" 80% CI: {np.percentile(sampled_zeros, [10, 90])}\")\n\ncheck_zeros(idata_1)\n \n\nFraction of zeros in the observed data: 0.35877862595419846\nFraction of zeros in the posterior predictive check: 0.0007022900763358779\n 80% CI: [0.         0.00381679]\n\n\nThe Poisson model here does not succeed in reproducing the observed fraction of zeros. In the data we have about 36% zeros, while in the replications we almost always have no zeros or very few. Gelman, Hill, and Vehtari suggest we try an overdispersed and more flexible model like the negative binomial.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Count Regression with Variable Exposure"
    ]
  },
  {
    "objectID": "notebooks/count_roaches.html#negative-binomial-fit",
    "href": "notebooks/count_roaches.html#negative-binomial-fit",
    "title": "Count Regression with Variable Exposure",
    "section": "Negative Binomial Fit",
    "text": "Negative Binomial Fit\n\n# bambi poisson model\nmodel_2 = bmb.Model(\"y ~ roach1 + treatment  + senior + offset(log(exposure2))\", family = \"negativebinomial\", data = roaches)\nidata_2 = model_2.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [alpha, Intercept, roach1, treatment, senior]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 18 seconds.\n\n\n\naz.summary(idata_2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n2.855\n0.234\n2.433\n3.306\n0.003\n0.002\n5333.0\n3562.0\n1.0\n\n\nalpha\n0.272\n0.026\n0.224\n0.322\n0.000\n0.000\n5228.0\n3369.0\n1.0\n\n\nroach1\n1.326\n0.258\n0.853\n1.806\n0.004\n0.003\n4783.0\n3311.0\n1.0\n\n\nsenior\n-0.333\n0.267\n-0.824\n0.177\n0.003\n0.003\n6074.0\n3265.0\n1.0\n\n\ntreatment\n-0.787\n0.250\n-1.257\n-0.327\n0.003\n0.002\n5756.0\n3379.0\n1.0\n\n\n\n\n\n\n\n\nplot_log_posterior_ppc(model_2, idata_2)\n\n\n\n\n\n\n\n\n\n\ncheck_zeros(idata_2)\n\nFraction of zeros in the observed data: 0.35877862595419846\nFraction of zeros in the posterior predictive check: 0.338175572519084\n 80% CI: [0.28625954 0.39312977]\n\n\n\ndef plot_zeros(ax, idata, model_label, **kwargs):\n    data_zeros = np.mean(roaches['y']==0)\n    # flatten over chains:\n    sampled_zeros = (idata.posterior_predictive[\"y\"]==0).mean((\"__obs__\")).values.flatten()\n    ax.hist(sampled_zeros, alpha=0.5, **kwargs)\n    ax.axvline(data_zeros, color='red', linestyle='--')\n    ax.set_xlabel(\"Fraction of zeros\")\n    ax.set_title(f\"Model: {model_label}\")\n    ax.yaxis.set_visible(False)\n    ax.set_facecolor('white')\n    return ax\n\nfig, ax = plt.subplots(1,2, gridspec_kw={'wspace': 0.2})\nplot_zeros(ax[0],idata_1, \"Poisson\", bins= 2) # use 2 bins to make it more clear. Almost no zeros.\nplot_zeros(ax[1],idata_2, \"Negative Binomial\")\n\nfig.legend([\"Observed data\", \"Posterior predictive\"], loc='center left', bbox_to_anchor=(0.05, 0.8)) \n\n\n\n\n\n\n\n\nThe negative binomial distribution fit works much better, predicting the number of zeros consistent with the observed data.\nRegression and Other Stories introduces a further improvement by introducing a zero-inflated regression later in the chapter, but I will not persue that here, after all the point of this example is to illustrate the use of offsets.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Count Regression with Variable Exposure"
    ]
  },
  {
    "objectID": "notebooks/count_roaches.html#pymc-equivalent-model",
    "href": "notebooks/count_roaches.html#pymc-equivalent-model",
    "title": "Count Regression with Variable Exposure",
    "section": "PYMC equivalent model",
    "text": "PYMC equivalent model\nThe model behind the scenes looks like this for the Poission model.\n\npymc_model = model_1.backend\npymc_model.model\n\n\\[\n            \\begin{array}{rcl}\n            \\text{Intercept} &\\sim & \\operatorname{Normal}(0,~4.52)\\\\\\text{roach1} &\\sim & \\operatorname{Normal}(0,~3.33)\\\\\\text{treatment} &\\sim & \\operatorname{Normal}(0,~5.11)\\\\\\text{senior} &\\sim & \\operatorname{Normal}(0,~5.43)\\\\\\text{mu} &\\sim & \\operatorname{Deterministic}(f(\\text{senior},~\\text{treatment},~\\text{roach1},~\\text{Intercept}))\\\\\\text{y} &\\sim & \\operatorname{Poisson}(\\text{mu})\n            \\end{array}\n            \\]\n\n\nLet’s look at the equivalent (Poisson) model in PYMC:\n\n# recreate the model using pymc\nimport pymc as pm\nwith pm.Model() as model_pymc:\n    # priors\n    alpha = pm.Normal(\"Intercept\", mu=0, sigma=4.5)\n    beta_roach1 = pm.Normal(\"beta_roach1\", mu=0, sigma=3.3)\n    beta_treatment = pm.Normal(\"beta_treatment\", mu=0, sigma=5.11)\n    beta_senior = pm.Normal(\"beta_senior\", mu=0, sigma=5.43)\n    \n    # likelihood\n    mu = pm.math.exp(alpha + beta_roach1 * roaches[\"roach1\"] +\n                             beta_treatment * roaches[\"treatment\"] +\n                             beta_senior * roaches[\"senior\"] +\n                             pm.math.log(roaches[\"exposure2\"])) # no beta for exposure2 \n    y = pm.Poisson(\"y\", mu=mu, observed=roaches[\"y\"])\n\n    idata_pymc = pm.sample(1000)  \n\naz.summary(idata_pymc)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Intercept, beta_roach1, beta_treatment, beta_senior]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 18 seconds.\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n3.089\n0.022\n3.049\n3.131\n0.000\n0.0\n2079.0\n2250.0\n1.0\n\n\nbeta_roach1\n0.698\n0.009\n0.681\n0.715\n0.000\n0.0\n2756.0\n2731.0\n1.0\n\n\nbeta_senior\n-0.380\n0.033\n-0.444\n-0.318\n0.001\n0.0\n3018.0\n2363.0\n1.0\n\n\nbeta_treatment\n-0.517\n0.025\n-0.565\n-0.469\n0.001\n0.0\n2520.0\n2340.0\n1.0\n\n\n\n\n\n\n\nIn this model (model_pymc) we have the equivalent Poisson regression with everything explicit to illustrate what the ‘offset’ function is doing. It simply makes it possible to express a term like this in the formulae string in a bambi model.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Count Regression with Variable Exposure"
    ]
  },
  {
    "objectID": "notebooks/getting_started.html",
    "href": "notebooks/getting_started.html",
    "title": "Getting Started",
    "section": "",
    "text": "Bambi requires a working Python interpreter (3.10+). We recommend installing Python and key numerical libraries using the Anaconda Distribution, which has one-click installers available on all major platforms.\nAssuming a standard Python environment is installed on your machine (including pip), Bambi itself can be installed in one line using pip:\nAlternatively, if you want the bleeding edge version of the package, you can install from GitHub:"
  },
  {
    "objectID": "notebooks/getting_started.html#quickstart",
    "href": "notebooks/getting_started.html#quickstart",
    "title": "Getting Started",
    "section": "Quickstart",
    "text": "Quickstart\nSuppose we have data for a typical within-subjects psychology experiment with 2 experimental conditions. Stimuli are nested within condition, and subjects are crossed with condition. We want to fit a model predicting reaction time (RT) from the common effect of condition, group specific intercepts for subjects, group specific condition slopes for students, and group specific intercepts for stimuli. Using Bambi we can fit this model and summarize its results as follows:\nimport bambi as bmb\n\n# Assume we already have our data loaded as a pandas DataFrame\nmodel = bmb.Model(\"rt ~ condition + (condition|subject) + (1|stimulus)\", data)\nresults = model.fit(draws=5000, chains=2)\naz.plot_trace(results)\naz.summary(results)"
  },
  {
    "objectID": "notebooks/getting_started.html#user-guide",
    "href": "notebooks/getting_started.html#user-guide",
    "title": "Getting Started",
    "section": "User Guide",
    "text": "User Guide\n\nSetup\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n\nimport arviz as az\nimport bambi as bmb\nimport numpy as np\nimport pandas as pd\n\n\naz.style.use(\"arviz-darkgrid\")\n\n\n\nCreating a model\nCreating a new model in Bambi is simple:\n\n# Read in a tab-delimited file containing our data\ndata = pd.read_table(\"data/my_data.txt\", sep=\"\\t\")\n\n# Initialize the model\nmodel = bmb.Model(\"y ~ x + z\", data)\n\n# Inspect model object\nmodel\n\n       Formula: y ~ x + z\n        Family: gaussian\n          Link: mu = identity\n  Observations: 50\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 0.1852, sigma: 2.5649)\n            x ~ Normal(mu: 0.0, sigma: 2.231)\n            z ~ Normal(mu: 0.0, sigma: 2.4374)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 1.013)\n\n\nTypically, we will initialize a Bambi Model by passing it a model formula and a pandas DataFrame. Other arguments such as family, priors, and link are available. By default, it uses family=\"gaussian\" which implies a linear regression with normal error. We get back a model that we can immediately fit by calling model.fit().\n\n\nData format\nAs with most mixed effect modeling packages, Bambi expects data in “long” format–meaning that each row should reflects a single observation at the most fine-grained level of analysis. For example, given a model where students are nested into classrooms and classrooms are nested into schools, we would want data with the following kind of structure:\n\n\n\n\nstudent\ngender\ngpa\nclass\nschool\n\n\n\n\n1\nF\n3.4\n1\n1\n\n\n2\nF\n3.7\n1\n1\n\n\n3\nM\n2.2\n1\n1\n\n\n4\nF\n3.9\n2\n1\n\n\n5\nM\n3.6\n2\n1\n\n\n6\nM\n3.5\n2\n1\n\n\n7\nF\n2.8\n3\n2\n\n\n8\nM\n3.9\n3\n2\n\n\n9\nF\n4.0\n3\n2"
  },
  {
    "objectID": "notebooks/getting_started.html#formula-based-specification",
    "href": "notebooks/getting_started.html#formula-based-specification",
    "title": "Getting Started",
    "section": "Formula-based specification",
    "text": "Formula-based specification\nModels are specified in Bambi using a formula-based syntax similar to what one might find in R packages like lme4 or brms using the Python formulae library. A couple of examples illustrate the breadth of models that can be easily specified in Bambi:\n\ndata = pd.read_csv(\"data/rrr_long.csv\")\ndata.head(10)\n\n\n\n\n\n\n\n\nuid\ncondition\ngender\nage\nstudy\nself_perf\nstimulus\nvalue\n\n\n\n\n0\n1.0\n0.0\n1.0\n24.0\n0.0\n8.0\nrating_c1\n3.0\n\n\n1\n2.0\n1.0\n0.0\n27.0\n0.0\n9.0\nrating_c1\n7.0\n\n\n2\n3.0\n0.0\n1.0\n25.0\n0.0\n3.0\nrating_c1\n5.0\n\n\n3\n5.0\n0.0\n1.0\n20.0\n0.0\n3.0\nrating_c1\n7.0\n\n\n4\n8.0\n1.0\n1.0\n19.0\n0.0\n6.0\nrating_c1\n6.0\n\n\n5\n9.0\n0.0\n1.0\n22.0\n0.0\n3.0\nrating_c1\n6.0\n\n\n6\n10.0\n1.0\n1.0\n49.0\n0.0\n4.0\nrating_c1\n6.0\n\n\n7\n11.0\n0.0\n0.0\n24.0\n0.0\n5.0\nrating_c1\n7.0\n\n\n8\n12.0\n1.0\n0.0\n26.0\n0.0\n6.0\nrating_c1\n2.0\n\n\n9\n13.0\n0.0\n1.0\n23.0\n0.0\n7.0\nrating_c1\n1.0\n\n\n\n\n\n\n\n\n# Number of rows with missing values\ndata.isna().any(axis=1).sum()\n\n401\n\n\nWe pass dropna=True to tell Bambi to drop rows containing missing values. The number of rows dropped is different from the number of rows with missing values because Bambi only considers columns involved in the model.\n\n# Common (or fixed) effects only\nbmb.Model(\"value ~ condition + age + gender\", data, dropna=True)\n\nAutomatically removing 33/6940 rows from the dataset.\n\n\n       Formula: value ~ condition + age + gender\n        Family: gaussian\n          Link: mu = identity\n  Observations: 6907\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 4.5457, sigma: 28.4114)\n            condition ~ Normal(mu: 0.0, sigma: 12.0966)\n            age ~ Normal(mu: 0.0, sigma: 1.3011)\n            gender ~ Normal(mu: 0.0, sigma: 13.1286)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 2.4186)\n\n\n\n# Common effects and group specific (or random) intercepts for subject\nbmb.Model(\"value ~ condition + age + gender + (1|uid)\", data, dropna=True)\n\nAutomatically removing 33/6940 rows from the dataset.\n\n\n       Formula: value ~ condition + age + gender + (1|uid)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 6907\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 4.5457, sigma: 28.4114)\n            condition ~ Normal(mu: 0.0, sigma: 12.0966)\n            age ~ Normal(mu: 0.0, sigma: 1.3011)\n            gender ~ Normal(mu: 0.0, sigma: 13.1286)\n        \n        Group-level effects\n            1|uid ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 28.4114))\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 2.4186)\n\n\n\n# Multiple, complex group specific effects with both\n# group specific slopes and group specific intercepts\nbmb.Model(\n    \"value ~ condition + age + gender + (1|uid) + (condition|study) + (condition|stimulus)\", \n    data, \n    dropna=True\n)\n\nAutomatically removing 33/6940 rows from the dataset.\n\n\n       Formula: value ~ condition + age + gender + (1|uid) + (condition|study) + (condition|stimulus)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 6907\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 4.5457, sigma: 28.4114)\n            condition ~ Normal(mu: 0.0, sigma: 12.0966)\n            age ~ Normal(mu: 0.0, sigma: 1.3011)\n            gender ~ Normal(mu: 0.0, sigma: 13.1286)\n        \n        Group-level effects\n            1|uid ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 28.4114))\n            1|study ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 28.4114))\n            condition|study ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 12.0966))\n            1|stimulus ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 28.4114))\n            condition|stimulus ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 12.0966))\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 2.4186)\n\n\nEach of the above examples specifies a full model that can be fitted using PyMC by doing\nresults = model.fit()\n\nCoding of categorical variables\nWhen a categorical common effect with N levels is added to a model, by default, it is coded by N-1 dummy variables (i.e., reduced-rank coding). For example, suppose we write \"y ~ condition + age + gender\", where condition is a categorical variable with 4 levels, and age and gender are continuous variables. Then our model would contain an intercept term (added to the model by default, as in R), three dummy-coded variables (each contrasting the first level of condition with one of the subsequent levels), and continuous predictors for age and gender. Suppose, however, that we would rather use full-rank coding of conditions. If we explicitly remove the intercept –as in \"y ~ 0 + condition + age + gender\"– then we get the desired effect. Now, the intercept is no longer included, and condition will be coded using 4 dummy indicators, each one coding for the presence or absence of the respective condition without reference to the other conditions.\nGroup specific effects are handled in a comparable way. When adding group specific intercepts, coding is always full-rank (e.g., when adding group specific intercepts for 100 schools, one gets 100 dummy-coded indicators coding each school separately, and not 99 indicators contrasting each school with the very first one). For group specific slopes, coding proceeds the same way as for common effects. The group specific effects specification \"(condition|subject)\" would add an intercept for each subject, plus N-1 condition slopes (each coded with respect to the first, omitted, level as the referent). If we instead specify \"(0+condition|subject)\", we get N condition slopes and no intercepts.\n\n\nFitting the model\nOnce a model is fully specified, we need to run the PyMC sampler to generate parameter estimates. If we’re using the one-line fit() interface, sampling will begin right away:\n\nmodel = bmb.Model(\"value ~ condition + age + gender + (1|uid)\", data, dropna=True)\nresults = model.fit()\n\nAutomatically removing 33/6940 rows from the dataset.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, condition, age, gender, 1|uid_sigma, 1|uid_offset]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 49 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nThe above code obtains 1,000 draws (the default value) and return them as an InferenceData instance.\n\n\n\n\n\n\nTip\n\n\n\nInferenceData is a rich data structure to store and manipulate data such as posterior samples, prior/posterior predictive samples, observations, etc. It is based on xarray, a library offering N-dimensional labeled arrays (you can think of it as a generalization of both Numpy arrays and Pandas dataframes). To learn how to perform common operations with InferenceData, like indexing, selection etc please check this and for details of the InferenceData Schema see this specification.\n\n\nIn this case, the fit() method accepts optional keyword arguments to pass onto PyMC’s sample() method, so any methods accepted by sample() can be specified here. We can also explicitly set the number of draws via the draws argument. For example, if we call fit(draws=2000, chains=2), the PyMC sampler will sample two chains in parallel, drawing 2,000 draws for each one. We could also specify starting parameter values, the step function to use, and so on (for full details, see the PyMC documentation).\nAlternatively, we can build a model, but not fit it.\n\nmodel = bmb.Model(\"value ~ condition + age + gender + (1|uid)\", data, dropna=True)\nmodel.build()\n\nAutomatically removing 33/6940 rows from the dataset.\n\n\nBuilding without sampling can be useful if we want to inspect the internal PyMC model before we start the (potentially long) sampling process. Once we’re satisfied, and wish to run the sampler, we can then simply call model.fit(), and the sampler will start running. Another good reason to build a model is to generate plot of the marginal priors using model.plot_priors().\n\nmodel.plot_priors();\n\nSampling: [1|uid_sigma, Intercept, age, condition, gender, sigma]"
  },
  {
    "objectID": "notebooks/getting_started.html#specifying-priors",
    "href": "notebooks/getting_started.html#specifying-priors",
    "title": "Getting Started",
    "section": "Specifying priors",
    "text": "Specifying priors\nBayesian inference requires one to specify prior probability distributions that represent the analyst’s belief (in advance of seeing the data) about the likely values of the model parameters. In practice, analysts often lack sufficient information to formulate well-defined priors, and instead opt to use “weakly informative” priors that mainly serve to keep the model from exploring completely pathological parts of the parameter space (e.g., when defining a prior on the distribution of human heights, a value of 3,000 cms should be assigned a probability of exactly 0).\nBy default, Bambi will intelligently generate weakly informative priors for all model terms, by loosely scaling them to the observed data. Currently, Bambi uses a methodology very similar to the one described in the documentation of the R package rstanarm. While the default priors will behave well in most typical settings, there are many cases where an analyst will want to specify their own priors–and in general, when informative priors are available, it’s a good idea to use them.\nFortunately, Bambi is built on top of PyMC, which means that we can seamlessly use any of the over 40 Distribution classes defined in PyMC. We can specify such priors in Bambi using the Prior class, which initializes with a name argument (which must map on exactly to the name of a valid PyMC Distribution) followed by any of the parameters accepted by the corresponding distribution. For example:\n\n# A Laplace prior with mean of 0 and scale given by a HalfNormal with a scale of 1\nmy_favorite_prior = bmb.Prior(\"Laplace\", mu=0, b=bmb.Prior(\"HalfNormal\", sigma=1))\n\n# Set the prior when adding a term to the model; more details on this below.\npriors = {\"1|uid\": my_favorite_prior}\nbmb.Model(\"value ~ condition + (1|uid)\", data, priors=priors, dropna=True)\n\nAutomatically removing 9/6940 rows from the dataset.\n\n\n       Formula: value ~ condition + (1|uid)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 6931\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 4.5516, sigma: 8.4548)\n            condition ~ Normal(mu: 0.0, sigma: 12.1019)\n        \n        Group-level effects\n            1|uid ~ Laplace(mu: 0.0, b: HalfNormal(sigma: 1.0))\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 2.4197)\n\n\nPriors specified using the Prior class can be nested to arbitrary depths–meaning, we can set any of a given prior’s argument to point to another Prior instance. This is particularly useful when specifying hierarchical priors on group specific effects, where the individual group specific slopes or intercepts are constrained to share a common source distribution:\n\nsubject_sd = bmb.Prior(\"HalfCauchy\", beta=5)\nsubject_prior = bmb.Prior(\"Normal\", mu=0, sd=subject_sd)\npriors = {\"1|uid\": subject_prior}\nbmb.Model(\"value ~ condition + (1|uid)\", data, priors=priors, dropna=True)\n\nAutomatically removing 9/6940 rows from the dataset.\n\n\n       Formula: value ~ condition + (1|uid)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 6931\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 4.5516, sigma: 8.4548)\n            condition ~ Normal(mu: 0.0, sigma: 12.1019)\n        \n        Group-level effects\n            1|uid ~ Normal(mu: 0.0, sd: HalfCauchy(beta: 5.0))\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 2.4197)\n\n\nThe above prior specification indicates that the individual subject intercepts are to be treated as if they are randomly sampled from the same underlying normal distribution, where the variance of that normal distribution is parameterized by a separate hyperprior (a half-cauchy with beta = 5).\nIt’s important to note that explicitly setting priors by passing in Prior objects will disable Bambi’s default behavior of scaling priors to the data in order to ensure that they remain weakly informative. This means that if you specify your own prior, you have to be sure not only to specify the distribution you want, but also any relevant scale parameters. For example, the 0.5 in Prior(\"Normal\", mu=0, sd=0.5) will be specified on the scale of the data, not the bounded partial correlation scale that Bambi uses for default priors. This means that if your outcome variable has a mean value of 10,000 and a standard deviation of, say, 1,000, you could potentially have some problems getting the model to produce reasonable estimates, since from the perspective of the data, you’re specifying an extremely strong prior.\n\nCustom Prior\nBambi’s priors are a thin layer on top of PyMC distributions. If you want to ask for a prior distribution by name, it must be the name of a PyMC distribution. But sometimes we want to use more complex distributions as priors. For all those cases, Bambi’s Prior class allow users to pass a function that returns a distribution that will be used as the prior. See the following example:\ndef CustomPrior(name, *args, dims=None, **kwargs):\n    return pm.Normal(name, *args, dims=dims, **kwargs)\n\npriors = {\"x\": Prior(\"CustomPrior\", mu=0, sigma=5, dist=CustomPrior)}\nmodel = Model(\"y ~ x\", data, priors=priors)\nThe example above is trival because it’s just a wrapper of the pm.Normal distribution. But we can use this pattern to construct more complex distributions, such as a Truncated Laplace distribution shown below.\ndef TruncatedLaplace(name, mu,b,lower,upper,*args, dims=None, **kwargs):\n    lap_dist = pm.Laplace.dist(mu=mu, b=b)\n    return pm.Truncated(name, lap_dist, lower=lower, upper=upper, *args, dims=dims, **kwargs)\nIn summary, custom priors allow for greater flexibility by combining existing PyMC distributions in different ways. If you need to use a distribution that’s not implemented in PyMC, please check the link for further details."
  },
  {
    "objectID": "notebooks/getting_started.html#generalized-linear-mixed-models",
    "href": "notebooks/getting_started.html#generalized-linear-mixed-models",
    "title": "Getting Started",
    "section": "Generalized linear mixed models",
    "text": "Generalized linear mixed models\nBambi supports the construction of mixed models with non-normal response distributions (i.e., generalized linear mixed models, or GLMMs). GLMMs are specified in the same way as LMMs, except that the user must specify the distribution to use for the response, and (optionally) the link function with which to transform the linear model prediction into the desired non-normal response. The easiest way to construct a GLMM is to simple set the family when creating the model:\n\ndata = bmb.load_data(\"admissions\")\nmodel = bmb.Model(\"admit ~ gre + gpa + rank\", data, family=\"bernoulli\")\nresults = model.fit()\n\nModeling the probability that admit==1\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [Intercept, gre, gpa, rank]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 36 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nIf no link argument is explicitly set (see below), the canonical link function (or an otherwise sensible default) will be used."
  },
  {
    "objectID": "notebooks/getting_started.html#families",
    "href": "notebooks/getting_started.html#families",
    "title": "Getting Started",
    "section": "Families",
    "text": "Families\nFollowing the convention used in many R packages, the response distribution to use for a GLMM is specified in a Family class that indicates how the response variable is distributed, as well as the link function transforming the linear response to a non-linear one.\nThe following table summarizes the currently available families and their associated links:\n\n\n\n\nFamily name\nResponse distribution\nDefault link\nExample notebook\n\n\n\n\nasymmetriclaplace\nAsymmetricLaplace\nidentity\nQuantile Regression\n\n\nbernoulli\nBernoulli\nlogit\nLogistic Regression\n\n\nbeta\nBeta\nlogit\nBeta Regression\n\n\nbeta_binomial\nBetaBinomial\nlogit\nTo be added\n\n\nbinomial\nBinomial\nlogit\nHierarchical Logistic Regression\n\n\ncategorical\nCategorical\nsoftmax\nCategorical Regression\n\n\ncumulative\nCumulative\nlogit\nOrdinal Models\n\n\ndirichlet_multinomial\nDirichletMultinomial\nlogit\nTo be added\n\n\nexponential\nExponential\nlog\nSurvival Models\n\n\ngamma\nGamma\ninverse\nGamma Regression\n\n\ngaussian\nNormal\nidentity\nMultiple Linear Regression\n\n\nhurdle_gamma\nHurdleGamma\nlog\nTo be added\n\n\nhurdle_lognormal\nHurdleLogNormal\nidentity\nTo be added\n\n\nhurdle_negativebinomial\nHurdleNegativeBinomial\nlog\nTo be added\n\n\nhurdle_poisson\nHurdlePoisson\nlog\nHurdle Poisson Regression\n\n\nmultinomial\nMultinomial\nsoftmax\nTo be added\n\n\nnegativebinomial\nNegativeBinomial\nlog\nNegative Binomial Regression\n\n\nlaplace\nLaplace\nidentity\nTo be added\n\n\npoisson\nPoisson\nlog\nGaussian Processes with a Poisson likelihood\n\n\nsratio\nStoppingRatio\nlogit\nOrdinal Models\n\n\nt\nStudentT\nidentity\nRobust Linear Regression\n\n\nvonmises\nVonMises\ntan(x / 2)\nCircular Regression\n\n\nwald\nInverseGaussian\ninverse squared\nWald Regression\n\n\nweibull\nWeibull\nlog\nTo be added\n\n\nzero_inflated_binomial\nZeroInflatedBinomial\nlogit\nTo be added\n\n\nzero_inflated_negativebinomial\nZeroInflatedNegativeBinomial\nlog\nTo be added\n\n\nzero_inflated_poisson\nZeroInflatedPoisson\nlog\nZero Inflated Poisson Regression\n\n\n\n\nAlthough the easiest way to specify a family is by name, using one of the options listed in the table above, users can also create and use their own family, providing enormous flexibility. In the following example, we show how the built-in Bernoulli family could be constructed on-the-fly:\n\nfrom scipy import special\n\n# Construct likelihood distribution ------------------------------\n# This must use a valid PyMC distribution name.\n# 'parent' is the name of the variable that represents the mean of the distribution. \n# The mean of the Bernoulli family is given by 'p'.\nlikelihood = bmb.Likelihood(\"Bernoulli\", parent=\"p\")\n\n# Set link function ----------------------------------------------\n# There are two alternative approaches.\n# 1. Pass a name that is known by Bambi\nlink = bmb.Link(\"logit\")\n\n# 2. Build everything from scratch\n# link: A function that maps the response to the linear predictor\n# linkinv: A function that maps the linear predictor to the response\n# linkinv_backend: A function that maps the linear predictor to the response\n#                  that works with PyTensor tensors.\n#                  bmb.math.sigmoid is a PyTensor tensor function wrapped by PyMC and Bambi \nlink = bmb.Link(\n    \"my_logit\", \n    link=special.logit,\n    linkinv=special.expit,\n    linkinv_backend=bmb.math.sigmoid\n)\n\n# Construct the family -------------------------------------------\n# Families are defined by a name, a Likelihood and a Link.\nfamily = bmb.Family(\"bernoulli\", likelihood, link)\n\n# Now it's business as usual\n# Note: 'gre' is standardized to mean 0 and variance 1\nmodel = bmb.Model(\"admit ~ scale(gre) + gpa + rank\", data, family=family)\nmodel.build()\nmodel.graph()\n\n\n\n\n\n\n\n\n\nresults = model.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [Intercept, scale(gre), gpa, rank]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 5 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nThe above example produces results identical to simply setting family='bernoulli'.\nOne complication in specifying a custom Family is that one must pass both a link function and an inverse link function which must be able to operate over PyTensor tensors rather than numpy arrays, so you’ll probably need to rely on tensor operations provided in pytensor.tensor (many of which are also wrapped by PyMC) when defining a new link."
  },
  {
    "objectID": "notebooks/getting_started.html#results",
    "href": "notebooks/getting_started.html#results",
    "title": "Getting Started",
    "section": "Results",
    "text": "Results\nWhen a model is fitted, it returns a InferenceData object containing data related to the model and the posterior. This object can be passed to many functions in ArviZ to obtain numerical and visuals diagnostics and plot in general."
  },
  {
    "objectID": "notebooks/getting_started.html#plotting",
    "href": "notebooks/getting_started.html#plotting",
    "title": "Getting Started",
    "section": "Plotting",
    "text": "Plotting\nTo visualize a plot of the posterior estimates and sample traces for all parameters, simply pass the InferenceData object to the arviz function az._plot_trace:\n\naz.plot_trace(results, compact=False);\n\n\n\n\n\n\n\n\nMore details on this plot are available in the ArviZ documentation."
  },
  {
    "objectID": "notebooks/getting_started.html#summarizing",
    "href": "notebooks/getting_started.html#summarizing",
    "title": "Getting Started",
    "section": "Summarizing",
    "text": "Summarizing\nIf you prefer numerical summaries of the posterior estimates, you can use the az.summary() function from ArviZ which provides a pandas DataFrame with some key summary and diagnostics info on the model parameters, such as the 94% highest posterior density intervals\n\naz.summary(results)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-2.125\n1.153\n-4.117\n0.110\n0.023\n0.017\n2528.0\n1716.0\n1.0\n\n\ngpa\n0.785\n0.327\n0.173\n1.402\n0.007\n0.005\n2503.0\n1817.0\n1.0\n\n\nrank\n-0.567\n0.125\n-0.787\n-0.329\n0.003\n0.002\n1801.0\n1473.0\n1.0\n\n\nscale(gre)\n0.268\n0.132\n0.011\n0.498\n0.003\n0.002\n2480.0\n1526.0\n1.0\n\n\n\n\n\n\n\nIf you want to view summaries or plots for specific parameters, you can pass a list of its names:\n\n# show the names of all variables stored in the InferenceData object\nlist(results.posterior.data_vars)\n\n['Intercept', 'gpa', 'rank', 'scale(gre)']\n\n\nYou can find detailed, worked examples of fitting Bambi models and working with the results in the example notebooks here."
  },
  {
    "objectID": "notebooks/getting_started.html#accessing-back-end-objects",
    "href": "notebooks/getting_started.html#accessing-back-end-objects",
    "title": "Getting Started",
    "section": "Accessing back-end objects",
    "text": "Accessing back-end objects\nBambi is just a high-level interface to PyMC. As such, Bambi internally stores virtually all objects generated by PyMC, making it easy for users to retrieve, inspect, and modify those objects. For example, the Model class created by PyMC (as opposed to the Bambi class of the same name) is accessible from model.backend.model.\n\ntype(model.backend.model)\n\npymc.model.core.Model\n\n\n\nmodel.backend.model\n\n\\[\n            \\begin{array}{rcl}\n            \\text{Intercept} &\\sim & \\operatorname{Normal}(0,~23.4)\\\\\\text{scale(gre)} &\\sim & \\operatorname{Normal}(0,~2.5)\\\\\\text{gpa} &\\sim & \\operatorname{Normal}(0,~6.58)\\\\\\text{rank} &\\sim & \\operatorname{Normal}(0,~2.65)\\\\\\text{p} &\\sim & \\operatorname{Deterministic}(f(\\text{rank},~\\text{gpa},~\\text{scale(gre)},~\\text{Intercept}))\\\\\\text{admit} &\\sim & \\operatorname{Bernoulli}(\\text{p})\n            \\end{array}\n            \\]\n\n\n\nmodel.backend.model.observed_RVs\n\n[admit ~ Bernoulli(p)]\n\n\n\nmodel.backend.model.unobserved_RVs\n\n[Intercept ~ Normal(0, 23.4),\n scale(gre) ~ Normal(0, 2.5),\n gpa ~ Normal(0, 6.58),\n rank ~ Normal(0, 2.65),\n p ~ Deterministic(f(rank, gpa, scale(gre), Intercept))]\n\n\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sun May 26 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\narviz : 0.18.0\npandas: 2.2.2\nnumpy : 1.26.4\nscipy : 1.13.0\nbambi : 0.13.1.dev39+gb7d6a6cb\n\nWatermark: 2.4.3"
  },
  {
    "objectID": "notebooks/horseshoe_prior.html",
    "href": "notebooks/horseshoe_prior.html",
    "title": "Horseshoe Prior",
    "section": "",
    "text": "In this example, we will use the Horseshoe Prior (Carvalho et al., 2009) to model a large number of variables, with only a few slopes being significantly different from zero.\n\nimport arviz as az\nimport bambi as bmb\nimport numpy as np\nimport pandas as pd\nimport pymc as pm\nimport pytensor.tensor as pt\n\nfrom matplotlib import pyplot as plt\n\nHere is what we did:\n\nWe defined an intercept.\nWe defined a vector of 50 betas, 5 of which were drawn from a normal(5,1) distribution, and then assigned a random sign.\nWe created the design matrix with normal(0,1) entries and set \\(\\sigma\\) to 1.\nWe calculated the deterministic means \\(\\mu\\) using the intercept and the design matrix multiplied by the betas.\nWe simulated 100 response variables (observations) from a normal distribution with mean \\(\\mu\\) and standard deviation \\(\\sigma\\).\n\nNext, we proceeded with the Bayesian estimation of the model. We proposed the horseshoe prior, for which the following parameters were calculated:\n\\[\\mu_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ... + \\beta_p x_{pi}\\]\n\\[y_i \\sim N(\\mu_i, \\sigma^2)\\]\n\\[\\alpha \\sim N(0,1)\\]\n\\[\\beta_j \\sim N(0,\\lambda_j^2 \\tau^2)\\]\n\\[\\lambda_j \\sim C^+(0,1)\\]\n\\[\\tau \\sim T^+(df=3)\\]\n\\[\\sigma^2 \\sim N^+(0,1)\\]\n\nD = 50\nD0 = 5\n\nSEED = 123456789 # for reproducibility\n\nrng = np.random.default_rng(SEED)\n\nINTERCEPT = rng.uniform(-3, 3) # simulate an intercept\n\nCOEF = np.zeros(D)\n# Simulate the slopes for significant variables\nCOEF[:D0] = rng.choice([-1, 1], size=D0) * rng.normal(5, 1, size=D0)\n\nN = 100\nX = rng.normal(size=(N, D))\nSIGMA = 1.\n# Simulate the data\ny = INTERCEPT + X.dot(COEF) + rng.normal(0, SIGMA, size=N)\n\nHere we create the dataframe and the term name for the set of variables, to define the formula.\n\ndf = pd.DataFrame(X)\ndf.columns = [f\"x{i}\" for i in range(X.shape[1])]\ndf[\"y\"] = y\n\n\nterm_name = \"c(\" + \", \".join([f\"x{i}\" for i in range(X.shape[1])]) + \")\"\nformula = f\"y ~ {term_name}\"\nformula\n\n'y ~ c(x0, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15, x16, x17, x18, x19, x20, x21, x22, x23, x24, x25, x26, x27, x28, x29, x30, x31, x32, x33, x34, x35, x36, x37, x38, x39, x40, x41, x42, x43, x44, x45, x46, x47, x48, x49)'\n\n\nFinally, we call the Horseshoe prior and create the model\n\npriors = {\n    term_name: bmb.Prior(\"Horseshoe\"),\n}\nmodel = bmb.Model(formula, df, priors=priors)\nmodel.set_alias({term_name: \"predictors\"})\n\nmodel.build()\nmodel.graph()\n\n\n\n\n\n\n\n\n\nidata = model.fit(target_accept = 0.95, chains=2)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, predictors_tau, predictors_lam, predictors_raw]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 444 seconds.\nThere were 64 divergences after tuning. Increase `target_accept` or reparameterize.\nChain 0 reached the maximum tree depth. Increase `max_treedepth`, increase `target_accept` or reparameterize.\nChain 1 reached the maximum tree depth. Increase `max_treedepth`, increase `target_accept` or reparameterize.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\npriors = {\n    term_name: bmb.Prior(\"Horseshoe\", tau_nu = 3, lam_nu = 3),\n}\nmodel = bmb.Model(formula, df, priors=priors)\nmodel.set_alias({term_name: \"predictors\"})\n\nmodel.build()\nmodel.graph()\n\n\n\n\n\n\n\n\n\nidata = model.fit(target_accept = 0.97, chains=2)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, predictors_tau, predictors_lam, predictors_raw]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 293 seconds.\nThere were 29 divergences after tuning. Increase `target_accept` or reparameterize.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\nax, = az.plot_forest(\n    idata, \n    var_names=[\"predictors\"], \n    coords={\"predictors_dim\": range(D0)},\n    kind='ridgeplot',\n    ridgeplot_truncate=False, \n    ridgeplot_alpha=0.5,\n    hdi_prob=0.95, \n    combined=True,\n    figsize=(8, 6)\n)\nax.scatter(COEF[:D0][::-1], ax.get_yticks(), c='C1', label=\"Actual value\");\nax.set_xlabel(r\"$\\beta_i$\");\nax.set_ylim(bottom=None, top=1.55 * ax.get_yticks().max())\nax.set_yticklabels(range(D0)[::-1]);\nax.set_ylabel(r\"$i$\");\nax.legend(loc='upper center');\nax.set_title(\"Posterior distribution of nonzero coefficients\");\n\n\n\n\n\n\n\n\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Thu Aug 22 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\npandas    : 2.2.2\nnumpy     : 1.26.4\nbambi     : 0.14.1.dev12+g64e57423.d20240730\narviz     : 0.18.0\nmatplotlib: 3.8.4\npymc      : 5.16.1\npytensor  : 2.23.0\n\nWatermark: 2.4.3"
  },
  {
    "objectID": "notebooks/hsgp_1d.html",
    "href": "notebooks/hsgp_1d.html",
    "title": "Gaussian Processes",
    "section": "",
    "text": "This article demonstrates the how to use Bambi with Gaussian Processes with 1 dimensional predictors. Bambi supports Gaussian Processes through the approximation known as Hilbert Space Gaussian Processes (HSGP).\nHSGP is a framework that falls under the class of low-rank approximations that are based on forming a basis function approximation with \\(m\\) basis functions, where \\(m\\) is usually much less smaller than \\(n\\), the number of observations.\nFor references see Hilbert Space Methods for Reduced-Rank Gaussian Process Regression and Practical Hilbert Space Approximate Bayesian Gaussian Processes for Probabilistic Programming.\nIf you prefer a video format, have a look at Introduction to Hilbert Space GPs in PyMC given by Bill Engels.\n%load_ext autoreload\n%autoreload 2\nfrom formulae import design_matrices\n\nimport arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom bambi.interpret import plot_predictions\nfrom matplotlib.lines import Line2D",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Gaussian Processes"
    ]
  },
  {
    "objectID": "notebooks/hsgp_1d.html#a-basic-example",
    "href": "notebooks/hsgp_1d.html#a-basic-example",
    "title": "Gaussian Processes",
    "section": "A basic example",
    "text": "A basic example\nLet’s get started simulating some data from a smooth function. The goal is to fit a normal likelihood model where a Gaussian process term contributes to the mean.\n\nrng = np.random.default_rng(seed=121195)\n\nsize = 100\nx = np.linspace(0, 50, size)\nb = 0.1 * rng.normal(size=6)\nsigma = 0.15\n\ndm = design_matrices(\"0 + bs(x, df=6, intercept=True)\", pd.DataFrame({\"x\": x}))\nX = np.array(dm.common)\nf = 10 * X @ b\ny = f + rng.normal(size=size) * sigma\ndf = pd.DataFrame({\"x\": x, \"y\": y})\n\nfig, ax = plt.subplots(figsize=(9, 6))\nax.scatter(x, y, s=30, alpha=0.8);\nax.plot(x, f, color=\"black\");\n\n\n\n\n\n\n\n\nNow let’s simply create and fit the model. We use the hsgp to initialize a HSGP term in the model formula. Notice we pass the variable x and values for two other arguments m and c that we’ll cover later.\n\nmodel = bmb.Model(\"y ~ 0 + hsgp(x, m=10, c=2)\", df)\nmodel\n\n       Formula: y ~ 0 + hsgp(x, m=10, c=2)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 100\n        Priors: \n    target = mu\n        HSGP contributions\n            hsgp(x, m=10, c=2)\n                cov: ExpQuad\n                sigma ~ Exponential(lam: 1.0)\n                ell ~ InverseGamma(alpha: 3.0, beta: 2.0)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 0.2745)\n\n\nIn the model description we can see the contribution of the HSGP term. It consists of two things: the name of the covariance kernel and the priors for its parameters. In this case, it’s an Exponentiated Quadratic covariance kernel with parameters sigma (amplitude) and ell (lengthscale). The prior for the amplitude is Exponential(1) and the prior for the lengthscale is InverseGamma(3, 2).\n\nidata = model.fit(random_seed=121195)\nprint(idata.sample_stats[\"diverging\"].sum().to_numpy())\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, hsgp(x, m=10, c=2)_sigma, hsgp(x, m=10, c=2)_ell, hsgp(x, m=10, c=2)_weights_raw]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 9 seconds.\nThere were 251 divergences after tuning. Increase `target_accept` or reparameterize.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\nThe effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n\n\n251\n\n\n\naz.plot_trace(idata, backend_kwargs={\"layout\": \"constrained\"});\n\n\n\n\n\n\n\n\nThe fit is horrible. To fix that we can use better priors. But before doing that, it’s important to note that HSGP terms have a unique characteristic in that they do not receive priors themselves. Rather, the associated parameters of an HSGP term, such as sigma and ell, are the ones that are assigned priors. Therefore, we need to assign the HSGP term a dictionary of priors instead of a single prior.\n\nprior_hsgp = {\n    \"sigma\": bmb.Prior(\"Exponential\", lam=2), # amplitude\n    \"ell\": bmb.Prior(\"InverseGamma\", mu=10, sigma=1) # lengthscale\n}\n\n# This is the dictionary we pass to Bambi\npriors = {\n    \"hsgp(x, m=10, c=2)\": prior_hsgp,\n    \"sigma\": bmb.Prior(\"HalfNormal\", sigma=10)\n}\nmodel = bmb.Model(\"y ~ 0 + hsgp(x, m=10, c=2)\", df, priors=priors)\nmodel\n\n       Formula: y ~ 0 + hsgp(x, m=10, c=2)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 100\n        Priors: \n    target = mu\n        HSGP contributions\n            hsgp(x, m=10, c=2)\n                cov: ExpQuad\n                sigma ~ Exponential(lam: 2.0)\n                ell ~ InverseGamma(mu: 10.0, sigma: 1.0)\n        \n        Auxiliary parameters\n            sigma ~ HalfNormal(sigma: 10.0)\n\n\nNotice the priors were updated in the model summary. Now we’re ready to fit the model!\n\nidata = model.fit(random_seed=121195)\nprint(idata.sample_stats[\"diverging\"].sum().to_numpy())\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, hsgp(x, m=10, c=2)_sigma, hsgp(x, m=10, c=2)_ell, hsgp(x, m=10, c=2)_weights_raw]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 22 seconds.\nThere were 11 divergences after tuning. Increase `target_accept` or reparameterize.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n11\n\n\n\naz.plot_trace(idata, backend_kwargs={\"layout\": \"constrained\"});\n\n\n\n\n\n\n\n\nThe marginal posteriors look somehow better, but we still have lots of divergences. What else can we do? Change the parametrization!\nThe hsgp() function has a centered argument which defaults to False and thus Bambi uses a non-centered parametrization by default. But we can change that actually. Let’s try it!\n\nprior_hsgp = {\n    \"sigma\": bmb.Prior(\"Exponential\", lam=2), # amplitude\n    \"ell\": bmb.Prior(\"InverseGamma\", mu=10, sigma=1) # lengthscale\n}\n\n# This is the dictionary we pass to Bambi\npriors = {\n    \"hsgp(x, m=10, c=2, centered=True)\": prior_hsgp,\n    \"sigma\": bmb.Prior(\"HalfNormal\", sigma=10)\n}\nmodel = bmb.Model(\"y ~ 0 + hsgp(x, m=10, c=2, centered=True)\", df, priors=priors)\nmodel\n\n       Formula: y ~ 0 + hsgp(x, m=10, c=2, centered=True)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 100\n        Priors: \n    target = mu\n        HSGP contributions\n            hsgp(x, m=10, c=2, centered=True)\n                cov: ExpQuad\n                sigma ~ Exponential(lam: 2.0)\n                ell ~ InverseGamma(mu: 10.0, sigma: 1.0)\n        \n        Auxiliary parameters\n            sigma ~ HalfNormal(sigma: 10.0)\n\n\n\nidata = model.fit(random_seed=121195)\nprint(idata.sample_stats[\"diverging\"].sum().to_numpy())\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, hsgp(x, m=10, c=2, centered=True)_sigma, hsgp(x, m=10, c=2, centered=True)_ell, hsgp(x, m=10, c=2, centered=True)_weights]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 19 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n0\n\n\n\naz.plot_trace(idata, backend_kwargs={\"layout\": \"constrained\"});\n\n\n\n\n\n\n\n\nAwesome! That looks much better now.\nWe still get all the nice things from Bambi when using GPs. An example of this is the plot_cap() function which enables us to generate a visualization of the adjusted mean with credible bands automatically.\n\nfig, ax = plt.subplots(figsize=(9, 6))\nax.scatter(df[\"x\"], df[\"y\"], s=30, color=\"0.5\", alpha=0.5)\nplot_predictions(model, idata, \"x\", ax=ax);\nax.set(xlabel=\"Predictor\", ylabel=\"Observed\");\n\nDefault computed for conditional variable: x\n\n\n\n\n\n\n\n\n\nAnd on top of that, it’s possible to get draws from the posterior predictive distribution and plot credible bands for it. All we need is the .predict() method from the model class.\n\nnew_data = pd.DataFrame({\"x\": np.linspace(0, 50, num=500)})\nmodel.predict(idata, kind=\"response\", data=new_data)\npps = idata.posterior_predictive[\"y\"].to_numpy().reshape(2000, 500)\nqts = np.quantile(pps, q=(0.025, 0.975), axis=0)\n\nfig, ax = plt.subplots(figsize=(9, 6))\nax.fill_between(new_data[\"x\"], qts[0], qts[1], color=\"C0\", alpha=0.6)\nax.scatter(df[\"x\"], df[\"y\"], s=30, color=\"C1\", alpha=0.9)\nax.plot(x, f, color=\"black\", ls=\"--\")\nax.set(xlabel=\"Predictor\", ylabel=\"Observed\");\n\nhandles = [Line2D([], [], color=\"black\", ls=\"--\"), Line2D([], [], color=\"C0\")]\nlabels = [\"True curve\", \"Posterior predictive distribution\"]\nax.legend(handles, labels);",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Gaussian Processes"
    ]
  },
  {
    "objectID": "notebooks/hsgp_1d.html#how-does-hsgp-work",
    "href": "notebooks/hsgp_1d.html#how-does-hsgp-work",
    "title": "Gaussian Processes",
    "section": "How does hsgp() work?",
    "text": "How does hsgp() work?\nhsgp() is a transformation that is available in the namespace where the model formula is evaluated. In plain english, hsgp() is like a function you can use in your model formulas. You don’t need to worry about the details, Bambi knows how to handle them.But if still you want to see the actual code, you can have a look at the implementation of the HSGP class in bambi/transformations.py.\nWhat users do need to care about is the arguments the hsgp() transformation support. There are a bunch of arguments that can be passed after the variable number of non-keyword arguments representing the variables of the HSGP contribution. Below is a brief overview of these arguments and their respective descriptions.\n\nm: The number of basis vectors\nL: The boundary of the variable space\nc: The proportion extension factor\nby: This argument specifies the values of a variable used for grouping. It is used to create a HSGP term by group. If left unspecified, the default value is None, which means that there is no group variable and all observations belong to the same group.\ncov: This argument specifies the name of the covariance function to be used. The default value is \"ExpQuad\".\nshare_cov: Determines whether the same covariance function is shared across all groups. This argument is relevant only when by is not None and the default value is True.\nscale: When set to True, the predictors are be rescaled such that the largest Euclidean distance between two points is 1. This adjustment often improves the sampling speed and convergence.\niso: Determines whether to use an isotropic or non-isotropic Gaussian Process. With an isotropic GP, the same level of smoothing is applied to all predictors, while a anisotropic GP allows different levels of smoothing for individual predictors. Note that this argument is ignored if only one predictor is provided. The default value is True.\ndrop_first: Whether to exclude the first basis vector or not. The default value is False.\ncentered: Whether to use the centered or the non-centered parametrization. Defaults to False.\n\nThe parameters m, L and c are directly related to the basis vectors of the HSGP approximation. If you want to know more about m, L, and/or c, it’s recommended to have a look at the documentation of the HSGP class in PyMC.\n\nSo far, we showcased how to use m, c and centered. In the remainder of this article we’re going to see how by and share_cov are used when we add a GP contribution by groups.",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Gaussian Processes"
    ]
  },
  {
    "objectID": "notebooks/hsgp_1d.html#hsgp-by-levels-of-a-categorical-covariate",
    "href": "notebooks/hsgp_1d.html#hsgp-by-levels-of-a-categorical-covariate",
    "title": "Gaussian Processes",
    "section": "HSGP by levels of a categorical covariate",
    "text": "HSGP by levels of a categorical covariate\nIn this section we fit a model with a HSGP contribution by levels of a categorical variable. The data was simulated with the gamSim() function from the R package {mgcv} by Simon Wood.\n\ndata = pd.read_csv(\"data/gam_data.csv\")\ndata[\"fac\"] = pd.Categorical(data[\"fac\"])\ndata.head()[[\"x2\", \"y\", \"fac\"]]\n\n\n\n\n\n\n\n\nx2\ny\nfac\n\n\n\n\n0\n0.497183\n3.085274\n3\n\n\n1\n0.196003\n-2.250410\n2\n\n\n2\n0.958474\n0.070548\n3\n\n\n3\n0.972759\n-0.230454\n1\n\n\n4\n0.755836\n2.173497\n2\n\n\n\n\n\n\n\nLet’s visualize x2 versus y for the different levels in fac.\n\nfig, ax = plt.subplots(figsize=(9, 5))\ncolors = [f\"C{i}\" for i in pd.Categorical(data[\"fac\"]).codes]\nax.scatter(data[\"x2\"], data[\"y\"], color=colors, alpha=0.6)\nax.set(xlabel=\"x2\", ylabel=\"y\");\n\n\n\n\n\n\n\n\nWe can observe the relation between x2 and y can be approximated by a smooth non-linear curve, for all groups.\nBelow, we create the model with Bambi. The biggest difference is that we’re passing by=fac in the hsgp() call. This is all we need to ask Bambi to create multiple GP contribution terms, one per group.\nAnother trick that was not shown previously is the usage of an alias. .set_alias() from the Model class allow us to have more readable and shorter names for the components of a model. As you’ll see below, it makes a huge difference when displaying summaries or visualizations for the parameters of the model.\n\nprior_hsgp = {\n    \"sigma\": bmb.Prior(\"Exponential\", lam=3),\n    \"ell\": bmb.Prior(\"Exponential\", lam=3)\n}\npriors = {\n    \"hsgp(x2, by=fac, m=12, c=1.5)\": prior_hsgp,\n    \"sigma\": bmb.Prior(\"HalfNormal\", sigma=1)\n}\nmodel = bmb.Model(\"y ~ 0 + hsgp(x2, by=fac, m=12, c=1.5)\", data, priors=priors)\nmodel.set_alias({\"hsgp(x2, by=fac, m=12, c=1.5)\": \"hsgp\"})\nmodel\n\n       Formula: y ~ 0 + hsgp(x2, by=fac, m=12, c=1.5)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 300\n        Priors: \n    target = mu\n        HSGP contributions\n            hsgp(x2, by=fac, m=12, c=1.5)\n                cov: ExpQuad\n                sigma ~ Exponential(lam: 3.0)\n                ell ~ Exponential(lam: 3.0)\n        \n        Auxiliary parameters\n            sigma ~ HalfNormal(sigma: 1.0)\n\n\n\nmodel.build()\nmodel.graph()\n\n\n\n\n\n\n\n\nSee how nicer are the names for the HSGP contribution parameters with the alias!\n\nidata = model.fit(target_accept=0.95, random_seed=121195)\nprint(idata.sample_stats.diverging.sum().item())\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, hsgp_sigma, hsgp_ell, hsgp_weights_raw]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 34 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n0\n\n\n\naz.plot_trace(\n    idata, \n    var_names=[\"hsgp_weights\", \"hsgp_sigma\", \"hsgp_ell\", \"sigma\"], \n    backend_kwargs={\"layout\": \"constrained\"}\n);\n\n\n\n\n\n\n\n\nThis time we got no divergences and good mixing and nice convergence in our first try (or perhaps it wasn’t the first try!). One thing that stands out are the marginal posterior for some of the beta parameters (the weights of the basis). This may indicate our approximation is using more basis vectors than what’s really needed.\nNote: At this point we have used the term ‘basis vector’ several times. This concept is very close to the concept of ‘basis functions’. The difference is that the ‘basis vector’ is a ‘basis function’ already evaluated at a set of points. In this case, the set of points is made by the values of the numerical predictor x2.\nDo you remember how easy was it to use plot_predictions() above? Should it be harder now? Well, the answer will surprise you: No!\nAll we need to do is passing a second variable name which is mapped to the color in the visualization. Voilà!\n\nfig, ax = plt.subplots(figsize = (9, 5))\ncolors = [f\"C{i}\" for i in pd.Categorical(data[\"fac\"]).codes]\nax.scatter(data[\"x2\"], data[\"y\"], color=colors, alpha=0.6)\nplot_predictions(model, idata, [\"x2\", \"fac\"], ax=ax);\n\nDefault computed for conditional variable: x2, fac\n\n\n\n\n\n\n\n\n\nWe can go one step further and modify the model to use different covariance functions for the different groups. For that purpose, we pass share_cov=False. As always, Bambi takes care of all the details.\n\nprior_hsgp = {\n    \"sigma\": bmb.Prior(\"Exponential\", lam=1),\n    \"ell\": bmb.Prior(\"Exponential\", lam=3)\n}\npriors = {\n    \"hsgp(x2, by=fac, m=12, c=1.5, share_cov=False)\": prior_hsgp,\n    \"sigma\": bmb.Prior(\"HalfNormal\", sigma=1)\n}\nmodel = bmb.Model(\"y ~ 0 + hsgp(x2, by=fac, m=12, c=1.5, share_cov=False)\", data, priors=priors)\nmodel.set_alias({\"hsgp(x2, by=fac, m=12, c=1.5, share_cov=False)\": \"hsgp\"})\nmodel\n\n       Formula: y ~ 0 + hsgp(x2, by=fac, m=12, c=1.5, share_cov=False)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 300\n        Priors: \n    target = mu\n        HSGP contributions\n            hsgp(x2, by=fac, m=12, c=1.5, share_cov=False)\n                cov: ExpQuad\n                sigma ~ Exponential(lam: 1.0)\n                ell ~ Exponential(lam: 3.0)\n        \n        Auxiliary parameters\n            sigma ~ HalfNormal(sigma: 1.0)\n\n\n\nmodel.build()\nmodel.graph()\n\n\n\n\n\n\n\n\nHave a closer look at the model graph. See that the hsgp_sigma and hsgp_ell parameters are no longer scalar. There are three of each, one for each group.\n\nidata = model.fit(target_accept=0.95, random_seed=121195)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, hsgp_sigma, hsgp_ell, hsgp_weights_raw]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 55 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\naz.plot_trace(\n    idata, \n    var_names=[\"hsgp_ell\", \"hsgp_sigma\", \"sigma\"], \n    backend_kwargs={\"layout\": \"constrained\"}\n);\n\n\n\n\n\n\n\n\nIn fact, we can see not all the groups have similar posteriors for the covariance function parameters when they are allowed to vary.\nBefore closing the article, it’s worth looking at a particular but not uncommon pattern when using the HSGP approximation. Let’s have a look at the posterior distributions for the weights of the basis.\n\naz.plot_trace(idata, var_names=[\"hsgp_weights\"], backend_kwargs={\"layout\": \"constrained\"});\n\n\n\n\n\n\n\n\nLooks like some distributions are extremely flat, and others are extremely tight around zero.\nTo investigate this further we can manually plot the posterior for the first J basis vectors and see what they look like.\n\nbasis_n = 6\nfig, axes = plt.subplots(3, 1, figsize = (7, 10))\nfor i in range(3):\n    ax = axes[i]\n    values = idata.posterior[\"hsgp_weights\"].sel({\"hsgp_by\": i + 1})\n    for j in range(basis_n):\n        az.plot_kde(\n            values.sel({\"hsgp_weights_dim\": j}).to_numpy().flatten(), \n            ax=ax, \n            plot_kwargs={\"color\": f\"C{j}\"}\n        );\n\n\n\n\n\n\n\n\nIndeed, we can see that, at least for the first group, the posterior of the weights start being too tight around zero when we consider the 6th basis vector. But the posteriors for the weights of the previous basis vectors look nice.\nTo confirm our thought, let’s increase the value of basis_n to 9 and see what happens.\n\nbasis_n = 9\nfig, axes = plt.subplots(3, 1, figsize = (7, 10))\nfor i in range(3):\n    ax = axes[i]\n    values = idata.posterior[\"hsgp_weights\"].sel({\"hsgp_by\": i + 1})\n    for j in range(basis_n):\n        az.plot_kde(\n            values.sel({\"hsgp_weights_dim\": j}).to_numpy().flatten(), \n            ax=ax, \n            plot_kwargs={\"color\": f\"C{j}\"}\n        );\n\n\n\n\n\n\n\n\nAlright, that’s too spiky! Nonetheless, we don’t see that happening for the third group yet, indicating the higher number of basis vectors is more appropriate for this group.",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Gaussian Processes"
    ]
  },
  {
    "objectID": "notebooks/interpret_advanced_usage.html",
    "href": "notebooks/interpret_advanced_usage.html",
    "title": "Interpret Advanced Usage",
    "section": "",
    "text": "The interpret module provides a set of helper functions to aid the user in more advanced and complex analysis not covered within the comparisons, predictions, and slopes functions. These helper functions are data_grid and select_draws. The data_grid can be used to create a pairwise grid of data points for the user to pass to model.predict. Subsequently, select_draws is used to select the draws from the posterior (or posterior predictive) group of the InferenceData object returned by the predict method that correspond to the data points that “produced” that draw.\nWith access to the appropriately indexed draws, and data used to generate those draws, it enables for more complex analysis such as cross-comparisons and the choice of which model parameter to compute a quantity of interest for; among others. Additionally, the user has more control over the data passed to model.predict. Below, it will be demonstrated how to use these helper functions. First, to reproduce the results from the standard interpret API, and then to compute cross-comparisons.\nimport warnings\n\nimport arviz as az\nimport numpy as np\nimport pandas as pd\n\nimport bambi as bmb\n\nfrom bambi.interpret.helpers import data_grid, select_draws\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Interpret Advanced Usage"
    ]
  },
  {
    "objectID": "notebooks/interpret_advanced_usage.html#zero-inflated-poisson",
    "href": "notebooks/interpret_advanced_usage.html#zero-inflated-poisson",
    "title": "Interpret Advanced Usage",
    "section": "Zero Inflated Poisson",
    "text": "Zero Inflated Poisson\nWe will adopt the zero inflated Poisson (ZIP) model from the comparisons documentation to demonstrate the helper functions introduced above.\nThe ZIP model will be used to predict how many fish are caught by visitors at a state park using survey data. Many visitors catch zero fish, either because they did not fish at all, or because they were unlucky. We would like to explicitly model this bimodal behavior (zero versus non-zero) using a Zero Inflated Poisson model, and to compare how different inputs of interest \\(w\\) and other covariate values \\(c\\) are associated with the number of fish caught. The dataset contains data on 250 groups that went to a state park to fish. Each group was questioned about how many fish they caught (count), how many children were in the group (child), how many people were in the group (persons), if they used a live bait and whether or not they brought a camper to the park (camper).\n\nfish_data = pd.read_csv(\"https://stats.idre.ucla.edu/stat/data/fish.csv\")\ncols = [\"count\", \"livebait\", \"camper\", \"persons\", \"child\"]\nfish_data = fish_data[cols]\nfish_data[\"child\"] = fish_data[\"child\"].astype(np.int8)\nfish_data[\"persons\"] = fish_data[\"persons\"].astype(np.int8)\nfish_data[\"livebait\"] = pd.Categorical(fish_data[\"livebait\"])\nfish_data[\"camper\"] = pd.Categorical(fish_data[\"camper\"])\n\n\nfish_model = bmb.Model(\n    \"count ~ livebait + camper + persons + child\", \n    fish_data, \n    family='zero_inflated_poisson'\n)\n\nfish_idata = fish_model.fit(random_seed=1234)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [psi, Intercept, livebait, camper, persons, child]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 8 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Interpret Advanced Usage"
    ]
  },
  {
    "objectID": "notebooks/interpret_advanced_usage.html#create-a-grid-of-data",
    "href": "notebooks/interpret_advanced_usage.html#create-a-grid-of-data",
    "title": "Interpret Advanced Usage",
    "section": "Create a grid of data",
    "text": "Create a grid of data\ndata_grid allows you to create a pairwise grid, also known as a cross-join or cartesian product, of data using the covariates passed to the conditional and the optional variable parameter. Covariates not passed to conditional, but are terms in the Bambi model, are set to typical values (e.g., mean or mode). If you are coming from R, this function is partially inspired from the data_grid function in the R package modelr.\nThere are two ways to create a pairwise grid of data:\n\nuser-provided values are passed as a dictionary to conditional where the keys are the names of the covariates and the values are the values to use in the grid.\na list of covariates where the elements are the names of the covariates to use in the grid. As only the names of the covariates were passed, default values are computed to construct the grid.\n\nAny unspecified covariates, i.e., covariates not passed to conditional but are terms in the Bambi model, are set to their “typical” values such as mean or mode depending on the data type of the covariate.\n\nUser-provided values\nTo construct a pairwise grid of data for specific covariate values, pass a dictionary to conditional. The values of the dictionary can be of type int, float, list, or np.ndarray.\n\nconditional = {\n    \"camper\": np.array([0, 1]),\n    \"persons\": np.arange(1, 5, 1),\n    \"child\": np.array([1, 2, 3]),\n}\nuser_passed_grid = data_grid(fish_model, conditional)\nuser_passed_grid.query(\"camper == 0\")\n\nDefault computed for unspecified variable: livebait\n\n\n\n\n\n\n\n\n\ncamper\npersons\nchild\nlivebait\n\n\n\n\n0\n0\n1\n1\n1\n\n\n1\n0\n1\n2\n1\n\n\n2\n0\n1\n3\n1\n\n\n3\n0\n2\n1\n1\n\n\n4\n0\n2\n2\n1\n\n\n5\n0\n2\n3\n1\n\n\n6\n0\n3\n1\n1\n\n\n7\n0\n3\n2\n1\n\n\n8\n0\n3\n3\n1\n\n\n9\n0\n4\n1\n1\n\n\n10\n0\n4\n2\n1\n\n\n11\n0\n4\n3\n1\n\n\n\n\n\n\n\nSubsetting by camper = 0, it can be seen that a combination of all possible pairs of values from the dictionary (including the unspecified variable livebait) results in a dataframe containing every possible combination of values from the original sets. livebait has been set to 1 as this is the mode of the unspecified categorical variable.\n\n\nDefault values\nAlternatively, a list of covariates can be passed to conditional where the elements are the names of the covariates to use in the grid. By doing this, you are telling interpret to compute default values for these covariates. The psuedocode below outlines the logic and functions used to compute these default values:\nif is_numeric_dtype(x) or is_float_dtype(x):\n    values = np.linspace(np.min(x), np.max(x), 50)\n\nelif is_integer_dtype(x):\n    values = np.quantile(x, np.linspace(0, 1, 5))\n\nelif is_categorical_dtype(x) or is_string_dtype(x) or is_object_dtype(x):\n    values = np.unique(x)\n\nconditional = [\"camper\", \"persons\", \"child\"]\ndefault_grid = data_grid(fish_model, conditional)\n\ndefault_grid.shape, user_passed_grid.shape\n\nDefault computed for conditional variable: camper, persons, child\nDefault computed for unspecified variable: livebait\n\n\n((32, 4), (24, 4))\n\n\nNotice how the resulting length is different between the user passed and default grid. This is due to the fact that values for child range from 0 to 3 for the default grid.\n\ndefault_grid.query(\"camper == 0\")\n\n\n\n\n\n\n\n\ncamper\npersons\nchild\nlivebait\n\n\n\n\n0\n0\n1\n0\n1\n\n\n1\n0\n1\n1\n1\n\n\n2\n0\n1\n2\n1\n\n\n3\n0\n1\n3\n1\n\n\n4\n0\n2\n0\n1\n\n\n5\n0\n2\n1\n1\n\n\n6\n0\n2\n2\n1\n\n\n7\n0\n2\n3\n1\n\n\n8\n0\n3\n0\n1\n\n\n9\n0\n3\n1\n1\n\n\n10\n0\n3\n2\n1\n\n\n11\n0\n3\n3\n1\n\n\n12\n0\n4\n0\n1\n\n\n13\n0\n4\n1\n1\n\n\n14\n0\n4\n2\n1\n\n\n15\n0\n4\n3\n1",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Interpret Advanced Usage"
    ]
  },
  {
    "objectID": "notebooks/interpret_advanced_usage.html#compute-comparisons",
    "href": "notebooks/interpret_advanced_usage.html#compute-comparisons",
    "title": "Interpret Advanced Usage",
    "section": "Compute comparisons",
    "text": "Compute comparisons\nTo use data_grid to help generate data in computing comparisons or slopes, additional data is passed to the optional variable parameter. The name variable is an abstraction for the comparisons parameter contrast and slopes parameter wrt. If you have used any of the interpret functions, these parameter names should be familiar and the use of data_grid should be analogous to comparisons, predictions, and slopes.\nvariable can also be passed user-provided data (as a dictionary), or a string indicating the name of the covariate of interest. If the latter, a default value will be computed. Additionally, if an argument is passed for variable, then the effect_type needs to be passed. This is because for comparisons and slopes an epsilon value eps needs to be determined to compute the centered and finite difference, respectively. You can also pass a value for eps as a kwarg.\n\nconditional = {\n    \"camper\": np.array([0, 1]),\n    \"persons\": np.arange(1, 5, 1),\n    \"child\": np.array([1, 2, 3, 4])\n}\nvariable = \"livebait\"\n\ngrid = data_grid(fish_model, conditional, variable, effect_type=\"comparisons\")\n\nDefault computed for contrast variable: livebait\n\n\n\nidata_grid = fish_model.predict(fish_idata, data=grid, inplace=False)\n\n\nSelect draws conditional on data\nThe second helper function to aid in more advanced analysis is select_draws. This is a function that selects the posterior or posterior predictive draws from the ArviZ InferenceData object returned by model.predict given a conditional dictionary. The conditional dictionary represents the values that correspond to that draw.\nFor example, if we wanted to select posterior draws where livebait = [0, 1], then all we need to do is pass a dictionary where the key is the name of the covariate and the value is the value that we want to condition on (or select). The resulting InferenceData object will contain the draws that correspond to the data points where livebait = [0, 1]. Additionally, you must pass the InferenceData object returned by model.predict, the data used to generate the predictions, and the name of the data variable data_var you would like to select from the InferenceData posterior group. If you specified to return the posterior predictive samples by passing model.predict(..., kind=\"pps\"), you can use this group instead of the posterior group by passing group=\"posterior_predictive\".\nBelow, it is demonstrated how to compute comparisons for count_mean for the contrast livebait = [0, 1] using the posterior draws.\n\nidata_grid\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 1MB\nDimensions:       (chain: 2, draw: 1000, camper_dim: 1, livebait_dim: 1,\n                   __obs__: 64)\nCoordinates:\n  * chain         (chain) int64 16B 0 1\n  * draw          (draw) int64 8kB 0 1 2 3 4 5 6 ... 993 994 995 996 997 998 999\n  * camper_dim    (camper_dim) &lt;U1 4B '1'\n  * livebait_dim  (livebait_dim) &lt;U1 4B '1'\n  * __obs__       (__obs__) int64 512B 0 1 2 3 4 5 6 7 ... 57 58 59 60 61 62 63\nData variables:\n    Intercept     (chain, draw) float64 16kB -2.319 -2.441 ... -2.705 -2.571\n    camper        (chain, draw, camper_dim) float64 16kB 0.7341 0.6539 ... 0.763\n    child         (chain, draw) float64 16kB -1.232 -1.251 ... -1.437 -1.344\n    livebait      (chain, draw, livebait_dim) float64 16kB 1.509 1.634 ... 1.7\n    persons       (chain, draw) float64 16kB 0.8448 0.8763 ... 0.903 0.8508\n    psi           (chain, draw) float64 16kB 0.6017 0.6008 ... 0.6933 0.5425\n    mu            (chain, draw, __obs__) float64 1MB 0.06677 0.3021 ... 0.1248\nAttributes:\n    created_at:                  2024-05-26T21:58:43.655562+00:00\n    arviz_version:               0.18.0\n    inference_library:           pymc\n    inference_library_version:   5.15.0+23.g19be124e\n    sampling_time:               8.18968677520752\n    tuning_steps:                1000\n    modeling_interface:          bambi\n    modeling_interface_version:  0.13.1.dev39+gb7d6a6cbxarray.DatasetDimensions:chain: 2draw: 1000camper_dim: 1livebait_dim: 1__obs__: 64Coordinates: (5)chain(chain)int640 1array([0, 1])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])camper_dim(camper_dim)&lt;U1'1'array(['1'], dtype='&lt;U1')livebait_dim(livebait_dim)&lt;U1'1'array(['1'], dtype='&lt;U1')__obs__(__obs__)int640 1 2 3 4 5 6 ... 58 59 60 61 62 63array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63])Data variables: (7)Intercept(chain, draw)float64-2.319 -2.441 ... -2.705 -2.571array([[-2.31938043, -2.44096796, -2.50242028, ..., -2.41008609,\n        -2.15482426, -2.20237051],\n       [-1.86640536, -2.67868737, -2.6339482 , ..., -2.12677232,\n        -2.70501072, -2.57088187]])camper(chain, draw, camper_dim)float640.7341 0.6539 ... 0.5571 0.763array([[[0.73412642],\n        [0.65388967],\n        [0.7163802 ],\n        ...,\n        [0.7833789 ],\n        [0.65108041],\n        [0.66538528]],\n\n       [[0.77244764],\n        [0.56742013],\n        [0.5377857 ],\n        ...,\n        [0.76498592],\n        [0.55708414],\n        [0.76296319]]])child(chain, draw)float64-1.232 -1.251 ... -1.437 -1.344array([[-1.2318687 , -1.25127852, -1.31269468, ..., -1.3926868 ,\n        -1.25774522, -1.33447648],\n       [-1.28422086, -1.34797375, -1.38221129, ..., -1.40623727,\n        -1.43746916, -1.34408764]])livebait(chain, draw, livebait_dim)float641.509 1.634 1.678 ... 1.859 1.7array([[[1.50949402],\n        [1.63437824],\n        [1.67808319],\n        ...,\n        [1.63405392],\n        [1.42685866],\n        [1.47076256]],\n\n       [[1.10221442],\n        [2.23616858],\n        [2.14968211],\n        ...,\n        [1.39522862],\n        [1.85878726],\n        [1.6999231 ]]])persons(chain, draw)float640.8448 0.8763 ... 0.903 0.8508array([[0.84478698, 0.87628243, 0.85830801, ..., 0.83912448, 0.84743311,\n        0.84884691],\n       [0.82922748, 0.78660974, 0.80622882, ..., 0.81224848, 0.90296207,\n        0.85075257]])psi(chain, draw)float640.6017 0.6008 ... 0.6933 0.5425array([[0.60167917, 0.60079901, 0.56511084, ..., 0.57885181, 0.56435481,\n        0.49627898],\n       [0.57723187, 0.58138806, 0.57220952, ..., 0.56246952, 0.69328445,\n        0.54246752]])mu(chain, draw, __obs__)float640.06677 0.3021 ... 0.02279 0.1248array([[[0.06677262, 0.30210878, 0.0194807 , ..., 0.67555671,\n         0.04356153, 0.19709156],\n        [0.059847  , 0.30679184, 0.01712454, ..., 0.66937831,\n         0.03736344, 0.19153506],\n        [0.05198464, 0.27839237, 0.01398875, ..., 0.5418268 ,\n         0.02722589, 0.14580232],\n        ...,\n        [0.0516302 , 0.26458453, 0.0128253 , ..., 0.4429866 ,\n         0.02147305, 0.11004097],\n        [0.07690869, 0.32037032, 0.0218647 , ..., 0.63103849,\n         0.04306726, 0.17940066],\n        [0.06801683, 0.29604686, 0.01790856, ..., 0.50953105,\n         0.03082271, 0.13415748]],\n\n       [[0.09813622, 0.29547108, 0.0271706 , ..., 0.5900807 ,\n         0.05426199, 0.16337341],\n        [0.03916188, 0.36645381, 0.01017293, ..., 0.4618196 ,\n         0.01282033, 0.11996507],\n        [0.04035941, 0.3463697 , 0.01013113, ..., 0.41970676,\n         0.01227621, 0.10535599],\n        ...,\n        [0.06582464, 0.26566146, 0.01613123, ..., 0.39208537,\n         0.02380781, 0.09608587],\n        [0.03918278, 0.25139483, 0.00930701, ..., 0.37168873,\n         0.01376047, 0.08828654],\n        [0.04669039, 0.25556108, 0.0121758 , ..., 0.47842863,\n         0.02279398, 0.12476343]]])Indexes: (5)chainPandasIndexPandasIndex(Index([0, 1], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))camper_dimPandasIndexPandasIndex(Index(['1'], dtype='object', name='camper_dim'))livebait_dimPandasIndexPandasIndex(Index(['1'], dtype='object', name='livebait_dim'))__obs__PandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63],\n      dtype='int64', name='__obs__'))Attributes: (8)created_at :2024-05-26T21:58:43.655562+00:00arviz_version :0.18.0inference_library :pymcinference_library_version :5.15.0+23.g19be124esampling_time :8.18968677520752tuning_steps :1000modeling_interface :bambimodeling_interface_version :0.13.1.dev39+gb7d6a6cb\n                      \n                  \n            \n            \n            \n                  \n                  sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 252kB\nDimensions:                (chain: 2, draw: 1000)\nCoordinates:\n  * chain                  (chain) int64 16B 0 1\n  * draw                   (draw) int64 8kB 0 1 2 3 4 5 ... 995 996 997 998 999\nData variables: (12/17)\n    acceptance_rate        (chain, draw) float64 16kB 0.4852 0.4691 ... 0.4878\n    diverging              (chain, draw) bool 2kB False False ... False False\n    energy                 (chain, draw) float64 16kB 756.7 754.8 ... 755.2\n    energy_error           (chain, draw) float64 16kB 0.1849 -0.1576 ... 0.6626\n    index_in_trajectory    (chain, draw) int64 16kB 6 -2 -2 5 3 ... 5 -2 -5 -5 6\n    largest_eigval         (chain, draw) float64 16kB nan nan nan ... nan nan\n    ...                     ...\n    process_time_diff      (chain, draw) float64 16kB 0.004515 ... 0.002555\n    reached_max_treedepth  (chain, draw) bool 2kB False False ... False False\n    smallest_eigval        (chain, draw) float64 16kB nan nan nan ... nan nan\n    step_size              (chain, draw) float64 16kB 0.4493 0.4493 ... 0.2491\n    step_size_bar          (chain, draw) float64 16kB 0.4092 0.4092 ... 0.3806\n    tree_depth             (chain, draw) int64 16kB 4 3 3 4 3 3 ... 4 3 3 3 4 3\nAttributes:\n    created_at:                  2024-05-26T21:58:43.673049+00:00\n    arviz_version:               0.18.0\n    inference_library:           pymc\n    inference_library_version:   5.15.0+23.g19be124e\n    sampling_time:               8.18968677520752\n    tuning_steps:                1000\n    modeling_interface:          bambi\n    modeling_interface_version:  0.13.1.dev39+gb7d6a6cbxarray.DatasetDimensions:chain: 2draw: 1000Coordinates: (2)chain(chain)int640 1array([0, 1])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])Data variables: (17)acceptance_rate(chain, draw)float640.4852 0.4691 ... 0.8185 0.4878array([[0.48524273, 0.46907635, 0.9900161 , ..., 0.94979748, 0.40116304,\n        0.93741625],\n       [0.58873199, 0.91215294, 0.49416685, ..., 0.53753997, 0.81845045,\n        0.48775355]])diverging(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])energy(chain, draw)float64756.7 754.8 752.2 ... 756.3 755.2array([[756.66437695, 754.81526077, 752.2446864 , ..., 755.57787795,\n        755.37790244, 754.18463256],\n       [757.69096989, 758.29295824, 756.92029865, ..., 759.27488214,\n        756.33063752, 755.1645284 ]])energy_error(chain, draw)float640.1849 -0.1576 ... -0.5226 0.6626array([[ 0.18490812, -0.15761089, -0.01500881, ..., -0.61241546,\n         0.04715335,  0.13670632],\n       [-0.30343495,  0.1003043 , -0.00980192, ...,  0.48894455,\n        -0.52259825,  0.66255443]])index_in_trajectory(chain, draw)int646 -2 -2 5 3 -6 ... 11 5 -2 -5 -5 6array([[ 6, -2, -2, ..., 13,  4, -3],\n       [-4, -5, -2, ..., -5, -5,  6]])largest_eigval(chain, draw)float64nan nan nan nan ... nan nan nan nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]])lp(chain, draw)float64-751.7 -751.0 ... -752.3 -752.8array([[-751.74419455, -751.04504395, -750.54322651, ..., -750.83344139,\n        -751.48798   , -753.41881499],\n       [-754.58377843, -754.16645365, -753.40879282, ..., -753.23969952,\n        -752.34621461, -752.81312555]])max_energy_error(chain, draw)float641.793 2.415 ... 0.7354 1.872array([[ 1.79320886,  2.41509386, -0.05842541, ..., -0.61241546,\n         3.19523992,  0.13670632],\n       [ 1.47885656,  0.22641457,  2.85988684, ...,  1.16100195,\n         0.73536126,  1.87172503]])n_steps(chain, draw)float6415.0 7.0 7.0 15.0 ... 7.0 15.0 7.0array([[15.,  7.,  7., ..., 15., 15.,  7.],\n       [ 7.,  7.,  7., ...,  7., 15.,  7.]])perf_counter_diff(chain, draw)float640.004514 0.002346 ... 0.002554array([[0.00451421, 0.00234647, 0.00234609, ..., 0.00520036, 0.00660593,\n        0.00227478],\n       [0.00251641, 0.00256408, 0.00261551, ..., 0.00242392, 0.00476616,\n        0.0025536 ]])perf_counter_start(chain, draw)float649.441e+03 9.441e+03 ... 9.444e+03array([[9440.65153013, 9440.65626809, 9440.65882007, ..., 9444.36672042,\n        9444.37217617, 9444.37899446],\n       [9440.65396041, 9440.65673697, 9440.65951651, ..., 9444.07317971,\n        9444.07582181, 9444.08080841]])process_time_diff(chain, draw)float640.004515 0.00233 ... 0.002555array([[0.00451509, 0.00233032, 0.00234784, ..., 0.00520224, 0.0066074 ,\n        0.00227581],\n       [0.00251693, 0.00256571, 0.00261747, ..., 0.00242573, 0.00476705,\n        0.00255493]])reached_max_treedepth(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])smallest_eigval(chain, draw)float64nan nan nan nan ... nan nan nan nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]])step_size(chain, draw)float640.4493 0.4493 ... 0.2491 0.2491array([[0.44934442, 0.44934442, 0.44934442, ..., 0.44934442, 0.44934442,\n        0.44934442],\n       [0.24907212, 0.24907212, 0.24907212, ..., 0.24907212, 0.24907212,\n        0.24907212]])step_size_bar(chain, draw)float640.4092 0.4092 ... 0.3806 0.3806array([[0.40917257, 0.40917257, 0.40917257, ..., 0.40917257, 0.40917257,\n        0.40917257],\n       [0.38056482, 0.38056482, 0.38056482, ..., 0.38056482, 0.38056482,\n        0.38056482]])tree_depth(chain, draw)int644 3 3 4 3 3 3 4 ... 4 3 4 3 3 3 4 3array([[4, 3, 3, ..., 4, 4, 3],\n       [3, 3, 3, ..., 3, 4, 3]])Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Attributes: (8)created_at :2024-05-26T21:58:43.673049+00:00arviz_version :0.18.0inference_library :pymcinference_library_version :5.15.0+23.g19be124esampling_time :8.18968677520752tuning_steps :1000modeling_interface :bambimodeling_interface_version :0.13.1.dev39+gb7d6a6cb\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 4kB\nDimensions:  (__obs__: 250)\nCoordinates:\n  * __obs__  (__obs__) int64 2kB 0 1 2 3 4 5 6 7 ... 243 244 245 246 247 248 249\nData variables:\n    count    (__obs__) int64 2kB 0 0 0 0 1 0 0 0 0 1 0 ... 4 1 1 0 1 0 0 0 0 0 0\nAttributes:\n    created_at:                  2024-05-26T21:58:43.678881+00:00\n    arviz_version:               0.18.0\n    inference_library:           pymc\n    inference_library_version:   5.15.0+23.g19be124e\n    modeling_interface:          bambi\n    modeling_interface_version:  0.13.1.dev39+gb7d6a6cbxarray.DatasetDimensions:__obs__: 250Coordinates: (1)__obs__(__obs__)int640 1 2 3 4 5 ... 245 246 247 248 249array([  0,   1,   2, ..., 247, 248, 249])Data variables: (1)count(__obs__)int640 0 0 0 1 0 0 0 ... 0 1 0 0 0 0 0 0array([  0,   0,   0,   0,   1,   0,   0,   0,   0,   1,   0,   0,   1,\n         2,   0,   1,   0,   0,   1,   0,   1,   5,   0,   3,  30,   0,\n        13,   0,   0,   0,   0,   0,  11,   5,   0,   1,   1,   7,   0,\n        14,   0,  32,   0,   1,   0,   0,   0,   1,   5,   0,   1,   0,\n        22,   0,  15,   0,   0,   0,   5,   4,   2,   0,   2,  32,   0,\n         0,   1,   0,   0,   0,   7,   0,   0,   0,   0,   0,   0,   0,\n         0,   2,   3,   1,   5,   0,   2,   1,   0,   1, 149,   0,   1,\n         0,   0,   1,   0,   0,   0,   2,   2,  29,   3,   0,   0,   5,\n         0,   0,   0,   0,   0,   1,   7,   1,   0,   2,   0,   2,   0,\n         0,   0,   1,   0,   0,   0,   0,   0,   3,   4,   3,   3,   8,\n         2,   1,   6,   0,   0,   5,   3,  31,   0,   2,   0,   0,   0,\n         0,   0,   0,   6,   9,   0,   0,   0,   0,   0,   2,  15,   1,\n         2,   3,   0,  65,   5,   0,   0,   0,   0,   1,   8,   0,   0,\n         0,   2,   4,   5,   9,   0,   0,   0,   0,  21,   0,   6,   0,\n         0,   0,   0,  16,   0,   0,   4,   2,  10,   0,   0,   0,   2,\n         1,   3,   0,   0,  21,   0,   0,   2,   0,   3,   0,  38,   0,\n         0,   0,   1,   3,   0,   1,   0,   0,   0,   0,   5,   0,   0,\n         2,   0,   0,   0,   1,   4,   0,   0,   2,   3,   0,   0,   0,\n         0,   1,   2,   0,   6,   4,   1,   1,   0,   1,   0,   0,   0,\n         0,   0,   0])Indexes: (1)__obs__PandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       240, 241, 242, 243, 244, 245, 246, 247, 248, 249],\n      dtype='int64', name='__obs__', length=250))Attributes: (6)created_at :2024-05-26T21:58:43.678881+00:00arviz_version :0.18.0inference_library :pymcinference_library_version :5.15.0+23.g19be124emodeling_interface :bambimodeling_interface_version :0.13.1.dev39+gb7d6a6cb\n                      \n                  \n            \n            \n              \n            \n            \n\n\n\ndraw_1 = select_draws(idata_grid, grid, {\"livebait\": 0}, \"mu\")\n\n\ndraw_1 = select_draws(idata_grid, grid, {\"livebait\": 0}, \"mu\")\ndraw_2 = select_draws(idata_grid, grid, {\"livebait\": 1}, \"mu\")\n\ncomparison_mean = (draw_2 - draw_1).mean((\"chain\", \"draw\"))\ncomparison_hdi = az.hdi(draw_2 - draw_1)\n\ncomparison_df = pd.DataFrame(\n    {\n        \"mean\": comparison_mean.values,\n        \"hdi_low\": comparison_hdi.sel(hdi=\"lower\")[\"mu\"].values,\n        \"hdi_high\": comparison_hdi.sel(hdi=\"higher\")[\"mu\"].values,\n    }\n)\ncomparison_df.head(10)\n\n\n\n\n\n\n\n\nmean\nhdi_low\nhdi_high\n\n\n\n\n0\n0.216038\n0.150384\n0.294501\n\n\n1\n0.054384\n0.029894\n0.077987\n\n\n2\n0.013811\n0.005794\n0.021496\n\n\n3\n0.003539\n0.001142\n0.006083\n\n\n4\n0.515839\n0.375190\n0.670931\n\n\n5\n0.129765\n0.078764\n0.182346\n\n\n6\n0.032932\n0.014961\n0.050478\n\n\n7\n0.008432\n0.002665\n0.014138\n\n\n8\n1.234183\n0.926056\n1.553555\n\n\n9\n0.310259\n0.195251\n0.425951\n\n\n\n\n\n\n\nWe can compare this comparison with bmb.interpret.comparisons.\n\nsummary_df = bmb.interpret.comparisons(\n    fish_model,\n    fish_idata,\n    contrast={\"livebait\": [0, 1]},\n    conditional=conditional\n)\nsummary_df.head(10)\n\n\n\n\n\n\n\n\nterm\nestimate_type\nvalue\ncamper\npersons\nchild\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\nlivebait\ndiff\n(0, 1)\n0\n1\n1\n0.216038\n0.150384\n0.294501\n\n\n1\nlivebait\ndiff\n(0, 1)\n0\n1\n2\n0.054384\n0.029894\n0.077987\n\n\n2\nlivebait\ndiff\n(0, 1)\n0\n1\n3\n0.013811\n0.005794\n0.021496\n\n\n3\nlivebait\ndiff\n(0, 1)\n0\n1\n4\n0.003539\n0.001142\n0.006083\n\n\n4\nlivebait\ndiff\n(0, 1)\n0\n2\n1\n0.515839\n0.375190\n0.670931\n\n\n5\nlivebait\ndiff\n(0, 1)\n0\n2\n2\n0.129765\n0.078764\n0.182346\n\n\n6\nlivebait\ndiff\n(0, 1)\n0\n2\n3\n0.032932\n0.014961\n0.050478\n\n\n7\nlivebait\ndiff\n(0, 1)\n0\n2\n4\n0.008432\n0.002665\n0.014138\n\n\n8\nlivebait\ndiff\n(0, 1)\n0\n3\n1\n1.234183\n0.926056\n1.553555\n\n\n9\nlivebait\ndiff\n(0, 1)\n0\n3\n2\n0.310259\n0.195251\n0.425951\n\n\n\n\n\n\n\nAlbeit the other information in the summary_df, the columns estimate, lower_3.0%, upper_97.0% are identical.\n\n\nCross comparisons\nComputing a cross-comparison is useful for when we want to compare contrasts when two (or more) predictors change at the same time. Cross-comparisons are currently not supported in the comparisons function, but we can use select_draws to compute them. For example, imagine we are interested in computing the cross-comparison between the two rows below.\n\nsummary_df.iloc[:2]\n\n\n\n\n\n\n\n\nterm\nestimate_type\nvalue\ncamper\npersons\nchild\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\nlivebait\ndiff\n(0, 1)\n0\n1\n1\n0.216038\n0.150384\n0.294501\n\n\n1\nlivebait\ndiff\n(0, 1)\n0\n1\n2\n0.054384\n0.029894\n0.077987\n\n\n\n\n\n\n\nThe cross-comparison amounts to first computing the comparison for row 0, given below, and can be verified by looking at the estimate in summary_df.\n\ncond_10 = {\n    \"camper\": 0,\n    \"persons\": 1,\n    \"child\": 1,\n    \"livebait\": 0 \n}\n\ncond_11 = {\n    \"camper\": 0,\n    \"persons\": 1,\n    \"child\": 1,\n    \"livebait\": 1\n}\n\ndraws_10 = select_draws(idata_grid, grid, cond_10, \"mu\")\ndraws_11 = select_draws(idata_grid, grid, cond_11, \"mu\")\n\n(draws_11 - draws_10).mean((\"chain\", \"draw\")).item()\n\n0.21603768204145285\n\n\nNext, we need to compute the comparison for row 1.\n\ncond_20 = {\n    \"camper\": 0,\n    \"persons\": 1,\n    \"child\": 2,\n    \"livebait\": 0\n}\n\ncond_21 = {\n    \"camper\": 0,\n    \"persons\": 1,\n    \"child\": 2,\n    \"livebait\": 1\n}\n\ndraws_20 = select_draws(idata_grid, grid, cond_20, \"mu\")\ndraws_21 = select_draws(idata_grid, grid, cond_21, \"mu\")\n\n\n(draws_21 - draws_20).mean((\"chain\", \"draw\")).item()\n\n0.0543836038546379\n\n\nNext, we compute the “first level” comparisons (diff_1 and diff_2). Subsequently, we compute the difference between these two differences to obtain the cross-comparison.\n\ndiff_1 = (draws_11 - draws_10)\ndiff_2 = (draws_21 - draws_20)\n\ncross_comparison = (diff_2 - diff_1).mean((\"chain\", \"draw\")).item()\ncross_comparison\n\n-0.16165407818681496\n\n\nTo verify this is correct, we can check by performing the cross-comparison directly on the summary_df.\n\nsummary_df.iloc[1][\"estimate\"] - summary_df.iloc[0][\"estimate\"]\n\n-0.16165407818681496",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Interpret Advanced Usage"
    ]
  },
  {
    "objectID": "notebooks/interpret_advanced_usage.html#summary",
    "href": "notebooks/interpret_advanced_usage.html#summary",
    "title": "Interpret Advanced Usage",
    "section": "Summary",
    "text": "Summary\nIn this notebook, the interpret helper functions data_grid and select_draws were introduced and it was demonstrated how they can be used to compute pairwise grids of data and cross-comparisons. With these functions, it is left to the user to generate their grids of data and quantities of interest allowing for more flexibility and control over the type of data passed to model.predict and the quantities of interest computed.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sun May 26 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\nnumpy : 1.26.4\narviz : 0.18.0\nbambi : 0.13.1.dev39+gb7d6a6cb\npandas: 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Interpret Advanced Usage"
    ]
  },
  {
    "objectID": "notebooks/mister_p.html",
    "href": "notebooks/mister_p.html",
    "title": "Multilevel Regression and Post-stratification",
    "section": "",
    "text": "What are we even doing when we fit a regression model? Is a question that arises when first learning the tools of the trade and again when debugging strange results of your thousandth logistic regression model.\nThis notebook is intended to showcase how regression can be seen as a method for automating the calculation of stratum specific conditional effects. Additionally, we’ll see how we can enrich regression models by a post-stratification adjustment with knowledge of the appropriate stratum specific weights. This technique of multilevel regression and post stratification (MrP) is often used in the context of national surveys where we have knowledge of the population weights appropriate to different demographic groups. It can be used in a wide variety of areas ranging from political polling to online market research. We will demonstrate how to fit and and assess these models using Bambi.\n\nimport warnings\n\nimport arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pymc as pm\n\nimport pytensor\nimport jax\nimport numpyro\nimport bayeux as bx\n\nprint(pm.__version__)\nprint(pytensor.__version__)\nprint(jax.__version__)\nprint(numpyro.__version__)\nprint(bmb.__version__)\nprint(bx.__version__)\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\n\n5.22.0\n2.30.3\n0.4.38\n0.18.0\n0.15.0\n0.1.15\n\n\n/Users/nathanielforde/mambaforge/envs/bambi-env2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Multilevel Regression and Post-stratification"
    ]
  },
  {
    "objectID": "notebooks/mister_p.html#regression-and-effect-modification",
    "href": "notebooks/mister_p.html#regression-and-effect-modification",
    "title": "Multilevel Regression and Post-stratification",
    "section": "",
    "text": "What are we even doing when we fit a regression model? Is a question that arises when first learning the tools of the trade and again when debugging strange results of your thousandth logistic regression model.\nThis notebook is intended to showcase how regression can be seen as a method for automating the calculation of stratum specific conditional effects. Additionally, we’ll see how we can enrich regression models by a post-stratification adjustment with knowledge of the appropriate stratum specific weights. This technique of multilevel regression and post stratification (MrP) is often used in the context of national surveys where we have knowledge of the population weights appropriate to different demographic groups. It can be used in a wide variety of areas ranging from political polling to online market research. We will demonstrate how to fit and and assess these models using Bambi.\n\nimport warnings\n\nimport arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pymc as pm\n\nimport pytensor\nimport jax\nimport numpyro\nimport bayeux as bx\n\nprint(pm.__version__)\nprint(pytensor.__version__)\nprint(jax.__version__)\nprint(numpyro.__version__)\nprint(bmb.__version__)\nprint(bx.__version__)\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\n\n5.22.0\n2.30.3\n0.4.38\n0.18.0\n0.15.0\n0.1.15\n\n\n/Users/nathanielforde/mambaforge/envs/bambi-env2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Multilevel Regression and Post-stratification"
    ]
  },
  {
    "objectID": "notebooks/mister_p.html#risk-stratification",
    "href": "notebooks/mister_p.html#risk-stratification",
    "title": "Multilevel Regression and Post-stratification",
    "section": "Risk Stratification",
    "text": "Risk Stratification\nFirst consider this example of heart transplant patients adapted from Hernan and Robins’ excellent book Causal Inference: What if. Here we have a number of patients (anonymised with names for the Greek Gods). The data records the outcomes of a heart transplant program for those who were part of the program and those who were not. We also see the different risk levels of each patient assigned the treatment.\nWhat we want to show here is that a regression model fit to this data automatically accounts for the weighting appropriate to the different risk strata. The data is coded with 0-1 indicators for status. Risk_Strata is either 1 for higher risk or 0 for lower risk. Outcome is whether or not the patient died from the procedure, and Treatment is whether or not the patient received treatment.\n\ndf = pd.DataFrame(\n    {\n        \"name\": [\n            \"Rheia\",\n            \"Kronos\",\n            \"Demeter\",\n            \"Hades\",\n            \"Hestia\",\n            \"Poseidon\",\n            \"Hera\",\n            \"Zeus\",\n            \"Artemis\",\n            \"Apollo\",\n            \"Leto\",\n            \"Ares\",\n            \"Athena\",\n            \"Hephaestus\",\n            \"Aphrodite\",\n            \"Cyclope\",\n            \"Persephone\",\n            \"Hermes\",\n            \"Hebe\",\n            \"Dionysus\",\n        ],\n        \"Risk_Strata\": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        \"Treatment\": [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        \"Outcome\": [0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n    }\n)\n\ndf[\"Treatment_x_Risk_Strata\"] = df.Treatment * df.Risk_Strata\n\ndf\n\n\n\n\n\n\n\n\nname\nRisk_Strata\nTreatment\nOutcome\nTreatment_x_Risk_Strata\n\n\n\n\n0\nRheia\n0\n0\n0\n0\n\n\n1\nKronos\n0\n0\n1\n0\n\n\n2\nDemeter\n0\n0\n0\n0\n\n\n3\nHades\n0\n0\n0\n0\n\n\n4\nHestia\n0\n1\n0\n0\n\n\n5\nPoseidon\n0\n1\n0\n0\n\n\n6\nHera\n0\n1\n0\n0\n\n\n7\nZeus\n0\n1\n1\n0\n\n\n8\nArtemis\n1\n0\n1\n0\n\n\n9\nApollo\n1\n0\n1\n0\n\n\n10\nLeto\n1\n0\n0\n0\n\n\n11\nAres\n1\n1\n1\n1\n\n\n12\nAthena\n1\n1\n1\n1\n\n\n13\nHephaestus\n1\n1\n1\n1\n\n\n14\nAphrodite\n1\n1\n1\n1\n\n\n15\nCyclope\n1\n1\n1\n1\n\n\n16\nPersephone\n1\n1\n1\n1\n\n\n17\nHermes\n1\n1\n0\n1\n\n\n18\nHebe\n1\n1\n0\n1\n\n\n19\nDionysus\n1\n1\n0\n1\n\n\n\n\n\n\n\nIf the treatment assignment procedure involved complete randomisation then we might expect a reasonable balance of strata effects across the treated and non-treated. In this sample we see (perhaps counter intuitively) that the treatment seems to induce a higher rate of death than the non-treated group.\n\nsimple_average = df.groupby(\"Treatment\")[[\"Outcome\"]].mean().rename({\"Outcome\": \"Share\"}, axis=1)\nsimple_average\n\n\n\n\n\n\n\n\nShare\n\n\nTreatment\n\n\n\n\n\n0\n0.428571\n\n\n1\n0.538462\n\n\n\n\n\n\n\nWhich suggests an alarming causal effect whereby the treatment seems to increase risk of death in the population.\n\ncausal_risk_ratio = simple_average.iloc[1][\"Share\"] / simple_average.iloc[0][\"Share\"]\nprint(\"Causal Risk Ratio:\", causal_risk_ratio)\n\nCausal Risk Ratio: 1.2564102564102564\n\n\nThis finding we know on inspection is driven by the imbalance in the risk strata across the treatment groups.\n\ndf.groupby(\"Risk_Strata\")[[\"Treatment\"]].count().assign(\n    proportion=lambda x: x[\"Treatment\"] / len(df)\n)\n\n\n\n\n\n\n\n\nTreatment\nproportion\n\n\nRisk_Strata\n\n\n\n\n\n\n0\n8\n0.4\n\n\n1\n12\n0.6\n\n\n\n\n\n\n\nWe can correct for this by weighting the results by the share each group represents across the Risk_Strata. In other words when we correct for the population size at the different levels of risk we get a better estimate of the effect. First we see what the expected outcome is for each strata.\n\noutcomes_controlled = (\n    df.groupby([\"Risk_Strata\", \"Treatment\"])[[\"Outcome\"]]\n    .mean()\n    .reset_index()\n    .pivot(index=\"Treatment\", columns=[\"Risk_Strata\"], values=\"Outcome\")\n)\n\noutcomes_controlled\n\n\n\n\n\n\n\nRisk_Strata\n0\n1\n\n\nTreatment\n\n\n\n\n\n\n0\n0.25\n0.666667\n\n\n1\n0.25\n0.666667\n\n\n\n\n\n\n\nNote how the expected outcomes are equal across the stratified groups. We can now combine these estimate with the population weights (derived earlier) in each segment to get our weighted average.\n\nweighted_avg = outcomes_controlled.assign(formula=\"0.4*0.25 + 0.6*0.66\").assign(\n    weighted_average=lambda x: x[0] * (df[df[\"Risk_Strata\"] == 0].shape[0] / len(df))\n    + x[1] * (df[df[\"Risk_Strata\"] == 1].shape[0] / len(df))\n)\n\nweighted_avg\n\n\n\n\n\n\n\nRisk_Strata\n0\n1\nformula\nweighted_average\n\n\nTreatment\n\n\n\n\n\n\n\n\n0\n0.25\n0.666667\n0.4*0.25 + 0.6*0.66\n0.5\n\n\n1\n0.25\n0.666667\n0.4*0.25 + 0.6*0.66\n0.5\n\n\n\n\n\n\n\nFrom which we can derive a more sensible treatment effect.\n\ncausal_risk_ratio = (\n    weighted_avg.iloc[1][\"weighted_average\"] / weighted_avg.iloc[0][\"weighted_average\"]\n)\n\nprint(\"Causal Risk Ratio:\", causal_risk_ratio)\n\nCausal Risk Ratio: 1.0",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Multilevel Regression and Post-stratification"
    ]
  },
  {
    "objectID": "notebooks/mister_p.html#regression-as-stratification",
    "href": "notebooks/mister_p.html#regression-as-stratification",
    "title": "Multilevel Regression and Post-stratification",
    "section": "Regression as Stratification",
    "text": "Regression as Stratification\nSo far, so good. But so what?\nThe point here is that the above series of steps can be difficult to accomplish with more complex sets of groups and risk profiles. So it’s useful to understand that regression can be used to automatically account for the variation in outcome effects across the different strata of our population. More prosaically, the example shows that it really matters what variables you put in your model.\n\nreg = bmb.Model(\"Outcome ~ 1 + Treatment\", df)\nresults = reg.fit()\n\nreg_strata = bmb.Model(\"Outcome ~ 1 + Treatment + Risk_Strata + Treatment_x_Risk_Strata\", df)\nresults_strata = reg_strata.fit()\n\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [sigma, Intercept, Treatment]\n\n\n/Users/nathanielforde/mambaforge/envs/bambi-env2/lib/python3.12/site-packages/rich/live.py:231: UserWarning: \ninstall \"ipywidgets\" for Jupyter support\n  warnings.warn('install \"ipywidgets\" for Jupyter support')\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 0 seconds.\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [sigma, Intercept, Treatment, Risk_Strata, Treatment_x_Risk_Strata]\n\n\n/Users/nathanielforde/mambaforge/envs/bambi-env2/lib/python3.12/site-packages/rich/live.py:231: UserWarning: \ninstall \"ipywidgets\" for Jupyter support\n  warnings.warn('install \"ipywidgets\" for Jupyter support')\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n\n\nWe can now inspect the treatment effect and the implied causal risk ratio in each model. We can quickly recover that controlling for the right variables in our regression model automatically adjusts the treatment effect downwards towards 0.\n\naz.summary(results)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n0.435\n0.212\n0.043\n0.830\n0.003\n0.003\n3917.0\n2928.0\n1.0\n\n\nTreatment\n0.104\n0.261\n-0.378\n0.598\n0.004\n0.005\n3932.0\n2631.0\n1.0\n\n\nsigma\n0.545\n0.095\n0.386\n0.725\n0.002\n0.002\n4173.0\n3192.0\n1.0\n\n\n\n\n\n\n\n\naz.summary(results_strata)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n0.252\n0.265\n-0.233\n0.762\n0.006\n0.004\n2284.0\n2545.0\n1.0\n\n\nRisk_Strata\n0.415\n0.411\n-0.310\n1.236\n0.010\n0.008\n1778.0\n1763.0\n1.0\n\n\nTreatment\n0.012\n0.372\n-0.710\n0.705\n0.008\n0.007\n1959.0\n2201.0\n1.0\n\n\nTreatment_x_Risk_Strata\n-0.011\n0.519\n-1.043\n0.935\n0.014\n0.011\n1491.0\n1505.0\n1.0\n\n\nsigma\n0.532\n0.097\n0.377\n0.730\n0.002\n0.002\n2252.0\n1613.0\n1.0\n\n\n\n\n\n\n\n\nax = az.plot_forest(\n    [results, results_strata],\n    model_names=[\"naive_model\", \"stratified_model\"],\n    var_names=[\"Treatment\"],\n    kind=\"ridgeplot\",\n    ridgeplot_alpha=0.4,\n    combined=True,\n    figsize=(10, 6),\n)\nax[0].axvline(0, color=\"black\", linestyle=\"--\")\nax[0].set_title(\"Treatment Effects under Stratification/Non-stratification\");\n\n\n\n\n\n\n\n\nWe can even see this in the predicted outcomes for the model. This is an important step. The regression model automatically adjusts for the risk profile within the appropriate strata in the data “seen” by the model.\n\nnew_df = df[[\"Risk_Strata\"]].assign(Treatment=1).assign(Treatment_x_Risk_Strata=1)\nnew_preds = reg_strata.predict(results_strata, kind=\"pps\", data=new_df, inplace=False)\nprint(\"Expected Outcome in the Treated\")\nnew_preds[\"posterior_predictive\"][\"Outcome\"].mean().item()\n\nExpected Outcome in the Treated\n\n\n0.5024635600643877\n\n\n\nnew_df = df[[\"Risk_Strata\"]].assign(Treatment=0).assign(Treatment_x_Risk_Strata=0)\nnew_preds = reg_strata.predict(results_strata, kind=\"pps\", data=new_df, inplace=False)\nprint(\"Expected Outcome in the Untreated\")\n\nnew_preds[\"posterior_predictive\"][\"Outcome\"].mean().item()\n\nExpected Outcome in the Untreated\n\n\n0.501960276578347\n\n\nWe can see these results more clearly using bambi model interpretation functions to see the predictions within a specific strata.\n\nfig, axs = plt.subplots(1, 2, figsize=(20, 6))\naxs = axs.flatten()\nbmb.interpret.plot_predictions(reg, results, [\"Treatment\"], ax=axs[0])\nbmb.interpret.plot_predictions(reg_strata, results_strata, [\"Treatment\"], ax=axs[1])\naxs[0].set_title(\"Non Stratified Regression \\n Model Predictions\")\naxs[1].set_title(\"Stratified Regression \\n Model Predictions\");\n\nDefault computed for conditional variable: Treatment\nDefault computed for conditional variable: Treatment\nDefault computed for unspecified variable: Risk_Strata, Treatment_x_Risk_Strata\n\n\n\n\n\n\n\n\n\nHernan and Robins expand on these foundational observations and elaborate the implications for causal inference and the bias of confounding variables. We won’t go into these details, as we instead we want to draw out the connection with controlling for the risk of non-representative sampling. The usefulness of “representative-ness” as an idea is disputed in the statistical literature due to the vagueness of the term. To say a sample is representative is ussually akin to meaning that it was generated from a high-quality probability sampling design. This design is specified to avoid the creep of bias due to selection effects contaminating the results.\nWe’ve seen how regression can automate stratification across the levels of covariates in the model conditional on the sample data. But what if the prevalence of the risk-profile in your data does not reflect the prevalance of risk in the wider population? Then the regression model will automatically adjust to the prevalence in the sample, but it is not adjusting to the correct weights.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Multilevel Regression and Post-stratification"
    ]
  },
  {
    "objectID": "notebooks/mister_p.html#the-need-for-post-stratification",
    "href": "notebooks/mister_p.html#the-need-for-post-stratification",
    "title": "Multilevel Regression and Post-stratification",
    "section": "The Need for Post-Stratification",
    "text": "The Need for Post-Stratification\nIn the context of national survey design there is always a concern that the sample respondents may be more or less representative of the population across different key demographics e.g. it’s unlikely we would put much faith in the survey’s accuracy if it had 90% male respondents on a question about the lived experience of women. Given that we can know before hand that certain demographic splits are not relective of the census data, we can use this information to appropriately re-weight the regressions fit to non-representative survey data.\nWe’ll demonstrate the idea of multi-level regression and post-stratification adjustment by replicating some of the steps discussed in Martin, Philips and Gelman’s “Multilevel Regression and Poststratification Case Studies”.\nThey cite data from the Cooperative Congressional Election Study (Schaffner, Ansolabehere, and Luks (2018)), a US nationwide survey designed by a consortium of 60 research teams and administered by YouGov. The outcome of interest is a binary question: Should employers decline coverage of abortions in insurance plans?\n\ncces_all_df = pd.read_csv(\"data/mr_p_cces18_common_vv.csv.gz\", low_memory=False)\ncces_all_df.head()\n\n\n\n\n\n\n\n\ncaseid\ncommonweight\ncommonpostweight\nvvweight\nvvweight_post\ntookpost\nCCEStake\nbirthyr\ngender\neduc\n...\nCL_party\nCL_2018gvm\nCL_2018pep\nCL_2018pvm\nstarttime\nendtime\nstarttime_post\nendtime_post\nDMA\ndmaname\n\n\n\n\n0\n123464282\n0.940543\n0.7936\n0.740858\n0.641412\n2\n1\n1964\n2\n4\n...\n11.0\n1.0\nNaN\nNaN\n04oct2018 02:47:10\n09oct2018 04:16:31\n11nov2018 00:41:13\n11nov2018 01:21:53\n512.0\nBALTIMORE\n\n\n1\n170169205\n0.769724\n0.7388\n0.425236\n0.415134\n2\n1\n1971\n2\n2\n...\n13.0\nNaN\n6.0\n2.0\n02oct2018 06:55:22\n02oct2018 07:32:51\n12nov2018 00:49:50\n12nov2018 01:08:43\n531.0\n\"TRI-CITIES\n\n\n2\n175996005\n1.491642\n1.3105\n1.700094\n1.603264\n2\n1\n1958\n2\n3\n...\n13.0\n5.0\nNaN\nNaN\n07oct2018 00:48:23\n07oct2018 01:38:41\n12nov2018 21:49:41\n12nov2018 22:19:28\n564.0\nCHARLESTON-HUNTINGTON\n\n\n3\n176818556\n5.104709\n4.6304\n5.946729\n5.658840\n2\n1\n1946\n2\n6\n...\n4.0\n3.0\nNaN\n3.0\n11oct2018 15:20:26\n11oct2018 16:18:42\n11nov2018 13:24:16\n11nov2018 14:00:14\n803.0\nLOS ANGELES\n\n\n4\n202120533\n0.466526\n0.3745\n0.412451\n0.422327\n2\n1\n1972\n2\n2\n...\n3.0\n5.0\nNaN\nNaN\n08oct2018 02:31:28\n08oct2018 03:03:48\n15nov2018 01:04:16\n15nov2018 01:57:21\n529.0\nLOUISVILLE\n\n\n\n\n5 rows × 526 columns\n\n\n\n\nCleaning Census Data\nTo prepare the census data for modelling we need to break the demographic data into appropriate stratum. We will break out these groupings as along broad categories familiar to audiences of election coverage news. Even these steps amount to a significant choice where we use our knowledge of pertinent demographics to decide upon the key strata we wish to represent in our model, as we seek to better predict and understand the voting outcome.\n\nstates = [\n    \"AL\",\n    \"AK\",\n    \"AZ\",\n    \"AR\",\n    \"CA\",\n    \"CO\",\n    \"CT\",\n    \"DE\",\n    \"FL\",\n    \"GA\",\n    \"HI\",\n    \"ID\",\n    \"IL\",\n    \"IN\",\n    \"IA\",\n    \"KS\",\n    \"KY\",\n    \"LA\",\n    \"ME\",\n    \"MD\",\n    \"MA\",\n    \"MI\",\n    \"MN\",\n    \"MS\",\n    \"MO\",\n    \"MT\",\n    \"NE\",\n    \"NV\",\n    \"NH\",\n    \"NJ\",\n    \"NM\",\n    \"NY\",\n    \"NC\",\n    \"ND\",\n    \"OH\",\n    \"OK\",\n    \"OR\",\n    \"PA\",\n    \"RI\",\n    \"SC\",\n    \"SD\",\n    \"TN\",\n    \"TX\",\n    \"UT\",\n    \"VT\",\n    \"VA\",\n    \"WA\",\n    \"WV\",\n    \"WI\",\n    \"WY\",\n]\n\n\nnumbers = list(range(1, 56, 1))\n\nlkup_states = dict(zip(numbers, states))\nlkup_states\n\n\nethnicity = [\n    \"White\",\n    \"Black\",\n    \"Hispanic\",\n    \"Asian\",\n    \"Native American\",\n    \"Mixed\",\n    \"Other\",\n    \"Middle Eastern\",\n]\nnumbers = list(range(1, 9, 1))\nlkup_ethnicity = dict(zip(numbers, ethnicity))\nlkup_ethnicity\n\n\nedu = [\"No HS\", \"HS\", \"Some college\", \"Associates\", \"4-Year College\", \"Post-grad\"]\nnumbers = list(range(1, 7, 1))\nlkup_edu = dict(zip(numbers, edu))\n\n\ndef clean_df(df):\n    ## 0 Oppose and 1 Support\n    df[\"abortion\"] = np.abs(df[\"CC18_321d\"] - 2)\n    df[\"state\"] = df[\"inputstate\"].map(lkup_states)\n    ## dichotomous (coded as -0.5 Female, +0.5 Male)\n    df[\"male\"] = np.abs(df[\"gender\"] - 2) - 0.5\n    df[\"eth\"] = df[\"race\"].map(lkup_ethnicity)\n    df[\"eth\"] = np.where(\n        df[\"eth\"].isin([\"Asian\", \"Other\", \"Middle Eastern\", \"Mixed\", \"Native American\"]),\n        \"Other\",\n        df[\"eth\"],\n    )\n    df[\"age\"] = 2018 - df[\"birthyr\"]\n    df[\"age\"] = pd.cut(\n        df[\"age\"].astype(int),\n        [0, 29, 39, 49, 59, 69, 120],\n        labels=[\"18-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"70+\"],\n        ordered=True,\n    )\n    df[\"edu\"] = df[\"educ\"].map(lkup_edu)\n    df[\"edu\"] = np.where(df[\"edu\"].isin([\"Some college\", \"Associates\"]), \"Some college\", df[\"edu\"])\n\n    df = df[[\"abortion\", \"state\", \"eth\", \"male\", \"age\", \"edu\", \"caseid\"]]\n    return df.dropna()\n\n\nstatelevel_predictors_df = pd.read_csv(\"data/mr_p_statelevel_predictors.csv\")\n\ncces_all_df = clean_df(cces_all_df)\ncces_all_df.head()\n\n\n\n\n\n\n\n\nabortion\nstate\neth\nmale\nage\nedu\ncaseid\n\n\n\n\n0\n1.0\nMS\nOther\n-0.5\n50-59\nSome college\n123464282\n\n\n1\n1.0\nWA\nWhite\n-0.5\n40-49\nHS\n170169205\n\n\n2\n1.0\nRI\nWhite\n-0.5\n60-69\nSome college\n175996005\n\n\n3\n0.0\nCO\nOther\n-0.5\n70+\nPost-grad\n176818556\n\n\n4\n1.0\nMA\nWhite\n-0.5\n40-49\nHS\n202120533\n\n\n\n\n\n\n\nWe will now show how estimates drawn from sample data (biased for whatever reasons of chance and circumstance) can be improved by using a post-stratification adjustment based on known facts about the size of the population in each strata considered in the model. This additional step is simply another modelling choice - another way to invest our model with information. In this manner the technique comes naturally in the Bayesian perspective.\n\n\nBiased Sample\nConsider a deliberately biased sample. Biased away from the census data and in this manner we show how to better recover population level estimates by incorporating details about the census population size across each of the stratum.\n\ncces_df = cces_all_df.merge(statelevel_predictors_df, left_on=\"state\", right_on=\"state\", how=\"left\")\ncces_df[\"weight\"] = (\n    5 * cces_df[\"repvote\"]\n    + (cces_df[\"age\"] == \"18-29\") * 0.5\n    + (cces_df[\"age\"] == \"30-39\") * 1\n    + (cces_df[\"age\"] == \"40-49\") * 2\n    + (cces_df[\"age\"] == \"50-59\") * 4\n    + (cces_df[\"age\"] == \"60-69\") * 6\n    + (cces_df[\"age\"] == \"70+\") * 8\n    + (cces_df[\"male\"] == 1) * 20\n    + (cces_df[\"eth\"] == \"White\") * 1.05\n)\n\ncces_df = cces_df.sample(5000, weights=\"weight\", random_state=1000)\ncces_df.head()\n\n\n\n\n\n\n\n\nabortion\nstate\neth\nmale\nage\nedu\ncaseid\nrepvote\nregion\nweight\n\n\n\n\n35171\n0.0\nKY\nWhite\n-0.5\n60-69\nHS\n415208636\n0.656706\nSouth\n10.333531\n\n\n5167\n0.0\nNM\nWhite\n0.5\n60-69\nNo HS\n412278020\n0.453492\nWest\n9.317460\n\n\n52365\n0.0\nOK\nHispanic\n-0.5\n30-39\n4-Year College\n419467449\n0.693047\nSouth\n4.465237\n\n\n23762\n1.0\nWV\nWhite\n-0.5\n50-59\nPost-grad\n413757903\n0.721611\nSouth\n8.658053\n\n\n48197\n0.0\nRI\nWhite\n0.5\n50-59\n4-Year College\n417619385\n0.416893\nNortheast\n7.134465\n\n\n\n\n\n\n\n\n\nVisualise the Bias\nNow we plot the outcome of expected shares within each demographic bucket across both the biased sample and the census data.\n\nmosaic = \"\"\"\n    ABCD\n    EEEE\n    \"\"\"\n\nfig = plt.figure(layout=\"constrained\", figsize=(20, 10))\nax_dict = fig.subplot_mosaic(mosaic)\n\n\ndef plot_var(var, ax):\n    a = (\n        cces_df.groupby(var, observed=False)[[\"abortion\"]]\n        .mean()\n        .rename({\"abortion\": \"share\"}, axis=1)\n        .reset_index()\n    )\n    b = (\n        cces_all_df.groupby(var, observed=False)[[\"abortion\"]]\n        .mean()\n        .rename({\"abortion\": \"share_census\"}, axis=1)\n        .reset_index()\n    )\n    a = a.merge(b).sort_values(\"share\")\n    ax_dict[ax].vlines(a[var], a.share, a.share_census)\n    ax_dict[ax].scatter(a[var], a.share, color=\"blue\", label=\"Sample\")\n    ax_dict[ax].scatter(a[var], a.share_census, color=\"red\", label=\"Census\")\n    ax_dict[ax].set_ylabel(\"Proportion\")\n\n\nplot_var(\"age\", \"A\")\nplot_var(\"edu\", \"B\")\nplot_var(\"male\", \"C\")\nplot_var(\"eth\", \"D\")\nplot_var(\"state\", \"E\")\n\nax_dict[\"E\"].legend()\n\nax_dict[\"C\"].set_xticklabels([])\nax_dict[\"C\"].set_xlabel(\"Female / Male\")\nplt.suptitle(\"Comparison of Proportions: Survey Sample V Census\", fontsize=20);\n\n\n\n\n\n\n\n\nWe can see here how the proportions differ markedly across the census report and our biased sample in how they represent the preferential votes with each strata. We now try and quantify the overall differences between the biased sample and the census report. We calculate the expected proportions in each dataset and their standard error.\n\ndef get_se_bernoulli(p, n):\n    return np.sqrt(p * (1 - p) / n)\n\n\nsample_cces_estimate = {\n    \"mean\": np.mean(cces_df[\"abortion\"].astype(float)),\n    \"se\": get_se_bernoulli(np.mean(cces_df[\"abortion\"].astype(float)), len(cces_df)),\n}\nsample_cces_estimate\n\n\nsample_cces_all_estimate = {\n    \"mean\": np.mean(cces_all_df[\"abortion\"].astype(float)),\n    \"se\": get_se_bernoulli(np.mean(cces_all_df[\"abortion\"].astype(float)), len(cces_all_df)),\n}\nsample_cces_all_estimate\n\nsummary = pd.DataFrame([sample_cces_all_estimate, sample_cces_estimate])\nsummary[\"data\"] = [\"Full Data\", \"Biased Data\"]\nsummary\n\n\n\n\n\n\n\n\nmean\nse\ndata\n\n\n\n\n0\n0.434051\n0.002113\nFull Data\n\n\n1\n0.465000\n0.007054\nBiased Data\n\n\n\n\n\n\n\nA 3 percent difference in a national survey is a substantial error in the case where the difference is due to preventable bias.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Multilevel Regression and Post-stratification"
    ]
  },
  {
    "objectID": "notebooks/mister_p.html#modelling-the-data",
    "href": "notebooks/mister_p.html#modelling-the-data",
    "title": "Multilevel Regression and Post-stratification",
    "section": "Modelling the Data",
    "text": "Modelling the Data\nTo facilitate regression based stratification we first need a regression model. In our case we will ultimately fit a multi-level regression model with intercept terms for each for each of the groups in our demographic stratum. In this way we try to account for the appropriate set of variables (as in the example above) to better specify the effect modification due to membership within a particular demographic stratum.\nWe will fit the model using bambi using the binomial link function on the biased sample data. But first we aggregate up by demographic strata and count the occurences within each strata.\n\nmodel_df = (\n    cces_df.groupby([\"state\", \"eth\", \"male\", \"age\", \"edu\"], observed=False)\n    .agg({\"caseid\": \"nunique\", \"abortion\": \"sum\"})\n    .reset_index()\n    .sort_values(\"abortion\", ascending=False)\n    .rename({\"caseid\": \"n\"}, axis=1)\n    .merge(statelevel_predictors_df, left_on=\"state\", right_on=\"state\", how=\"left\")\n)\nmodel_df[\"abortion\"] = model_df[\"abortion\"].astype(int)\nmodel_df[\"n\"] = model_df[\"n\"].astype(int)\nmodel_df.head()\n\n\n\n\n\n\n\n\nstate\neth\nmale\nage\nedu\nn\nabortion\nrepvote\nregion\n\n\n\n\n0\nID\nWhite\n-0.5\n70+\nHS\n32\n18\n0.683102\nWest\n\n\n1\nID\nWhite\n0.5\n70+\n4-Year College\n20\n16\n0.683102\nWest\n\n\n2\nWV\nWhite\n0.5\n70+\nSome college\n17\n13\n0.721611\nSouth\n\n\n3\nWV\nWhite\n0.5\n70+\n4-Year College\n15\n12\n0.721611\nSouth\n\n\n4\nID\nWhite\n0.5\n70+\nPost-grad\n17\n11\n0.683102\nWest\n\n\n\n\n\n\n\nOur model_df now has one row per Strata across all the demographic cuts.\n\nFit Base Model to Biased Sample\nHere we use some of bambi’s latest functionality to assess the interaction effects between the variables.\n\nformula = \"\"\" p(abortion, n) ~ C(state) + C(eth) + C(edu) + male + repvote\"\"\"\n\nbase_model = bmb.Model(formula, model_df, family=\"binomial\")\n\nresult = base_model.fit(\n    random_seed=100,\n    target_accept=0.95,\n    inference_method=\"nutpie\",\n    num_chains=4,\n    idata_kwargs={\"log_likelihood\": True},\n)\n\nWe plot the predicted outcomes within each group using the plot_predictions function.\n\nmosaic = \"\"\"\n    AABB\n    CCCC\n    \"\"\"\n\nfig = plt.figure(layout=\"constrained\", figsize=(20, 7))\naxs = fig.subplot_mosaic(mosaic)\n\nbmb.interpret.plot_predictions(base_model, result, \"eth\", ax=axs[\"A\"])\nbmb.interpret.plot_predictions(base_model, result, \"edu\", ax=axs[\"B\"])\nbmb.interpret.plot_predictions(base_model, result, \"state\", ax=axs[\"C\"])\nplt.suptitle(\"Plot Prediction per Class\", fontsize=20);\n\nDefault computed for conditional variable: eth\nDefault computed for unspecified variable: edu, male, repvote, state\nDefault computed for conditional variable: edu\nDefault computed for unspecified variable: eth, male, repvote, state\nDefault computed for conditional variable: state\nDefault computed for unspecified variable: edu, eth, male, repvote\n\n\n\n\n\n\n\n\n\nMore interesting we can use the comparison functionality to compare differences in eth conditional on age and edu. Where we can see that the differences between ethnicities are pretty stable across all age groups, slightly shifted by within the Post-grad level of education.\n\nfig, ax = bmb.interpret.plot_comparisons(\n    model=base_model,\n    idata=result,\n    contrast={\"eth\": [\"Black\", \"White\"]},\n    conditional=[\"age\", \"edu\"],\n    comparison_type=\"diff\",\n    subplot_kwargs={\"main\": \"age\", \"group\": \"edu\"},\n    fig_kwargs={\"figsize\": (12, 5), \"sharey\": True},\n    legend=True,\n)\nax[0].set_title(\"Comparison of Difference in Ethnicity \\n within Age and Educational Strata\");\n\nDefault computed for conditional variable: age, edu\nDefault computed for unspecified variable: male, repvote, state\n\n\n\n\n\n\n\n\n\nWe can pull these specific estimates out into a table for closer inspection to see that the differences in response expected between the extremes of educational attainment are moderated by state iand race.\n\nbmb.interpret.comparisons(\n    model=base_model,\n    idata=result,\n    contrast={\"edu\": [\"Post-grad\", \"No HS\"]},\n    conditional={\"eth\": [\"Black\", \"White\"], \"state\": [\"NY\", \"CA\", \"ID\", \"VA\"]},\n    comparison_type=\"diff\",\n)\n\nDefault computed for unspecified variable: male, repvote\n\n\n\n\n\n\n\n\n\nterm\nestimate_type\nvalue\neth\nstate\nmale\nrepvote\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\nedu\ndiff\n(Post-grad, No HS)\nBlack\nCA\n0.0\n0.530191\n0.140916\n0.061406\n0.213647\n\n\n1\nedu\ndiff\n(Post-grad, No HS)\nBlack\nID\n0.0\n0.530191\n0.140846\n0.066105\n0.213532\n\n\n2\nedu\ndiff\n(Post-grad, No HS)\nBlack\nNY\n0.0\n0.530191\n0.146986\n0.071022\n0.222133\n\n\n3\nedu\ndiff\n(Post-grad, No HS)\nBlack\nVA\n0.0\n0.530191\n0.155752\n0.077262\n0.233255\n\n\n4\nedu\ndiff\n(Post-grad, No HS)\nWhite\nCA\n0.0\n0.530191\n0.163718\n0.091147\n0.239729\n\n\n5\nedu\ndiff\n(Post-grad, No HS)\nWhite\nID\n0.0\n0.530191\n0.167293\n0.091431\n0.241690\n\n\n6\nedu\ndiff\n(Post-grad, No HS)\nWhite\nNY\n0.0\n0.530191\n0.164431\n0.089027\n0.237907\n\n\n7\nedu\ndiff\n(Post-grad, No HS)\nWhite\nVA\n0.0\n0.530191\n0.136760\n0.056895\n0.219031\n\n\n\n\n\n\n\nWith this in mind we want to fit our final model to incorporate the variation we see here across the different levels of our stratified data.\n\n\nFit Final Model to Biased Sample\nWe can specify these features of our model using a hierarchical structure as follows:\n\\[\nPr(y_i = 1) = \\text{logit}^{-1}(\n\\alpha_{\\rm s[i]}^{\\rm state}\n+ \\alpha_{\\rm a[i]}^{\\rm age}\n+ \\alpha_{\\rm r[i]}^{\\rm eth}\n+ \\alpha_{\\rm e[i]}^{\\rm edu}\n+ \\beta^{\\rm male} \\cdot {\\rm Male}_{\\rm i}\n+ \\alpha_{\\rm g[i], r[i]}^{\\rm male.eth}\n+ \\alpha_{\\rm e[i], a[i]}^{\\rm edu.age}\n+ \\alpha_{\\rm e[i], r[i]}^{\\rm edu.eth}\n)\n\\]\nHere we have used the fact that we can add components to the \\(\\alpha\\) intercept terms and interaction effects to express the stratum specific variation in the outcomes that we’ve seen in our exploratory work. Using the bambi formula syntax. We have:\n\nformula = \"p(abortion, n) ~ male + repvote + (1 | state) + (1 | eth) + (1 | edu) + (1 | male:eth) + (1 | edu:age) + (1 | edu:eth)\"\n\nmodel_hierarchical = bmb.Model(formula, model_df, family=\"binomial\")\n\nresult = model_hierarchical.fit(\n    draws=4000,\n    random_seed=110,\n    target_accept=0.99,\n    inference_method=\"nutpie\",\n    idata_kwargs={\"log_likelihood\": True},\n)\n\n\nresult\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 16MB\nDimensions:               (chain: 4, draw: 4000, state__factor_dim: 46,\n                           eth__factor_dim: 4, edu__factor_dim: 5,\n                           male:eth__factor_dim: 8, edu:age__factor_dim: 30,\n                           edu:eth__factor_dim: 20)\nCoordinates:\n  * state__factor_dim     (state__factor_dim) &lt;U2 368B 'AK' 'AL' ... 'WV' 'WY'\n  * eth__factor_dim       (eth__factor_dim) &lt;U8 128B 'Black' ... 'White'\n  * edu__factor_dim       (edu__factor_dim) &lt;U14 280B '4-Year College' ... 'S...\n  * male:eth__factor_dim  (male:eth__factor_dim) &lt;U13 416B '-0.5:Black' ... '...\n  * draw                  (draw) int64 32kB 0 1 2 3 4 ... 3996 3997 3998 3999\n  * edu:age__factor_dim   (edu:age__factor_dim) &lt;U20 2kB '4-Year College:18-2...\n  * chain                 (chain) int64 32B 0 1 2 3\n  * edu:eth__factor_dim   (edu:eth__factor_dim) &lt;U23 2kB '4-Year College:Blac...\nData variables: (12/15)\n    1|edu:age_sigma       (chain, draw) float64 128kB 0.1344 0.1437 ... 0.156\n    1|edu:eth_sigma       (chain, draw) float64 128kB 0.1177 0.1093 ... 0.2808\n    1|edu_sigma           (chain, draw) float64 128kB 1.346 1.351 ... 0.04706\n    1|eth_sigma           (chain, draw) float64 128kB 0.4771 0.4858 ... 0.03536\n    1|male:eth_sigma      (chain, draw) float64 128kB 0.354 0.3236 ... 0.1215\n    1|state_sigma         (chain, draw) float64 128kB 0.2385 0.248 ... 0.2483\n    ...                    ...\n    1|edu                 (chain, draw, edu__factor_dim) float64 640kB -0.236...\n    1|edu:age             (chain, draw, edu:age__factor_dim) float64 4MB -0.0...\n    1|edu:eth             (chain, draw, edu:eth__factor_dim) float64 3MB 0.14...\n    1|eth                 (chain, draw, eth__factor_dim) float64 512kB -0.813...\n    1|male:eth            (chain, draw, male:eth__factor_dim) float64 1MB 0.5...\n    1|state               (chain, draw, state__factor_dim) float64 6MB -0.154...\nAttributes:\n    created_at:                  2025-04-12T20:47:44.644117+00:00\n    arviz_version:               0.21.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.15.0xarray.DatasetDimensions:chain: 4draw: 4000state__factor_dim: 46eth__factor_dim: 4edu__factor_dim: 5male:eth__factor_dim: 8edu:age__factor_dim: 30edu:eth__factor_dim: 20Coordinates: (8)state__factor_dim(state__factor_dim)&lt;U2'AK' 'AL' 'AR' ... 'WI' 'WV' 'WY'array(['AK', 'AL', 'AR', 'CA', 'CO', 'DE', 'FL', 'GA', 'HI', 'IA', 'ID', 'IL',\n       'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC',\n       'ND', 'NE', 'NH', 'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI',\n       'SC', 'SD', 'TN', 'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY'], dtype='&lt;U2')eth__factor_dim(eth__factor_dim)&lt;U8'Black' 'Hispanic' 'Other' 'White'array(['Black', 'Hispanic', 'Other', 'White'], dtype='&lt;U8')edu__factor_dim(edu__factor_dim)&lt;U14'4-Year College' ... 'Some college'array(['4-Year College', 'HS', 'No HS', 'Post-grad', 'Some college'],\n      dtype='&lt;U14')male:eth__factor_dim(male:eth__factor_dim)&lt;U13'-0.5:Black' ... '0.5:White'array(['-0.5:Black', '-0.5:Hispanic', '-0.5:Other', '-0.5:White', '0.5:Black',\n       '0.5:Hispanic', '0.5:Other', '0.5:White'], dtype='&lt;U13')draw(draw)int640 1 2 3 4 ... 3996 3997 3998 3999array([   0,    1,    2, ..., 3997, 3998, 3999], shape=(4000,))edu:age__factor_dim(edu:age__factor_dim)&lt;U20'4-Year College:18-29' ... 'Some...array(['4-Year College:18-29', '4-Year College:30-39', '4-Year College:40-49',\n       '4-Year College:50-59', '4-Year College:60-69', '4-Year College:70+',\n       'HS:18-29', 'HS:30-39', 'HS:40-49', 'HS:50-59', 'HS:60-69', 'HS:70+',\n       'No HS:18-29', 'No HS:30-39', 'No HS:40-49', 'No HS:50-59',\n       'No HS:60-69', 'No HS:70+', 'Post-grad:18-29', 'Post-grad:30-39',\n       'Post-grad:40-49', 'Post-grad:50-59', 'Post-grad:60-69',\n       'Post-grad:70+', 'Some college:18-29', 'Some college:30-39',\n       'Some college:40-49', 'Some college:50-59', 'Some college:60-69',\n       'Some college:70+'], dtype='&lt;U20')chain(chain)int640 1 2 3array([0, 1, 2, 3])edu:eth__factor_dim(edu:eth__factor_dim)&lt;U23'4-Year College:Black' ... 'Some...array(['4-Year College:Black', '4-Year College:Hispanic',\n       '4-Year College:Other', '4-Year College:White', 'HS:Black',\n       'HS:Hispanic', 'HS:Other', 'HS:White', 'No HS:Black', 'No HS:Hispanic',\n       'No HS:Other', 'No HS:White', 'Post-grad:Black', 'Post-grad:Hispanic',\n       'Post-grad:Other', 'Post-grad:White', 'Some college:Black',\n       'Some college:Hispanic', 'Some college:Other', 'Some college:White'],\n      dtype='&lt;U23')Data variables: (15)1|edu:age_sigma(chain, draw)float640.1344 0.1437 ... 0.1536 0.156array([[0.13441164, 0.14370398, 0.15916931, ..., 0.18880834, 0.03518931,\n        0.14314809],\n       [0.16019625, 0.16871859, 0.15828631, ..., 0.15253245, 0.11724478,\n        0.16203634],\n       [0.19024498, 0.16992334, 0.27460906, ..., 0.07731436, 0.07383145,\n        0.20263921],\n       [0.06723177, 0.06522316, 0.08860448, ..., 0.11617668, 0.15355656,\n        0.15598383]], shape=(4, 4000))1|edu:eth_sigma(chain, draw)float640.1177 0.1093 ... 0.2217 0.2808array([[0.11771773, 0.10931956, 0.09975393, ..., 0.11124875, 0.12363697,\n        0.09228348],\n       [0.13976966, 0.1288965 , 0.14463339, ..., 0.23322617, 0.23736116,\n        0.19920126],\n       [0.36019768, 0.41347014, 0.40604164, ..., 0.15508335, 0.18207936,\n        0.13132313],\n       [0.28470192, 0.25976583, 0.2111311 , ..., 0.3431292 , 0.22170838,\n        0.28077583]], shape=(4, 4000))1|edu_sigma(chain, draw)float641.346 1.351 ... 0.1539 0.04706array([[1.34609022, 1.35111116, 0.2212135 , ..., 0.51850869, 0.23301459,\n        0.51940129],\n       [0.20084021, 0.17433647, 0.18136098, ..., 0.08054317, 0.10585751,\n        0.2394544 ],\n       [0.00820515, 0.00878228, 0.01468995, ..., 0.25704124, 0.19729321,\n        0.20225655],\n       [0.03352157, 0.02812175, 0.03744695, ..., 0.34170865, 0.1538545 ,\n        0.04706238]], shape=(4, 4000))1|eth_sigma(chain, draw)float640.4771 0.4858 ... 0.2314 0.03536array([[0.4770694 , 0.48582884, 0.75481753, ..., 0.60639702, 0.45636024,\n        0.53714328],\n       [0.47658548, 0.41481086, 0.48152598, ..., 0.33476645, 0.78326188,\n        0.88538029],\n       [1.46112274, 1.43538558, 1.47628137, ..., 0.9759116 , 0.84937992,\n        1.00957962],\n       [0.19702956, 0.21981617, 0.16767914, ..., 0.17715399, 0.23135967,\n        0.03535978]], shape=(4, 4000))1|male:eth_sigma(chain, draw)float640.354 0.3236 ... 0.2696 0.1215array([[0.35397165, 0.32364947, 0.02384236, ..., 0.03622344, 0.14971025,\n        0.18014677],\n       [0.387906  , 0.41517064, 0.35954647, ..., 0.18629486, 0.17286002,\n        0.01491758],\n       [0.12495751, 0.2235392 , 0.1203779 , ..., 0.18473111, 0.10086279,\n        0.08655779],\n       [0.7184852 , 0.66431673, 0.52878106, ..., 0.29469976, 0.2695665 ,\n        0.12150705]], shape=(4, 4000))1|state_sigma(chain, draw)float640.2385 0.248 ... 0.2569 0.2483array([[0.23853477, 0.24803782, 0.25990388, ..., 0.26522649, 0.26257531,\n        0.27854286],\n       [0.2949392 , 0.2928506 , 0.29134995, ..., 0.34535457, 0.29752227,\n        0.27131224],\n       [0.36691287, 0.36180375, 0.28429242, ..., 0.26233375, 0.2947532 ,\n        0.2601899 ],\n       [0.21685807, 0.21907411, 0.2135662 , ..., 0.35388117, 0.25694889,\n        0.24834829]], shape=(4, 4000))Intercept(chain, draw)float64-0.0003219 -0.07621 ... 0.3622array([[-3.21858306e-04, -7.62069524e-02, -1.85344231e-01, ...,\n         3.72455227e-01, -1.28357710e-01, -1.75070205e-02],\n       [ 6.75254365e-01,  6.86267808e-01,  6.64230580e-01, ...,\n        -5.24206572e-02,  4.50979939e-01,  1.76310324e-01],\n       [ 5.63949358e-01,  4.04841939e-01,  4.75318513e-01, ...,\n        -4.73871675e-01, -1.43988959e-01, -6.65968891e-01],\n       [ 3.95783430e-01,  4.30751300e-01,  1.57790349e-01, ...,\n         5.72417898e-01,  5.99219020e-01,  3.62194073e-01]],\n      shape=(4, 4000))male(chain, draw)float640.1861 0.1973 ... 0.2833 0.15array([[0.18614108, 0.1972769 , 0.24609322, ..., 0.28845895, 0.14738262,\n        0.38867358],\n       [0.24864871, 0.26618414, 0.30451655, ..., 0.290124  , 0.40927837,\n        0.26403336],\n       [0.01147796, 0.00675254, 0.00233586, ..., 0.22756571, 0.20263934,\n        0.24459288],\n       [0.36824705, 0.37411922, 0.38068321, ..., 0.62651956, 0.28326965,\n        0.14996354]], shape=(4, 4000))repvote(chain, draw)float64-0.3935 -0.3044 ... -1.388 -1.119array([[-0.3934767 , -0.3044197 , -0.18716323, ..., -1.47690415,\n        -1.01878333, -0.61104586],\n       [-1.116523  , -1.10614173, -1.14699793, ..., -0.67779123,\n        -1.43154409, -0.67383683],\n       [-1.78520666, -1.58065665, -1.49763204, ..., -0.32421597,\n        -0.96578146, -0.20842237],\n       [-0.94040154, -1.02003633, -0.76954264, ..., -1.1079926 ,\n        -1.38755167, -1.11909619]], shape=(4, 4000))1|edu(chain, draw, edu__factor_dim)float64-0.2361 0.03952 ... -0.08723array([[[-0.23606639,  0.03952195,  0.19390099, -0.58725864,\n         -0.10353753],\n        [-0.04072258, -0.05117268,  0.0944052 , -0.56205338,\n          0.03253908],\n        [-0.06853926, -0.00565181,  0.12518418, -0.44266426,\n          0.05553575],\n        ...,\n        [-0.14576388,  0.14932598,  0.28614487, -0.35608171,\n          0.02875589],\n        [ 0.12322133,  0.16399086,  0.29470316, -0.10561501,\n          0.1359425 ],\n        [-0.06701444, -0.04051351,  0.21726117, -0.36566861,\n         -0.13364958]],\n\n       [[-0.0576874 , -0.12125953,  0.09555403, -0.19359222,\n          0.16842842],\n        [-0.0584045 , -0.09947117,  0.09720323, -0.18202035,\n          0.14304346],\n        [-0.06979621, -0.10658497,  0.12894312, -0.14951308,\n          0.16244339],\n...\n        [ 0.16398121,  0.02355287,  0.05073705, -0.34309796,\n         -0.04993389],\n        [-0.01554162, -0.06221654,  0.02175718, -0.29554477,\n         -0.22269852],\n        [ 0.05869026, -0.22167485,  0.00438661, -0.36304784,\n         -0.12497928]],\n\n       [[ 0.01106397,  0.00913131,  0.01688615, -0.01077497,\n         -0.02580242],\n        [ 0.0048783 , -0.00149741, -0.00177262,  0.00663449,\n         -0.01237859],\n        [ 0.01842357, -0.01586298,  0.01010242,  0.01033829,\n         -0.00466377],\n        ...,\n        [-0.1117301 ,  0.19562763,  0.00675094, -0.76317213,\n         -0.02942159],\n        [-0.17036106,  0.02770568,  0.26875207,  0.01220776,\n          0.00094009],\n        [-0.00703157,  0.0854295 , -0.00123738, -0.02605878,\n         -0.08722852]]], shape=(4, 4000, 5))1|edu:age(chain, draw, edu:age__factor_dim)float64-0.0658 -0.09502 ... 0.12 -0.0549array([[[-0.06580405, -0.09501558,  0.1117735 , ..., -0.161431  ,\n          0.06880415,  0.09496863],\n        [-0.06568834, -0.07150977,  0.11391269, ..., -0.17510751,\n          0.0642265 ,  0.11404995],\n        [ 0.06671058, -0.06212731, -0.15775793, ..., -0.00986691,\n          0.10263592,  0.13340623],\n        ...,\n        [ 0.24962068,  0.22585613, -0.11065996, ...,  0.00842856,\n          0.19569075,  0.25245259],\n        [-0.04149419,  0.00966698, -0.02895544, ...,  0.00099467,\n         -0.02481149, -0.02970359],\n        [ 0.03411322, -0.19025902, -0.04022661, ...,  0.00494236,\n          0.0963688 ,  0.29311101]],\n\n       [[ 0.07784129, -0.04760669,  0.00683357, ..., -0.15049798,\n          0.01717726,  0.11121074],\n        [ 0.06663115, -0.04488087, -0.00399348, ..., -0.1646276 ,\n          0.0031251 ,  0.11959057],\n        [ 0.10554835, -0.04361274, -0.00759353, ..., -0.13586593,\n         -0.03044159,  0.17281195],\n...\n        [-0.00373851,  0.03225081, -0.1176617 , ...,  0.08989114,\n          0.11482376,  0.03773806],\n        [ 0.01626914, -0.0147687 , -0.10202513, ...,  0.0326447 ,\n          0.07211576,  0.01780689],\n        [-0.45474507, -0.16836101, -0.28859303, ..., -0.0252933 ,\n         -0.05470419,  0.29621247]],\n\n       [[-0.00282311, -0.08021558,  0.02250639, ...,  0.01537817,\n          0.09167904,  0.06972863],\n        [ 0.05604518, -0.03303047,  0.02468017, ...,  0.00189076,\n          0.09297964,  0.12434294],\n        [ 0.05579271, -0.04335375, -0.00739794, ...,  0.00754659,\n          0.08632638,  0.13417489],\n        ...,\n        [-0.06643662, -0.07156536, -0.08991674, ..., -0.07743765,\n          0.13517072, -0.024519  ],\n        [ 0.03862708,  0.14417763, -0.07728414, ...,  0.14113535,\n          0.08486243,  0.3274914 ],\n        [-0.04941882,  0.00230183, -0.01546024, ..., -0.11303916,\n          0.11997926, -0.05490342]]], shape=(4, 4000, 30))1|edu:eth(chain, draw, edu:eth__factor_dim)float640.1416 -0.02554 ... -0.1221 0.6262array([[[ 1.41552800e-01, -2.55372634e-02, -4.13537297e-02, ...,\n          8.06654268e-02,  1.12093738e-01,  1.74819555e-01],\n        [ 1.48043337e-01, -3.88778108e-02, -1.19108127e-02, ...,\n          6.80000359e-02,  1.19721248e-01,  1.73944853e-01],\n        [-1.08284988e-01, -2.39574397e-02,  1.38273186e-01, ...,\n         -6.49435053e-02, -1.46928886e-01,  3.81065660e-02],\n        ...,\n        [ 2.54121469e-02,  9.92249123e-02,  4.41362660e-02, ...,\n          5.81225282e-02, -5.98904317e-02,  2.55109883e-01],\n        [-1.05956417e-01, -3.53505242e-01, -3.30730244e-02, ...,\n          1.93970671e-01, -9.94523759e-02,  1.02401566e-01],\n        [ 1.16564656e-01,  1.58589118e-01,  4.54278311e-02, ...,\n         -1.90160234e-01,  4.23185965e-02,  2.85031059e-01]],\n\n       [[-2.77373049e-02, -3.00759886e-01, -2.16976647e-02, ...,\n         -3.33475054e-01, -1.32921253e-02,  9.10967145e-02],\n        [-2.86452627e-02, -3.03551376e-01, -2.95181391e-02, ...,\n         -3.38176810e-01,  2.74523792e-03,  9.55083085e-02],\n        [ 3.23616518e-02, -3.47651801e-01, -6.06412486e-02, ...,\n         -2.95783064e-01,  2.29155216e-02,  1.44689727e-01],\n...\n          1.29182899e-01,  2.09732131e-01,  2.31666873e-01],\n        [-5.27013102e-02, -2.36951601e-01,  1.72038476e-01, ...,\n          2.29523419e-01,  3.30497675e-01,  2.80871478e-01],\n        [ 4.04275531e-02, -1.73196897e-01,  1.62445186e-01, ...,\n         -9.66062913e-02,  6.33620840e-02,  1.46286311e-01]],\n\n       [[ 3.80728677e-01, -1.27113675e-01,  4.17930524e-02, ...,\n          2.07388380e-02,  8.04929936e-02,  4.76554332e-02],\n        [ 2.73369833e-01,  3.80901603e-03, -3.57404701e-01, ...,\n         -8.80357513e-02,  1.51508895e-01,  7.72201950e-02],\n        [ 2.72481084e-01, -8.73063441e-03, -2.39814236e-01, ...,\n         -2.65066393e-02,  9.80264076e-02,  5.17560252e-02],\n        ...,\n        [ 2.30311217e-01, -3.34987473e-01, -2.57489529e-01, ...,\n         -2.48816444e-01, -2.15065852e-01,  3.46272219e-01],\n        [ 9.42023631e-02,  1.19818352e-04,  3.86048731e-01, ...,\n         -6.06371493e-02,  2.10485093e-01,  2.95462063e-01],\n        [-1.66574647e-01,  3.46865305e-02,  1.98867547e-01, ...,\n          1.85916285e-01, -1.22075234e-01,  6.26150382e-01]]],\n      shape=(4, 4000, 20))1|eth(chain, draw, eth__factor_dim)float64-0.813 0.376 ... 0.01006 -0.01473array([[[-0.81300941,  0.37598337,  0.33992714,  0.40225461],\n        [-0.73591208,  0.44240008,  0.32706899,  0.41423505],\n        [-0.64901435,  0.20310546,  0.15831128,  0.27652794],\n        ...,\n        [-0.29069406,  0.15600426,  0.1414519 ,  0.31656927],\n        [-0.35531592,  0.44696303,  0.41187067,  0.6334792 ],\n        [-0.10005083,  0.04771385,  0.47991707,  0.30580031]],\n\n       [[-0.7382472 , -0.11106205, -0.07110273, -0.53509545],\n        [-0.61320653, -0.131576  , -0.0859798 , -0.4748674 ],\n        [-0.74770391, -0.15147255, -0.14979473, -0.49323646],\n        ...,\n        [-0.04051779, -0.07522958,  0.42199783,  0.13724378],\n        [-0.13098407,  0.1611958 ,  0.40540588,  0.08518507],\n        [-0.23532152,  0.24372888,  0.16984744,  0.42337685]],\n\n       [[-0.22091011,  0.26695156,  0.21715657,  0.46316998],\n        [-0.16781611,  0.01703062,  0.36230376,  0.68904393],\n        [-0.50723314,  0.11310465,  0.16856559,  0.41465675],\n        ...,\n        [-0.07859355,  0.46873659,  0.21127119,  0.66537277],\n        [ 0.25550376,  0.45557766,  0.37056397,  0.76009951],\n        [ 0.26670344,  0.84316704,  0.66777948,  0.90391942]],\n\n       [[-0.15810267, -0.02843205, -0.1752418 , -0.15141295],\n        [-0.24641641,  0.06571814, -0.13337538, -0.15771727],\n        [-0.18192129,  0.12485717, -0.10055871, -0.14864204],\n        ...,\n        [-0.26494812,  0.32982861, -0.0424683 , -0.22476109],\n        [-0.01008326,  0.17393471,  0.02683767, -0.19003531],\n        [ 0.00685285,  0.00541247,  0.01005723, -0.01473437]]],\n      shape=(4, 4000, 4))1|male:eth(chain, draw, male:eth__factor_dim)float640.5367 -0.1466 ... 0.04687 0.1735array([[[ 0.53666726, -0.14659088, -0.01051454, ..., -0.07886515,\n         -0.26242731, -0.06394192],\n        [ 0.49983783, -0.03773404, -0.08990654, ..., -0.10159896,\n         -0.2396677 , -0.02977189],\n        [-0.02027423, -0.01914877,  0.02354076, ...,  0.01255169,\n          0.02164773,  0.00742125],\n        ...,\n        [-0.03312325,  0.03090077, -0.0067438 , ...,  0.00447494,\n          0.01608005, -0.03327538],\n        [ 0.12421165, -0.07967298,  0.0739437 , ..., -0.09117925,\n         -0.06883314, -0.06168866],\n        [-0.19453771,  0.09743795, -0.05669856, ...,  0.1765203 ,\n         -0.21333708,  0.03118991]],\n\n       [[-0.30101035, -0.13763932, -0.24753248, ...,  0.26099436,\n         -0.17428794,  0.48749867],\n        [-0.18781258, -0.1782078 , -0.20678099, ...,  0.24099459,\n         -0.13348059,  0.53420899],\n        [-0.1584891 , -0.05736607, -0.28940156, ...,  0.1618874 ,\n         -0.33393529,  0.4555195 ],\n...\n        [ 0.09868322, -0.36299329,  0.06631239, ...,  0.02873544,\n         -0.09298074, -0.05020437],\n        [-0.05537263, -0.01639645,  0.10740681, ...,  0.1675895 ,\n         -0.09719602, -0.07247783],\n        [-0.09817336, -0.12545263, -0.07364686, ..., -0.00308771,\n         -0.04985223, -0.0823832 ]],\n\n       [[-0.67515165, -0.33331529,  0.06219964, ...,  0.10726802,\n          0.04554298,  0.21340511],\n        [-0.43433301, -0.18892972,  0.21716303, ..., -0.26259872,\n         -0.04755359,  0.19030465],\n        [-0.49615194, -0.22545399,  0.23793127, ..., -0.01304088,\n         -0.01962695,  0.34990258],\n        ...,\n        [-0.23933899,  0.13106667,  0.2208941 , ..., -0.08476503,\n          0.18526623,  0.07594984],\n        [-0.39046374, -0.11455443, -0.28321851, ..., -0.09104462,\n         -0.0646196 ,  0.10316641],\n        [-0.07583492, -0.06073763,  0.18137331, ...,  0.21309601,\n          0.04687095,  0.17349325]]], shape=(4, 4000, 8))1|state(chain, draw, state__factor_dim)float64-0.1547 -0.04735 ... 0.3345 -0.1952array([[[-1.54713295e-01, -4.73476880e-02,  8.20595488e-02, ...,\n         -1.58003948e-01,  7.27553354e-02,  3.62057400e-01],\n        [-2.04601681e-01, -3.23745203e-02,  7.36662212e-02, ...,\n         -1.68892587e-01,  7.30813214e-02,  3.67768155e-01],\n        [ 4.35385009e-01,  4.01403727e-01, -1.66041061e-01, ...,\n          4.08629417e-01,  4.61206759e-01, -2.94980043e-01],\n        ...,\n        [ 2.04333612e-01,  1.36918396e-01,  1.90852903e-01, ...,\n          4.16465975e-02,  4.17282109e-01,  7.26306856e-02],\n        [ 2.94135990e-01,  3.91411284e-01, -3.90516760e-02, ...,\n         -1.38545935e-01,  4.71502407e-01, -5.58963464e-02],\n        [-2.72980644e-02,  1.63809778e-01,  1.28677607e-01, ...,\n          9.64369358e-02,  3.80814045e-01,  4.84268827e-02]],\n\n       [[ 1.93710139e-01,  1.46261526e-01,  6.47443284e-02, ...,\n         -9.63762571e-02,  5.63566303e-01, -3.22097128e-01],\n        [ 3.10778844e-02,  1.78542916e-01,  6.94696415e-02, ...,\n         -1.61681231e-01,  5.73968344e-01, -3.83559859e-01],\n        [ 9.02372178e-02,  1.93320685e-01, -5.99915354e-02, ...,\n         -1.20579835e-01,  5.36800809e-01, -3.62891352e-01],\n...\n          8.94609641e-02,  4.70647435e-01,  1.88396082e-01],\n        [ 3.82913651e-01,  3.40828846e-01,  7.79209736e-02, ...,\n          2.28512066e-01,  4.97625240e-01, -3.69064217e-01],\n        [ 1.94561414e-01,  1.16993643e-01,  2.59973717e-01, ...,\n          1.26311901e-01,  3.75683765e-01,  8.09470861e-02]],\n\n       [[-1.72469487e-01,  2.83054539e-01,  2.76103336e-02, ...,\n          2.70089069e-01,  5.10136092e-01,  7.62677209e-02],\n        [ 3.15014363e-02,  2.86295249e-01,  4.19188246e-02, ...,\n          2.92696575e-01,  4.94168187e-01,  1.03153740e-01],\n        [-5.19507574e-03,  3.73057517e-01,  7.80096128e-02, ...,\n          9.06004034e-02,  4.76666500e-01,  1.71554718e-01],\n        ...,\n        [-6.28950018e-02,  3.39280628e-01,  4.92034480e-02, ...,\n         -3.51470501e-01,  4.48495073e-01, -2.63362750e-01],\n        [ 5.08924441e-01,  2.11967257e-01,  1.51174541e-02, ...,\n          3.94309100e-01,  3.57383418e-01,  1.15675811e-01],\n        [-1.33127632e-01,  2.80507213e-01,  4.09042457e-02, ...,\n         -3.95254617e-01,  3.34464820e-01, -1.95206105e-01]]],\n      shape=(4, 4000, 46))Indexes: (8)state__factor_dimPandasIndexPandasIndex(Index(['AK', 'AL', 'AR', 'CA', 'CO', 'DE', 'FL', 'GA', 'HI', 'IA', 'ID', 'IL',\n       'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC',\n       'ND', 'NE', 'NH', 'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI',\n       'SC', 'SD', 'TN', 'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY'],\n      dtype='object', name='state__factor_dim'))eth__factor_dimPandasIndexPandasIndex(Index(['Black', 'Hispanic', 'Other', 'White'], dtype='object', name='eth__factor_dim'))edu__factor_dimPandasIndexPandasIndex(Index(['4-Year College', 'HS', 'No HS', 'Post-grad', 'Some college'], dtype='object', name='edu__factor_dim'))male:eth__factor_dimPandasIndexPandasIndex(Index(['-0.5:Black', '-0.5:Hispanic', '-0.5:Other', '-0.5:White', '0.5:Black',\n       '0.5:Hispanic', '0.5:Other', '0.5:White'],\n      dtype='object', name='male:eth__factor_dim'))drawPandasIndexPandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       3990, 3991, 3992, 3993, 3994, 3995, 3996, 3997, 3998, 3999],\n      dtype='int64', name='draw', length=4000))edu:age__factor_dimPandasIndexPandasIndex(Index(['4-Year College:18-29', '4-Year College:30-39', '4-Year College:40-49',\n       '4-Year College:50-59', '4-Year College:60-69', '4-Year College:70+',\n       'HS:18-29', 'HS:30-39', 'HS:40-49', 'HS:50-59', 'HS:60-69', 'HS:70+',\n       'No HS:18-29', 'No HS:30-39', 'No HS:40-49', 'No HS:50-59',\n       'No HS:60-69', 'No HS:70+', 'Post-grad:18-29', 'Post-grad:30-39',\n       'Post-grad:40-49', 'Post-grad:50-59', 'Post-grad:60-69',\n       'Post-grad:70+', 'Some college:18-29', 'Some college:30-39',\n       'Some college:40-49', 'Some college:50-59', 'Some college:60-69',\n       'Some college:70+'],\n      dtype='object', name='edu:age__factor_dim'))chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))edu:eth__factor_dimPandasIndexPandasIndex(Index(['4-Year College:Black', '4-Year College:Hispanic',\n       '4-Year College:Other', '4-Year College:White', 'HS:Black',\n       'HS:Hispanic', 'HS:Other', 'HS:White', 'No HS:Black', 'No HS:Hispanic',\n       'No HS:Other', 'No HS:White', 'Post-grad:Black', 'Post-grad:Hispanic',\n       'Post-grad:Other', 'Post-grad:White', 'Some college:Black',\n       'Some college:Hispanic', 'Some college:Other', 'Some college:White'],\n      dtype='object', name='edu:eth__factor_dim'))Attributes: (4)created_at :2025-04-12T20:47:44.644117+00:00arviz_version :0.21.0modeling_interface :bambimodeling_interface_version :0.15.0\n                      \n                  \n            \n            \n            \n                  \n                  sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 1MB\nDimensions:               (chain: 4, draw: 4000)\nCoordinates:\n  * chain                 (chain) int64 32B 0 1 2 3\n  * draw                  (draw) int64 32kB 0 1 2 3 4 ... 3996 3997 3998 3999\nData variables:\n    depth                 (chain, draw) uint64 128kB 5 5 5 5 4 5 ... 5 6 5 5 5 5\n    diverging             (chain, draw) bool 16kB False False ... False False\n    energy                (chain, draw) float64 128kB 2.255e+03 ... 2.265e+03\n    energy_error          (chain, draw) float64 128kB 0.0 0.8447 ... 0.3695\n    index_in_trajectory   (chain, draw) int64 128kB 0 -1 20 10 ... -4 11 21 21\n    logp                  (chain, draw) float64 128kB -2.195e+03 ... -2.192e+03\n    maxdepth_reached      (chain, draw) bool 16kB False False ... False False\n    mean_tree_accept      (chain, draw) float64 128kB 0.003212 ... 0.5059\n    mean_tree_accept_sym  (chain, draw) float64 128kB 0.006398 ... 0.6373\n    n_steps               (chain, draw) uint64 128kB 31 31 31 31 ... 31 31 31 31\n    step_size             (chain, draw) float64 128kB 0.1945 0.1945 ... 0.1749\n    step_size_bar         (chain, draw) float64 128kB 0.1945 0.1945 ... 0.1749\nAttributes:\n    created_at:                  2025-04-12T20:47:44.479410+00:00\n    arviz_version:               0.21.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.15.0xarray.DatasetDimensions:chain: 4draw: 4000Coordinates: (2)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 ... 3996 3997 3998 3999array([   0,    1,    2, ..., 3997, 3998, 3999], shape=(4000,))Data variables: (12)depth(chain, draw)uint645 5 5 5 4 5 5 5 ... 5 5 5 6 5 5 5 5array([[5, 5, 5, ..., 5, 5, 5],\n       [5, 5, 6, ..., 5, 5, 5],\n       [5, 5, 5, ..., 5, 5, 5],\n       [5, 5, 5, ..., 5, 5, 5]], shape=(4, 4000), dtype=uint64)diverging(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]], shape=(4, 4000))energy(chain, draw)float642.255e+03 2.265e+03 ... 2.265e+03array([[2255.117334  , 2264.51911296, 2271.28129   , ..., 2251.66136029,\n        2269.75710454, 2265.80349644],\n       [2237.80104932, 2243.93710343, 2230.0145833 , ..., 2257.31341858,\n        2272.02897877, 2246.81377807],\n       [2252.14394962, 2246.62068636, 2236.1609259 , ..., 2251.75162628,\n        2238.84657812, 2241.87218089],\n       [2264.40923367, 2260.40331607, 2250.3805075 , ..., 2240.2513712 ,\n        2249.09295148, 2264.5290031 ]], shape=(4, 4000))energy_error(chain, draw)float640.0 0.8447 ... 0.01143 0.3695array([[ 0.        ,  0.84470961, -1.4539347 , ..., -0.31018692,\n         0.25727831, -0.62968532],\n       [-0.51218275,  3.05568577, -2.8394705 , ...,  0.02725061,\n        -0.20539784, -0.11696598],\n       [-1.20939903,  0.7575223 , -0.3399562 , ...,  0.11625358,\n         0.0552306 , -0.29775544],\n       [ 0.11760641,  0.01299384,  0.39737546, ...,  1.77924518,\n         0.01143386,  0.36951499]], shape=(4, 4000))index_in_trajectory(chain, draw)int640 -1 20 10 11 23 ... 20 -4 11 21 21array([[  0,  -1,  20, ..., -26, -24, -17],\n       [ -8,   1,  -2, ..., -17, -14, -19],\n       [ -7,   3,   8, ..., -10,   8,  -9],\n       [ 17,  -4,  -4, ...,  11,  21,  21]], shape=(4, 4000))logp(chain, draw)float64-2.195e+03 -2.2e+03 ... -2.192e+03array([[-2195.28683531, -2199.69964304, -2192.48052209, ...,\n        -2190.6539001 , -2204.62821134, -2196.67659335],\n       [-2178.45558846, -2181.68135477, -2174.42955449, ...,\n        -2202.52662822, -2191.97227334, -2190.34640282],\n       [-2174.0529038 , -2177.6868388 , -2176.95514328, ...,\n        -2189.79435862, -2176.25676299, -2192.38894971],\n       [-2200.77698495, -2195.69861311, -2190.99082132, ...,\n        -2179.17716831, -2186.05129393, -2191.79406429]], shape=(4, 4000))maxdepth_reached(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]], shape=(4, 4000))mean_tree_accept(chain, draw)float640.003212 0.01469 ... 0.9123 0.5059array([[0.0032122 , 0.01468574, 0.7121965 , ..., 0.99523485, 0.93958582,\n        0.76843208],\n       [0.4646414 , 0.02347937, 0.35517416, ..., 0.99451639, 0.90787172,\n        0.82817024],\n       [0.97277143, 0.19049798, 0.21162333, ..., 0.91410456, 0.43072501,\n        0.49844013],\n       [0.48641789, 0.93830285, 0.52977933, ..., 0.23108827, 0.91234701,\n        0.50593332]], shape=(4, 4000))mean_tree_accept_sym(chain, draw)float640.006398 0.02101 ... 0.8852 0.6373array([[0.00639806, 0.02100856, 0.26571785, ..., 0.91373449, 0.93793325,\n        0.7677669 ],\n       [0.48529583, 0.03865938, 0.31063868, ..., 0.94220104, 0.92448941,\n        0.8299252 ],\n       [0.87320319, 0.21384995, 0.19321452, ..., 0.94347875, 0.56745197,\n        0.57673148],\n       [0.61583831, 0.95821908, 0.58996206, ..., 0.34443986, 0.88518716,\n        0.63731185]], shape=(4, 4000))n_steps(chain, draw)uint6431 31 31 31 15 ... 63 31 31 31 31array([[ 31,  31,  31, ...,  31,  31,  31],\n       [ 31,  31, 127, ...,  31,  31,  31],\n       [ 31,  31,  63, ...,  31,  31,  31],\n       [ 31,  31,  31, ...,  31,  31,  31]], shape=(4, 4000), dtype=uint64)step_size(chain, draw)float640.1945 0.1945 ... 0.1749 0.1749array([[0.19447538, 0.19447538, 0.19447538, ..., 0.19447538, 0.19447538,\n        0.19447538],\n       [0.17929565, 0.17929565, 0.17929565, ..., 0.17929565, 0.17929565,\n        0.17929565],\n       [0.17100847, 0.17100847, 0.17100847, ..., 0.17100847, 0.17100847,\n        0.17100847],\n       [0.17490276, 0.17490276, 0.17490276, ..., 0.17490276, 0.17490276,\n        0.17490276]], shape=(4, 4000))step_size_bar(chain, draw)float640.1945 0.1945 ... 0.1749 0.1749array([[0.19447538, 0.19447538, 0.19447538, ..., 0.19447538, 0.19447538,\n        0.19447538],\n       [0.17929565, 0.17929565, 0.17929565, ..., 0.17929565, 0.17929565,\n        0.17929565],\n       [0.17100847, 0.17100847, 0.17100847, ..., 0.17100847, 0.17100847,\n        0.17100847],\n       [0.17490276, 0.17490276, 0.17490276, ..., 0.17490276, 0.17490276,\n        0.17490276]], shape=(4, 4000))Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       3990, 3991, 3992, 3993, 3994, 3995, 3996, 3997, 3998, 3999],\n      dtype='int64', name='draw', length=4000))Attributes: (4)created_at :2025-04-12T20:47:44.479410+00:00arviz_version :0.21.0modeling_interface :bambimodeling_interface_version :0.15.0\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 177kB\nDimensions:         (__obs__: 11040)\nCoordinates:\n  * __obs__         (__obs__) int64 88kB 0 1 2 3 4 ... 11036 11037 11038 11039\nData variables:\n    p(abortion, n)  (__obs__) int64 88kB 18 16 13 12 11 11 11 ... 0 0 0 0 0 0 0\nAttributes:\n    created_at:                  2025-04-12T20:47:44.644117+00:00\n    arviz_version:               0.21.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.15.0xarray.DatasetDimensions:__obs__: 11040Coordinates: (1)__obs__(__obs__)int640 1 2 3 ... 11036 11037 11038 11039array([    0,     1,     2, ..., 11037, 11038, 11039], shape=(11040,))Data variables: (1)p(abortion, n)(__obs__)int6418 16 13 12 11 11 ... 0 0 0 0 0 0array([18, 16, 13, ...,  0,  0,  0], shape=(11040,))Indexes: (1)__obs__PandasIndexPandasIndex(Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,     9,\n       ...\n       11030, 11031, 11032, 11033, 11034, 11035, 11036, 11037, 11038, 11039],\n      dtype='int64', name='__obs__', length=11040))Attributes: (4)created_at :2025-04-12T20:47:44.644117+00:00arviz_version :0.21.0modeling_interface :bambimodeling_interface_version :0.15.0\n                      \n                  \n            \n            \n            \n                  \n                  warmup_posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 4MB\nDimensions:                  (chain: 4, draw: 1000, 1|edu:age_offset_dim_0: 30,\n                              1|edu:eth_offset_dim_0: 20,\n                              1|edu_offset_dim_0: 5, 1|eth_offset_dim_0: 4,\n                              1|male:eth_offset_dim_0: 8,\n                              1|state_offset_dim_0: 46)\nCoordinates:\n  * chain                    (chain) int64 32B 0 1 2 3\n  * draw                     (draw) int64 8kB 0 1 2 3 4 ... 995 996 997 998 999\n  * 1|edu:age_offset_dim_0   (1|edu:age_offset_dim_0) int64 240B 0 1 2 ... 28 29\n  * 1|edu:eth_offset_dim_0   (1|edu:eth_offset_dim_0) int64 160B 0 1 2 ... 18 19\n  * 1|edu_offset_dim_0       (1|edu_offset_dim_0) int64 40B 0 1 2 3 4\n  * 1|eth_offset_dim_0       (1|eth_offset_dim_0) int64 32B 0 1 2 3\n  * 1|male:eth_offset_dim_0  (1|male:eth_offset_dim_0) int64 64B 0 1 2 3 4 5 6 7\n  * 1|state_offset_dim_0     (1|state_offset_dim_0) int64 368B 0 1 2 ... 44 45\nData variables: (12/15)\n    1|edu:age_offset         (chain, draw, 1|edu:age_offset_dim_0) float64 960kB ...\n    1|edu:age_sigma          (chain, draw) float64 32kB 2.207 2.207 ... 0.2669\n    1|edu:eth_offset         (chain, draw, 1|edu:eth_offset_dim_0) float64 640kB ...\n    1|edu:eth_sigma          (chain, draw) float64 32kB 3.4 3.4 ... 0.2148\n    1|edu_offset             (chain, draw, 1|edu_offset_dim_0) float64 160kB ...\n    1|edu_sigma              (chain, draw) float64 32kB 1.923 1.923 ... 0.04515\n    ...                       ...\n    1|male:eth_sigma         (chain, draw) float64 32kB 0.5565 0.5565 ... 0.4587\n    1|state_offset           (chain, draw, 1|state_offset_dim_0) float64 1MB ...\n    1|state_sigma            (chain, draw) float64 32kB 0.6829 0.6829 ... 0.2371\n    Intercept                (chain, draw) float64 32kB 1.71 1.71 ... 0.1291\n    male                     (chain, draw) float64 32kB 1.447 1.447 ... 0.4612\n    repvote                  (chain, draw) float64 32kB -0.9648 ... -1.736\nAttributes:\n    created_at:                  2025-04-12T20:47:44.648045+00:00\n    arviz_version:               0.21.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.15.0xarray.DatasetDimensions:chain: 4draw: 10001|edu:age_offset_dim_0: 301|edu:eth_offset_dim_0: 201|edu_offset_dim_0: 51|eth_offset_dim_0: 41|male:eth_offset_dim_0: 81|state_offset_dim_0: 46Coordinates: (8)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999], shape=(1000,))1|edu:age_offset_dim_0(1|edu:age_offset_dim_0)int640 1 2 3 4 5 6 ... 24 25 26 27 28 29array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])1|edu:eth_offset_dim_0(1|edu:eth_offset_dim_0)int640 1 2 3 4 5 6 ... 14 15 16 17 18 19array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19])1|edu_offset_dim_0(1|edu_offset_dim_0)int640 1 2 3 4array([0, 1, 2, 3, 4])1|eth_offset_dim_0(1|eth_offset_dim_0)int640 1 2 3array([0, 1, 2, 3])1|male:eth_offset_dim_0(1|male:eth_offset_dim_0)int640 1 2 3 4 5 6 7array([0, 1, 2, 3, 4, 5, 6, 7])1|state_offset_dim_0(1|state_offset_dim_0)int640 1 2 3 4 5 6 ... 40 41 42 43 44 45array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45])Data variables: (15)1|edu:age_offset(chain, draw, 1|edu:age_offset_dim_0)float640.7128 -0.5591 ... 0.005938 0.3943array([[[ 0.71284134, -0.559058  ,  0.37604117, ...,  0.74880404,\n          0.39094029, -1.70421955],\n        [ 0.71284134, -0.559058  ,  0.37604117, ...,  0.74880404,\n          0.39094029, -1.70421955],\n        [ 0.4123814 , -0.93819344, -0.02554036, ...,  0.32689999,\n          0.13899644, -1.19476971],\n        ...,\n        [ 0.2688731 ,  0.85206963, -0.65962647, ..., -0.70168721,\n          1.43265963,  1.4161706 ],\n        [ 0.80456226, -0.28526599,  0.43157533, ...,  0.06894895,\n          0.9645582 ,  0.22450678],\n        [-0.48957108, -0.70689993,  0.83157602, ..., -1.20101943,\n          0.51189126,  0.70655059]],\n\n       [[-1.21768468,  1.46814066,  0.02411921, ...,  1.82335468,\n         -0.42807295, -1.75143342],\n        [-1.21768468,  1.46814066,  0.02411921, ...,  1.82335468,\n         -0.42807295, -1.75143342],\n        [-1.31805243,  1.32350838, -0.06725975, ...,  1.62623674,\n         -0.61223836, -1.9421984 ],\n...\n        [-0.74162495, -0.8804506 , -1.12681241, ..., -0.9669782 ,\n          0.53939908,  1.27312825],\n        [ 0.0894784 ,  0.17694982, -0.91446162, ...,  0.6731494 ,\n          0.40317466,  0.32936144],\n        [-1.14579979, -0.88363346, -0.96322569, ..., -0.54172027,\n          0.84529024,  1.26946813]],\n\n       [[ 0.29170452, -0.44934613,  0.71507369, ...,  0.61230857,\n         -1.29450008,  1.53568806],\n        [ 0.29170452, -0.44934613,  0.71507369, ...,  0.61230857,\n         -1.29450008,  1.53568806],\n        [ 0.19294842, -0.67933206,  0.5395378 , ...,  0.50094114,\n         -0.65779379,  1.54083684],\n        ...,\n        [ 0.97462607, -0.38596485, -1.27249723, ...,  0.75782858,\n          0.82203813,  1.834766  ],\n        [-0.47406525,  0.02122943,  0.30284372, ..., -0.06532138,\n          0.14637834,  0.67223118],\n        [-0.35694681,  0.72158438, -1.37142036, ..., -0.23166229,\n          0.00593751,  0.39427214]]], shape=(4, 1000, 30))1|edu:age_sigma(chain, draw)float642.207 2.207 1.741 ... 0.2755 0.2669array([[2.20679535, 2.20679535, 1.74138944, ..., 0.19250073, 0.19368443,\n        0.13441164],\n       [0.51136144, 0.51136144, 0.6314906 , ..., 0.30519338, 0.1541938 ,\n        0.17071181],\n       [0.72213574, 0.72213574, 0.48138778, ..., 0.14969559, 0.15653443,\n        0.10686433],\n       [0.68243807, 0.68243807, 0.57525882, ..., 0.20726959, 0.27550811,\n        0.26694358]], shape=(4, 1000))1|edu:eth_offset(chain, draw, 1|edu:eth_offset_dim_0)float641.444 1.782 ... -0.765 1.817array([[[ 1.44358834,  1.78188384, -0.3140895 , ..., -1.70353938,\n         -1.51594326,  0.13619058],\n        [ 1.44358834,  1.78188384, -0.3140895 , ..., -1.70353938,\n         -1.51594326,  0.13619058],\n        [ 1.17256779,  1.37940198,  0.09445394, ..., -1.27980578,\n         -1.10235072, -0.12960883],\n        ...,\n        [ 0.22817186, -2.29355524,  1.21622413, ...,  0.21409064,\n          1.40904082,  2.58940913],\n        [ 1.13859571, -1.02730924, -0.09432704, ...,  0.4263745 ,\n          0.83989848,  2.32297436],\n        [ 1.20247648, -0.21693643, -0.35129568, ...,  0.68524451,\n          0.95222478,  1.48507414]],\n\n       [[-1.09759564,  1.34260381, -0.71388256, ..., -1.21759091,\n          1.95427275,  0.1335923 ],\n        [-1.09759564,  1.34260381, -0.71388256, ..., -1.21759091,\n          1.95427275,  0.1335923 ],\n        [-1.31947569,  1.2015818 , -0.59328092, ..., -1.28976924,\n          1.76558803,  0.04491539],\n...\n        [-1.1444141 , -0.98827778,  0.65455218, ...,  0.37755987,\n         -1.40151706,  1.87303559],\n        [ 1.74927511, -0.3606366 , -0.56677345, ..., -0.11671515,\n          1.10394301,  1.21906373],\n        [-1.00871338, -1.28078011,  1.50015663, ...,  0.59647944,\n         -0.67371608,  0.4514342 ]],\n\n       [[-0.0687315 ,  0.24114353, -1.00602106, ...,  1.14399771,\n         -0.13716406,  0.44994605],\n        [-0.0687315 ,  0.24114353, -1.00602106, ...,  1.14399771,\n         -0.13716406,  0.44994605],\n        [-0.13716768,  0.13189594, -1.23614932, ...,  0.99470055,\n          0.00838824,  0.47072865],\n        ...,\n        [ 0.42372791,  0.21598527,  0.17775972, ..., -0.49084891,\n         -0.12306211,  0.5570425 ],\n        [ 0.00693822, -2.42175288, -0.10464558, ...,  1.13306058,\n          0.40161278,  2.62168841],\n        [-0.80003785, -1.02202843,  0.67516659, ...,  0.37221963,\n         -0.76499699,  1.81682732]]], shape=(4, 1000, 20))1|edu:eth_sigma(chain, draw)float643.4 3.4 2.434 ... 0.1439 0.2148array([[3.39982226, 3.39982226, 2.43409832, ..., 0.1327177 , 0.08950519,\n        0.11771773],\n       [2.94300814, 2.94300814, 3.32859576, ..., 0.17159414, 0.08078945,\n        0.09115935],\n       [0.3416421 , 0.3416421 , 0.42488684, ..., 0.22939412, 0.15340315,\n        0.31419936],\n       [0.23591808, 0.23591808, 0.2232372 , ..., 0.2514691 , 0.14392624,\n        0.21483413]], shape=(4, 1000))1|edu_offset(chain, draw, 1|edu_offset_dim_0)float64-0.6799 -0.6844 ... 2.152 -1.49array([[[-6.79935877e-01, -6.84408955e-01,  1.59365968e+00,\n          7.92140493e-01, -6.18473772e-03],\n        [-6.79935877e-01, -6.84408955e-01,  1.59365968e+00,\n          7.92140493e-01, -6.18473772e-03],\n        [-1.09305519e+00, -3.41392211e-01,  1.10731435e+00,\n          6.43737360e-01, -1.84907701e-01],\n        ...,\n        [ 1.15816502e-01,  3.64117553e-01,  4.78521421e-01,\n         -3.95091176e-01,  1.34470320e-01],\n        [-3.31028337e-01, -5.52540954e-02,  5.24320116e-01,\n         -9.60232694e-01, -1.37144148e-01],\n        [-1.75371893e-01,  2.93605514e-02,  1.44047545e-01,\n         -4.36269895e-01, -7.69172279e-02]],\n\n       [[ 1.61806159e+00,  1.79286740e+00,  1.54573293e+00,\n         -7.01920512e-01,  1.33111758e+00],\n        [ 1.61806159e+00,  1.79286740e+00,  1.54573293e+00,\n         -7.01920512e-01,  1.33111758e+00],\n        [ 1.47970882e+00,  1.53454918e+00,  1.55723103e+00,\n         -6.28465213e-01,  1.22880413e+00],\n...\n        [-5.17364216e-01,  8.76813774e-01, -1.85970157e+00,\n         -7.84438830e-01,  1.24563036e+00],\n        [ 1.10720607e-01,  1.00951612e+00,  2.19785908e-03,\n          3.99383423e-02, -6.91177056e-02],\n        [-1.18266225e+00,  7.25895500e-01, -4.89571991e-02,\n         -8.87131886e-01,  2.07018417e+00]],\n\n       [[ 1.41498026e+00,  8.57629353e-01, -9.99644481e-01,\n          1.64880866e+00, -2.12788773e+00],\n        [ 1.41498026e+00,  8.57629353e-01, -9.99644481e-01,\n          1.64880866e+00, -2.12788773e+00],\n        [ 1.39117169e+00,  7.40003640e-01, -9.02709435e-01,\n          1.50073062e+00, -2.32017906e+00],\n        ...,\n        [ 9.48002620e-01, -5.67396497e-01,  6.39786518e-01,\n         -4.12647871e-01, -2.58774270e+00],\n        [-6.27536039e-01,  2.27203639e+00,  1.72646246e-01,\n          3.30741996e+00, -1.60296639e+00],\n        [-4.72089868e-01,  2.70965145e+00, -2.50499836e-01,\n          2.15224708e+00, -1.49040802e+00]]], shape=(4, 1000, 5))1|edu_sigma(chain, draw)float641.923 1.923 ... 0.02619 0.04515array([[1.92258148, 1.92258148, 2.03860841, ..., 0.79197204, 0.61015705,\n        1.34609022],\n       [0.47593805, 0.47593805, 0.44675043, ..., 0.18640394, 0.22803854,\n        0.30466096],\n       [3.15137817, 3.15137817, 3.049039  , ..., 0.00522084, 0.01586651,\n        0.00860991],\n       [0.12569072, 0.12569072, 0.10984866, ..., 0.0200157 , 0.0261926 ,\n        0.0451503 ]], shape=(4, 1000))1|eth_offset(chain, draw, 1|eth_offset_dim_0)float64-1.164 -0.7458 ... -0.1858 -1.456array([[[-1.16423607, -0.7458115 , -1.71091637,  0.84569769],\n        [-1.16423607, -0.7458115 , -1.71091637,  0.84569769],\n        [-1.6805584 , -1.39265605, -1.39822273,  0.50515946],\n        ...,\n        [-1.78706275, -0.36278758, -0.74613155,  0.44885528],\n        [-1.11690926,  0.00452115,  0.16627439,  0.77984695],\n        [-1.70417429,  0.78811042,  0.71253183,  0.84317838]],\n\n       [[ 0.33530368,  1.23202858, -1.89355075,  0.70002915],\n        [ 0.33530368,  1.23202858, -1.89355075,  0.70002915],\n        [ 0.20728239,  1.13354082, -1.81398765,  0.5699263 ],\n        ...,\n        [-1.39126029, -1.04293742, -0.17549371, -0.72012673],\n        [-1.22717927, -0.97711633,  0.06983505, -1.02376793],\n        [-1.58778742, -0.43288271, -0.04551575, -1.06405512]],\n\n       [[-0.334924  ,  0.76886558, -1.25737908, -1.34129619],\n        [-0.334924  ,  0.76886558, -1.25737908, -1.34129619],\n        [-0.53626431,  1.21687794,  0.27810603, -1.27912712],\n        ...,\n        [-0.75266115, -0.29809349,  0.41913554, -0.1667127 ],\n        [-0.77472939, -0.23572446, -0.08319828,  0.19420046],\n        [-0.42365684,  0.17548603, -0.05446857,  0.44084516]],\n\n       [[ 1.56784721,  0.15929714, -0.1720116 ,  0.88865306],\n        [ 1.56784721,  0.15929714, -0.1720116 ,  0.88865306],\n        [ 1.35437949,  0.19857634,  0.17339459,  0.75178772],\n        ...,\n        [-3.25323958, -0.67517452, -0.08829342, -1.73117769],\n        [-1.0131411 , -1.10757146, -0.15901279, -1.35809749],\n        [-0.56733943, -0.70313804, -0.18576981, -1.45609532]]],\n      shape=(4, 1000, 4))1|eth_sigma(chain, draw)float640.2866 0.2866 ... 0.3137 0.4433array([[0.28658842, 0.28658842, 0.2044168 , ..., 0.31388123, 0.4135409 ,\n        0.4770694 ],\n       [0.85290821, 0.85290821, 0.76836297, ..., 0.31341053, 0.19105631,\n        0.29057462],\n       [1.90209977, 1.90209977, 1.70711999, ..., 0.58543312, 0.79502785,\n        1.02221963],\n       [0.16795377, 0.16795377, 0.15681596, ..., 0.24204904, 0.31368987,\n        0.4433213 ]], shape=(4, 1000))1|male:eth_offset(chain, draw, 1|male:eth_offset_dim_0)float640.6706 -0.3828 ... -0.7867 0.919array([[[ 0.67057163, -0.38282787, -1.92864715, ...,  0.58750663,\n         -1.15339175, -1.57570338],\n        [ 0.67057163, -0.38282787, -1.92864715, ...,  0.58750663,\n         -1.15339175, -1.57570338],\n        [ 0.3198245 , -0.57849822, -1.70308278, ...,  0.70945675,\n         -0.55956457, -1.99412672],\n        ...,\n        [ 0.23617281, -1.12068392,  0.45955454, ...,  0.79103077,\n         -0.9808991 , -0.4587655 ],\n        [ 0.60897805, -0.45938247,  0.18883163, ...,  1.19447145,\n         -0.12878561, -0.68026181],\n        [ 1.51613063, -0.41413169, -0.02970446, ..., -0.22280074,\n         -0.74137946, -0.18064136]],\n\n       [[ 1.08247912,  0.85950671, -0.92743118, ..., -1.53946097,\n         -1.32494537, -0.5559548 ],\n        [ 1.08247912,  0.85950671, -0.92743118, ..., -1.53946097,\n         -1.32494537, -0.5559548 ],\n        [ 0.9987628 ,  0.70358365, -0.77533989, ..., -1.43862678,\n         -1.20037422, -0.44734798],\n...\n        [-0.31883389,  0.23839145, -0.44028795, ...,  1.73303938,\n         -1.45333747, -0.28443378],\n        [ 0.30045055, -0.02002226,  1.69398056, ..., -1.17483091,\n          0.34217228, -0.48570567],\n        [ 0.37034702, -0.34928659, -0.70996217, ...,  1.22835604,\n         -0.79119053, -1.46678738]],\n\n       [[ 0.68243096,  1.35181653,  0.44409381, ...,  0.36092888,\n          0.85691157, -0.69123998],\n        [ 0.68243096,  1.35181653,  0.44409381, ...,  0.36092888,\n          0.85691157, -0.69123998],\n        [ 0.70719832,  1.23008949,  0.23278259, ...,  0.26154587,\n          0.72962884, -0.74513839],\n        ...,\n        [-0.49218514, -1.49285637,  0.01997551, ..., -0.14111163,\n         -0.53292376,  1.32663378],\n        [ 0.23977966,  1.26458124,  0.54516764, ...,  0.74745682,\n          0.24040893,  0.78454126],\n        [-0.33138344,  0.52250237,  0.10679882, ...,  0.76968037,\n         -0.78674429,  0.91898486]]], shape=(4, 1000, 8))1|male:eth_sigma(chain, draw)float640.5565 0.5565 ... 0.3144 0.4587array([[0.55654638, 0.55654638, 0.47173424, ..., 0.14502639, 0.11510072,\n        0.35397165],\n       [5.92096708, 5.92096708, 5.30469133, ..., 0.28376172, 0.44457125,\n        0.25405373],\n       [2.84398156, 2.84398156, 2.69861033, ..., 0.24587144, 0.11621561,\n        0.11500084],\n       [0.49223971, 0.49223971, 0.44182216, ..., 0.28661462, 0.31435972,\n        0.45866093]], shape=(4, 1000))1|state_offset(chain, draw, 1|state_offset_dim_0)float641.328 1.512 ... 0.7377 -0.1718array([[[ 1.32764977e+00,  1.51240388e+00,  7.38744287e-01, ...,\n          1.51712510e+00, -9.55234167e-01, -1.32477381e+00],\n        [ 1.32764977e+00,  1.51240388e+00,  7.38744287e-01, ...,\n          1.51712510e+00, -9.55234167e-01, -1.32477381e+00],\n        [ 1.19815751e+00,  1.07778935e+00,  1.73197696e-01, ...,\n          1.12046093e+00, -4.47833064e-01, -1.01715084e+00],\n        ...,\n        [ 1.52811810e+00,  3.85987874e-01,  6.09365671e-01, ...,\n         -8.03484486e-01,  1.06356820e+00,  1.10305668e+00],\n        [-2.87006599e-01,  4.37404478e-01, -1.97034173e-01, ...,\n         -6.18244363e-01,  1.32706091e+00,  1.28199453e+00],\n        [-6.48598495e-01, -1.98493860e-01,  3.44015036e-01, ...,\n         -6.62393772e-01,  3.05009346e-01,  1.51783908e+00]],\n\n       [[ 3.99929191e-02,  1.14009809e-01, -2.26559882e-03, ...,\n         -1.47190428e+00, -1.85196771e+00,  1.69641207e+00],\n        [ 3.99929191e-02,  1.14009809e-01, -2.26559882e-03, ...,\n         -1.47190428e+00, -1.85196771e+00,  1.69641207e+00],\n        [ 8.51255720e-02, -2.00036421e-02, -2.57014718e-02, ...,\n         -1.37853408e+00, -1.91445673e+00,  1.92665108e+00],\n...\n          5.12683584e-02,  6.59013542e-01,  3.66731795e-01],\n        [-7.50212401e-01,  1.50119085e+00,  5.87311601e-01, ...,\n         -1.31594922e-01,  2.81097129e+00, -5.01790444e-01],\n        [ 1.54852717e+00,  5.60001907e-01,  4.11253345e-01, ...,\n         -3.17406129e-02,  1.38807976e+00,  8.10677570e-01]],\n\n       [[ 5.37297425e-01, -2.48550831e-01,  2.70162548e-01, ...,\n          8.13976596e-01,  1.13454382e+00,  1.39958396e+00],\n        [ 5.37297425e-01, -2.48550831e-01,  2.70162548e-01, ...,\n          8.13976596e-01,  1.13454382e+00,  1.39958396e+00],\n        [ 4.82238542e-01, -8.35327561e-02,  8.23319485e-01, ...,\n          7.18426076e-01,  1.05092443e+00,  1.33024596e+00],\n        ...,\n        [-2.08706331e-01,  5.05488764e-01, -1.25808331e-01, ...,\n          1.45668663e+00,  1.03769998e+00,  5.85423010e-01],\n        [ 2.14996048e+00,  1.90346523e+00, -4.68219970e-01, ...,\n         -2.26125772e+00,  1.62691117e+00, -1.89182626e-01],\n        [ 1.74338111e+00,  1.46272570e+00,  6.77247764e-01, ...,\n         -9.12021602e-01,  7.37728283e-01, -1.71831129e-01]]],\n      shape=(4, 1000, 46))1|state_sigma(chain, draw)float640.6829 0.6829 ... 0.2709 0.2371array([[0.68294453, 0.68294453, 0.47597338, ..., 0.3166898 , 0.26310342,\n        0.23853477],\n       [0.48732248, 0.48732248, 0.56707422, ..., 0.26024814, 0.32277951,\n        0.32279895],\n       [2.05568578, 2.05568578, 1.65932599, ..., 0.30970357, 0.21027966,\n        0.31050671],\n       [2.38824981, 2.38824981, 2.11596641, ..., 0.34811532, 0.27093666,\n        0.23708151]], shape=(4, 1000))Intercept(chain, draw)float641.71 1.71 1.28 ... -0.01795 0.1291array([[ 1.71028959,  1.71028959,  1.28005466, ..., -0.29997418,\n        -0.12755291, -0.20893971],\n       [ 1.74645266,  1.74645266,  1.60297339, ...,  0.11459596,\n         0.07938967,  0.08932437],\n       [ 0.08662674,  0.08662674,  0.13167436, ..., -0.00511883,\n        -0.10603177, -0.28388583],\n       [-1.64414654, -1.64414654, -1.78845943, ..., -0.02493661,\n        -0.01795309,  0.12905368]], shape=(4, 1000))male(chain, draw)float641.447 1.447 1.303 ... 0.419 0.4612array([[ 1.44738757,  1.44738757,  1.3033607 , ...,  0.22013317,\n         0.19386891,  0.18614108],\n       [ 0.24508297,  0.24508297,  0.34051537, ...,  0.35577553,\n         0.55212564,  0.28104772],\n       [-0.7803069 , -0.7803069 , -0.44296594, ...,  0.06652206,\n         0.37866062,  0.26965973],\n       [ 0.25440362,  0.25440362,  0.45240137, ...,  0.22115184,\n         0.41900722,  0.46124262]], shape=(4, 1000))repvote(chain, draw)float64-0.9648 -0.9648 ... -1.35 -1.736array([[-0.96478962, -0.96478962, -1.5002596 , ..., -1.00577532,\n        -0.82047131, -0.3934767 ],\n       [-1.88419423, -1.88419423, -2.05791893, ..., -1.0962935 ,\n        -0.88288692, -1.34401508],\n       [-0.12793358, -0.12793358,  0.54299439, ..., -0.68627744,\n        -1.8192177 , -1.72799597],\n       [ 0.11495385,  0.11495385, -0.06781174, ..., -0.3260194 ,\n        -1.35030456, -1.73640289]], shape=(4, 1000))Indexes: (8)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))1|edu:age_offset_dim_0PandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n      dtype='int64', name='1|edu:age_offset_dim_0'))1|edu:eth_offset_dim_0PandasIndexPandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], dtype='int64', name='1|edu:eth_offset_dim_0'))1|edu_offset_dim_0PandasIndexPandasIndex(Index([0, 1, 2, 3, 4], dtype='int64', name='1|edu_offset_dim_0'))1|eth_offset_dim_0PandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='1|eth_offset_dim_0'))1|male:eth_offset_dim_0PandasIndexPandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7], dtype='int64', name='1|male:eth_offset_dim_0'))1|state_offset_dim_0PandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45],\n      dtype='int64', name='1|state_offset_dim_0'))Attributes: (4)created_at :2025-04-12T20:47:44.648045+00:00arviz_version :0.21.0modeling_interface :bambimodeling_interface_version :0.15.0\n                      \n                  \n            \n            \n            \n                  \n                  warmup_sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 336kB\nDimensions:               (chain: 4, draw: 1000)\nCoordinates:\n  * chain                 (chain) int64 32B 0 1 2 3\n  * draw                  (draw) int64 8kB 0 1 2 3 4 5 ... 995 996 997 998 999\nData variables:\n    depth                 (chain, draw) uint64 32kB 3 0 3 4 3 6 ... 5 5 4 4 5 5\n    diverging             (chain, draw) bool 4kB False True ... False False\n    energy                (chain, draw) float64 32kB 1.163e+04 ... 2.258e+03\n    energy_error          (chain, draw) float64 32kB -12.69 0.0 ... -0.1273\n    index_in_trajectory   (chain, draw) int64 32kB -5 0 4 -10 3 ... -14 0 25 -8\n    logp                  (chain, draw) float64 32kB -8.802e+03 ... -2.197e+03\n    maxdepth_reached      (chain, draw) bool 4kB False False ... False False\n    mean_tree_accept      (chain, draw) float64 32kB 1.0 0.0 ... 0.9372 0.837\n    mean_tree_accept_sym  (chain, draw) float64 32kB 0.2232 0.0 ... 0.8704\n    n_steps               (chain, draw) uint64 32kB 7 1 7 15 7 ... 15 15 31 31\n    step_size             (chain, draw) float64 32kB 1.439 0.2431 ... 0.1749\n    step_size_bar         (chain, draw) float64 32kB 1.439 0.4998 ... 0.1749\nAttributes:\n    created_at:                  2025-04-12T20:47:44.482123+00:00\n    arviz_version:               0.21.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.15.0xarray.DatasetDimensions:chain: 4draw: 1000Coordinates: (2)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999], shape=(1000,))Data variables: (12)depth(chain, draw)uint643 0 3 4 3 6 6 9 ... 6 5 5 5 4 4 5 5array([[3, 0, 3, ..., 5, 5, 5],\n       [2, 0, 2, ..., 5, 5, 5],\n       [4, 0, 3, ..., 5, 5, 5],\n       [3, 0, 3, ..., 4, 5, 5]], shape=(4, 1000), dtype=uint64)diverging(chain, draw)boolFalse True False ... False Falsearray([[False,  True, False, ..., False, False, False],\n       [False,  True, False, ..., False, False, False],\n       [False,  True, False, ..., False, False, False],\n       [False,  True, False, ..., False, False, False]], shape=(4, 1000))energy(chain, draw)float641.163e+04 8.876e+03 ... 2.258e+03array([[11630.39659342,  8875.95400608,  8731.7105997 , ...,\n         2250.83930412,  2243.96656194,  2243.24562894],\n       [15508.82555299, 14799.0247763 , 14647.12376649, ...,\n         2241.45380703,  2266.52538866,  2248.32629247],\n       [19634.60905307,  6136.76898751,  6069.04618878, ...,\n         2254.15195234,  2262.64088572,  2259.71541804],\n       [ 8455.51551647,  5778.68271162,  5770.14323876, ...,\n         2251.5893131 ,  2257.50973536,  2257.71825493]], shape=(4, 1000))energy_error(chain, draw)float64-12.69 0.0 ... 0.0964 -0.1273array([[-1.26874175e+01,  0.00000000e+00, -1.18235842e+02, ...,\n        -1.87099748e-01, -4.61500536e-01,  6.16699716e-01],\n       [-2.19738055e+00,  0.00000000e+00, -1.54099219e+02, ...,\n         2.09381959e-02,  5.69970491e-02, -2.19654431e-01],\n       [-6.50602947e+01,  0.00000000e+00, -5.99272334e+01, ...,\n         1.43495268e-01,  3.57982356e-01, -5.12772453e-03],\n       [-1.16804471e+01,  0.00000000e+00, -9.65278264e+00, ...,\n         0.00000000e+00,  9.64028068e-02, -1.27309524e-01]],\n      shape=(4, 1000))index_in_trajectory(chain, draw)int64-5 0 4 -10 3 -1 ... 10 -14 0 25 -8array([[ -5,   0,   4, ...,  23,  -6,  -9],\n       [ -2,   0,   2, ...,  11,  14,  13],\n       [-11,   0,  -3, ...,  22, -19, -18],\n       [  6,   0,   5, ...,   0,  25,  -8]], shape=(4, 1000))logp(chain, draw)float64-8.802e+03 ... -2.197e+03array([[ -8801.99773353,  -8801.99773353,  -3857.74954779, ...,\n         -2191.20283656,  -2169.4019842 ,  -2195.28683531],\n       [-14742.65778228, -14742.65778228, -11337.47783939, ...,\n         -2187.16423116,  -2198.51860258,  -2183.51992171],\n       [ -6073.03632037,  -6073.03632037,  -4087.85589492, ...,\n         -2195.32950386,  -2199.74915674,  -2196.88935438],\n       [ -5719.7057596 ,  -5719.7057596 ,  -4365.99102415, ...,\n         -2181.86080397,  -2196.81183832,  -2197.07896621]],\n      shape=(4, 1000))maxdepth_reached(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]], shape=(4, 1000))mean_tree_accept(chain, draw)float641.0 0.0 1.0 ... 0.9372 0.837array([[1.        , 0.        , 1.        , ..., 0.94820469, 0.6575515 ,\n        0.38282188],\n       [1.        , 0.        , 1.        , ..., 0.96535511, 0.86948813,\n        0.99835153],\n       [1.        , 0.        , 1.        , ..., 0.54108044, 0.75834751,\n        0.97295798],\n       [0.71632126, 0.        , 1.        , ..., 0.06437551, 0.93719768,\n        0.83699878]], shape=(4, 1000))mean_tree_accept_sym(chain, draw)float640.2232 0.0 ... 0.9671 0.8704array([[2.23182798e-01, 0.00000000e+00, 5.70036852e-05, ...,\n        9.19227881e-01, 6.01457694e-01, 3.93897177e-01],\n       [5.44861695e-01, 0.00000000e+00, 7.41236751e-08, ...,\n        9.78589224e-01, 9.27714113e-01, 9.04122588e-01],\n       [3.76669847e-02, 0.00000000e+00, 6.70633098e-12, ...,\n        5.70272349e-01, 8.56619604e-01, 9.20436092e-01],\n       [1.84135629e-01, 0.00000000e+00, 7.69498300e-02, ...,\n        1.10110476e-01, 9.67128032e-01, 8.70411249e-01]], shape=(4, 1000))n_steps(chain, draw)uint647 1 7 15 7 63 ... 31 42 15 15 31 31array([[ 7,  1,  7, ..., 31, 31, 31],\n       [ 3,  1,  3, ..., 31, 31, 31],\n       [15,  1,  7, ..., 63, 31, 31],\n       [ 7,  1,  7, ..., 15, 31, 31]], shape=(4, 1000), dtype=uint64)step_size(chain, draw)float641.439 0.2431 0.1 ... 0.1628 0.1749array([[1.43855101, 0.24311673, 0.1       , ..., 0.18561769, 0.164043  ,\n        0.19447538],\n       [1.43855101, 0.24311673, 0.1       , ..., 0.12515236, 0.13571602,\n        0.17929565],\n       [1.43855101, 0.24311673, 0.1       , ..., 0.16715003, 0.17333772,\n        0.17100847],\n       [0.85886532, 0.12457457, 0.1       , ..., 0.14649379, 0.16281773,\n        0.17490276]], shape=(4, 1000))step_size_bar(chain, draw)float641.439 0.4998 ... 0.1749 0.1749array([[1.43855101, 0.49983385, 0.42449831, ..., 0.19513229, 0.1949418 ,\n        0.19447538],\n       [1.43855101, 0.49983385, 0.42449831, ..., 0.17979539, 0.17951104,\n        0.17929565],\n       [1.43855101, 0.49983385, 0.42449831, ..., 0.17090807, 0.17092164,\n        0.17100847],\n       [0.85886532, 0.27249125, 0.21675445, ..., 0.17500014, 0.17492909,\n        0.17490276]], shape=(4, 1000))Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Attributes: (4)created_at :2025-04-12T20:47:44.482123+00:00arviz_version :0.21.0modeling_interface :bambimodeling_interface_version :0.15.0\n                      \n                  \n            \n            \n              \n            \n            \n\n\n\naz.summary(result, var_names=[\"Intercept\", \"male\", \"1|edu\", \"1|eth\", \"repvote\"])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n0.388\n0.414\n-0.425\n1.150\n0.010\n0.008\n1697.0\n2529.0\n1.00\n\n\nmale\n0.206\n0.198\n-0.203\n0.531\n0.007\n0.014\n1504.0\n1082.0\n1.00\n\n\n1|edu[4-Year College]\n-0.052\n0.176\n-0.406\n0.282\n0.004\n0.005\n2460.0\n2670.0\n1.00\n\n\n1|edu[HS]\n0.056\n0.171\n-0.271\n0.398\n0.004\n0.005\n2363.0\n2061.0\n1.00\n\n\n1|edu[No HS]\n0.162\n0.207\n-0.167\n0.599\n0.005\n0.005\n2149.0\n1783.0\n1.00\n\n\n1|edu[Post-grad]\n-0.200\n0.212\n-0.621\n0.133\n0.004\n0.004\n2383.0\n3237.0\n1.00\n\n\n1|edu[Some college]\n0.026\n0.173\n-0.321\n0.360\n0.004\n0.004\n1893.0\n3734.0\n1.00\n\n\n1|eth[Black]\n-0.388\n0.323\n-0.998\n0.170\n0.008\n0.007\n1540.0\n2772.0\n1.00\n\n\n1|eth[Hispanic]\n0.079\n0.285\n-0.481\n0.637\n0.006\n0.006\n2206.0\n2823.0\n1.00\n\n\n1|eth[Other]\n0.085\n0.290\n-0.426\n0.740\n0.007\n0.007\n2138.0\n2360.0\n1.00\n\n\n1|eth[White]\n0.180\n0.273\n-0.311\n0.754\n0.007\n0.006\n1639.0\n2598.0\n1.01\n\n\nrepvote\n-1.181\n0.523\n-2.148\n-0.173\n0.007\n0.006\n5134.0\n3597.0\n1.00\n\n\n\n\n\n\n\nThe terms in the model formula allow for specific intercept terms across the demographic splits of eth, edu, and state. These represent stratum specific adjustments of the intercept term in the model. Similarly we invoke intercepts for the interaction terms of age:edu, male:eth and edu:eth. Each of these cohorts represents a share of the data in our sample.\n\nmodel_hierarchical.graph()\n\n\n\n\n\n\n\n\nWe then predict the outcomes implied by the biased sample. These predictions are to be adjusted by what we take to be the share of that demographic cohort in population. We can plot the posterior predictive distribution against the observed data from our biased sample to see that we have generally good fit to the distribution.\n\nmodel_hierarchical.predict(result, kind=\"pps\")\nax = az.plot_ppc(result, figsize=(8, 5), kind=\"cumulative\", observed_rug=True, num_pp_samples=500)\nax.set_title(\"Posterior Predictive Checks \\n On Biased Sample\");\n\n/Users/nathanielforde/mambaforge/envs/bambi-env2/lib/python3.12/site-packages/IPython/core/events.py:82: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  func(*args, **kwargs)\n/Users/nathanielforde/mambaforge/envs/bambi-env2/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  fig.canvas.print_figure(bytes_io, **kw)\n\n\n\n\n\n\n\n\n\n\n\nApply the Post-stratification Weighting\nWe now use the fitted model to predict the voting shares on the data where we use the genuine state numbers per strata. To do so we load data from the national census and augment our data set so as to be able to apply the appropriate weights.\n\npoststrat_df = pd.read_csv(\"data/mr_p_poststrat_df.csv\")\n\nnew_data = poststrat_df.merge(\n    statelevel_predictors_df, left_on=\"state\", right_on=\"state\", how=\"left\"\n)\nnew_data.rename({\"educ\": \"edu\"}, axis=1, inplace=True)\nnew_data = model_df.merge(\n    new_data,\n    how=\"left\",\n    left_on=[\"state\", \"eth\", \"male\", \"age\", \"edu\"],\n    right_on=[\"state\", \"eth\", \"male\", \"age\", \"edu\"],\n).rename({\"n_y\": \"n\", \"repvote_y\": \"repvote\"}, axis=1)[\n    [\"state\", \"eth\", \"male\", \"age\", \"edu\", \"n\", \"repvote\"]\n]\n\n\nnew_data = new_data.merge(\n    new_data.groupby(\"state\").agg({\"n\": \"sum\"}).reset_index().rename({\"n\": \"state_total\"}, axis=1)\n)\nnew_data[\"state_percent\"] = new_data[\"n\"] / new_data[\"state_total\"]\nnew_data.head()\n\n\n\n\n\n\n\n\nstate\neth\nmale\nage\nedu\nn\nrepvote\nstate_total\nstate_percent\n\n\n\n\n0\nID\nWhite\n-0.5\n70+\nHS\n31503\n0.683102\n1193885\n0.026387\n\n\n1\nID\nWhite\n0.5\n70+\n4-Year College\n11809\n0.683102\n1193885\n0.009891\n\n\n2\nWV\nWhite\n0.5\n70+\nSome college\n17089\n0.721611\n1441882\n0.011852\n\n\n3\nWV\nWhite\n0.5\n70+\n4-Year College\n7396\n0.721611\n1441882\n0.005129\n\n\n4\nID\nWhite\n0.5\n70+\nPost-grad\n9873\n0.683102\n1193885\n0.008270\n\n\n\n\n\n\n\nThis dataset is exactly the same structure and length as our input data to the fitted model. We have simply switched the observed counts across the demographic strata with the counts that reflect their proportion in the national survey. Additionally we have calculated the state totals and the share of each strata within the state. This will be important for later when we use this state_percent variable to calculate an adjusted MrP estimate of the predictions at a state level. We now use this data set with our fitted model to generate posterior predictive distribution.\n\nresult_adjust = model_hierarchical.predict(result, data=new_data, inplace=False, kind=\"pps\")\nresult_adjust\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 1GB\nDimensions:               (chain: 4, draw: 4000, state__factor_dim: 46,\n                           eth__factor_dim: 4, edu__factor_dim: 5,\n                           male:eth__factor_dim: 8, edu:age__factor_dim: 30,\n                           edu:eth__factor_dim: 20, __obs__: 11040)\nCoordinates:\n  * state__factor_dim     (state__factor_dim) &lt;U2 368B 'AK' 'AL' ... 'WV' 'WY'\n  * eth__factor_dim       (eth__factor_dim) &lt;U8 128B 'Black' ... 'White'\n  * edu__factor_dim       (edu__factor_dim) &lt;U14 280B '4-Year College' ... 'S...\n  * male:eth__factor_dim  (male:eth__factor_dim) &lt;U13 416B '-0.5:Black' ... '...\n  * draw                  (draw) int64 32kB 0 1 2 3 4 ... 3996 3997 3998 3999\n  * edu:age__factor_dim   (edu:age__factor_dim) &lt;U20 2kB '4-Year College:18-2...\n  * chain                 (chain) int64 32B 0 1 2 3\n  * edu:eth__factor_dim   (edu:eth__factor_dim) &lt;U23 2kB '4-Year College:Blac...\n  * __obs__               (__obs__) int64 88kB 0 1 2 3 ... 11037 11038 11039\nData variables: (12/16)\n    1|edu:age_sigma       (chain, draw) float64 128kB 0.1344 0.1437 ... 0.156\n    1|edu:eth_sigma       (chain, draw) float64 128kB 0.1177 0.1093 ... 0.2808\n    1|edu_sigma           (chain, draw) float64 128kB 1.346 1.351 ... 0.04706\n    1|eth_sigma           (chain, draw) float64 128kB 0.4771 0.4858 ... 0.03536\n    1|male:eth_sigma      (chain, draw) float64 128kB 0.354 0.3236 ... 0.1215\n    1|state_sigma         (chain, draw) float64 128kB 0.2385 0.248 ... 0.2483\n    ...                    ...\n    1|edu:age             (chain, draw, edu:age__factor_dim) float64 4MB -0.0...\n    1|edu:eth             (chain, draw, edu:eth__factor_dim) float64 3MB 0.14...\n    1|eth                 (chain, draw, eth__factor_dim) float64 512kB -0.813...\n    1|male:eth            (chain, draw, male:eth__factor_dim) float64 1MB 0.5...\n    1|state               (chain, draw, state__factor_dim) float64 6MB -0.154...\n    p                     (chain, draw, __obs__) float64 1GB 0.4474 ... 0.4396\nAttributes:\n    created_at:                  2025-04-12T20:47:44.644117+00:00\n    arviz_version:               0.21.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.15.0xarray.DatasetDimensions:chain: 4draw: 4000state__factor_dim: 46eth__factor_dim: 4edu__factor_dim: 5male:eth__factor_dim: 8edu:age__factor_dim: 30edu:eth__factor_dim: 20__obs__: 11040Coordinates: (9)state__factor_dim(state__factor_dim)&lt;U2'AK' 'AL' 'AR' ... 'WI' 'WV' 'WY'array(['AK', 'AL', 'AR', 'CA', 'CO', 'DE', 'FL', 'GA', 'HI', 'IA', 'ID', 'IL',\n       'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC',\n       'ND', 'NE', 'NH', 'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI',\n       'SC', 'SD', 'TN', 'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY'], dtype='&lt;U2')eth__factor_dim(eth__factor_dim)&lt;U8'Black' 'Hispanic' 'Other' 'White'array(['Black', 'Hispanic', 'Other', 'White'], dtype='&lt;U8')edu__factor_dim(edu__factor_dim)&lt;U14'4-Year College' ... 'Some college'array(['4-Year College', 'HS', 'No HS', 'Post-grad', 'Some college'],\n      dtype='&lt;U14')male:eth__factor_dim(male:eth__factor_dim)&lt;U13'-0.5:Black' ... '0.5:White'array(['-0.5:Black', '-0.5:Hispanic', '-0.5:Other', '-0.5:White', '0.5:Black',\n       '0.5:Hispanic', '0.5:Other', '0.5:White'], dtype='&lt;U13')draw(draw)int640 1 2 3 4 ... 3996 3997 3998 3999array([   0,    1,    2, ..., 3997, 3998, 3999], shape=(4000,))edu:age__factor_dim(edu:age__factor_dim)&lt;U20'4-Year College:18-29' ... 'Some...array(['4-Year College:18-29', '4-Year College:30-39', '4-Year College:40-49',\n       '4-Year College:50-59', '4-Year College:60-69', '4-Year College:70+',\n       'HS:18-29', 'HS:30-39', 'HS:40-49', 'HS:50-59', 'HS:60-69', 'HS:70+',\n       'No HS:18-29', 'No HS:30-39', 'No HS:40-49', 'No HS:50-59',\n       'No HS:60-69', 'No HS:70+', 'Post-grad:18-29', 'Post-grad:30-39',\n       'Post-grad:40-49', 'Post-grad:50-59', 'Post-grad:60-69',\n       'Post-grad:70+', 'Some college:18-29', 'Some college:30-39',\n       'Some college:40-49', 'Some college:50-59', 'Some college:60-69',\n       'Some college:70+'], dtype='&lt;U20')chain(chain)int640 1 2 3array([0, 1, 2, 3])edu:eth__factor_dim(edu:eth__factor_dim)&lt;U23'4-Year College:Black' ... 'Some...array(['4-Year College:Black', '4-Year College:Hispanic',\n       '4-Year College:Other', '4-Year College:White', 'HS:Black',\n       'HS:Hispanic', 'HS:Other', 'HS:White', 'No HS:Black', 'No HS:Hispanic',\n       'No HS:Other', 'No HS:White', 'Post-grad:Black', 'Post-grad:Hispanic',\n       'Post-grad:Other', 'Post-grad:White', 'Some college:Black',\n       'Some college:Hispanic', 'Some college:Other', 'Some college:White'],\n      dtype='&lt;U23')__obs__(__obs__)int640 1 2 3 ... 11036 11037 11038 11039array([    0,     1,     2, ..., 11037, 11038, 11039], shape=(11040,))Data variables: (16)1|edu:age_sigma(chain, draw)float640.1344 0.1437 ... 0.1536 0.156array([[0.13441164, 0.14370398, 0.15916931, ..., 0.18880834, 0.03518931,\n        0.14314809],\n       [0.16019625, 0.16871859, 0.15828631, ..., 0.15253245, 0.11724478,\n        0.16203634],\n       [0.19024498, 0.16992334, 0.27460906, ..., 0.07731436, 0.07383145,\n        0.20263921],\n       [0.06723177, 0.06522316, 0.08860448, ..., 0.11617668, 0.15355656,\n        0.15598383]], shape=(4, 4000))1|edu:eth_sigma(chain, draw)float640.1177 0.1093 ... 0.2217 0.2808array([[0.11771773, 0.10931956, 0.09975393, ..., 0.11124875, 0.12363697,\n        0.09228348],\n       [0.13976966, 0.1288965 , 0.14463339, ..., 0.23322617, 0.23736116,\n        0.19920126],\n       [0.36019768, 0.41347014, 0.40604164, ..., 0.15508335, 0.18207936,\n        0.13132313],\n       [0.28470192, 0.25976583, 0.2111311 , ..., 0.3431292 , 0.22170838,\n        0.28077583]], shape=(4, 4000))1|edu_sigma(chain, draw)float641.346 1.351 ... 0.1539 0.04706array([[1.34609022, 1.35111116, 0.2212135 , ..., 0.51850869, 0.23301459,\n        0.51940129],\n       [0.20084021, 0.17433647, 0.18136098, ..., 0.08054317, 0.10585751,\n        0.2394544 ],\n       [0.00820515, 0.00878228, 0.01468995, ..., 0.25704124, 0.19729321,\n        0.20225655],\n       [0.03352157, 0.02812175, 0.03744695, ..., 0.34170865, 0.1538545 ,\n        0.04706238]], shape=(4, 4000))1|eth_sigma(chain, draw)float640.4771 0.4858 ... 0.2314 0.03536array([[0.4770694 , 0.48582884, 0.75481753, ..., 0.60639702, 0.45636024,\n        0.53714328],\n       [0.47658548, 0.41481086, 0.48152598, ..., 0.33476645, 0.78326188,\n        0.88538029],\n       [1.46112274, 1.43538558, 1.47628137, ..., 0.9759116 , 0.84937992,\n        1.00957962],\n       [0.19702956, 0.21981617, 0.16767914, ..., 0.17715399, 0.23135967,\n        0.03535978]], shape=(4, 4000))1|male:eth_sigma(chain, draw)float640.354 0.3236 ... 0.2696 0.1215array([[0.35397165, 0.32364947, 0.02384236, ..., 0.03622344, 0.14971025,\n        0.18014677],\n       [0.387906  , 0.41517064, 0.35954647, ..., 0.18629486, 0.17286002,\n        0.01491758],\n       [0.12495751, 0.2235392 , 0.1203779 , ..., 0.18473111, 0.10086279,\n        0.08655779],\n       [0.7184852 , 0.66431673, 0.52878106, ..., 0.29469976, 0.2695665 ,\n        0.12150705]], shape=(4, 4000))1|state_sigma(chain, draw)float640.2385 0.248 ... 0.2569 0.2483array([[0.23853477, 0.24803782, 0.25990388, ..., 0.26522649, 0.26257531,\n        0.27854286],\n       [0.2949392 , 0.2928506 , 0.29134995, ..., 0.34535457, 0.29752227,\n        0.27131224],\n       [0.36691287, 0.36180375, 0.28429242, ..., 0.26233375, 0.2947532 ,\n        0.2601899 ],\n       [0.21685807, 0.21907411, 0.2135662 , ..., 0.35388117, 0.25694889,\n        0.24834829]], shape=(4, 4000))Intercept(chain, draw)float64-0.0003219 -0.07621 ... 0.3622array([[-3.21858306e-04, -7.62069524e-02, -1.85344231e-01, ...,\n         3.72455227e-01, -1.28357710e-01, -1.75070205e-02],\n       [ 6.75254365e-01,  6.86267808e-01,  6.64230580e-01, ...,\n        -5.24206572e-02,  4.50979939e-01,  1.76310324e-01],\n       [ 5.63949358e-01,  4.04841939e-01,  4.75318513e-01, ...,\n        -4.73871675e-01, -1.43988959e-01, -6.65968891e-01],\n       [ 3.95783430e-01,  4.30751300e-01,  1.57790349e-01, ...,\n         5.72417898e-01,  5.99219020e-01,  3.62194073e-01]],\n      shape=(4, 4000))male(chain, draw)float640.1861 0.1973 ... 0.2833 0.15array([[0.18614108, 0.1972769 , 0.24609322, ..., 0.28845895, 0.14738262,\n        0.38867358],\n       [0.24864871, 0.26618414, 0.30451655, ..., 0.290124  , 0.40927837,\n        0.26403336],\n       [0.01147796, 0.00675254, 0.00233586, ..., 0.22756571, 0.20263934,\n        0.24459288],\n       [0.36824705, 0.37411922, 0.38068321, ..., 0.62651956, 0.28326965,\n        0.14996354]], shape=(4, 4000))repvote(chain, draw)float64-0.3935 -0.3044 ... -1.388 -1.119array([[-0.3934767 , -0.3044197 , -0.18716323, ..., -1.47690415,\n        -1.01878333, -0.61104586],\n       [-1.116523  , -1.10614173, -1.14699793, ..., -0.67779123,\n        -1.43154409, -0.67383683],\n       [-1.78520666, -1.58065665, -1.49763204, ..., -0.32421597,\n        -0.96578146, -0.20842237],\n       [-0.94040154, -1.02003633, -0.76954264, ..., -1.1079926 ,\n        -1.38755167, -1.11909619]], shape=(4, 4000))1|edu(chain, draw, edu__factor_dim)float64-0.2361 0.03952 ... -0.08723array([[[-0.23606639,  0.03952195,  0.19390099, -0.58725864,\n         -0.10353753],\n        [-0.04072258, -0.05117268,  0.0944052 , -0.56205338,\n          0.03253908],\n        [-0.06853926, -0.00565181,  0.12518418, -0.44266426,\n          0.05553575],\n        ...,\n        [-0.14576388,  0.14932598,  0.28614487, -0.35608171,\n          0.02875589],\n        [ 0.12322133,  0.16399086,  0.29470316, -0.10561501,\n          0.1359425 ],\n        [-0.06701444, -0.04051351,  0.21726117, -0.36566861,\n         -0.13364958]],\n\n       [[-0.0576874 , -0.12125953,  0.09555403, -0.19359222,\n          0.16842842],\n        [-0.0584045 , -0.09947117,  0.09720323, -0.18202035,\n          0.14304346],\n        [-0.06979621, -0.10658497,  0.12894312, -0.14951308,\n          0.16244339],\n...\n        [ 0.16398121,  0.02355287,  0.05073705, -0.34309796,\n         -0.04993389],\n        [-0.01554162, -0.06221654,  0.02175718, -0.29554477,\n         -0.22269852],\n        [ 0.05869026, -0.22167485,  0.00438661, -0.36304784,\n         -0.12497928]],\n\n       [[ 0.01106397,  0.00913131,  0.01688615, -0.01077497,\n         -0.02580242],\n        [ 0.0048783 , -0.00149741, -0.00177262,  0.00663449,\n         -0.01237859],\n        [ 0.01842357, -0.01586298,  0.01010242,  0.01033829,\n         -0.00466377],\n        ...,\n        [-0.1117301 ,  0.19562763,  0.00675094, -0.76317213,\n         -0.02942159],\n        [-0.17036106,  0.02770568,  0.26875207,  0.01220776,\n          0.00094009],\n        [-0.00703157,  0.0854295 , -0.00123738, -0.02605878,\n         -0.08722852]]], shape=(4, 4000, 5))1|edu:age(chain, draw, edu:age__factor_dim)float64-0.0658 -0.09502 ... 0.12 -0.0549array([[[-0.06580405, -0.09501558,  0.1117735 , ..., -0.161431  ,\n          0.06880415,  0.09496863],\n        [-0.06568834, -0.07150977,  0.11391269, ..., -0.17510751,\n          0.0642265 ,  0.11404995],\n        [ 0.06671058, -0.06212731, -0.15775793, ..., -0.00986691,\n          0.10263592,  0.13340623],\n        ...,\n        [ 0.24962068,  0.22585613, -0.11065996, ...,  0.00842856,\n          0.19569075,  0.25245259],\n        [-0.04149419,  0.00966698, -0.02895544, ...,  0.00099467,\n         -0.02481149, -0.02970359],\n        [ 0.03411322, -0.19025902, -0.04022661, ...,  0.00494236,\n          0.0963688 ,  0.29311101]],\n\n       [[ 0.07784129, -0.04760669,  0.00683357, ..., -0.15049798,\n          0.01717726,  0.11121074],\n        [ 0.06663115, -0.04488087, -0.00399348, ..., -0.1646276 ,\n          0.0031251 ,  0.11959057],\n        [ 0.10554835, -0.04361274, -0.00759353, ..., -0.13586593,\n         -0.03044159,  0.17281195],\n...\n        [-0.00373851,  0.03225081, -0.1176617 , ...,  0.08989114,\n          0.11482376,  0.03773806],\n        [ 0.01626914, -0.0147687 , -0.10202513, ...,  0.0326447 ,\n          0.07211576,  0.01780689],\n        [-0.45474507, -0.16836101, -0.28859303, ..., -0.0252933 ,\n         -0.05470419,  0.29621247]],\n\n       [[-0.00282311, -0.08021558,  0.02250639, ...,  0.01537817,\n          0.09167904,  0.06972863],\n        [ 0.05604518, -0.03303047,  0.02468017, ...,  0.00189076,\n          0.09297964,  0.12434294],\n        [ 0.05579271, -0.04335375, -0.00739794, ...,  0.00754659,\n          0.08632638,  0.13417489],\n        ...,\n        [-0.06643662, -0.07156536, -0.08991674, ..., -0.07743765,\n          0.13517072, -0.024519  ],\n        [ 0.03862708,  0.14417763, -0.07728414, ...,  0.14113535,\n          0.08486243,  0.3274914 ],\n        [-0.04941882,  0.00230183, -0.01546024, ..., -0.11303916,\n          0.11997926, -0.05490342]]], shape=(4, 4000, 30))1|edu:eth(chain, draw, edu:eth__factor_dim)float640.1416 -0.02554 ... -0.1221 0.6262array([[[ 1.41552800e-01, -2.55372634e-02, -4.13537297e-02, ...,\n          8.06654268e-02,  1.12093738e-01,  1.74819555e-01],\n        [ 1.48043337e-01, -3.88778108e-02, -1.19108127e-02, ...,\n          6.80000359e-02,  1.19721248e-01,  1.73944853e-01],\n        [-1.08284988e-01, -2.39574397e-02,  1.38273186e-01, ...,\n         -6.49435053e-02, -1.46928886e-01,  3.81065660e-02],\n        ...,\n        [ 2.54121469e-02,  9.92249123e-02,  4.41362660e-02, ...,\n          5.81225282e-02, -5.98904317e-02,  2.55109883e-01],\n        [-1.05956417e-01, -3.53505242e-01, -3.30730244e-02, ...,\n          1.93970671e-01, -9.94523759e-02,  1.02401566e-01],\n        [ 1.16564656e-01,  1.58589118e-01,  4.54278311e-02, ...,\n         -1.90160234e-01,  4.23185965e-02,  2.85031059e-01]],\n\n       [[-2.77373049e-02, -3.00759886e-01, -2.16976647e-02, ...,\n         -3.33475054e-01, -1.32921253e-02,  9.10967145e-02],\n        [-2.86452627e-02, -3.03551376e-01, -2.95181391e-02, ...,\n         -3.38176810e-01,  2.74523792e-03,  9.55083085e-02],\n        [ 3.23616518e-02, -3.47651801e-01, -6.06412486e-02, ...,\n         -2.95783064e-01,  2.29155216e-02,  1.44689727e-01],\n...\n          1.29182899e-01,  2.09732131e-01,  2.31666873e-01],\n        [-5.27013102e-02, -2.36951601e-01,  1.72038476e-01, ...,\n          2.29523419e-01,  3.30497675e-01,  2.80871478e-01],\n        [ 4.04275531e-02, -1.73196897e-01,  1.62445186e-01, ...,\n         -9.66062913e-02,  6.33620840e-02,  1.46286311e-01]],\n\n       [[ 3.80728677e-01, -1.27113675e-01,  4.17930524e-02, ...,\n          2.07388380e-02,  8.04929936e-02,  4.76554332e-02],\n        [ 2.73369833e-01,  3.80901603e-03, -3.57404701e-01, ...,\n         -8.80357513e-02,  1.51508895e-01,  7.72201950e-02],\n        [ 2.72481084e-01, -8.73063441e-03, -2.39814236e-01, ...,\n         -2.65066393e-02,  9.80264076e-02,  5.17560252e-02],\n        ...,\n        [ 2.30311217e-01, -3.34987473e-01, -2.57489529e-01, ...,\n         -2.48816444e-01, -2.15065852e-01,  3.46272219e-01],\n        [ 9.42023631e-02,  1.19818352e-04,  3.86048731e-01, ...,\n         -6.06371493e-02,  2.10485093e-01,  2.95462063e-01],\n        [-1.66574647e-01,  3.46865305e-02,  1.98867547e-01, ...,\n          1.85916285e-01, -1.22075234e-01,  6.26150382e-01]]],\n      shape=(4, 4000, 20))1|eth(chain, draw, eth__factor_dim)float64-0.813 0.376 ... 0.01006 -0.01473array([[[-0.81300941,  0.37598337,  0.33992714,  0.40225461],\n        [-0.73591208,  0.44240008,  0.32706899,  0.41423505],\n        [-0.64901435,  0.20310546,  0.15831128,  0.27652794],\n        ...,\n        [-0.29069406,  0.15600426,  0.1414519 ,  0.31656927],\n        [-0.35531592,  0.44696303,  0.41187067,  0.6334792 ],\n        [-0.10005083,  0.04771385,  0.47991707,  0.30580031]],\n\n       [[-0.7382472 , -0.11106205, -0.07110273, -0.53509545],\n        [-0.61320653, -0.131576  , -0.0859798 , -0.4748674 ],\n        [-0.74770391, -0.15147255, -0.14979473, -0.49323646],\n        ...,\n        [-0.04051779, -0.07522958,  0.42199783,  0.13724378],\n        [-0.13098407,  0.1611958 ,  0.40540588,  0.08518507],\n        [-0.23532152,  0.24372888,  0.16984744,  0.42337685]],\n\n       [[-0.22091011,  0.26695156,  0.21715657,  0.46316998],\n        [-0.16781611,  0.01703062,  0.36230376,  0.68904393],\n        [-0.50723314,  0.11310465,  0.16856559,  0.41465675],\n        ...,\n        [-0.07859355,  0.46873659,  0.21127119,  0.66537277],\n        [ 0.25550376,  0.45557766,  0.37056397,  0.76009951],\n        [ 0.26670344,  0.84316704,  0.66777948,  0.90391942]],\n\n       [[-0.15810267, -0.02843205, -0.1752418 , -0.15141295],\n        [-0.24641641,  0.06571814, -0.13337538, -0.15771727],\n        [-0.18192129,  0.12485717, -0.10055871, -0.14864204],\n        ...,\n        [-0.26494812,  0.32982861, -0.0424683 , -0.22476109],\n        [-0.01008326,  0.17393471,  0.02683767, -0.19003531],\n        [ 0.00685285,  0.00541247,  0.01005723, -0.01473437]]],\n      shape=(4, 4000, 4))1|male:eth(chain, draw, male:eth__factor_dim)float640.5367 -0.1466 ... 0.04687 0.1735array([[[ 0.53666726, -0.14659088, -0.01051454, ..., -0.07886515,\n         -0.26242731, -0.06394192],\n        [ 0.49983783, -0.03773404, -0.08990654, ..., -0.10159896,\n         -0.2396677 , -0.02977189],\n        [-0.02027423, -0.01914877,  0.02354076, ...,  0.01255169,\n          0.02164773,  0.00742125],\n        ...,\n        [-0.03312325,  0.03090077, -0.0067438 , ...,  0.00447494,\n          0.01608005, -0.03327538],\n        [ 0.12421165, -0.07967298,  0.0739437 , ..., -0.09117925,\n         -0.06883314, -0.06168866],\n        [-0.19453771,  0.09743795, -0.05669856, ...,  0.1765203 ,\n         -0.21333708,  0.03118991]],\n\n       [[-0.30101035, -0.13763932, -0.24753248, ...,  0.26099436,\n         -0.17428794,  0.48749867],\n        [-0.18781258, -0.1782078 , -0.20678099, ...,  0.24099459,\n         -0.13348059,  0.53420899],\n        [-0.1584891 , -0.05736607, -0.28940156, ...,  0.1618874 ,\n         -0.33393529,  0.4555195 ],\n...\n        [ 0.09868322, -0.36299329,  0.06631239, ...,  0.02873544,\n         -0.09298074, -0.05020437],\n        [-0.05537263, -0.01639645,  0.10740681, ...,  0.1675895 ,\n         -0.09719602, -0.07247783],\n        [-0.09817336, -0.12545263, -0.07364686, ..., -0.00308771,\n         -0.04985223, -0.0823832 ]],\n\n       [[-0.67515165, -0.33331529,  0.06219964, ...,  0.10726802,\n          0.04554298,  0.21340511],\n        [-0.43433301, -0.18892972,  0.21716303, ..., -0.26259872,\n         -0.04755359,  0.19030465],\n        [-0.49615194, -0.22545399,  0.23793127, ..., -0.01304088,\n         -0.01962695,  0.34990258],\n        ...,\n        [-0.23933899,  0.13106667,  0.2208941 , ..., -0.08476503,\n          0.18526623,  0.07594984],\n        [-0.39046374, -0.11455443, -0.28321851, ..., -0.09104462,\n         -0.0646196 ,  0.10316641],\n        [-0.07583492, -0.06073763,  0.18137331, ...,  0.21309601,\n          0.04687095,  0.17349325]]], shape=(4, 4000, 8))1|state(chain, draw, state__factor_dim)float64-0.1547 -0.04735 ... 0.3345 -0.1952array([[[-1.54713295e-01, -4.73476880e-02,  8.20595488e-02, ...,\n         -1.58003948e-01,  7.27553354e-02,  3.62057400e-01],\n        [-2.04601681e-01, -3.23745203e-02,  7.36662212e-02, ...,\n         -1.68892587e-01,  7.30813214e-02,  3.67768155e-01],\n        [ 4.35385009e-01,  4.01403727e-01, -1.66041061e-01, ...,\n          4.08629417e-01,  4.61206759e-01, -2.94980043e-01],\n        ...,\n        [ 2.04333612e-01,  1.36918396e-01,  1.90852903e-01, ...,\n          4.16465975e-02,  4.17282109e-01,  7.26306856e-02],\n        [ 2.94135990e-01,  3.91411284e-01, -3.90516760e-02, ...,\n         -1.38545935e-01,  4.71502407e-01, -5.58963464e-02],\n        [-2.72980644e-02,  1.63809778e-01,  1.28677607e-01, ...,\n          9.64369358e-02,  3.80814045e-01,  4.84268827e-02]],\n\n       [[ 1.93710139e-01,  1.46261526e-01,  6.47443284e-02, ...,\n         -9.63762571e-02,  5.63566303e-01, -3.22097128e-01],\n        [ 3.10778844e-02,  1.78542916e-01,  6.94696415e-02, ...,\n         -1.61681231e-01,  5.73968344e-01, -3.83559859e-01],\n        [ 9.02372178e-02,  1.93320685e-01, -5.99915354e-02, ...,\n         -1.20579835e-01,  5.36800809e-01, -3.62891352e-01],\n...\n          8.94609641e-02,  4.70647435e-01,  1.88396082e-01],\n        [ 3.82913651e-01,  3.40828846e-01,  7.79209736e-02, ...,\n          2.28512066e-01,  4.97625240e-01, -3.69064217e-01],\n        [ 1.94561414e-01,  1.16993643e-01,  2.59973717e-01, ...,\n          1.26311901e-01,  3.75683765e-01,  8.09470861e-02]],\n\n       [[-1.72469487e-01,  2.83054539e-01,  2.76103336e-02, ...,\n          2.70089069e-01,  5.10136092e-01,  7.62677209e-02],\n        [ 3.15014363e-02,  2.86295249e-01,  4.19188246e-02, ...,\n          2.92696575e-01,  4.94168187e-01,  1.03153740e-01],\n        [-5.19507574e-03,  3.73057517e-01,  7.80096128e-02, ...,\n          9.06004034e-02,  4.76666500e-01,  1.71554718e-01],\n        ...,\n        [-6.28950018e-02,  3.39280628e-01,  4.92034480e-02, ...,\n         -3.51470501e-01,  4.48495073e-01, -2.63362750e-01],\n        [ 5.08924441e-01,  2.11967257e-01,  1.51174541e-02, ...,\n          3.94309100e-01,  3.57383418e-01,  1.15675811e-01],\n        [-1.33127632e-01,  2.80507213e-01,  4.09042457e-02, ...,\n         -3.95254617e-01,  3.34464820e-01, -1.95206105e-01]]],\n      shape=(4, 4000, 46))p(chain, draw, __obs__)float640.4474 0.451 ... 0.4265 0.4396array([[[0.44744132, 0.45100029, 0.59535083, ..., 0.31692549,\n         0.45354804, 0.36823698],\n        [0.43650381, 0.50385374, 0.64126007, ..., 0.29498502,\n         0.45743476, 0.4235269 ],\n        [0.48006666, 0.4897864 , 0.68456866, ..., 0.34448363,\n         0.50351093, 0.2726274 ],\n        ...,\n        [0.43293482, 0.58641111, 0.66548391, ..., 0.22718231,\n         0.41448401, 0.43561749],\n        [0.48724838, 0.46562346, 0.61351277, ..., 0.3223898 ,\n         0.38399172, 0.34333802],\n        [0.4509811 , 0.52909391, 0.71057728, ..., 0.41255468,\n         0.46928817, 0.33781057]],\n\n       [[0.458138  , 0.4682769 , 0.70694434, ..., 0.4209459 ,\n         0.54727455, 0.3718362 ],\n        [0.48003899, 0.49895365, 0.73353035, ..., 0.4223712 ,\n         0.53750718, 0.42338092],\n        [0.45591336, 0.47176164, 0.72468716, ..., 0.34433434,\n         0.4745395 , 0.40187599],\n...\n        [0.44067846, 0.48226843, 0.67067518, ..., 0.20258534,\n         0.36774633, 0.42850245],\n        [0.47150454, 0.4698387 , 0.62753104, ..., 0.36685024,\n         0.45490751, 0.4490857 ],\n        [0.41991635, 0.52733105, 0.69437796, ..., 0.16818608,\n         0.29538734, 0.29771256]],\n\n       [[0.49578902, 0.46908655, 0.63761171, ..., 0.31618689,\n         0.3682525 , 0.32890784],\n        [0.4665025 , 0.49473491, 0.64512582, ..., 0.38201625,\n         0.44164373, 0.31974139],\n        [0.47347064, 0.50823725, 0.65746464, ..., 0.3192674 ,\n         0.42266074, 0.27710497],\n        ...,\n        [0.4678561 , 0.51854623, 0.66332657, ..., 0.21917098,\n         0.36631841, 0.42141452],\n        [0.4810996 , 0.45966067, 0.65339364, ..., 0.27476291,\n         0.43762709, 0.35200435],\n        [0.42390189, 0.5123979 , 0.64722565, ..., 0.42396048,\n         0.42651207, 0.43963847]]], shape=(4, 4000, 11040))Indexes: (9)state__factor_dimPandasIndexPandasIndex(Index(['AK', 'AL', 'AR', 'CA', 'CO', 'DE', 'FL', 'GA', 'HI', 'IA', 'ID', 'IL',\n       'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC',\n       'ND', 'NE', 'NH', 'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI',\n       'SC', 'SD', 'TN', 'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY'],\n      dtype='object', name='state__factor_dim'))eth__factor_dimPandasIndexPandasIndex(Index(['Black', 'Hispanic', 'Other', 'White'], dtype='object', name='eth__factor_dim'))edu__factor_dimPandasIndexPandasIndex(Index(['4-Year College', 'HS', 'No HS', 'Post-grad', 'Some college'], dtype='object', name='edu__factor_dim'))male:eth__factor_dimPandasIndexPandasIndex(Index(['-0.5:Black', '-0.5:Hispanic', '-0.5:Other', '-0.5:White', '0.5:Black',\n       '0.5:Hispanic', '0.5:Other', '0.5:White'],\n      dtype='object', name='male:eth__factor_dim'))drawPandasIndexPandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       3990, 3991, 3992, 3993, 3994, 3995, 3996, 3997, 3998, 3999],\n      dtype='int64', name='draw', length=4000))edu:age__factor_dimPandasIndexPandasIndex(Index(['4-Year College:18-29', '4-Year College:30-39', '4-Year College:40-49',\n       '4-Year College:50-59', '4-Year College:60-69', '4-Year College:70+',\n       'HS:18-29', 'HS:30-39', 'HS:40-49', 'HS:50-59', 'HS:60-69', 'HS:70+',\n       'No HS:18-29', 'No HS:30-39', 'No HS:40-49', 'No HS:50-59',\n       'No HS:60-69', 'No HS:70+', 'Post-grad:18-29', 'Post-grad:30-39',\n       'Post-grad:40-49', 'Post-grad:50-59', 'Post-grad:60-69',\n       'Post-grad:70+', 'Some college:18-29', 'Some college:30-39',\n       'Some college:40-49', 'Some college:50-59', 'Some college:60-69',\n       'Some college:70+'],\n      dtype='object', name='edu:age__factor_dim'))chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))edu:eth__factor_dimPandasIndexPandasIndex(Index(['4-Year College:Black', '4-Year College:Hispanic',\n       '4-Year College:Other', '4-Year College:White', 'HS:Black',\n       'HS:Hispanic', 'HS:Other', 'HS:White', 'No HS:Black', 'No HS:Hispanic',\n       'No HS:Other', 'No HS:White', 'Post-grad:Black', 'Post-grad:Hispanic',\n       'Post-grad:Other', 'Post-grad:White', 'Some college:Black',\n       'Some college:Hispanic', 'Some college:Other', 'Some college:White'],\n      dtype='object', name='edu:eth__factor_dim'))__obs__PandasIndexPandasIndex(Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,     9,\n       ...\n       11030, 11031, 11032, 11033, 11034, 11035, 11036, 11037, 11038, 11039],\n      dtype='int64', name='__obs__', length=11040))Attributes: (4)created_at :2025-04-12T20:47:44.644117+00:00arviz_version :0.21.0modeling_interface :bambimodeling_interface_version :0.15.0\n                      \n                  \n            \n            \n            \n                  \n                  posterior_predictive\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 1GB\nDimensions:         (chain: 4, draw: 4000, __obs__: 11040)\nCoordinates:\n  * chain           (chain) int64 32B 0 1 2 3\n  * draw            (draw) int64 32kB 0 1 2 3 4 5 ... 3995 3996 3997 3998 3999\n  * __obs__         (__obs__) int64 88kB 0 1 2 3 4 ... 11036 11037 11038 11039\nData variables:\n    p(abortion, n)  (chain, draw, __obs__) int64 1GB 14010 5341 ... 3965 12383\nAttributes:\n    modeling_interface:          bambi\n    modeling_interface_version:  0.15.0xarray.DatasetDimensions:chain: 4draw: 4000__obs__: 11040Coordinates: (3)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 ... 3996 3997 3998 3999array([   0,    1,    2, ..., 3997, 3998, 3999], shape=(4000,))__obs__(__obs__)int640 1 2 3 ... 11036 11037 11038 11039array([    0,     1,     2, ..., 11037, 11038, 11039], shape=(11040,))Data variables: (1)p(abortion, n)(chain, draw, __obs__)int6414010 5341 10206 ... 3965 12383array([[[14010,  5341, 10206, ...,  3190,  4185, 10212],\n        [13818,  5891, 10978, ...,  2898,  4236, 11850],\n        [15139,  5688, 11610, ...,  3455,  4647,  7733],\n        ...,\n        [13786,  6913, 11417, ...,  2245,  3821, 12253],\n        [15385,  5551, 10471, ...,  3190,  3536,  9615],\n        [14081,  6341, 12224, ...,  4203,  4355,  9471]],\n\n       [[14323,  5568, 12149, ...,  4218,  5072, 10396],\n        [15068,  5881, 12499, ...,  4237,  4888, 11863],\n        [14444,  5547, 12410, ...,  3426,  4401, 11186],\n        ...,\n        [13676,  5244, 12228, ...,  2131,  3828, 14183],\n        [15352,  6645, 10146, ...,  4090,  2989,  9722],\n        [13889,  5098, 11388, ...,  2574,  4302, 11684]],\n\n       [[14908,  5862, 11154, ...,  3692,  4296, 13474],\n        [14313,  6298, 11726, ...,  2738,  4031, 15852],\n        [14024,  6091, 11225, ...,  4302,  4561,  6608],\n        ...,\n        [13804,  5719, 11322, ...,  2103,  3349, 12018],\n        [14899,  5564, 10774, ...,  3656,  4173, 12654],\n        [13323,  6160, 11889, ...,  1633,  2721,  8324]],\n\n       [[15644,  5447, 10770, ...,  3184,  3407,  9063],\n        [14729,  5971, 11018, ...,  3884,  4072,  9071],\n        [14888,  5955, 11251, ...,  3265,  3849,  7712],\n        ...,\n        [14675,  6143, 11369, ...,  2215,  3372, 11805],\n        [15132,  5472, 11173, ...,  2853,  3942,  9997],\n        [13314,  5965, 11234, ...,  4291,  3965, 12383]]],\n      shape=(4, 4000, 11040))Indexes: (3)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       3990, 3991, 3992, 3993, 3994, 3995, 3996, 3997, 3998, 3999],\n      dtype='int64', name='draw', length=4000))__obs__PandasIndexPandasIndex(Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,     9,\n       ...\n       11030, 11031, 11032, 11033, 11034, 11035, 11036, 11037, 11038, 11039],\n      dtype='int64', name='__obs__', length=11040))Attributes: (2)modeling_interface :bambimodeling_interface_version :0.15.0\n                      \n                  \n            \n            \n            \n                  \n                  sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 1MB\nDimensions:               (chain: 4, draw: 4000)\nCoordinates:\n  * chain                 (chain) int64 32B 0 1 2 3\n  * draw                  (draw) int64 32kB 0 1 2 3 4 ... 3996 3997 3998 3999\nData variables:\n    depth                 (chain, draw) uint64 128kB 5 5 5 5 4 5 ... 5 6 5 5 5 5\n    diverging             (chain, draw) bool 16kB False False ... False False\n    energy                (chain, draw) float64 128kB 2.255e+03 ... 2.265e+03\n    energy_error          (chain, draw) float64 128kB 0.0 0.8447 ... 0.3695\n    index_in_trajectory   (chain, draw) int64 128kB 0 -1 20 10 ... -4 11 21 21\n    logp                  (chain, draw) float64 128kB -2.195e+03 ... -2.192e+03\n    maxdepth_reached      (chain, draw) bool 16kB False False ... False False\n    mean_tree_accept      (chain, draw) float64 128kB 0.003212 ... 0.5059\n    mean_tree_accept_sym  (chain, draw) float64 128kB 0.006398 ... 0.6373\n    n_steps               (chain, draw) uint64 128kB 31 31 31 31 ... 31 31 31 31\n    step_size             (chain, draw) float64 128kB 0.1945 0.1945 ... 0.1749\n    step_size_bar         (chain, draw) float64 128kB 0.1945 0.1945 ... 0.1749\nAttributes:\n    created_at:                  2025-04-12T20:47:44.479410+00:00\n    arviz_version:               0.21.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.15.0xarray.DatasetDimensions:chain: 4draw: 4000Coordinates: (2)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 ... 3996 3997 3998 3999array([   0,    1,    2, ..., 3997, 3998, 3999], shape=(4000,))Data variables: (12)depth(chain, draw)uint645 5 5 5 4 5 5 5 ... 5 5 5 6 5 5 5 5array([[5, 5, 5, ..., 5, 5, 5],\n       [5, 5, 6, ..., 5, 5, 5],\n       [5, 5, 5, ..., 5, 5, 5],\n       [5, 5, 5, ..., 5, 5, 5]], shape=(4, 4000), dtype=uint64)diverging(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]], shape=(4, 4000))energy(chain, draw)float642.255e+03 2.265e+03 ... 2.265e+03array([[2255.117334  , 2264.51911296, 2271.28129   , ..., 2251.66136029,\n        2269.75710454, 2265.80349644],\n       [2237.80104932, 2243.93710343, 2230.0145833 , ..., 2257.31341858,\n        2272.02897877, 2246.81377807],\n       [2252.14394962, 2246.62068636, 2236.1609259 , ..., 2251.75162628,\n        2238.84657812, 2241.87218089],\n       [2264.40923367, 2260.40331607, 2250.3805075 , ..., 2240.2513712 ,\n        2249.09295148, 2264.5290031 ]], shape=(4, 4000))energy_error(chain, draw)float640.0 0.8447 ... 0.01143 0.3695array([[ 0.        ,  0.84470961, -1.4539347 , ..., -0.31018692,\n         0.25727831, -0.62968532],\n       [-0.51218275,  3.05568577, -2.8394705 , ...,  0.02725061,\n        -0.20539784, -0.11696598],\n       [-1.20939903,  0.7575223 , -0.3399562 , ...,  0.11625358,\n         0.0552306 , -0.29775544],\n       [ 0.11760641,  0.01299384,  0.39737546, ...,  1.77924518,\n         0.01143386,  0.36951499]], shape=(4, 4000))index_in_trajectory(chain, draw)int640 -1 20 10 11 23 ... 20 -4 11 21 21array([[  0,  -1,  20, ..., -26, -24, -17],\n       [ -8,   1,  -2, ..., -17, -14, -19],\n       [ -7,   3,   8, ..., -10,   8,  -9],\n       [ 17,  -4,  -4, ...,  11,  21,  21]], shape=(4, 4000))logp(chain, draw)float64-2.195e+03 -2.2e+03 ... -2.192e+03array([[-2195.28683531, -2199.69964304, -2192.48052209, ...,\n        -2190.6539001 , -2204.62821134, -2196.67659335],\n       [-2178.45558846, -2181.68135477, -2174.42955449, ...,\n        -2202.52662822, -2191.97227334, -2190.34640282],\n       [-2174.0529038 , -2177.6868388 , -2176.95514328, ...,\n        -2189.79435862, -2176.25676299, -2192.38894971],\n       [-2200.77698495, -2195.69861311, -2190.99082132, ...,\n        -2179.17716831, -2186.05129393, -2191.79406429]], shape=(4, 4000))maxdepth_reached(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]], shape=(4, 4000))mean_tree_accept(chain, draw)float640.003212 0.01469 ... 0.9123 0.5059array([[0.0032122 , 0.01468574, 0.7121965 , ..., 0.99523485, 0.93958582,\n        0.76843208],\n       [0.4646414 , 0.02347937, 0.35517416, ..., 0.99451639, 0.90787172,\n        0.82817024],\n       [0.97277143, 0.19049798, 0.21162333, ..., 0.91410456, 0.43072501,\n        0.49844013],\n       [0.48641789, 0.93830285, 0.52977933, ..., 0.23108827, 0.91234701,\n        0.50593332]], shape=(4, 4000))mean_tree_accept_sym(chain, draw)float640.006398 0.02101 ... 0.8852 0.6373array([[0.00639806, 0.02100856, 0.26571785, ..., 0.91373449, 0.93793325,\n        0.7677669 ],\n       [0.48529583, 0.03865938, 0.31063868, ..., 0.94220104, 0.92448941,\n        0.8299252 ],\n       [0.87320319, 0.21384995, 0.19321452, ..., 0.94347875, 0.56745197,\n        0.57673148],\n       [0.61583831, 0.95821908, 0.58996206, ..., 0.34443986, 0.88518716,\n        0.63731185]], shape=(4, 4000))n_steps(chain, draw)uint6431 31 31 31 15 ... 63 31 31 31 31array([[ 31,  31,  31, ...,  31,  31,  31],\n       [ 31,  31, 127, ...,  31,  31,  31],\n       [ 31,  31,  63, ...,  31,  31,  31],\n       [ 31,  31,  31, ...,  31,  31,  31]], shape=(4, 4000), dtype=uint64)step_size(chain, draw)float640.1945 0.1945 ... 0.1749 0.1749array([[0.19447538, 0.19447538, 0.19447538, ..., 0.19447538, 0.19447538,\n        0.19447538],\n       [0.17929565, 0.17929565, 0.17929565, ..., 0.17929565, 0.17929565,\n        0.17929565],\n       [0.17100847, 0.17100847, 0.17100847, ..., 0.17100847, 0.17100847,\n        0.17100847],\n       [0.17490276, 0.17490276, 0.17490276, ..., 0.17490276, 0.17490276,\n        0.17490276]], shape=(4, 4000))step_size_bar(chain, draw)float640.1945 0.1945 ... 0.1749 0.1749array([[0.19447538, 0.19447538, 0.19447538, ..., 0.19447538, 0.19447538,\n        0.19447538],\n       [0.17929565, 0.17929565, 0.17929565, ..., 0.17929565, 0.17929565,\n        0.17929565],\n       [0.17100847, 0.17100847, 0.17100847, ..., 0.17100847, 0.17100847,\n        0.17100847],\n       [0.17490276, 0.17490276, 0.17490276, ..., 0.17490276, 0.17490276,\n        0.17490276]], shape=(4, 4000))Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       3990, 3991, 3992, 3993, 3994, 3995, 3996, 3997, 3998, 3999],\n      dtype='int64', name='draw', length=4000))Attributes: (4)created_at :2025-04-12T20:47:44.479410+00:00arviz_version :0.21.0modeling_interface :bambimodeling_interface_version :0.15.0\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 177kB\nDimensions:         (__obs__: 11040)\nCoordinates:\n  * __obs__         (__obs__) int64 88kB 0 1 2 3 4 ... 11036 11037 11038 11039\nData variables:\n    p(abortion, n)  (__obs__) int64 88kB 18 16 13 12 11 11 11 ... 0 0 0 0 0 0 0\nAttributes:\n    created_at:                  2025-04-12T20:47:44.644117+00:00\n    arviz_version:               0.21.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.15.0xarray.DatasetDimensions:__obs__: 11040Coordinates: (1)__obs__(__obs__)int640 1 2 3 ... 11036 11037 11038 11039array([    0,     1,     2, ..., 11037, 11038, 11039], shape=(11040,))Data variables: (1)p(abortion, n)(__obs__)int6418 16 13 12 11 11 ... 0 0 0 0 0 0array([18, 16, 13, ...,  0,  0,  0], shape=(11040,))Indexes: (1)__obs__PandasIndexPandasIndex(Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,     9,\n       ...\n       11030, 11031, 11032, 11033, 11034, 11035, 11036, 11037, 11038, 11039],\n      dtype='int64', name='__obs__', length=11040))Attributes: (4)created_at :2025-04-12T20:47:44.644117+00:00arviz_version :0.21.0modeling_interface :bambimodeling_interface_version :0.15.0\n                      \n                  \n            \n            \n            \n                  \n                  warmup_posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 4MB\nDimensions:                  (chain: 4, draw: 1000, 1|edu:age_offset_dim_0: 30,\n                              1|edu:eth_offset_dim_0: 20,\n                              1|edu_offset_dim_0: 5, 1|eth_offset_dim_0: 4,\n                              1|male:eth_offset_dim_0: 8,\n                              1|state_offset_dim_0: 46)\nCoordinates:\n  * chain                    (chain) int64 32B 0 1 2 3\n  * draw                     (draw) int64 8kB 0 1 2 3 4 ... 995 996 997 998 999\n  * 1|edu:age_offset_dim_0   (1|edu:age_offset_dim_0) int64 240B 0 1 2 ... 28 29\n  * 1|edu:eth_offset_dim_0   (1|edu:eth_offset_dim_0) int64 160B 0 1 2 ... 18 19\n  * 1|edu_offset_dim_0       (1|edu_offset_dim_0) int64 40B 0 1 2 3 4\n  * 1|eth_offset_dim_0       (1|eth_offset_dim_0) int64 32B 0 1 2 3\n  * 1|male:eth_offset_dim_0  (1|male:eth_offset_dim_0) int64 64B 0 1 2 3 4 5 6 7\n  * 1|state_offset_dim_0     (1|state_offset_dim_0) int64 368B 0 1 2 ... 44 45\nData variables: (12/15)\n    1|edu:age_offset         (chain, draw, 1|edu:age_offset_dim_0) float64 960kB ...\n    1|edu:age_sigma          (chain, draw) float64 32kB 2.207 2.207 ... 0.2669\n    1|edu:eth_offset         (chain, draw, 1|edu:eth_offset_dim_0) float64 640kB ...\n    1|edu:eth_sigma          (chain, draw) float64 32kB 3.4 3.4 ... 0.2148\n    1|edu_offset             (chain, draw, 1|edu_offset_dim_0) float64 160kB ...\n    1|edu_sigma              (chain, draw) float64 32kB 1.923 1.923 ... 0.04515\n    ...                       ...\n    1|male:eth_sigma         (chain, draw) float64 32kB 0.5565 0.5565 ... 0.4587\n    1|state_offset           (chain, draw, 1|state_offset_dim_0) float64 1MB ...\n    1|state_sigma            (chain, draw) float64 32kB 0.6829 0.6829 ... 0.2371\n    Intercept                (chain, draw) float64 32kB 1.71 1.71 ... 0.1291\n    male                     (chain, draw) float64 32kB 1.447 1.447 ... 0.4612\n    repvote                  (chain, draw) float64 32kB -0.9648 ... -1.736\nAttributes:\n    created_at:                  2025-04-12T20:47:44.648045+00:00\n    arviz_version:               0.21.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.15.0xarray.DatasetDimensions:chain: 4draw: 10001|edu:age_offset_dim_0: 301|edu:eth_offset_dim_0: 201|edu_offset_dim_0: 51|eth_offset_dim_0: 41|male:eth_offset_dim_0: 81|state_offset_dim_0: 46Coordinates: (8)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999], shape=(1000,))1|edu:age_offset_dim_0(1|edu:age_offset_dim_0)int640 1 2 3 4 5 6 ... 24 25 26 27 28 29array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])1|edu:eth_offset_dim_0(1|edu:eth_offset_dim_0)int640 1 2 3 4 5 6 ... 14 15 16 17 18 19array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19])1|edu_offset_dim_0(1|edu_offset_dim_0)int640 1 2 3 4array([0, 1, 2, 3, 4])1|eth_offset_dim_0(1|eth_offset_dim_0)int640 1 2 3array([0, 1, 2, 3])1|male:eth_offset_dim_0(1|male:eth_offset_dim_0)int640 1 2 3 4 5 6 7array([0, 1, 2, 3, 4, 5, 6, 7])1|state_offset_dim_0(1|state_offset_dim_0)int640 1 2 3 4 5 6 ... 40 41 42 43 44 45array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45])Data variables: (15)1|edu:age_offset(chain, draw, 1|edu:age_offset_dim_0)float640.7128 -0.5591 ... 0.005938 0.3943array([[[ 0.71284134, -0.559058  ,  0.37604117, ...,  0.74880404,\n          0.39094029, -1.70421955],\n        [ 0.71284134, -0.559058  ,  0.37604117, ...,  0.74880404,\n          0.39094029, -1.70421955],\n        [ 0.4123814 , -0.93819344, -0.02554036, ...,  0.32689999,\n          0.13899644, -1.19476971],\n        ...,\n        [ 0.2688731 ,  0.85206963, -0.65962647, ..., -0.70168721,\n          1.43265963,  1.4161706 ],\n        [ 0.80456226, -0.28526599,  0.43157533, ...,  0.06894895,\n          0.9645582 ,  0.22450678],\n        [-0.48957108, -0.70689993,  0.83157602, ..., -1.20101943,\n          0.51189126,  0.70655059]],\n\n       [[-1.21768468,  1.46814066,  0.02411921, ...,  1.82335468,\n         -0.42807295, -1.75143342],\n        [-1.21768468,  1.46814066,  0.02411921, ...,  1.82335468,\n         -0.42807295, -1.75143342],\n        [-1.31805243,  1.32350838, -0.06725975, ...,  1.62623674,\n         -0.61223836, -1.9421984 ],\n...\n        [-0.74162495, -0.8804506 , -1.12681241, ..., -0.9669782 ,\n          0.53939908,  1.27312825],\n        [ 0.0894784 ,  0.17694982, -0.91446162, ...,  0.6731494 ,\n          0.40317466,  0.32936144],\n        [-1.14579979, -0.88363346, -0.96322569, ..., -0.54172027,\n          0.84529024,  1.26946813]],\n\n       [[ 0.29170452, -0.44934613,  0.71507369, ...,  0.61230857,\n         -1.29450008,  1.53568806],\n        [ 0.29170452, -0.44934613,  0.71507369, ...,  0.61230857,\n         -1.29450008,  1.53568806],\n        [ 0.19294842, -0.67933206,  0.5395378 , ...,  0.50094114,\n         -0.65779379,  1.54083684],\n        ...,\n        [ 0.97462607, -0.38596485, -1.27249723, ...,  0.75782858,\n          0.82203813,  1.834766  ],\n        [-0.47406525,  0.02122943,  0.30284372, ..., -0.06532138,\n          0.14637834,  0.67223118],\n        [-0.35694681,  0.72158438, -1.37142036, ..., -0.23166229,\n          0.00593751,  0.39427214]]], shape=(4, 1000, 30))1|edu:age_sigma(chain, draw)float642.207 2.207 1.741 ... 0.2755 0.2669array([[2.20679535, 2.20679535, 1.74138944, ..., 0.19250073, 0.19368443,\n        0.13441164],\n       [0.51136144, 0.51136144, 0.6314906 , ..., 0.30519338, 0.1541938 ,\n        0.17071181],\n       [0.72213574, 0.72213574, 0.48138778, ..., 0.14969559, 0.15653443,\n        0.10686433],\n       [0.68243807, 0.68243807, 0.57525882, ..., 0.20726959, 0.27550811,\n        0.26694358]], shape=(4, 1000))1|edu:eth_offset(chain, draw, 1|edu:eth_offset_dim_0)float641.444 1.782 ... -0.765 1.817array([[[ 1.44358834,  1.78188384, -0.3140895 , ..., -1.70353938,\n         -1.51594326,  0.13619058],\n        [ 1.44358834,  1.78188384, -0.3140895 , ..., -1.70353938,\n         -1.51594326,  0.13619058],\n        [ 1.17256779,  1.37940198,  0.09445394, ..., -1.27980578,\n         -1.10235072, -0.12960883],\n        ...,\n        [ 0.22817186, -2.29355524,  1.21622413, ...,  0.21409064,\n          1.40904082,  2.58940913],\n        [ 1.13859571, -1.02730924, -0.09432704, ...,  0.4263745 ,\n          0.83989848,  2.32297436],\n        [ 1.20247648, -0.21693643, -0.35129568, ...,  0.68524451,\n          0.95222478,  1.48507414]],\n\n       [[-1.09759564,  1.34260381, -0.71388256, ..., -1.21759091,\n          1.95427275,  0.1335923 ],\n        [-1.09759564,  1.34260381, -0.71388256, ..., -1.21759091,\n          1.95427275,  0.1335923 ],\n        [-1.31947569,  1.2015818 , -0.59328092, ..., -1.28976924,\n          1.76558803,  0.04491539],\n...\n        [-1.1444141 , -0.98827778,  0.65455218, ...,  0.37755987,\n         -1.40151706,  1.87303559],\n        [ 1.74927511, -0.3606366 , -0.56677345, ..., -0.11671515,\n          1.10394301,  1.21906373],\n        [-1.00871338, -1.28078011,  1.50015663, ...,  0.59647944,\n         -0.67371608,  0.4514342 ]],\n\n       [[-0.0687315 ,  0.24114353, -1.00602106, ...,  1.14399771,\n         -0.13716406,  0.44994605],\n        [-0.0687315 ,  0.24114353, -1.00602106, ...,  1.14399771,\n         -0.13716406,  0.44994605],\n        [-0.13716768,  0.13189594, -1.23614932, ...,  0.99470055,\n          0.00838824,  0.47072865],\n        ...,\n        [ 0.42372791,  0.21598527,  0.17775972, ..., -0.49084891,\n         -0.12306211,  0.5570425 ],\n        [ 0.00693822, -2.42175288, -0.10464558, ...,  1.13306058,\n          0.40161278,  2.62168841],\n        [-0.80003785, -1.02202843,  0.67516659, ...,  0.37221963,\n         -0.76499699,  1.81682732]]], shape=(4, 1000, 20))1|edu:eth_sigma(chain, draw)float643.4 3.4 2.434 ... 0.1439 0.2148array([[3.39982226, 3.39982226, 2.43409832, ..., 0.1327177 , 0.08950519,\n        0.11771773],\n       [2.94300814, 2.94300814, 3.32859576, ..., 0.17159414, 0.08078945,\n        0.09115935],\n       [0.3416421 , 0.3416421 , 0.42488684, ..., 0.22939412, 0.15340315,\n        0.31419936],\n       [0.23591808, 0.23591808, 0.2232372 , ..., 0.2514691 , 0.14392624,\n        0.21483413]], shape=(4, 1000))1|edu_offset(chain, draw, 1|edu_offset_dim_0)float64-0.6799 -0.6844 ... 2.152 -1.49array([[[-6.79935877e-01, -6.84408955e-01,  1.59365968e+00,\n          7.92140493e-01, -6.18473772e-03],\n        [-6.79935877e-01, -6.84408955e-01,  1.59365968e+00,\n          7.92140493e-01, -6.18473772e-03],\n        [-1.09305519e+00, -3.41392211e-01,  1.10731435e+00,\n          6.43737360e-01, -1.84907701e-01],\n        ...,\n        [ 1.15816502e-01,  3.64117553e-01,  4.78521421e-01,\n         -3.95091176e-01,  1.34470320e-01],\n        [-3.31028337e-01, -5.52540954e-02,  5.24320116e-01,\n         -9.60232694e-01, -1.37144148e-01],\n        [-1.75371893e-01,  2.93605514e-02,  1.44047545e-01,\n         -4.36269895e-01, -7.69172279e-02]],\n\n       [[ 1.61806159e+00,  1.79286740e+00,  1.54573293e+00,\n         -7.01920512e-01,  1.33111758e+00],\n        [ 1.61806159e+00,  1.79286740e+00,  1.54573293e+00,\n         -7.01920512e-01,  1.33111758e+00],\n        [ 1.47970882e+00,  1.53454918e+00,  1.55723103e+00,\n         -6.28465213e-01,  1.22880413e+00],\n...\n        [-5.17364216e-01,  8.76813774e-01, -1.85970157e+00,\n         -7.84438830e-01,  1.24563036e+00],\n        [ 1.10720607e-01,  1.00951612e+00,  2.19785908e-03,\n          3.99383423e-02, -6.91177056e-02],\n        [-1.18266225e+00,  7.25895500e-01, -4.89571991e-02,\n         -8.87131886e-01,  2.07018417e+00]],\n\n       [[ 1.41498026e+00,  8.57629353e-01, -9.99644481e-01,\n          1.64880866e+00, -2.12788773e+00],\n        [ 1.41498026e+00,  8.57629353e-01, -9.99644481e-01,\n          1.64880866e+00, -2.12788773e+00],\n        [ 1.39117169e+00,  7.40003640e-01, -9.02709435e-01,\n          1.50073062e+00, -2.32017906e+00],\n        ...,\n        [ 9.48002620e-01, -5.67396497e-01,  6.39786518e-01,\n         -4.12647871e-01, -2.58774270e+00],\n        [-6.27536039e-01,  2.27203639e+00,  1.72646246e-01,\n          3.30741996e+00, -1.60296639e+00],\n        [-4.72089868e-01,  2.70965145e+00, -2.50499836e-01,\n          2.15224708e+00, -1.49040802e+00]]], shape=(4, 1000, 5))1|edu_sigma(chain, draw)float641.923 1.923 ... 0.02619 0.04515array([[1.92258148, 1.92258148, 2.03860841, ..., 0.79197204, 0.61015705,\n        1.34609022],\n       [0.47593805, 0.47593805, 0.44675043, ..., 0.18640394, 0.22803854,\n        0.30466096],\n       [3.15137817, 3.15137817, 3.049039  , ..., 0.00522084, 0.01586651,\n        0.00860991],\n       [0.12569072, 0.12569072, 0.10984866, ..., 0.0200157 , 0.0261926 ,\n        0.0451503 ]], shape=(4, 1000))1|eth_offset(chain, draw, 1|eth_offset_dim_0)float64-1.164 -0.7458 ... -0.1858 -1.456array([[[-1.16423607, -0.7458115 , -1.71091637,  0.84569769],\n        [-1.16423607, -0.7458115 , -1.71091637,  0.84569769],\n        [-1.6805584 , -1.39265605, -1.39822273,  0.50515946],\n        ...,\n        [-1.78706275, -0.36278758, -0.74613155,  0.44885528],\n        [-1.11690926,  0.00452115,  0.16627439,  0.77984695],\n        [-1.70417429,  0.78811042,  0.71253183,  0.84317838]],\n\n       [[ 0.33530368,  1.23202858, -1.89355075,  0.70002915],\n        [ 0.33530368,  1.23202858, -1.89355075,  0.70002915],\n        [ 0.20728239,  1.13354082, -1.81398765,  0.5699263 ],\n        ...,\n        [-1.39126029, -1.04293742, -0.17549371, -0.72012673],\n        [-1.22717927, -0.97711633,  0.06983505, -1.02376793],\n        [-1.58778742, -0.43288271, -0.04551575, -1.06405512]],\n\n       [[-0.334924  ,  0.76886558, -1.25737908, -1.34129619],\n        [-0.334924  ,  0.76886558, -1.25737908, -1.34129619],\n        [-0.53626431,  1.21687794,  0.27810603, -1.27912712],\n        ...,\n        [-0.75266115, -0.29809349,  0.41913554, -0.1667127 ],\n        [-0.77472939, -0.23572446, -0.08319828,  0.19420046],\n        [-0.42365684,  0.17548603, -0.05446857,  0.44084516]],\n\n       [[ 1.56784721,  0.15929714, -0.1720116 ,  0.88865306],\n        [ 1.56784721,  0.15929714, -0.1720116 ,  0.88865306],\n        [ 1.35437949,  0.19857634,  0.17339459,  0.75178772],\n        ...,\n        [-3.25323958, -0.67517452, -0.08829342, -1.73117769],\n        [-1.0131411 , -1.10757146, -0.15901279, -1.35809749],\n        [-0.56733943, -0.70313804, -0.18576981, -1.45609532]]],\n      shape=(4, 1000, 4))1|eth_sigma(chain, draw)float640.2866 0.2866 ... 0.3137 0.4433array([[0.28658842, 0.28658842, 0.2044168 , ..., 0.31388123, 0.4135409 ,\n        0.4770694 ],\n       [0.85290821, 0.85290821, 0.76836297, ..., 0.31341053, 0.19105631,\n        0.29057462],\n       [1.90209977, 1.90209977, 1.70711999, ..., 0.58543312, 0.79502785,\n        1.02221963],\n       [0.16795377, 0.16795377, 0.15681596, ..., 0.24204904, 0.31368987,\n        0.4433213 ]], shape=(4, 1000))1|male:eth_offset(chain, draw, 1|male:eth_offset_dim_0)float640.6706 -0.3828 ... -0.7867 0.919array([[[ 0.67057163, -0.38282787, -1.92864715, ...,  0.58750663,\n         -1.15339175, -1.57570338],\n        [ 0.67057163, -0.38282787, -1.92864715, ...,  0.58750663,\n         -1.15339175, -1.57570338],\n        [ 0.3198245 , -0.57849822, -1.70308278, ...,  0.70945675,\n         -0.55956457, -1.99412672],\n        ...,\n        [ 0.23617281, -1.12068392,  0.45955454, ...,  0.79103077,\n         -0.9808991 , -0.4587655 ],\n        [ 0.60897805, -0.45938247,  0.18883163, ...,  1.19447145,\n         -0.12878561, -0.68026181],\n        [ 1.51613063, -0.41413169, -0.02970446, ..., -0.22280074,\n         -0.74137946, -0.18064136]],\n\n       [[ 1.08247912,  0.85950671, -0.92743118, ..., -1.53946097,\n         -1.32494537, -0.5559548 ],\n        [ 1.08247912,  0.85950671, -0.92743118, ..., -1.53946097,\n         -1.32494537, -0.5559548 ],\n        [ 0.9987628 ,  0.70358365, -0.77533989, ..., -1.43862678,\n         -1.20037422, -0.44734798],\n...\n        [-0.31883389,  0.23839145, -0.44028795, ...,  1.73303938,\n         -1.45333747, -0.28443378],\n        [ 0.30045055, -0.02002226,  1.69398056, ..., -1.17483091,\n          0.34217228, -0.48570567],\n        [ 0.37034702, -0.34928659, -0.70996217, ...,  1.22835604,\n         -0.79119053, -1.46678738]],\n\n       [[ 0.68243096,  1.35181653,  0.44409381, ...,  0.36092888,\n          0.85691157, -0.69123998],\n        [ 0.68243096,  1.35181653,  0.44409381, ...,  0.36092888,\n          0.85691157, -0.69123998],\n        [ 0.70719832,  1.23008949,  0.23278259, ...,  0.26154587,\n          0.72962884, -0.74513839],\n        ...,\n        [-0.49218514, -1.49285637,  0.01997551, ..., -0.14111163,\n         -0.53292376,  1.32663378],\n        [ 0.23977966,  1.26458124,  0.54516764, ...,  0.74745682,\n          0.24040893,  0.78454126],\n        [-0.33138344,  0.52250237,  0.10679882, ...,  0.76968037,\n         -0.78674429,  0.91898486]]], shape=(4, 1000, 8))1|male:eth_sigma(chain, draw)float640.5565 0.5565 ... 0.3144 0.4587array([[0.55654638, 0.55654638, 0.47173424, ..., 0.14502639, 0.11510072,\n        0.35397165],\n       [5.92096708, 5.92096708, 5.30469133, ..., 0.28376172, 0.44457125,\n        0.25405373],\n       [2.84398156, 2.84398156, 2.69861033, ..., 0.24587144, 0.11621561,\n        0.11500084],\n       [0.49223971, 0.49223971, 0.44182216, ..., 0.28661462, 0.31435972,\n        0.45866093]], shape=(4, 1000))1|state_offset(chain, draw, 1|state_offset_dim_0)float641.328 1.512 ... 0.7377 -0.1718array([[[ 1.32764977e+00,  1.51240388e+00,  7.38744287e-01, ...,\n          1.51712510e+00, -9.55234167e-01, -1.32477381e+00],\n        [ 1.32764977e+00,  1.51240388e+00,  7.38744287e-01, ...,\n          1.51712510e+00, -9.55234167e-01, -1.32477381e+00],\n        [ 1.19815751e+00,  1.07778935e+00,  1.73197696e-01, ...,\n          1.12046093e+00, -4.47833064e-01, -1.01715084e+00],\n        ...,\n        [ 1.52811810e+00,  3.85987874e-01,  6.09365671e-01, ...,\n         -8.03484486e-01,  1.06356820e+00,  1.10305668e+00],\n        [-2.87006599e-01,  4.37404478e-01, -1.97034173e-01, ...,\n         -6.18244363e-01,  1.32706091e+00,  1.28199453e+00],\n        [-6.48598495e-01, -1.98493860e-01,  3.44015036e-01, ...,\n         -6.62393772e-01,  3.05009346e-01,  1.51783908e+00]],\n\n       [[ 3.99929191e-02,  1.14009809e-01, -2.26559882e-03, ...,\n         -1.47190428e+00, -1.85196771e+00,  1.69641207e+00],\n        [ 3.99929191e-02,  1.14009809e-01, -2.26559882e-03, ...,\n         -1.47190428e+00, -1.85196771e+00,  1.69641207e+00],\n        [ 8.51255720e-02, -2.00036421e-02, -2.57014718e-02, ...,\n         -1.37853408e+00, -1.91445673e+00,  1.92665108e+00],\n...\n          5.12683584e-02,  6.59013542e-01,  3.66731795e-01],\n        [-7.50212401e-01,  1.50119085e+00,  5.87311601e-01, ...,\n         -1.31594922e-01,  2.81097129e+00, -5.01790444e-01],\n        [ 1.54852717e+00,  5.60001907e-01,  4.11253345e-01, ...,\n         -3.17406129e-02,  1.38807976e+00,  8.10677570e-01]],\n\n       [[ 5.37297425e-01, -2.48550831e-01,  2.70162548e-01, ...,\n          8.13976596e-01,  1.13454382e+00,  1.39958396e+00],\n        [ 5.37297425e-01, -2.48550831e-01,  2.70162548e-01, ...,\n          8.13976596e-01,  1.13454382e+00,  1.39958396e+00],\n        [ 4.82238542e-01, -8.35327561e-02,  8.23319485e-01, ...,\n          7.18426076e-01,  1.05092443e+00,  1.33024596e+00],\n        ...,\n        [-2.08706331e-01,  5.05488764e-01, -1.25808331e-01, ...,\n          1.45668663e+00,  1.03769998e+00,  5.85423010e-01],\n        [ 2.14996048e+00,  1.90346523e+00, -4.68219970e-01, ...,\n         -2.26125772e+00,  1.62691117e+00, -1.89182626e-01],\n        [ 1.74338111e+00,  1.46272570e+00,  6.77247764e-01, ...,\n         -9.12021602e-01,  7.37728283e-01, -1.71831129e-01]]],\n      shape=(4, 1000, 46))1|state_sigma(chain, draw)float640.6829 0.6829 ... 0.2709 0.2371array([[0.68294453, 0.68294453, 0.47597338, ..., 0.3166898 , 0.26310342,\n        0.23853477],\n       [0.48732248, 0.48732248, 0.56707422, ..., 0.26024814, 0.32277951,\n        0.32279895],\n       [2.05568578, 2.05568578, 1.65932599, ..., 0.30970357, 0.21027966,\n        0.31050671],\n       [2.38824981, 2.38824981, 2.11596641, ..., 0.34811532, 0.27093666,\n        0.23708151]], shape=(4, 1000))Intercept(chain, draw)float641.71 1.71 1.28 ... -0.01795 0.1291array([[ 1.71028959,  1.71028959,  1.28005466, ..., -0.29997418,\n        -0.12755291, -0.20893971],\n       [ 1.74645266,  1.74645266,  1.60297339, ...,  0.11459596,\n         0.07938967,  0.08932437],\n       [ 0.08662674,  0.08662674,  0.13167436, ..., -0.00511883,\n        -0.10603177, -0.28388583],\n       [-1.64414654, -1.64414654, -1.78845943, ..., -0.02493661,\n        -0.01795309,  0.12905368]], shape=(4, 1000))male(chain, draw)float641.447 1.447 1.303 ... 0.419 0.4612array([[ 1.44738757,  1.44738757,  1.3033607 , ...,  0.22013317,\n         0.19386891,  0.18614108],\n       [ 0.24508297,  0.24508297,  0.34051537, ...,  0.35577553,\n         0.55212564,  0.28104772],\n       [-0.7803069 , -0.7803069 , -0.44296594, ...,  0.06652206,\n         0.37866062,  0.26965973],\n       [ 0.25440362,  0.25440362,  0.45240137, ...,  0.22115184,\n         0.41900722,  0.46124262]], shape=(4, 1000))repvote(chain, draw)float64-0.9648 -0.9648 ... -1.35 -1.736array([[-0.96478962, -0.96478962, -1.5002596 , ..., -1.00577532,\n        -0.82047131, -0.3934767 ],\n       [-1.88419423, -1.88419423, -2.05791893, ..., -1.0962935 ,\n        -0.88288692, -1.34401508],\n       [-0.12793358, -0.12793358,  0.54299439, ..., -0.68627744,\n        -1.8192177 , -1.72799597],\n       [ 0.11495385,  0.11495385, -0.06781174, ..., -0.3260194 ,\n        -1.35030456, -1.73640289]], shape=(4, 1000))Indexes: (8)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))1|edu:age_offset_dim_0PandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n      dtype='int64', name='1|edu:age_offset_dim_0'))1|edu:eth_offset_dim_0PandasIndexPandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], dtype='int64', name='1|edu:eth_offset_dim_0'))1|edu_offset_dim_0PandasIndexPandasIndex(Index([0, 1, 2, 3, 4], dtype='int64', name='1|edu_offset_dim_0'))1|eth_offset_dim_0PandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='1|eth_offset_dim_0'))1|male:eth_offset_dim_0PandasIndexPandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7], dtype='int64', name='1|male:eth_offset_dim_0'))1|state_offset_dim_0PandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45],\n      dtype='int64', name='1|state_offset_dim_0'))Attributes: (4)created_at :2025-04-12T20:47:44.648045+00:00arviz_version :0.21.0modeling_interface :bambimodeling_interface_version :0.15.0\n                      \n                  \n            \n            \n            \n                  \n                  warmup_sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 336kB\nDimensions:               (chain: 4, draw: 1000)\nCoordinates:\n  * chain                 (chain) int64 32B 0 1 2 3\n  * draw                  (draw) int64 8kB 0 1 2 3 4 5 ... 995 996 997 998 999\nData variables:\n    depth                 (chain, draw) uint64 32kB 3 0 3 4 3 6 ... 5 5 4 4 5 5\n    diverging             (chain, draw) bool 4kB False True ... False False\n    energy                (chain, draw) float64 32kB 1.163e+04 ... 2.258e+03\n    energy_error          (chain, draw) float64 32kB -12.69 0.0 ... -0.1273\n    index_in_trajectory   (chain, draw) int64 32kB -5 0 4 -10 3 ... -14 0 25 -8\n    logp                  (chain, draw) float64 32kB -8.802e+03 ... -2.197e+03\n    maxdepth_reached      (chain, draw) bool 4kB False False ... False False\n    mean_tree_accept      (chain, draw) float64 32kB 1.0 0.0 ... 0.9372 0.837\n    mean_tree_accept_sym  (chain, draw) float64 32kB 0.2232 0.0 ... 0.8704\n    n_steps               (chain, draw) uint64 32kB 7 1 7 15 7 ... 15 15 31 31\n    step_size             (chain, draw) float64 32kB 1.439 0.2431 ... 0.1749\n    step_size_bar         (chain, draw) float64 32kB 1.439 0.4998 ... 0.1749\nAttributes:\n    created_at:                  2025-04-12T20:47:44.482123+00:00\n    arviz_version:               0.21.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.15.0xarray.DatasetDimensions:chain: 4draw: 1000Coordinates: (2)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999], shape=(1000,))Data variables: (12)depth(chain, draw)uint643 0 3 4 3 6 6 9 ... 6 5 5 5 4 4 5 5array([[3, 0, 3, ..., 5, 5, 5],\n       [2, 0, 2, ..., 5, 5, 5],\n       [4, 0, 3, ..., 5, 5, 5],\n       [3, 0, 3, ..., 4, 5, 5]], shape=(4, 1000), dtype=uint64)diverging(chain, draw)boolFalse True False ... False Falsearray([[False,  True, False, ..., False, False, False],\n       [False,  True, False, ..., False, False, False],\n       [False,  True, False, ..., False, False, False],\n       [False,  True, False, ..., False, False, False]], shape=(4, 1000))energy(chain, draw)float641.163e+04 8.876e+03 ... 2.258e+03array([[11630.39659342,  8875.95400608,  8731.7105997 , ...,\n         2250.83930412,  2243.96656194,  2243.24562894],\n       [15508.82555299, 14799.0247763 , 14647.12376649, ...,\n         2241.45380703,  2266.52538866,  2248.32629247],\n       [19634.60905307,  6136.76898751,  6069.04618878, ...,\n         2254.15195234,  2262.64088572,  2259.71541804],\n       [ 8455.51551647,  5778.68271162,  5770.14323876, ...,\n         2251.5893131 ,  2257.50973536,  2257.71825493]], shape=(4, 1000))energy_error(chain, draw)float64-12.69 0.0 ... 0.0964 -0.1273array([[-1.26874175e+01,  0.00000000e+00, -1.18235842e+02, ...,\n        -1.87099748e-01, -4.61500536e-01,  6.16699716e-01],\n       [-2.19738055e+00,  0.00000000e+00, -1.54099219e+02, ...,\n         2.09381959e-02,  5.69970491e-02, -2.19654431e-01],\n       [-6.50602947e+01,  0.00000000e+00, -5.99272334e+01, ...,\n         1.43495268e-01,  3.57982356e-01, -5.12772453e-03],\n       [-1.16804471e+01,  0.00000000e+00, -9.65278264e+00, ...,\n         0.00000000e+00,  9.64028068e-02, -1.27309524e-01]],\n      shape=(4, 1000))index_in_trajectory(chain, draw)int64-5 0 4 -10 3 -1 ... 10 -14 0 25 -8array([[ -5,   0,   4, ...,  23,  -6,  -9],\n       [ -2,   0,   2, ...,  11,  14,  13],\n       [-11,   0,  -3, ...,  22, -19, -18],\n       [  6,   0,   5, ...,   0,  25,  -8]], shape=(4, 1000))logp(chain, draw)float64-8.802e+03 ... -2.197e+03array([[ -8801.99773353,  -8801.99773353,  -3857.74954779, ...,\n         -2191.20283656,  -2169.4019842 ,  -2195.28683531],\n       [-14742.65778228, -14742.65778228, -11337.47783939, ...,\n         -2187.16423116,  -2198.51860258,  -2183.51992171],\n       [ -6073.03632037,  -6073.03632037,  -4087.85589492, ...,\n         -2195.32950386,  -2199.74915674,  -2196.88935438],\n       [ -5719.7057596 ,  -5719.7057596 ,  -4365.99102415, ...,\n         -2181.86080397,  -2196.81183832,  -2197.07896621]],\n      shape=(4, 1000))maxdepth_reached(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]], shape=(4, 1000))mean_tree_accept(chain, draw)float641.0 0.0 1.0 ... 0.9372 0.837array([[1.        , 0.        , 1.        , ..., 0.94820469, 0.6575515 ,\n        0.38282188],\n       [1.        , 0.        , 1.        , ..., 0.96535511, 0.86948813,\n        0.99835153],\n       [1.        , 0.        , 1.        , ..., 0.54108044, 0.75834751,\n        0.97295798],\n       [0.71632126, 0.        , 1.        , ..., 0.06437551, 0.93719768,\n        0.83699878]], shape=(4, 1000))mean_tree_accept_sym(chain, draw)float640.2232 0.0 ... 0.9671 0.8704array([[2.23182798e-01, 0.00000000e+00, 5.70036852e-05, ...,\n        9.19227881e-01, 6.01457694e-01, 3.93897177e-01],\n       [5.44861695e-01, 0.00000000e+00, 7.41236751e-08, ...,\n        9.78589224e-01, 9.27714113e-01, 9.04122588e-01],\n       [3.76669847e-02, 0.00000000e+00, 6.70633098e-12, ...,\n        5.70272349e-01, 8.56619604e-01, 9.20436092e-01],\n       [1.84135629e-01, 0.00000000e+00, 7.69498300e-02, ...,\n        1.10110476e-01, 9.67128032e-01, 8.70411249e-01]], shape=(4, 1000))n_steps(chain, draw)uint647 1 7 15 7 63 ... 31 42 15 15 31 31array([[ 7,  1,  7, ..., 31, 31, 31],\n       [ 3,  1,  3, ..., 31, 31, 31],\n       [15,  1,  7, ..., 63, 31, 31],\n       [ 7,  1,  7, ..., 15, 31, 31]], shape=(4, 1000), dtype=uint64)step_size(chain, draw)float641.439 0.2431 0.1 ... 0.1628 0.1749array([[1.43855101, 0.24311673, 0.1       , ..., 0.18561769, 0.164043  ,\n        0.19447538],\n       [1.43855101, 0.24311673, 0.1       , ..., 0.12515236, 0.13571602,\n        0.17929565],\n       [1.43855101, 0.24311673, 0.1       , ..., 0.16715003, 0.17333772,\n        0.17100847],\n       [0.85886532, 0.12457457, 0.1       , ..., 0.14649379, 0.16281773,\n        0.17490276]], shape=(4, 1000))step_size_bar(chain, draw)float641.439 0.4998 ... 0.1749 0.1749array([[1.43855101, 0.49983385, 0.42449831, ..., 0.19513229, 0.1949418 ,\n        0.19447538],\n       [1.43855101, 0.49983385, 0.42449831, ..., 0.17979539, 0.17951104,\n        0.17929565],\n       [1.43855101, 0.49983385, 0.42449831, ..., 0.17090807, 0.17092164,\n        0.17100847],\n       [0.85886532, 0.27249125, 0.21675445, ..., 0.17500014, 0.17492909,\n        0.17490276]], shape=(4, 1000))Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Attributes: (4)created_at :2025-04-12T20:47:44.482123+00:00arviz_version :0.21.0modeling_interface :bambimodeling_interface_version :0.15.0\n                      \n                  \n            \n            \n              \n            \n            \n\n\n\n\nMake Adjustments by State\nWe need to adjust each state specific strata by the weight appropriate for each state to post-stratify the estimates.To do so we extract the indices for each strata in our data on a state by state basis. Then we weight the predicted estimate by the appropriate percentage on a state basis and sum them to recover a state level estimate.\n\nestimates = []\nabortion_posterior_base = az.extract(result, num_samples=2000)[\"p\"]\nabortion_posterior_mrp = az.extract(result_adjust, num_samples=2000)[\"p\"]\n\nfor s in new_data[\"state\"].unique():\n    idx = new_data.index[new_data[\"state\"] == s].tolist()\n    predicted_mrp = (\n        ((abortion_posterior_mrp[idx].mean(dim=\"sample\") * new_data.iloc[idx][\"state_percent\"]))\n        .sum()\n        .item()\n    )\n    predicted_mrp_lb = (\n        (\n            (\n                abortion_posterior_mrp[idx].quantile(0.025, dim=\"sample\")\n                * new_data.iloc[idx][\"state_percent\"]\n            )\n        )\n        .sum()\n        .item()\n    )\n    predicted_mrp_ub = (\n        (\n            (\n                abortion_posterior_mrp[idx].quantile(0.975, dim=\"sample\")\n                * new_data.iloc[idx][\"state_percent\"]\n            )\n        )\n        .sum()\n        .item()\n    )\n    predicted = abortion_posterior_base[idx].mean().item()\n    base_lb = abortion_posterior_base[idx].quantile(0.025).item()\n    base_ub = abortion_posterior_base[idx].quantile(0.975).item()\n\n    estimates.append(\n        [s, predicted, base_lb, base_ub, predicted_mrp, predicted_mrp_ub, predicted_mrp_lb]\n    )\n\n\nstate_predicted = pd.DataFrame(\n    estimates,\n    columns=[\"state\", \"base_expected\", \"base_lb\", \"base_ub\", \"mrp_adjusted\", \"mrp_ub\", \"mrp_lb\"],\n)\n\nstate_predicted = (\n    state_predicted.merge(cces_all_df.groupby(\"state\")[[\"abortion\"]].mean().reset_index())\n    .sort_values(\"mrp_adjusted\")\n    .rename({\"abortion\": \"census_share\"}, axis=1)\n)\nstate_predicted.head()\n\n\n\n\n\n\n\n\nstate\nbase_expected\nbase_lb\nbase_ub\nmrp_adjusted\nmrp_ub\nmrp_lb\ncensus_share\n\n\n\n\n9\nOK\n0.287090\n0.132526\n0.462596\n0.326511\n0.416584\n0.245737\n0.321553\n\n\n34\nMS\n0.378908\n0.185678\n0.581087\n0.381865\n0.495032\n0.276797\n0.374640\n\n\n2\nCO\n0.359471\n0.179086\n0.544080\n0.397966\n0.482375\n0.315880\n0.354857\n\n\n24\nME\n0.359866\n0.167999\n0.567097\n0.418089\n0.535638\n0.304914\n0.403636\n\n\n25\nMO\n0.379362\n0.186468\n0.578759\n0.421756\n0.524727\n0.321150\n0.302954\n\n\n\n\n\n\n\nThis was the crucial step and we’ll need to unpack it a little. We have taken (state by state) each demographic strata and reweighted the expected posterior predictive value by the share that strata represents in the national census within that state. We have then aggregated this score within the state to generate a state specific value. This value can now be compared to the expected value derived from our biased data and, more interestingly, the value reported in the national census.\n\n\nPlot the Effect of Adjustment\nThese adjusted estimates can be plotted against the shares ascribed at the state level in the census. These adjustments provide a far better reflection of the national picture than the ones derived from model fitted to the biased sample.\n\nfig, axs = plt.subplots(2, 1, figsize=(17, 10))\naxs = axs.flatten()\nax = axs[0]\nax1 = axs[1]\nax.scatter(\n    state_predicted[\"state\"], state_predicted[\"base_expected\"], color=\"red\", label=\"Biased Sample\"\n)\nax.scatter(\n    state_predicted[\"state\"],\n    state_predicted[\"mrp_adjusted\"],\n    color=\"slateblue\",\n    label=\"Mr P Adjusted\",\n)\nax.scatter(\n    state_predicted[\"state\"],\n    state_predicted[\"census_share\"],\n    color=\"darkgreen\",\n    label=\"Census Aggregates\",\n)\nax.legend()\nax.vlines(\n    state_predicted[\"state\"],\n    state_predicted[\"mrp_adjusted\"],\n    state_predicted[\"census_share\"],\n    color=\"black\",\n    linestyles=\"--\",\n)\n\n\nax1.scatter(\n    state_predicted[\"state\"], state_predicted[\"base_expected\"], color=\"red\", label=\"Biased Sample\"\n)\nax1.scatter(\n    state_predicted[\"state\"],\n    state_predicted[\"mrp_adjusted\"],\n    color=\"slateblue\",\n    label=\"Mr P Adjusted\",\n)\nax1.legend()\n\nax1.vlines(\n    state_predicted[\"state\"], state_predicted[\"base_ub\"], state_predicted[\"base_lb\"], color=\"red\"\n)\nax1.vlines(\n    state_predicted[\"state\"],\n    state_predicted[\"mrp_ub\"],\n    state_predicted[\"mrp_lb\"],\n    color=\"slateblue\",\n)\nax.set_xlabel(\"State\")\nax.set_ylabel(\"Proportion\")\nax1.set_title(\n    \"Comparison of Uncertainty in Biased Predictions and Post-stratified Adjustment\", fontsize=15\n)\nax.set_title(\"Comparison of Post-stratified Adjustment and Census Report\", fontsize=15)\nax1.set_ylabel(\"Proportion\");\n\n\n\n\n\n\n\n\nIn the top plot here we see the state specific MrP estimates for the proportion voting yes, compared to the estimate inferred from the biased sample and estimates from the national census. We can see how the MrP estimates are much closer to those drawn from the national census.\nIn the below plot we’ve shown the estimates from the MrP model and the estimates drawn from the biased sample, but here we’ve shown the uncertainty in the estimation on a state level. Clearly, the MrP adjustments also shrinks the uncertainty in our estimate of vote-share.\nMrP is in this sense a corrective procedure for the avoidance of bias in sample data, where we have strong evidence for adjusting the weight accorded to any stratum of data in our population.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Multilevel Regression and Post-stratification"
    ]
  },
  {
    "objectID": "notebooks/mister_p.html#conclusion",
    "href": "notebooks/mister_p.html#conclusion",
    "title": "Multilevel Regression and Post-stratification",
    "section": "Conclusion",
    "text": "Conclusion\nIn this notebook we have seen how to use bambi to concisely and quickly apply the technique of multilevel regression and post-stratification. We’ve seen how this technique is a natural and compelling extension to regression modelling in general, that incorporates prior knowledge in an interesting and flexible manner.\nThe problems of representation in data are serious. Policy gets made and changed on the basis of anticipated policy effects. Without the ability to control and adjust for non-representative samples, politicians and policy makers risk prioritising initiatives for a vocal majority among the represented in the sample. The question of whether a given sample is “good” or “bad” cannot (at the time) ever be known, so some care needs to be taken when choosing to adjust your model of the data.\nPredictions made from sample data are consequential. It’s not even an exaggeration to say that the fates of entire nations can hang on decisions made from poorly understood sampling procedures. Multilevel regression and post-stratification is an apt tool for making the adjustments required and guiding decisions makers in crucial policy choices, but it should be used carefully.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Multilevel Regression and Post-stratification"
    ]
  },
  {
    "objectID": "notebooks/multi-level_regression.html",
    "href": "notebooks/multi-level_regression.html",
    "title": "Hierarchical Linear Regression (Pigs dataset)",
    "section": "",
    "text": "import arviz as az\nimport bambi as bmb\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport xarray as xr\n\n\naz.style.use(\"arviz-darkgrid\")\nSEED = 7355608\n\nIn this notebook we demo how to perform a Bayesian hierarchical linear regression.\nWe’ll use a multi-level dataset included with statsmodels containing the growth curve of pigs. Since the weight of each pig is measured multiple times, we’ll estimate a model that allows varying intercepts and slopes for time, for each pig.\n\nLoad data\n\n# Load up data from statsmodels\ndata = sm.datasets.get_rdataset(\"dietox\", \"geepack\").data\ndata.describe()\n\n\n\n\n\n\n\n\nPig\nLitter\nStart\nWeight\nFeed\nTime\n\n\n\n\ncount\n861.000000\n861.000000\n861.000000\n861.000000\n789.000000\n861.000000\n\n\nmean\n6238.319396\n12.135889\n25.672701\n60.725769\n80.728645\n6.480836\n\n\nstd\n1323.845928\n7.427252\n3.624336\n24.978881\n52.877736\n3.444735\n\n\nmin\n4601.000000\n1.000000\n15.000000\n15.000000\n3.300003\n1.000000\n\n\n25%\n4857.000000\n5.000000\n23.799990\n38.299990\n32.800003\n3.000000\n\n\n50%\n5866.000000\n11.000000\n25.700000\n59.199980\n74.499996\n6.000000\n\n\n75%\n8050.000000\n20.000000\n27.299990\n81.199950\n123.000000\n9.000000\n\n\nmax\n8442.000000\n24.000000\n35.399990\n117.000000\n224.500000\n12.000000\n\n\n\n\n\n\n\n\n\nModel\n\\[\nY_i = \\beta_{0, i} + \\beta_{1, i} X + \\epsilon_i\n\\]\nwith\n\\[\n\\begin{aligned}\n\\beta_{0, i} &= \\beta_0 + \\alpha_{0, i} \\\\\n\\beta_{1, i} &= \\beta_1 + \\alpha_{1, i}\n\\end{aligned}\n\\]\nwhere \\(\\beta_0\\) and \\(\\beta_1\\) are usual common intercept and slope you find in a linear regression. \\(\\alpha_{0, i}\\) and \\(\\alpha_{1, i}\\) are the group specific components for the pig \\(i\\), influencing the intercept and the slope respectively. Finally \\(\\epsilon_i\\) is the random error we always see in this type of models, assumed to be Gaussian with mean 0. Note that here we use “common” and “group specific” effects to denote what in many fields are known as “fixed” and “random” effects, respectively.\nWe use the formula syntax to specify the model. Previously, you had to specify common and group specific components separately. Now, thanks to formulae, you can specify model formulas just as you would do with R packages like lme4 and brms. In a nutshell, the term on the left side tells Weight is the response variable, Time on the right-hand side tells we include a main effect for the variable Time, and (Time|Pig) indicates we want to allow a each pig to have its own slope for Time as well as its own intercept (which is implicit). If we only wanted different intercepts, we would have written Weight ~ Time + (1 | Pig) and if we wanted slopes specific to each pig without including a pig specific intercept, we would write Weight ~ Time + (0 + Time | Pig).\n\nmodel = bmb.Model(\"Weight ~ Time + (Time|Pig)\", data)\nresults = model.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, Time, 1|Pig_sigma, 1|Pig_offset, Time|Pig_sigma, Time|Pig_offset]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 30 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nWe can print the model to have a summary of the details\n\nmodel\n\n       Formula: Weight ~ Time + (Time|Pig)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 861\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 60.7258, sigma: 133.0346)\n            Time ~ Normal(mu: 0.0, sigma: 18.1283)\n        \n        Group-level effects\n            1|Pig ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 133.0346))\n            Time|Pig ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 18.1283))\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 24.9644)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\nSince we have not specified prior distributions for the parameters in the model, Bambi has chosen sensible defaults for us. We can explore these priors through samples generated from them with a call to Model.plot_priors(), which plots a kernel density estimate for each prior.\n\nmodel.plot_priors();\n\nSampling: [1|Pig_sigma, Intercept, Time, Time|Pig_sigma, sigma]\n\n\n\n\n\n\n\n\n\nNow we are ready to check the results. Using az.plot_trace() we get traceplots that show the values sampled from the posteriors and density estimates that gives us an idea of the shape of the posterior distribution of our parameters.\nIn this case it is very convenient to use compact=True. We tell ArviZ to plot all the group specific posteriors in the same panel which saves space and makes it easier to compare group specific posteriors. Thus, we’ll have a panel with all the group specific intercepts, and another panel with all the group specific slopes. If we used compact=False, which is the default, we would end up with a huge number of panels which would make the plot unreadable.\n\n# Plot posteriors\naz.plot_trace(\n    results,\n    var_names=[\"Intercept\", \"Time\", \"1|Pig\", \"Time|Pig\", \"sigma\"],\n    compact=True,\n);\n\n\n\n\n\n\n\n\nThe same plot could have been generated with less typing by calling\naz.plot_trace(results, var_names=[\"~1|Pig_sigma\", \"~Time|Pig_sigma\"], compact=True);\nwhich uses an alternative notation to pass var_names based on the negation symbol in Python, ~. There we are telling ArviZ to plot all the variables in the InferenceData object results, except from 1|Pig_sigma and Time|Pig_sigma.\nCan’t believe it? Come on, run this notebook on your side and have a try!\nThe plots generated by az.plot_trace() are enough to be confident that the sampler did a good job and conclude about plausible values for the distribution of each parameter in the model. But if we want to, and it is a good idea to do it, we can get umerical summaries for the posteriors with az.summary().\n\naz.summary(results, var_names=[\"Intercept\", \"Time\", \"1|Pig_sigma\", \"Time|Pig_sigma\", \"sigma\"])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n15.750\n0.568\n14.698\n16.868\n0.028\n0.020\n423.0\n415.0\n1.01\n\n\nTime\n6.932\n0.086\n6.765\n7.100\n0.005\n0.004\n247.0\n513.0\n1.01\n\n\n1|Pig_sigma\n4.557\n0.442\n3.750\n5.410\n0.022\n0.015\n424.0\n865.0\n1.00\n\n\nTime|Pig_sigma\n0.664\n0.061\n0.557\n0.780\n0.002\n0.002\n617.0\n1088.0\n1.00\n\n\nsigma\n2.458\n0.067\n2.339\n2.582\n0.001\n0.001\n2677.0\n1453.0\n1.00\n\n\n\n\n\n\n\n\n\nEstimated regression line\nHere we’ll visualize the regression equations we have sampled for a particular pig and then we’ll compare the mean regression equation for all the 72 pigs in the dataset.\nIn the following plot we can see the 2000 linear regressions we have sampled for the pig ‘4601’. The mean regression line is plotted in black and the observed weights for this pig are respresented by the blue dots.\n\n# The ID of the first pig is '4601'\ndata_0 = data[data[\"Pig\"] == 4601][[\"Time\", \"Weight\"]]\ntime = np.array([1, 12])\n\nposterior = az.extract_dataset(results)\nintercept_common = posterior[\"Intercept\"]\nslope_common = posterior[\"Time\"]\n\nintercept_specific_0 = posterior[\"1|Pig\"].sel(Pig__factor_dim=\"4601\")\nslope_specific_0 = posterior[\"Time|Pig\"].sel(Pig__factor_dim=\"4601\")\n\na = (intercept_common + intercept_specific_0)\nb = (slope_common + slope_specific_0)\n\n# make time a DataArray so we can get automatic broadcasting\ntime_xi = xr.DataArray(time)\nplt.plot(time_xi, (a + b * time_xi).T, color=\"C1\", lw=0.1)\nplt.plot(time_xi, a.mean() + b.mean() * time_xi, color=\"black\")\nplt.scatter(data_0[\"Time\"], data_0[\"Weight\"], zorder=2)\nplt.ylabel(\"Weight (kg)\")\nplt.xlabel(\"Time (weeks)\");\n\n/tmp/ipykernel_42686/3021069513.py:5: FutureWarning: extract_dataset has been deprecated, please use extract\n  posterior = az.extract_dataset(results)\n\n\n\n\n\n\n\n\n\nNext, we calculate the mean regression line for each pig and show them together in one plot. Here we clearly see each pig has a different pair of intercept and slope.\n\nintercept_group_specific = posterior[\"1|Pig\"]\nslope_group_specific = posterior[\"Time|Pig\"]\na = intercept_common.mean() + intercept_group_specific.mean(\"sample\")\nb = slope_common.mean() + slope_group_specific.mean(\"sample\")\ntime_xi = xr.DataArray(time)\nplt.plot(time_xi, (a + b * time_xi).T, color=\"C1\", alpha=0.7, lw=0.8)\nplt.ylabel(\"Weight (kg)\")\nplt.xlabel(\"Time (weeks)\");\n\n\n\n\n\n\n\n\nWe can get credible interval plots with ArviZ. Here the line indicates a 94% credible interval calculated as higher posterior density, the thicker line represents the interquartile range and the dot is the median. We can quickly note two things:\n\nThe uncertainty about the intercept estimate is much higher than the uncertainty about the Time slope.\nThe credible interval for Time is far away from 0, so we can be confident there’s a positive relationship the Weight of the pigs and Time.\n\nWe’re not making any great discovering by stating that as time passes we expect the pigs to weight more, but this very simple example can be used as a starting point in applications where the relationship between the variables is not that clear beforehand.\n\naz.plot_forest(\n    results,\n    var_names=[\"Intercept\", \"Time\"],\n    figsize=(8, 2),\n);\n\n\n\n\n\n\n\n\nWe can also plot the posterior overlaid with a region of practical equivalence (ROPE). This region indicates a range of parameter values that are considered to be practically equivalent to some reference value of interest to the particular application, for example 0. In the following plot we can see that all our posterior distributions fall outside of this range.\n\naz.plot_posterior(results, var_names=[\"Intercept\", \"Time\"], ref_val=0, rope=[-1, 1]);\n\n\n\n\n\n\n\n\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sun May 26 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\nbambi      : 0.13.1.dev39+gb7d6a6cb\nnumpy      : 1.26.4\nmatplotlib : 3.8.4\nstatsmodels: 0.14.2\narviz      : 0.18.0\nxarray     : 2024.3.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Hierarchical Linear Regression (Pigs dataset)"
    ]
  },
  {
    "objectID": "notebooks/ordinal_regression.html",
    "href": "notebooks/ordinal_regression.html",
    "title": "Ordinal Regression",
    "section": "",
    "text": "import arviz as az\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\nimport numpy as np\nimport pandas as pd\nimport warnings\n\nimport bambi as bmb\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nIn some scenarios, the response variable is discrete, like a count, and ordered. Common examples of such data come from questionnaires where the respondent is asked to rate a product, service, or experience on a scale. This scale is often referred to as a Likert scale. For example, a five-level Likert scale could be:\nThe result is a set of ordered categories where each category has an associated numeric value (1-5). However, you can’t compute a meaningful difference between the categories. Moreover, the response variable can also be a count where meaningful differences can be computed. For example, a restaurant can be rated on a scale of 1-5 stars where 1 is the worst and 5 is the best. Yes, you can compute the difference between 1 and 2 stars, but it is often treated as ordinal in an applied setting.\nOrdinal data presents three challenges when modelling:\nThus, treating ordered categories as continuous is not appropriate. To this extent, Bambi supports two classes of ordinal regression models: (1) cumulative, and (2) sequential. Below, it is demonstrated how to fit these two models using Bambi to overcome the challenges of ordered category response data.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Ordinal Regression"
    ]
  },
  {
    "objectID": "notebooks/ordinal_regression.html#cumulative-model",
    "href": "notebooks/ordinal_regression.html#cumulative-model",
    "title": "Ordinal Regression",
    "section": "Cumulative model",
    "text": "Cumulative model\nA cumulative model assumes that the observed ordinal variable \\(Y\\) originates from the “categorization” of a latent continuous variable \\(Z\\). To model the categorization process, the model assumes that there are \\(K\\) thresholds (or cutpoints) \\(\\tau_k\\) that partition \\(Z\\) into \\(K+1\\) observable, ordered categories of \\(Y\\). The subscript \\(k\\) in \\(\\tau_k\\) is an index that associates that threshold to a particular category \\(k\\). For example, if the response has three categories such as “disagree”, “neither agree nor disagree”, and “agree”, then there are two thresholds \\(\\tau_1\\) and \\(\\tau_2\\) that partition \\(Z\\) into \\(K+1 = 3\\) categories. Additionally, if we assume \\(Z\\) to have a certain distribution (e.g., Normal) with a cumulative distribution function \\(F\\), the probability of \\(Y\\) being equal to category \\(k\\) is\n\\[P(Y = k) = F(\\tau_k) - F(\\tau_{k-1})\\]\nwhere \\(F(\\tau)\\) is a cumulative probability. For example, suppose we are interested in the probability of each category stated above, and have two thresholds \\(\\tau_1 = -1, \\tau_2 = 1\\) for the three categories. Additionally, if we assume \\(Z\\) to be normally distributed with \\(\\sigma = 1\\) and a cumulative distribution function \\(\\Phi\\) then\n\\[P(Y = 1) = \\Phi(\\tau_1) = \\Phi(-1)\\]\n\\[P(Y = 2) = \\Phi(\\tau_2) - \\Phi(\\tau_1) = \\Phi(1) - \\Phi(-1)\\]\n\\[P(Y = 3) = 1 - \\Phi(\\tau_2) = 1 - \\Phi(1)\\]\nBut how to set the values of the thresholds? By default, Bambi uses a Normal distribution with a grid of evenly spaced \\(\\mu\\) that depends on the number of response levels as the prior for the thresholds. Additionally, since the thresholds need to be orderd, Bambi applies a transformation to the values such that the order is preserved. Furthermore, the model specification for ordinal regression typically transforms the cumulative probabilities using the log-cumulative-odds (logit) transformation. Therefore, the learned parameters for the thresholds \\(\\tau\\) will be logits.\nLastly, as each \\(F(\\tau)\\) implies a cumulative probability for each category, the largest response level always has a cumulative probability of 1. Thus, we effectively do not need a parameter for it due to the law of total probability. For example, for three response values, we only need two thresholds as two thresholds partition \\(Z\\) into \\(K+1\\) categories.\n\nThe moral intuition dataset\nTo illustrate an cumulative ordinal model, we will model data from a series of experiments conducted by philsophers (this example comes from Richard McElreath’s Statistical Rethinking). The experiments aim to collect empirical evidence relevant to debates about moral intuition, the forms of reasoning through which people develop judgments about the moral goodness and badness of actions.\nIn the dataset there are 12 columns and 9930 rows, comprising data for 331 unique individuals. The response we are interested in response, is an integer from 1 to 7 indicating how morally permissible the participant found the action to be taken (or not) in the story. The predictors are as follows:\n\naction: a factor with levels 0 and 1 where 1 indicates that the story contained “harm caused by action is morally worse than equivalent harm caused by omission”.\nintention: a factor with levels 0 and 1 where 1 indicates that the story contained “harm intended as the means to a goal is morally worse than equivalent harm foreseen as the side effect of a goal”.\ncontact: a factor with levels 0 and 1 where 1 indicates that the story contained “using physical contact to cause harm to a victim is morally worse than causing equivalent harm to a victim without using physical contact”.\n\n\ntrolly = pd.read_csv(\"https://raw.githubusercontent.com/rmcelreath/rethinking/master/data/Trolley.csv\", sep=\";\")\ntrolly = trolly[[\"response\", \"action\", \"intention\", \"contact\"]]\ntrolly[\"action\"] = pd.Categorical(trolly[\"action\"], ordered=False)\ntrolly[\"intention\"] = pd.Categorical(trolly[\"intention\"], ordered=False)\ntrolly[\"contact\"] = pd.Categorical(trolly[\"contact\"], ordered=False)\ntrolly[\"response\"] = pd.Categorical(trolly[\"response\"], ordered=True)\n\n\n# 7 ordered categories from 1-7\ntrolly.response.unique()\n\n[4, 3, 5, 2, 1, 7, 6]\nCategories (7, int64): [1 &lt; 2 &lt; 3 &lt; 4 &lt; 5 &lt; 6 &lt; 7]\n\n\n\n\nIntercept only model\nBefore we fit a model with predictors, let’s attempt to recover the parameters of an ordinal model using only the thresholds to get a feel for the cumulative family. Traditionally, in Bambi if we wanted to recover the parameters of the likelihood, we would use an intercept only model and write the formula as response ~ 1 where 1 indicates to include the intercept. However, in the case of ordinal regression, the thresholds “take the place” of the intercept. Thus, we can write the formula as response ~ 0 to indicate that we do not want to include an intercept. To fit a cumulative ordinal model, we pass family=\"cumulative\". To compare the thresholds only model, we compute the empirical log-cumulative-odds of the categories directly from the data below and generate a bar plot of the response probabilities.\n\npr_k = trolly.response.value_counts().sort_index().values / trolly.shape[0]\ncum_pr_k = np.cumsum(pr_k)\nlogit_func = lambda x: np.log(x / (1 - x))\ncum_logit = logit_func(cum_pr_k)\ncum_logit\n\n/tmp/ipykernel_117147/1548491577.py:3: RuntimeWarning: invalid value encountered in log\n  logit_func = lambda x: np.log(x / (1 - x))\n\n\narray([-1.91609116, -1.26660559, -0.718634  ,  0.24778573,  0.88986365,\n        1.76938091,         nan])\n\n\n\nplt.figure(figsize=(7, 3))\nplt.bar(np.arange(1, 8), pr_k)\nplt.ylabel(\"Probability\")\nplt.xlabel(\"Response\")\nplt.title(\"Empirical probability of each response category\");\n\n\n\n\n\n\n\n\n\nmodel = bmb.Model(\"response ~ 0\", data=trolly, family=\"cumulative\")\nidata = model.fit(random_seed=1234)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [threshold]\n\n\n\n\n\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/compile/function/types.py:970: RuntimeWarning: invalid value encountered in add\n  self.vm()\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 8 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nBelow, the components of the model are outputed. Notice how the thresholds are a grid of six values ranging from -2 to 2.\n\nmodel\n\n       Formula: response ~ 0\n        Family: cumulative\n          Link: p = logit\n  Observations: 9930\n        Priors: \n    target = p\n        \n        \n        Auxiliary parameters\n            threshold ~ Normal(mu: [-2.  -1.2 -0.4  0.4  1.2  2. ], sigma: 1.0, transform: ordered)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\n\naz.summary(idata)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nthreshold[0]\n-1.917\n0.030\n-1.969\n-1.859\n0.001\n0.0\n2293.0\n1520.0\n1.0\n\n\nthreshold[1]\n-1.267\n0.024\n-1.314\n-1.223\n0.000\n0.0\n2826.0\n1286.0\n1.0\n\n\nthreshold[2]\n-0.718\n0.021\n-0.759\n-0.679\n0.000\n0.0\n2621.0\n2089.0\n1.0\n\n\nthreshold[3]\n0.248\n0.020\n0.211\n0.286\n0.000\n0.0\n2491.0\n1849.0\n1.0\n\n\nthreshold[4]\n0.891\n0.022\n0.850\n0.931\n0.000\n0.0\n2334.0\n1882.0\n1.0\n\n\nthreshold[5]\n1.771\n0.028\n1.719\n1.822\n0.001\n0.0\n2352.0\n1795.0\n1.0\n\n\n\n\n\n\n\nViewing the summary dataframe, we see a total of six response_threshold coefficients. Why six? Remember, we get the last parameter for free. Since there are seven categories, we only need six cutpoints. The index (using zero based indexing) of the response_threshold indicates the category that the threshold is associated with. Comparing to the empirical log-cumulative-odds computation above, the mean of the posterior distribution for each category is close to the empirical value.\nAs the the log cumulative link is used, we need to apply the inverse of the logit function to transform back to cumulative probabilities. Below, we plot the cumulative probabilities for each category.\n\nexpit_func = lambda x: 1 / (1 + np.exp(-x))\ncumprobs = expit_func(idata.posterior.threshold).mean((\"chain\", \"draw\"))\ncumprobs = np.append(cumprobs, 1)\n\nplt.figure(figsize=(7, 3))\nplt.plot(sorted(trolly.response.unique()), cumprobs, marker='o')\nplt.ylabel(\"Cumulative probability\")\nplt.xlabel(\"Response category\")\nplt.title(\"Cumulative probabilities of response categories\");\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(7, 3))\nfor i in range(6):\n    outcome = expit_func(idata.posterior.threshold).sel(threshold_dim=i).to_numpy().flatten()\n    ax.hist(outcome, bins=15, alpha=0.5, label=f\"Category: {i}\")\nax.set_xlabel(\"Probability\")\nax.set_ylabel(\"Count\")\nax.set_title(\"Cumulative Probability by Category\")\nax.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\");\n\n\n\n\n\n\n\n\nWe can take the derivative of the cumulative probabilities to get the posterior probabilities for each category. Notice how the posterior probabilities in the barplot below are close to the empirical probabilities in barplot above.\n\n# derivative\nddx = np.diff(cumprobs)\nprobs = np.insert(ddx, 0, cumprobs[0])\n\nplt.figure(figsize=(7, 3))\nplt.bar(sorted(trolly.response.unique()), probs)\nplt.ylabel(\"Probability\")\nplt.xlabel(\"Response category\")\nplt.title(\"Posterior Probability of each response category\");\n\n\n\n\n\n\n\n\nNotice in the plots above, the jump in probability from category 3 to 4. Additionally, the estimates of the coefficients is precise for each category. Now that we have an understanding how the cumulative link function is applied to produce ordered cumulative outcomes, we will add predictors to the model.\n\n\nAdding predictors\nIn the cumulative model described above, adding predictors was explicitly left out. In this section, it is described how predictors are added to ordinal cumulative models. When adding predictor variables, what we would like is for any predictor, as it increases, predictions are moved progressively (increased) through the categories in sequence. A linear regression is formed for \\(Z\\) by adding a predictor term \\(\\eta\\)\n\\[\\eta = \\beta_1 x_1 + \\beta_2 x_2 +, . . ., \\beta_n x_n\\]\nNotice how similar this looks to an ordinary linear model. However, there is no intercept or error term. This is because the intercept is replaced by the threshold \\(\\tau\\) and the error term \\(\\epsilon\\) is added seperately to obtain\n\\[Z = \\eta + \\epsilon\\]\nPutting the predictor term together with the thresholds and cumulative distribution function, we obtain the probability of \\(Y\\) being equal to a category \\(k\\) as\n\\[Pr(Y = k | \\eta) = F(\\tau_k - \\eta) - F(\\tau_{k-1} - \\eta)\\]\nThe same predictor term \\(\\eta\\) is subtracted from each threshold because if we decrease the log-cumulative-odds of every outcome value \\(k\\) below the maximum, this shifts probability mass upwards towards higher outcome values. Thus, positive \\(\\beta\\) values correspond to increasing \\(x\\), which is associated with an increase in the mean response \\(Y\\). The parameters to be estimated from the model are the thresholds \\(\\tau\\) and the predictor terms \\(\\eta\\) coefficients.\nTo add predictors for ordinal models in Bambi, we continue to use the formula interface.\n\nmodel = bmb.Model(\n    \"response ~ 0 + action + intention + contact + action:intention + contact:intention\", \n    data=trolly, \n    family=\"cumulative\"\n)\nidata = model.fit(random_seed=1234)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [threshold, action, intention, contact, action:intention, contact:intention]\n\n\n\n\n\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/pytensor/compile/function/types.py:970: RuntimeWarning: invalid value encountered in accumulate\n  self.vm()\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 93 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nIn the summary dataframe below, we only select the predictor variables as the cutpoints are not of interest at the moment.\n\naz.summary(\n    idata, \n    var_names=[\"action\", \"intention\", \"contact\", \n               \"action:intention\", \"contact:intention\"]\n)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\naction[1]\n-0.463\n0.054\n-0.564\n-0.360\n0.001\n0.001\n1418.0\n1691.0\n1.0\n\n\nintention[1]\n-0.274\n0.058\n-0.380\n-0.161\n0.002\n0.001\n1264.0\n1446.0\n1.0\n\n\ncontact[1]\n-0.325\n0.068\n-0.445\n-0.189\n0.002\n0.001\n1203.0\n1310.0\n1.0\n\n\naction:intention[1, 1]\n-0.455\n0.081\n-0.607\n-0.303\n0.002\n0.001\n1505.0\n1625.0\n1.0\n\n\ncontact:intention[1, 1]\n-1.279\n0.099\n-1.473\n-1.109\n0.003\n0.002\n1326.0\n1456.0\n1.0\n\n\n\n\n\n\n\nThe posterior distribution of the slopes are all negative indicating that each of these story features reduces the rating—the acceptability of the story. Below, a forest plot is used to make this insight more clear.\n\naz.plot_forest(\n    idata,\n    combined=True,\n    var_names=[\"action\", \"intention\", \"contact\", \n               \"action:intention\", \"contact:intention\"],\n    figsize=(7, 3),\n    textsize=11\n);\n\n\n\n\n\n\n\n\nAgain, we can plot the cumulative probability of each category. Compared to the same plot above, notice how most of the category probabilities have been shifted to the left. Additionally, there is more uncertainty for category 3, 4, and 5.\n\nfig, ax = plt.subplots(figsize=(7, 3))\nfor i in range(6):\n    outcome = expit_func(idata.posterior.threshold).sel(threshold_dim=i).to_numpy().flatten()\n    ax.hist(outcome, bins=15, alpha=0.5, label=f\"Category: {i}\")\nax.set_xlabel(\"Probability\")\nax.set_ylabel(\"Count\")\nax.set_title(\"Cumulative Probability by Category\")\nax.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\");\n\n\n\n\n\n\n\n\n\n\nPosterior predictive distribution\nTo get a sense of how well the ordinal model fits the data, we can plot samples from the posterior predictive distribution. To plot the samples, a utility function is defined below to assist in the plotting of discrete values.\n\ndef adjust_lightness(color, amount=0.5):\n    import matplotlib.colors as mc\n    import colorsys\n    try:\n        c = mc.cnames[color]\n    except:\n        c = color\n    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n    return colorsys.hls_to_rgb(c[0], c[1] * amount, c[2])\n\ndef plot_ppc_discrete(idata, bins, ax):\n    \n    def add_discrete_bands(x, lower, upper, ax, **kwargs):\n        for i, (l, u) in enumerate(zip(lower, upper)):\n            s = slice(i, i + 2)\n            ax.fill_between(x[s], [l, l], [u, u], **kwargs)\n\n    var_name = list(idata.observed_data.data_vars)[0]\n    y_obs = idata.observed_data[var_name].to_numpy()\n    \n    counts_list = []\n    for draw_values in az.extract(idata, \"posterior_predictive\")[var_name].to_numpy().T:\n        counts, _ = np.histogram(draw_values, bins=bins)\n        counts_list.append(counts)\n    counts_arr = np.stack(counts_list)\n\n    qts_90 = np.quantile(counts_arr, (0.05, 0.95), axis=0)\n    qts_70 = np.quantile(counts_arr, (0.15, 0.85), axis=0)\n    qts_50 = np.quantile(counts_arr, (0.25, 0.75), axis=0)\n    qts_30 = np.quantile(counts_arr, (0.35, 0.65), axis=0)\n    median = np.quantile(counts_arr, 0.5, axis=0)\n\n    colors = [adjust_lightness(\"C0\", x) for x in [1.8, 1.6, 1.4, 1.2, 0.9]]\n\n    add_discrete_bands(bins, qts_90[0], qts_90[1], ax=ax, color=colors[0])\n    add_discrete_bands(bins, qts_70[0], qts_70[1], ax=ax, color=colors[1])\n    add_discrete_bands(bins, qts_50[0], qts_50[1], ax=ax, color=colors[2])\n    add_discrete_bands(bins, qts_30[0], qts_30[1], ax=ax, color=colors[3])\n\n    \n    ax.step(bins[:-1], median, color=colors[4], lw=2, where=\"post\")\n    ax.hist(y_obs, bins=bins, histtype=\"step\", lw=2, color=\"black\", align=\"mid\")\n    handles = [\n        Line2D([], [], label=\"Observed data\", color=\"black\", lw=2),\n        Line2D([], [], label=\"Posterior predictive median\", color=colors[4], lw=2)\n    ]\n    ax.legend(handles=handles)\n    return ax\n\n\nidata_pps = model.predict(idata=idata, kind=\"response\", inplace=False)\n\nbins = np.arange(7)\nfig, ax = plt.subplots(figsize=(7, 3))\nax = plot_ppc_discrete(idata_pps, bins, ax)\nax.set_xlabel(\"Response category\")\nax.set_ylabel(\"Count\")\nax.set_title(\"Cumulative model - Posterior Predictive Distribution\");",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Ordinal Regression"
    ]
  },
  {
    "objectID": "notebooks/ordinal_regression.html#sequential-model",
    "href": "notebooks/ordinal_regression.html#sequential-model",
    "title": "Ordinal Regression",
    "section": "Sequential Model",
    "text": "Sequential Model\nFor some ordinal variables, the assumption of a single underlying continuous variable (as in cumulative models) may not be appropriate. If the response can be understood as being the result of a sequential process, such that a higher response category is possible only after all lower categories are achieved, then a sequential model may be more appropriate than a cumulative model.\nSequential models assume that for every category \\(k\\) there is a latent continuous variable \\(Z\\) that determines the transition between categories \\(k\\) and \\(k+1\\). Now, a threshold \\(\\tau\\) belongs to each latent process. If there are 3 categories, then there are 3 latent processes. If \\(Z_k\\) is greater than the threshold \\(\\tau_k\\), the sequential process continues, otherwise it stops at category \\(k\\). As with the cumulative model, we assume a distribution for \\(Z_k\\) with a cumulative distribution function \\(F\\).\nAs an example, lets suppose we are interested in modeling the probability a boxer makes it to round 3. This implies that the particular boxer in question survived round 1 \\(Z_1 &gt; \\tau_1\\) , 2 \\(Z_2 &gt; \\tau_2\\), and 3 \\(Z_3 &gt; \\tau_3\\). This can be written as\n\\[Pr(Y = 3) = (1 - P(Z_1 \\leq \\tau_1)) * (1 - P(Z_2 \\leq \\tau_2)) * P(Z_3 \\leq \\tau_3)\\]\nAs in the cumulative model above, if we assume \\(Y\\) to be normally distributed with the thresholds \\(\\tau_1 = -1, \\tau_2 = 0, \\tau_3 = 1\\) and cumulative distribution function \\(\\Phi\\) then\n\\[Pr(Y = 3) = (1 - \\Phi(\\tau_1)) * (1 - \\Phi(\\tau_2)) * \\Phi(\\tau_3)\\]\nTo add predictors to this sequential model, we follow the same specification in the Adding Predictors section above. Thus, the sequential model with predictor terms becomes\n\\[P(Y = k) = F(\\tau_k - \\eta) * \\prod_{j=1}^{k-1}{(1 - F(\\tau_j - \\eta))}\\]\nThus, the probability that \\(Y\\) is equal to category \\(k\\) is equal to the probability that it did not fall in one of the former categories \\(1: k-1\\) multiplied by the probability that the sequential process stopped at \\(k\\) rather than continuing past it.\n\nHuman resources attrition dataset\nTo illustrate an sequential model with a stopping ratio link function, we will use data from the IBM human resources employee attrition and performance dataset. The original dataset contains 1470 rows and 35 columns. However, our goal is to model the total working years of employees using age as a predictor. This data lends itself to a sequential model as the response, total working years, is a sequential process. In order to have 10 years of working experience, it is necessarily true that the employee had 9 years of working experience. Additionally, age is choosen as a predictor as it is positively correlated with total working years.\n\nattrition = pd.read_csv(\"data/hr_employee_attrition.tsv.txt\", sep=\"\\t\")\nattrition = attrition[attrition[\"Attrition\"] == \"No\"]\nattrition[\"YearsAtCompany\"] = pd.Categorical(attrition[\"YearsAtCompany\"], ordered=True)\nattrition[[\"YearsAtCompany\", \"Age\"]].head()\n\n\n\n\n\n\n\n\nYearsAtCompany\nAge\n\n\n\n\n1\n10\n49\n\n\n3\n8\n33\n\n\n4\n2\n27\n\n\n5\n7\n32\n\n\n6\n1\n59\n\n\n\n\n\n\n\nBelow, the empirical probabilities of the response categories are computed. Employees are most likely to stay at the company between 1 and 10 years.\n\npr_k = attrition.YearsAtCompany.value_counts().sort_index().values / attrition.shape[0]\n\nplt.figure(figsize=(7, 3))\nplt.bar(np.arange(0, 36), pr_k)\nplt.xlabel(\"Response category\")\nplt.ylabel(\"Probability\")\nplt.title(\"Empirical probability of each response category\");\n\n\n\n\n\n\n\n\n\n\nDefault prior of thresholds\nBefore we fit the sequential model, it’s worth mentioning that the default priors for the thresholds in a sequential model are different than the cumulative model. In the cumulative model, the default prior for the thresholds is a Normal distribution with a grid of evenly spaced \\(\\mu\\) where an ordered transformation is applied to ensure the ordering of the values. However, in the sequential model, the ordering of the thresholds does not matter. Thus, the default prior for the thresholds is a Normal distribution with a zero \\(\\mu\\) vector of length \\(k - 1\\) where \\(k\\) is the number of response levels. Refer to the getting started docs if you need a refresher on priors in Bambi.\nSubsequently, fitting a sequential model is similar to fitting a cumulative model. The only difference is that we pass family=\"sratio\" to the bambi.Model constructor.\n\nsequence_model = bmb.Model(\n    \"YearsAtCompany ~ 0 + TotalWorkingYears\", \n    data=attrition, \n    family=\"sratio\"\n)\nsequence_idata = sequence_model.fit(random_seed=1234)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [threshold, TotalWorkingYears]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 370 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\nsequence_model\n\n       Formula: YearsAtCompany ~ 0 + TotalWorkingYears\n        Family: sratio\n          Link: p = logit\n  Observations: 1233\n        Priors: \n    target = p\n        Common-level effects\n            TotalWorkingYears ~ Normal(mu: 0.0, sigma: 0.3223)\n        \n        Auxiliary parameters\n            threshold ~ Normal(mu: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n             0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma: 1.0)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\n\naz.summary(sequence_idata)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nTotalWorkingYears\n0.127\n0.006\n0.117\n0.138\n0.000\n0.000\n458.0\n719.0\n1.00\n\n\nthreshold[0]\n-2.518\n0.188\n-2.849\n-2.154\n0.004\n0.003\n2139.0\n893.0\n1.00\n\n\nthreshold[1]\n-1.051\n0.106\n-1.253\n-0.861\n0.003\n0.002\n1668.0\n1416.0\n1.00\n\n\nthreshold[2]\n-1.014\n0.117\n-1.237\n-0.806\n0.003\n0.002\n1480.0\n1458.0\n1.00\n\n\nthreshold[3]\n-0.757\n0.113\n-0.973\n-0.554\n0.003\n0.002\n1200.0\n1390.0\n1.00\n\n\nthreshold[4]\n-0.759\n0.122\n-0.978\n-0.521\n0.003\n0.002\n1394.0\n1346.0\n1.00\n\n\nthreshold[5]\n0.250\n0.108\n0.060\n0.458\n0.003\n0.002\n1069.0\n1283.0\n1.00\n\n\nthreshold[6]\n-0.505\n0.148\n-0.790\n-0.228\n0.004\n0.003\n1436.0\n1496.0\n1.00\n\n\nthreshold[7]\n-0.085\n0.138\n-0.338\n0.171\n0.004\n0.003\n1373.0\n1364.0\n1.00\n\n\nthreshold[8]\n0.028\n0.143\n-0.228\n0.305\n0.005\n0.003\n980.0\n1503.0\n1.00\n\n\nthreshold[9]\n0.388\n0.151\n0.101\n0.662\n0.004\n0.003\n1306.0\n1373.0\n1.00\n\n\nthreshold[10]\n1.269\n0.153\n0.948\n1.523\n0.005\n0.004\n801.0\n1164.0\n1.00\n\n\nthreshold[11]\n0.440\n0.218\n0.061\n0.871\n0.006\n0.004\n1224.0\n1354.0\n1.00\n\n\nthreshold[12]\n-0.105\n0.297\n-0.643\n0.454\n0.007\n0.006\n1733.0\n1697.0\n1.00\n\n\nthreshold[13]\n0.517\n0.242\n0.084\n0.992\n0.007\n0.005\n1361.0\n1272.0\n1.00\n\n\nthreshold[14]\n0.390\n0.280\n-0.151\n0.910\n0.007\n0.005\n1730.0\n1358.0\n1.00\n\n\nthreshold[15]\n0.797\n0.264\n0.289\n1.273\n0.007\n0.005\n1632.0\n1534.0\n1.00\n\n\nthreshold[16]\n0.426\n0.335\n-0.193\n1.066\n0.008\n0.006\n1787.0\n1330.0\n1.00\n\n\nthreshold[17]\n0.249\n0.372\n-0.444\n0.944\n0.010\n0.007\n1390.0\n1357.0\n1.00\n\n\nthreshold[18]\n0.794\n0.335\n0.180\n1.423\n0.008\n0.006\n1591.0\n1638.0\n1.00\n\n\nthreshold[19]\n0.793\n0.370\n0.110\n1.499\n0.009\n0.007\n1689.0\n1201.0\n1.00\n\n\nthreshold[20]\n2.201\n0.272\n1.723\n2.725\n0.008\n0.006\n1133.0\n1333.0\n1.00\n\n\nthreshold[21]\n1.842\n0.349\n1.177\n2.449\n0.009\n0.007\n1388.0\n1316.0\n1.00\n\n\nthreshold[22]\n2.444\n0.342\n1.762\n3.046\n0.009\n0.006\n1544.0\n1429.0\n1.00\n\n\nthreshold[23]\n0.030\n0.724\n-1.373\n1.291\n0.013\n0.016\n3182.0\n1571.0\n1.00\n\n\nthreshold[24]\n1.587\n0.538\n0.516\n2.535\n0.013\n0.009\n1902.0\n1429.0\n1.00\n\n\nthreshold[25]\n1.507\n0.597\n0.292\n2.507\n0.011\n0.008\n2841.0\n1557.0\n1.00\n\n\nthreshold[26]\n1.735\n0.632\n0.582\n2.871\n0.012\n0.008\n3066.0\n1220.0\n1.01\n\n\nthreshold[27]\n1.047\n0.749\n-0.325\n2.439\n0.014\n0.010\n2780.0\n1363.0\n1.00\n\n\nthreshold[28]\n1.156\n0.755\n-0.300\n2.467\n0.014\n0.010\n2965.0\n1382.0\n1.00\n\n\nthreshold[29]\n0.543\n0.850\n-1.078\n2.144\n0.016\n0.016\n2806.0\n1360.0\n1.00\n\n\nthreshold[30]\n1.268\n0.788\n-0.124\n2.844\n0.014\n0.012\n3180.0\n1638.0\n1.00\n\n\nthreshold[31]\n1.373\n0.781\n-0.118\n2.799\n0.014\n0.011\n2961.0\n1629.0\n1.00\n\n\nthreshold[32]\n2.653\n0.732\n1.315\n4.084\n0.015\n0.011\n2384.0\n1292.0\n1.00\n\n\nthreshold[33]\n0.861\n0.942\n-0.994\n2.554\n0.014\n0.016\n4345.0\n1567.0\n1.00\n\n\nthreshold[34]\n1.757\n0.892\n0.128\n3.399\n0.018\n0.013\n2441.0\n1202.0\n1.00\n\n\n\n\n\n\n\nThe coefficients are still on the logits scale, so we need to apply the inverse of the logit function to transform back to probabilities. Below, we plot the probabilities for each category.\n\nprobs = expit_func(sequence_idata.posterior.threshold).mean((\"chain\", \"draw\"))\nprobs = np.append(probs, 1)\n\nplt.figure(figsize=(7, 3))\nplt.plot(sorted(attrition.YearsAtCompany.unique()), probs, marker='o')\nplt.ylabel(\"Probability\")\nplt.xlabel(\"Response category\");\n\n\n\n\n\n\n\n\nThis plot can seem confusing at first. Remember, the sequential model is a product of probabilities, i.e., the probability that \\(Y\\) is equal to category \\(k\\) is equal to the probability that it did not fall in one of the former categories \\(1: k-1\\) multiplied by the probability that the sequential process stopped at \\(k\\). Thus, the probability of category 5 is the probability that the sequential process did not fall in 0, 1, 2, 3, or 4 multiplied by the probability that the sequential process stopped at 5. This makes sense why the probability of category 36 is 1. There is no category after 36, so once you multiply all of the previous probabilities with the current category, you get 1. This is the reason for the “cumulative-like” shape of the plot. But if the coefficients were truly cumulative, the probability could not decreases as \\(k\\) increases.\n\n\nPosterior predictive samples\nAgain, using the posterior predictive samples, we can visualize the model fit against the observed data. In the case of the sequential model, the model does an alright job of capturing the observed frequencies of the categories. For pedagogical purposes, this fit is sufficient.\n\nidata_pps = model.predict(idata=idata, kind=\"response\", inplace=False)\n\nbins = np.arange(35)\nfig, ax = plt.subplots(figsize=(7, 3))\nax = plot_ppc_discrete(idata_pps, bins, ax)\nax.set_xlabel(\"Response category\")\nax.set_ylabel(\"Count\")\nax.set_title(\"Sequential model - Posterior Predictive Distribution\");",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Ordinal Regression"
    ]
  },
  {
    "objectID": "notebooks/ordinal_regression.html#summary",
    "href": "notebooks/ordinal_regression.html#summary",
    "title": "Ordinal Regression",
    "section": "Summary",
    "text": "Summary\nThis notebook demonstrated how to fit cumulative and sequential ordinal regression models using Bambi. Cumulative models focus on modeling the cumulative probabilities of an ordinal outcome variable taking on values up to and including a certain category, whereas a sequential model focuses on modeling the probability that an ordinal outcome variable stops at a particular category, rather than continuing to higher categories. To achieve this, both models assume that the reponse variable originates from a categorization of a latent continuous variable \\(Z\\). However, the cumulative model assumes that there are \\(K\\) thresholds \\(\\tau_k\\) that partition \\(Z\\) into \\(K+1\\) observable, ordered categories of \\(Y\\). The sequential model assumes that for every category \\(k\\) there is a latent continuous variable \\(Z\\) that determines the transition between categories \\(k\\) and \\(k+1\\); thus, a threshold \\(\\tau\\) belongs to each latent process.\nCumulative models can be used in situations where the outcome variable is on the Likert scale, and you are interested in understanding the impact of predictors on the probability of reaching or exceeding specific categories. Sequential models are particularly useful when you are interested in understanding the predictors that influence the decision to stop at a specific response level. It’s well-suited for analyzing data where categories represent stages, and the focus is on the transitions between these stages.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sat May 25 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\nbambi     : 0.13.1.dev37+g2a54df76.d20240525\narviz     : 0.18.0\nnumpy     : 1.26.4\nmatplotlib: 3.8.4\npandas    : 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Ordinal Regression"
    ]
  },
  {
    "objectID": "notebooks/plot_comparisons.html",
    "href": "notebooks/plot_comparisons.html",
    "title": "Plot Comparisons",
    "section": "",
    "text": "comparisons and plot_comparisons are a part of Bambi’s sub-package plots that feature a set of functions used to interpret complex regression models. This sub-package is inspired by the R package marginaleffects. These two functions allow the modeler to compare the predictions made by a model for different contrast and covariate values. Below, it is described why comparing predictions is useful in interpreting generalized linear models (GLMs), how this methodology is implemented in Bambi, and how to use comparisons and plot_comparisons. It is assumed that the reader is familiar with the basics of GLMs. If not, refer to the Bambi Basic Building Blocks example.\nDue to the link function in a GLM, there are typically three quantities of interest to interpret:\nOften, with GLMs, \\(\\eta\\) is linear in the parameters, but nonlinear in relation of inputs to the outcome \\(Y\\) due to the link function \\(g\\). Thus, as modelers, we are usually more interested in interpreting (2) and (3). For example, in logistic regression, the linear predictor is on the log-odds scale, but the quantity of interest is on the probability scale. In Poisson regression, the linear predictor is on the log-scale, but the response variable is on the count scale. Referring back to logistic regression, a specified difference in one of the \\(x\\) variables does not correspond to a constant difference in the the probability of the outcome.\nIt is often helpful with GLMs, for the modeler and audience, to have a summary that gives the expected difference in the outcome corresponding to a unit difference in each of the input variables. Thus, the goal of comparisons and plot_comparisons is to provide the modeler with a summary and visualization of the average predicted difference.",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Plot Comparisons"
    ]
  },
  {
    "objectID": "notebooks/plot_comparisons.html#average-predictive-differences",
    "href": "notebooks/plot_comparisons.html#average-predictive-differences",
    "title": "Plot Comparisons",
    "section": "Average Predictive Differences",
    "text": "Average Predictive Differences\nHere, we adopt the notation from Chapter 14.4 of Regression and Other Stories to describe average predictive differences. Assume we have fit a Bambi model predicting an outcome \\(Y\\) based on inputs \\(X\\) and parameters \\(\\theta\\). Consider the following scalar inputs:\n\\[w: \\text{the input of interest}\\] \\[c: \\text{all the other inputs}\\] \\[X = (w, c)\\]\nSuppose for the input of interest, we are interested in comparing \\(w^{\\text{high}}\\) to \\(w^{\\text{low}}\\) (perhaps age = \\(60\\) and \\(40\\) respectively) with all other inputs \\(c\\) held constant. The predictive difference in the outcome changing only \\(w\\) is:\n\\[\\text{average predictive difference} = \\mathbb{E}(y|w^{\\text{high}}, c, \\theta) - \\mathbb{E}(y|w^{\\text{low}}, c, \\theta)\\]\nSelecting the maximum and minimum values of \\(w\\) and averaging over all other inputs \\(c\\) in the data gives you a new “hypothetical” dataset and corresponds to counting all pairs of transitions of \\((w^\\text{low})\\) to \\((w^\\text{high})\\), i.e., differences in \\(w\\) with \\(c\\) held constant. The difference between these two terms is the average predictive difference.\n\nComputing Average Predictive Differences\nThe objective of comparisons and plot_comparisons is to compute the expected difference in the outcome corresponding to three different scenarios for \\(w\\) and \\(c\\) where \\(w\\) is either provided by the user, else a default value is computed by Bambi (described in the default values section). The three scenarios are:\n\nuser provided values for \\(c\\).\na grid of equally spaced and central values for \\(c\\).\nempirical distribution (original data used to fit the model) for \\(c\\).\n\nIn the case of (1) and (2) above, Bambi assembles all pairwise combinations (transitions) of \\(w\\) and \\(c\\) into a new “hypothetical” dataset. In (3), Bambi uses the original \\(c\\), but replaces \\(w\\) with the user provided value or the default value computed by Bambi. In each scenario, predictions are made on the data using the fitted model. Once the predictions are made, comparisons are computed using the posterior samples by taking the difference in the predicted outcome for each pair of transitions. The average of these differences is the average predictive difference.\nThus, the goal of comparisons and plot_comparisons is to provide the modeler with a summary and visualization of the average predictive difference. Below, we demonstrate how to compute and plot average predictive differences with comparisons and plot_comparions using several examples.\n\nimport arviz as az\nimport numpy as np\nimport pandas as pd\nimport warnings\n\nimport bambi as bmb\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Plot Comparisons"
    ]
  },
  {
    "objectID": "notebooks/plot_comparisons.html#zero-inflated-poisson",
    "href": "notebooks/plot_comparisons.html#zero-inflated-poisson",
    "title": "Plot Comparisons",
    "section": "Zero Inflated Poisson",
    "text": "Zero Inflated Poisson\nWe model and predict how many fish are caught by visitors at a state park using survey data. Many visitors catch zero fish, either because they did not fish at all, or because they were unlucky. We would like to explicitly model this bimodal behavior (zero versus non-zero) using a Zero Inflated Poisson model, and to compare how different inputs of interest \\(w\\) and other covariate values \\(c\\) are associated with the number of fish caught. The dataset contains data on 250 groups that went to a state park to fish. Each group was questioned about how many fish they caught (count), how many children were in the group (child), how many people were in the group (persons), if they used a live bait and whether or not they brought a camper to the park (camper).\n\nfish_data = pd.read_csv(\"https://stats.idre.ucla.edu/stat/data/fish.csv\")\ncols = [\"count\", \"livebait\", \"camper\", \"persons\", \"child\"]\nfish_data = fish_data[cols]\nfish_data[\"child\"] = fish_data[\"child\"].astype(int)\nfish_data[\"livebait\"] = pd.Categorical(fish_data[\"livebait\"])\nfish_data[\"camper\"] = pd.Categorical(fish_data[\"camper\"])\n\n\nfish_model = bmb.Model(\n    \"count ~ livebait + camper + persons + child\", \n    fish_data, \n    family=\"zero_inflated_poisson\"\n)\n\nfish_idata = fish_model.fit(\n    draws=1000, \n    target_accept=0.95, \n    random_seed=1234, \n    chains=4\n)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [psi, Intercept, livebait, camper, persons, child]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 45 seconds.\n\n\n\nUser Provided Values\nFirst, an example of scenario 1 (user provided values) is given below. In both plot_comparisons and comparisons, \\(w\\) and \\(c\\) are represented by contrast and conditional, respectively. The modeler has the ability to pass their own values for contrast and conditional by using a dictionary where the key-value pairs are the covariate and value(s) of interest. For example, if we wanted to compare the number of fish caught for \\(4\\) versus \\(1\\) persons conditional on a range of child and livebait values, we would pass the following dictionary in the code block below. By default, for \\(w\\), Bambi compares \\(w^\\text{high}\\) to \\(w^\\text{low}\\). Thus, in this example, \\(w^\\text{high}\\) = 4 and \\(w^\\text{low}\\) = 1. The user is not limited to passing a list for the values. A np.array can also be used. Furthermore, Bambi by default, maps the order of the dict keys to the main, group, and panel of the matplotlib figure. Below, since child is the first key, this is used for the x-axis, and livebait is used for the group (color). If a third key was passed, it would be used for the panel (facet).\n\nfig, ax = bmb.interpret.plot_comparisons(\n    model=fish_model,\n    idata=fish_idata,\n    contrast={\"persons\": [1, 4]},\n    conditional={\"child\": [0, 1, 2], \"livebait\": [0, 1]},\n) \nfig.set_size_inches(7, 3)\n\nDefault computed for unspecified variable: camper\n\n\n\n\n\n\n\n\n\nThe plot above shows that, comparing \\(4\\) to \\(1\\) persons given \\(0\\) children and using livebait, the expected difference is about \\(26\\) fish. When not using livebait, the expected difference decreases substantially to about \\(5\\) fish. Using livebait with a group of people is associated with a much larger expected difference in the number of fish caught.\ncomparisons can be called to view a summary dataframe that includes the term \\(w\\) and its contrast, the specified conditional covariate, and the expected difference in the outcome with the uncertainty interval (by default the 94% highest density interval is computed).\n\nbmb.interpret.comparisons(\n    model=fish_model,\n    idata=fish_idata,\n    contrast={\"persons\": [1, 4]},\n    conditional={\"child\": [0, 1, 2], \"livebait\": [0, 1]},\n) \n\nDefault computed for unspecified variable: camper\n\n\n\n\n\n\n\n\n\nterm\nestimate_type\nvalue\nchild\nlivebait\ncamper\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\npersons\ndiff\n(1, 4)\n0\n0\n1\n4.834472\n2.563472\n7.037150\n\n\n1\npersons\ndiff\n(1, 4)\n0\n1\n1\n26.423188\n23.739729\n29.072748\n\n\n2\npersons\ndiff\n(1, 4)\n1\n0\n1\n1.202003\n0.631629\n1.780965\n\n\n3\npersons\ndiff\n(1, 4)\n1\n1\n1\n6.571943\n5.469275\n7.642248\n\n\n4\npersons\ndiff\n(1, 4)\n2\n0\n1\n0.301384\n0.143676\n0.467608\n\n\n5\npersons\ndiff\n(1, 4)\n2\n1\n1\n1.648417\n1.140415\n2.187190\n\n\n\n\n\n\n\nBut why is camper also in the summary dataframe? This is because in order to peform predictions, Bambi is expecting a value for each covariate used to fit the model. Additionally, with GLM models, average predictive comparisons are conditional in the sense that the estimate depends on the values of all the covariates in the model. Thus, for unspecified covariates, comparisons and plot_comparisons computes a default value (mean or mode based on the data type of the covariate). Thus, \\(c\\) = child, livebait, camper. Each row in the summary dataframe is read as “comparing \\(4\\) to \\(1\\) persons conditional on \\(c\\), the expected difference in the outcome is \\(y\\).”\n\n\nMultiple contrast values\nUsers can also perform comparisons on multiple contrast values. For example, if we wanted to compare the number of fish caught between \\((1, 2)\\), \\((1, 4)\\), and \\((2, 4)\\) persons conditional on a range of values for child and livebait.\n\nmultiple_values = bmb.interpret.comparisons(\n    model=fish_model,\n    idata=fish_idata,\n    contrast={\"persons\": [1, 2, 4]},\n    conditional={\"child\": [0, 1, 2], \"livebait\": [0, 1]}\n)\n\nmultiple_values\n\nDefault computed for unspecified variable: camper\n\n\n\n\n\n\n\n\n\nterm\nestimate_type\nvalue\nchild\nlivebait\ncamper\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\npersons\ndiff\n(1, 2)\n0\n0\n1\n0.527627\n0.295451\n0.775465\n\n\n1\npersons\ndiff\n(1, 2)\n0\n1\n1\n2.883694\n2.605690\n3.177685\n\n\n2\npersons\ndiff\n(1, 2)\n1\n0\n1\n0.131319\n0.067339\n0.195132\n\n\n3\npersons\ndiff\n(1, 2)\n1\n1\n1\n0.717965\n0.592968\n0.857893\n\n\n4\npersons\ndiff\n(1, 2)\n2\n0\n1\n0.032960\n0.015212\n0.052075\n\n\n5\npersons\ndiff\n(1, 2)\n2\n1\n1\n0.180270\n0.123173\n0.244695\n\n\n6\npersons\ndiff\n(1, 4)\n0\n0\n1\n4.834472\n2.563472\n7.037150\n\n\n7\npersons\ndiff\n(1, 4)\n0\n1\n1\n26.423188\n23.739729\n29.072748\n\n\n8\npersons\ndiff\n(1, 4)\n1\n0\n1\n1.202003\n0.631629\n1.780965\n\n\n9\npersons\ndiff\n(1, 4)\n1\n1\n1\n6.571943\n5.469275\n7.642248\n\n\n10\npersons\ndiff\n(1, 4)\n2\n0\n1\n0.301384\n0.143676\n0.467608\n\n\n11\npersons\ndiff\n(1, 4)\n2\n1\n1\n1.648417\n1.140415\n2.187190\n\n\n12\npersons\ndiff\n(2, 4)\n0\n0\n1\n4.306845\n2.267097\n6.280005\n\n\n13\npersons\ndiff\n(2, 4)\n0\n1\n1\n23.539494\n20.990931\n26.240169\n\n\n14\npersons\ndiff\n(2, 4)\n1\n0\n1\n1.070683\n0.565931\n1.585718\n\n\n15\npersons\ndiff\n(2, 4)\n1\n1\n1\n5.853978\n4.858957\n6.848519\n\n\n16\npersons\ndiff\n(2, 4)\n2\n0\n1\n0.268423\n0.124033\n0.412274\n\n\n17\npersons\ndiff\n(2, 4)\n2\n1\n1\n1.468147\n1.024800\n1.960934\n\n\n\n\n\n\n\nNotice how the contrast \\(w\\) varies while the covariates \\(c\\) are held constant. Currently, however, plotting multiple contrast values can be difficult to interpret since the contrast is “abstracted” away onto the y-axis. Thus, it would be difficult to interpret which portion of the plot corresponds to which contrast value. Therefore, it is currently recommended that if you want to plot multiple contrast values, call comparisons directly to obtain the summary dataframe and plot the results yourself.\n\n\nDefault contrast and conditional values\nNow, we move onto scenario 2 described above (grid of equally spaced and central values) in computing average predictive comparisons. You are not required to pass values for contrast and conditional. If you do not pass values, Bambi will compute default values for you. Below, it is described how these default values are computed.\nThe default value for contrast is a centered difference at the mean for a contrast variable with a numeric dtype, and unique levels for a contrast varaible with a categorical dtype. For example, if the modeler is interested in the comparison of a \\(5\\) unit increase in \\(w\\) where \\(w\\) is a numeric variable, Bambi computes the mean and then subtracts and adds \\(2.5\\) units to the mean to obtain a centered difference. By default, if no value is passed for the contrast covariate, Bambi computes a one unit centered difference at the mean. For example, if only contrast=\"persons\" is passed, then \\(\\pm\\) \\(0.5\\) is applied to the mean of persons. If \\(w\\) is a categorical variable, Bambi computes and returns the unique levels. For example, if \\(w\\) has levels [“high scool”, “vocational”, “university”], Bambi computes and returns the unique values of this variable.\nThe default values for conditional are more involved. Currently, by default, if a dict or list is passed to conditional, Bambi uses the ordering (keys if dict and elements if list) to determine which covariate to use as the main, group (color), and panel (facet) variable. This is the same logic used in plot_comparisons described above. Subsequently, the default values used for the conditional covariates depend on their ordering and dtype. Below, the psuedocode used for computing default values covariates passed to conditional is outlined:\nif v == \"main\":\n    \n    if v == numeric:\n        return np.linspace(v.min(), v.max(), 50)\n    elif v == categorical:\n        return np.unique(v)\n\nelif v == \"group\":\n    \n    if v == numeric:\n        return np.quantile(v, np.linspace(0, 1, 5))\n    elif v == categorical:\n        return np.unique(v)\n\nelif v == \"panel\":\n    \n    if v == numeric:\n        return np.quantile(v, np.linspace(0, 1, 5))\n    elif v == categorical:\n        return np.unique(v)\nThus, letting Bambi compute default values for conditional is equivalent to creating a hypothetical “data grid” of new values. Lets say we are interested in comparing the number of fish caught for the contrast livebait conditional on persons and child. This time, lets call comparisons first to gain an understanding of the data generating the plot.\n\ncontrast_df = bmb.interpret.comparisons(\n    model=fish_model,\n    idata=fish_idata,\n    contrast=\"livebait\",\n    conditional=[\"persons\", \"child\"],\n)\n\ncontrast_df.head(10)\n\nDefault computed for contrast variable: livebait\nDefault computed for conditional variable: persons, child\nDefault computed for unspecified variable: camper\n\n\n\n\n\n\n\n\n\nterm\nestimate_type\nvalue\npersons\nchild\ncamper\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\nlivebait\ndiff\n(0, 1)\n1\n0\n1\n1.694646\n1.252803\n2.081207\n\n\n1\nlivebait\ndiff\n(0, 1)\n1\n1\n1\n0.422448\n0.299052\n0.551766\n\n\n2\nlivebait\ndiff\n(0, 1)\n1\n2\n1\n0.106202\n0.063174\n0.152961\n\n\n3\nlivebait\ndiff\n(0, 1)\n1\n3\n1\n0.026923\n0.012752\n0.043035\n\n\n4\nlivebait\ndiff\n(0, 1)\n2\n0\n1\n4.050713\n3.299138\n4.782635\n\n\n5\nlivebait\ndiff\n(0, 1)\n2\n1\n1\n1.009094\n0.755449\n1.249551\n\n\n6\nlivebait\ndiff\n(0, 1)\n2\n2\n1\n0.253511\n0.163468\n0.355214\n\n\n7\nlivebait\ndiff\n(0, 1)\n2\n3\n1\n0.064224\n0.032733\n0.100539\n\n\n8\nlivebait\ndiff\n(0, 1)\n3\n0\n1\n9.701813\n8.391122\n11.084168\n\n\n9\nlivebait\ndiff\n(0, 1)\n3\n1\n1\n2.415233\n1.922802\n2.927737\n\n\n\n\n\n\n\nBefore we talk about the summary output, you should have noticed that messages are being logged to the console. By default interpret is verbose and logs a message to the console if a default value is computed for covariates in conditional and contrast. This is useful because unless the documentation is read, it can be difficult to tell which covariates are having default values computed for. Thus, Bambi has a config file bmb.config[\"INTERPRET_VERBOSE\"] where we can specify whether or not to log messages. By default, this is set to true. To turn off logging, set bmb.config[\"INTERPRET_VERBOSE\"] = False. From here on, we will turn off logging.\nAs livebait was encoded as a categorical dtype, Bambi returned the unique levels of \\([0, 1]\\) for the contrast. persons and child were passed as the first and second element and thus act as the main and group variables, respectively. It can be see from the output above, that an equally spaced grid was used to compute the values for persons, whereas a quantile based grid was used for child. Furthermore, as camper was unspecified, the mode was used as the default value. Lets go ahead and plot the commparisons.\n\nbmb.config[\"INTERPRET_VERBOSE\"] = False\n\n\nfig, ax = bmb.interpret.plot_comparisons(\n    model=fish_model,\n    idata=fish_idata,\n    contrast=\"livebait\",\n    conditional=[\"persons\", \"child\"],\n) \nfig.set_size_inches(7, 3)\n\n\n\n\n\n\n\n\nThe plot shows us that the expected differences in fish caught comparing a group of people who use livebait and no livebait is not only conditional on the number of persons, but also children. However, the plotted comparisons for child = \\(3\\) is difficult to interpret on a single plot. Thus, it can be useful to pass specific group and panel arguments to aid in the interpretation of the plot. Therefore, subplot_kwargs allows the user to manipulate the plotting by passing a dictionary where the keys are {\"main\": ..., \"group\": ..., \"panel\": ...} and the values are the names of the covariates to be plotted. Below, we plot the same comparisons as above, but this time we specify group and panel to both be child.\n\nfig, ax = bmb.interpret.plot_comparisons(\n    model=fish_model,\n    idata=fish_idata,\n    contrast=\"livebait\",\n    conditional=[\"persons\", \"child\"],\n    subplot_kwargs={\"main\": \"persons\", \"group\": \"child\", \"panel\": \"child\"},\n    fig_kwargs={\"figsize\":(12, 3), \"sharey\": True},\n    legend=False\n) \n\n\n\n\n\n\n\n\n\n\nUnit level contrasts\nEvaluating average predictive comparisons at central values for the conditional covariates \\(c\\) can be problematic when the inputs have a large variance since no single central value (mean, median, etc.) is representative of the covariate. This is especially true when \\(c\\) exhibits bi or multimodality. Thus, it may be desireable to use the empirical distribution of \\(c\\) to compute the predictive comparisons, and then average over a specific or set of covariates to obtain the average predictive comparisons. To achieve unit level contrasts, do not pass a parameter into conditional and or specify None.\n\nunit_level = bmb.interpret.comparisons(\n    model=fish_model,\n    idata=fish_idata,\n    contrast=\"livebait\",\n    conditional=None,\n)\n\n# empirical distribution\nprint(unit_level.shape[0] == fish_model.data.shape[0])\nunit_level.head(10)\n\nTrue\n\n\n\n\n\n\n\n\n\nterm\nestimate_type\nvalue\ncamper\nchild\npersons\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\nlivebait\ndiff\n(0, 1)\n0\n0\n1\n0.864408\n0.627063\n1.116105\n\n\n1\nlivebait\ndiff\n(0, 1)\n1\n0\n1\n1.694646\n1.252803\n2.081207\n\n\n2\nlivebait\ndiff\n(0, 1)\n0\n0\n1\n0.864408\n0.627063\n1.116105\n\n\n3\nlivebait\ndiff\n(0, 1)\n1\n1\n2\n1.009094\n0.755449\n1.249551\n\n\n4\nlivebait\ndiff\n(0, 1)\n0\n0\n1\n0.864408\n0.627063\n1.116105\n\n\n5\nlivebait\ndiff\n(0, 1)\n1\n2\n4\n1.453235\n0.964674\n1.956434\n\n\n6\nlivebait\ndiff\n(0, 1)\n0\n1\n3\n1.233247\n0.900295\n1.569891\n\n\n7\nlivebait\ndiff\n(0, 1)\n0\n3\n4\n0.188019\n0.090328\n0.289560\n\n\n8\nlivebait\ndiff\n(0, 1)\n1\n2\n3\n0.606361\n0.390571\n0.818549\n\n\n9\nlivebait\ndiff\n(0, 1)\n1\n0\n1\n1.694646\n1.252803\n2.081207\n\n\n\n\n\n\n\n\n# empirical (observed) data used to fit the model\nfish_model.data.head(10)\n\n\n\n\n\n\n\n\ncount\nlivebait\ncamper\npersons\nchild\n\n\n\n\n0\n0\n0\n0\n1\n0\n\n\n1\n0\n1\n1\n1\n0\n\n\n2\n0\n1\n0\n1\n0\n\n\n3\n0\n1\n1\n2\n1\n\n\n4\n1\n1\n0\n1\n0\n\n\n5\n0\n1\n1\n4\n2\n\n\n6\n0\n1\n0\n3\n1\n\n\n7\n0\n1\n0\n4\n3\n\n\n8\n0\n0\n1\n3\n2\n\n\n9\n1\n1\n1\n1\n0\n\n\n\n\n\n\n\nAbove, unit_level is the comparisons summary dataframe and fish_model.data is the empirical data. Notice how the values for \\(c\\) are identical in both dataframes. However, for \\(w\\), the values are different. However, these unit level contrasts are difficult to interpret as each row corresponds to that unit’s contrast. Therefore, it is useful to average over (marginalize) the estimates to summarize the unit level predictive comparisons.\n\nMarginalizing over covariates\nSince the empirical distrubution is used for computing the average predictive comparisons, the same number of rows (250) is returned as the data used to fit the model. To average over a covariate, use the average_by argument. If True is passed, then comparisons averages over all covariates. Else, if a single or list of covariates are passed, then comparisons averages by the covariates passed.\n\n# marginalize over all covariates\nbmb.interpret.comparisons(\n    model=fish_model,\n    idata=fish_idata,\n    contrast=\"livebait\",\n    conditional=None,\n    average_by=True\n)\n\n\n\n\n\n\n\n\nterm\nestimate_type\nvalue\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\nlivebait\ndiff\n(0, 1)\n3.649691\n2.956185\n4.333621\n\n\n\n\n\n\n\nPassing True to average_by averages over all covariates and is equivalent to taking the mean of the estimate and uncertainty columns. For example:\n\nunit_level = bmb.interpret.comparisons(\n    model=fish_model,\n    idata=fish_idata,\n    contrast=\"livebait\",\n    conditional=None,\n)\n\nunit_level[[\"estimate\", \"lower_3.0%\", \"upper_97.0%\"]].mean()\n\nestimate       3.649691\nlower_3.0%     2.956185\nupper_97.0%    4.333621\ndtype: float64\n\n\n\n\nAverage by subgroups\nAveraging over all covariates may not be desired, and you would rather average by a group or specific covariate. To perform averaging by subgroups, users can pass a single or list of covariates to average_by to average over specific covariates. For example, if we wanted to average by persons:\n\n# average by number of persons\nbmb.interpret.comparisons(\n    model=fish_model,\n    idata=fish_idata,\n    contrast=\"livebait\",\n    conditional=None,\n    average_by=\"persons\"\n)\n\n\n\n\n\n\n\n\nterm\nestimate_type\nvalue\npersons\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\nlivebait\ndiff\n(0, 1)\n1\n1.374203\n1.011290\n1.708711\n\n\n1\nlivebait\ndiff\n(0, 1)\n2\n1.963362\n1.543330\n2.376636\n\n\n2\nlivebait\ndiff\n(0, 1)\n3\n3.701510\n3.056586\n4.357385\n\n\n3\nlivebait\ndiff\n(0, 1)\n4\n7.358662\n6.047642\n8.655654\n\n\n\n\n\n\n\n\n# average by number of persons and camper by passing a list\nbmb.interpret.comparisons(\n    model=fish_model,\n    idata=fish_idata,\n    contrast=\"livebait\",\n    conditional=None,\n    average_by=[\"persons\", \"camper\"]\n)\n\n\n\n\n\n\n\n\nterm\nestimate_type\nvalue\npersons\ncamper\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\nlivebait\ndiff\n(0, 1)\n1\n0\n0.864408\n0.627063\n1.116105\n\n\n1\nlivebait\ndiff\n(0, 1)\n1\n1\n1.694646\n1.252803\n2.081207\n\n\n2\nlivebait\ndiff\n(0, 1)\n2\n0\n1.424598\n1.078389\n1.777154\n\n\n3\nlivebait\ndiff\n(0, 1)\n2\n1\n2.344439\n1.872191\n2.800661\n\n\n4\nlivebait\ndiff\n(0, 1)\n3\n0\n2.429459\n1.871578\n2.964242\n\n\n5\nlivebait\ndiff\n(0, 1)\n3\n1\n4.443540\n3.747840\n5.170052\n\n\n6\nlivebait\ndiff\n(0, 1)\n4\n0\n3.541921\n2.686445\n4.391176\n\n\n7\nlivebait\ndiff\n(0, 1)\n4\n1\n10.739204\n9.024702\n12.432764\n\n\n\n\n\n\n\nIt is still possible to use plot_comparisons when passing an argument to average_by. In the plot below, the empirical distribution is used to compute unit level contrasts for livebait and then averaged over persons to obtain the average predictive comparisons. The plot below is similar to the second plot in this notebook. The differences being that: (1) a pairwise transition grid is defined for the second plot above, whereas the empirical distribution is used in the plot below, and (2) in the plot below, we marginalized over the other covariates in the model (thus the reason for not having a camper or child group and panel, and a reduction in the uncertainty interval).\n\nfig, ax = bmb.interpret.plot_comparisons(\n    model=fish_model,\n    idata=fish_idata,\n    contrast=\"livebait\",\n    conditional=None,\n    average_by=\"persons\"\n)\nfig.set_size_inches(7, 3)",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Plot Comparisons"
    ]
  },
  {
    "objectID": "notebooks/plot_comparisons.html#logistic-regression",
    "href": "notebooks/plot_comparisons.html#logistic-regression",
    "title": "Plot Comparisons",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nTo showcase an additional functionality of comparisons and plot_comparisons, we fit a logistic regression model to the titanic dataset with interaction terms to model the probability of survival. The titanic dataset gives the values of four categorical attributes for each of the 2201 people on board the Titanic when it struck an iceberg and sank. The attributes are social class (first class, second class, third class, crewmember), age, sex (0 = female, 1 = male), and whether or not the person survived (0 = deceased, 1 = survived).\n\ndat = pd.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\", index_col=0)\n\ndat[\"PClass\"] = dat[\"PClass\"].str.replace(\"[st, nd, rd]\", \"\", regex=True)\ndat[\"PClass\"] = dat[\"PClass\"].str.replace(\"*\", \"0\").astype(int)\ndat[\"PClass\"] = dat[\"PClass\"].replace(0, np.nan)\ndat[\"PClass\"] = pd.Categorical(dat[\"PClass\"], ordered=True)\ndat[\"SexCode\"] = pd.Categorical(dat[\"SexCode\"], ordered=True)\n\ndat = dat.dropna(axis=0, how=\"any\")\n\n\ntitanic_model = bmb.Model(\n    \"Survived ~ PClass * SexCode * Age\", \n    data=dat, \n    family=\"bernoulli\"\n)\ntitanic_idata = titanic_model.fit(\n    draws=500, \n    tune=500, \n    target_accept=0.95, \n    random_seed=1234\n)\n\nModeling the probability that Survived==1\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Intercept, PClass, SexCode, PClass:SexCode, Age, PClass:Age, SexCode:Age, PClass:SexCode:Age]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 500 tune and 500 draw iterations (2_000 + 2_000 draws total) took 127 seconds.\n\n\n\nComparison types\ncomparisons and plot_comparisons also allow you to specify the type of comparison to be computed. By default, a difference is used. However, it is also possible to take the ratio where comparisons would then become average predictive ratios. To achieve this, pass \"ratio\" into the argument comparison_type. Using different comparison types offers a way to produce alternative insights; especially when there are interaction terms as the value of one covariate depends on the value of the other covariate.\n\nfig, ax = bmb.interpret.plot_comparisons(\n    model=titanic_model,\n    idata=titanic_idata,\n    contrast={\"PClass\": [1, 3]},\n    conditional=[\"Age\", \"SexCode\"],\n    comparison_type=\"ratio\",\n    subplot_kwargs={\"main\": \"Age\", \"group\": \"SexCode\", \"panel\": \"SexCode\"},\n    fig_kwargs={\"figsize\":(12, 3), \"sharey\": True},\n    legend=False\n\n)\n\n\n\n\n\n\n\n\nThe left panel shows that the ratio of the probability of survival comparing PClass \\(3\\) to \\(1\\) conditional on Age is non-constant. Whereas the right panel shows an approximately constant ratio in the probability of survival comparing PClass \\(3\\) to \\(1\\) conditional on Age.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Thu Aug 15 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\nbambi : 0.14.1.dev12+g64e57423.d20240730\npandas: 2.2.2\nnumpy : 1.26.4\narviz : 0.18.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Plot Comparisons"
    ]
  },
  {
    "objectID": "notebooks/plot_slopes.html",
    "href": "notebooks/plot_slopes.html",
    "title": "Plot Slopes",
    "section": "",
    "text": "Bambi’s sub-package interpret features a set of functions to help interpret complex regression models. The sub-package is inspired by the R package marginaleffects. In this notebook we will discuss two functions slopes and plot_slopes. These two functions allow the modeler to easier interpret slopes, either by a inspecting a summary output or plotting them.\nBelow, it is described why estimating the slope of the prediction function is useful in interpreting generalized linear models (GLMs), how this methodology is implemented in Bambi, and how to use slopes and plot_slopes. It is assumed that the reader is familiar with the basics of GLMs. If not, refer to the Bambi Basic Building Blocks example.",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Plot Slopes"
    ]
  },
  {
    "objectID": "notebooks/plot_slopes.html#interpretation-of-regression-coefficients",
    "href": "notebooks/plot_slopes.html#interpretation-of-regression-coefficients",
    "title": "Plot Slopes",
    "section": "Interpretation of Regression Coefficients",
    "text": "Interpretation of Regression Coefficients\nAssuming we have fit a linear regression model of the form\n\\[y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_k x_k + \\epsilon\\]\nthe “safest” interpretation of the regression coefficients \\(\\beta\\) is as a comparison between two groups of items that differ by \\(1\\) in the relevant predictor variable \\(x_i\\) while being identical in all the other predictors. Formally, the predicted difference between two items \\(i\\) and \\(j\\) that differ by an amount \\(n\\) on predictor \\(k\\), but are identical on all other predictors, the predicted difference is \\(y_i - y_j\\) is \\(\\beta_kx\\), on average.\nHowever, once we move away from a regression model with a Gaussian response, the identity function, and no interaction terms, the interpretation of the coefficients are not as straightforward. For example, in a logistic regression model, the coefficients are on a different scale and are measured in logits (log odds), not probabilities or percentage points. Thus, you cannot interpret the coefficents as a “one unit increase in \\(x_k\\) is associated with an \\(n\\) percentage point decrease in \\(y\\)”. First, the logits must be converted to the probability scale. Secondly, a one unit change in \\(x_k\\) may produce a larger or smaller change in the outcome, depending upon how far away from zero the logits are.\nslopes and plot_slopes, by default, computes quantities of interest on the response scale for GLMs. For example, for a logistic regression model, this is the probability scale, and for a Poisson regression model, this is the count scale.\n\nInterpreting interaction effects\nSpecifying interactions in a regression model is a way of allowing parameters to be conditional on certain aspects of the data. By contrast, for a model with no interactions, the parameters are not conditional and thus, the value of one parameter is not dependent on the value of another covariate. However, once interactions exist, multiple parameters are always in play at the same time. Additionally, interactions can be specified for either categorical, continuous, or both types of covariates. Thus, making the interpretation of the parameters more difficult.\nWith GLMs, every covariate essentially interacts with itself because of the link function. To demonstrate parameters interacting with themselves, consider the mean of a Gaussian linear model with an identity link function\n\\[\\mu = \\alpha + \\beta x\\]\nwhere the rate of change in \\(\\mu\\) with respect to \\(x\\) is just \\(\\beta\\), i.e., the rate of change is constant no matter what the value of \\(x\\) is. But when we consider GLMs with link functions used to map outputs to exponential family distribution parameters, calculating the derivative of the mean output \\(\\mu\\) with respect to the predictor is not as straightforward as in the Gaussian linear model. For example, computing the rate of change in a binomial probability \\(p\\) with respect to \\(x\\)\n\\[p = \\frac{exp(\\alpha + \\beta x)}{1 + exp(\\alpha + \\beta x)}\\]\nAnd taking the derivative of \\(p\\) with respect to \\(x\\) yields\n\\[\\frac{\\partial p}{\\partial x} = \\frac{\\beta}{2(1 + cosh(\\alpha + \\beta x))}\\]\nSince \\(x\\) appears in the derivative, the impact of a change in \\(x\\) depends upon \\(x\\), i.e., an interaction with itself even though no interaction term was specified in the model.Thus, visualizing the rate of change in the mean response with respect to a covariate \\(x\\) becomes a useful tool in interpreting GLMs.",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Plot Slopes"
    ]
  },
  {
    "objectID": "notebooks/plot_slopes.html#average-predictive-slopes",
    "href": "notebooks/plot_slopes.html#average-predictive-slopes",
    "title": "Plot Slopes",
    "section": "Average Predictive Slopes",
    "text": "Average Predictive Slopes\nHere, we adopt the notation from Chapter 14.4 of Regression and Other Stories to first describe average predictive differences which is essential to computing slopes, and then secondly, average predictive slopes. Assume we have fit a Bambi model predicting an outcome \\(Y\\) based on inputs \\(X\\) and parameters \\(\\theta\\). Consider the following scalar inputs:\n\\[w: \\text{the input of interest}\\] \\[c: \\text{all the other inputs}\\] \\[X = (w, c)\\]\nIn contrast to comparisons, for slopes we are interested in comparing \\(w^{\\text{value}}\\) to \\(w^{\\text{value}+\\epsilon}\\) (perhaps age = 60 and 60.0001 respectively) with all other inputs \\(c\\) held constant. The predictive difference in the outcome changing only \\(w\\) is:\n\\[\\text{average predictive difference} = \\mathbb{E}(y|w^{\\text{value}+\\epsilon}, c, \\theta) - \\mathbb{E}(y|w^{\\text{value}}, c, \\theta)\\]\nSelecting \\(w\\) and \\(w^{\\text{value}+\\epsilon}\\) and averaging over all other inputs \\(c\\) in the data gives you a new “hypothetical” dataset and corresponds to counting all pairs of transitions of \\((w^\\text{value})\\) to \\((w^{\\text{value}+\\epsilon})\\), i.e., differences in \\(w\\) with \\(c\\) held constant. The difference between these two terms is the average predictive difference.\nHowever, to obtain the slope estimate, we need to take the above formula and divide by \\(\\epsilon\\) to obtain the average predictive slope:\n\\[\\text{average predictive slope} = \\frac{\\mathbb{E}(y|w^{\\text{value}+\\epsilon}, c, \\theta) - \\mathbb{E}(y|w^{\\text{value}}, c, \\theta)}{\\epsilon}\\]",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Plot Slopes"
    ]
  },
  {
    "objectID": "notebooks/plot_slopes.html#computing-slopes",
    "href": "notebooks/plot_slopes.html#computing-slopes",
    "title": "Plot Slopes",
    "section": "Computing Slopes",
    "text": "Computing Slopes\nThe objective of slopes and plot_slopes is to compute the rate of change (slope) in the mean of the response \\(y\\) with respect to a small change \\(\\epsilon\\) in the predictor \\(x\\) conditional on other covariates \\(c\\) specified in the model. \\(w\\) is specified by the user and the original value is either provided by the user, else a default value (the mean) is computed by Bambi. The values for the other covariates \\(c\\) specified in the model can be determined under the following three scenarios:\n\nuser provided values\na grid of equally spaced and central values\nempirical distribution (original data used to fit the model)\n\nIn the case of (1) and (2) above, Bambi assembles all pairwise combinations (transitions) of \\(w\\) and \\(c\\) into a new “hypothetical” dataset. In (3), Bambi uses the original \\(c\\), and adds a small amount \\(\\epsilon\\) to each unit of observation’s \\(w\\). In each scenario, predictions are made on the data using the fitted model. Once the predictions are made, comparisons are computed using the posterior samples by taking the difference in the predicted outcome for each pair of transitions and dividing by \\(\\epsilon\\). The average of these slopes is the average predictive slopes.\nFor variables \\(w\\) with a string or categorical data type, the comparisons function is called to compute the expected difference in group means. Please refer to the comparisons documentation for more details.\nBelow, we present several examples showing how to use Bambi to perform these computations for us, and to return either a summary dataframe, or a visualization of the results.\n\nimport arviz as az\nimport numpy as np\nimport pandas as pd\nimport warnings\n\nimport bambi as bmb\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\n\n%load_ext autoreload\n%autoreload 2",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Plot Slopes"
    ]
  },
  {
    "objectID": "notebooks/plot_slopes.html#logistic-regression",
    "href": "notebooks/plot_slopes.html#logistic-regression",
    "title": "Plot Slopes",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nTo demonstrate slopes and plot_slopes, we will use the well switching dataset to model the probability a household in Bangladesh switches water wells. The data are for an area of Arahazar Upazila, Bangladesh. The researchers labelled each well with its level of arsenic and an indication of whether the well was “safe” or “unsafe”. Those using unsafe wells were encouraged to switch. After several years, it was determined whether each household using an unsafe well had changed its well. The data contains \\(3020\\) observations on the following five variables:\n\nswitch: a factor with levels no and yes indicating whether the household switched to a new well\narsenic: the level of arsenic in the old well (measured in micrograms per liter)\ndist: the distance to the nearest safe well (measured in meters)\nassoc: a factor with levels no and yes indicating whether the household is a member of an arsenic education group\neduc: years of education of the household head\n\nFirst, a logistic regression model with no interactions is fit to the data. Subsequently, to demonstrate the benefits of plot_slopes in interpreting interactions, we will fit a logistic regression model with an interaction term.\n\ndata = pd.read_csv(\"http://www.stat.columbia.edu/~gelman/arm/examples/arsenic/wells.dat\", sep=\" \")\ndata[\"switch\"] = pd.Categorical(data[\"switch\"])\ndata[\"dist100\"] = data[\"dist\"] / 100\ndata[\"educ4\"] = data[\"educ\"] / 4\ndata.head()\n\n\n\n\n\n\n\n\nswitch\narsenic\ndist\nassoc\neduc\ndist100\neduc4\n\n\n\n\n1\n1\n2.36\n16.826000\n0\n0\n0.16826\n0.0\n\n\n2\n1\n0.71\n47.321999\n0\n0\n0.47322\n0.0\n\n\n3\n0\n2.07\n20.966999\n0\n10\n0.20967\n2.5\n\n\n4\n1\n1.15\n21.486000\n0\n12\n0.21486\n3.0\n\n\n5\n1\n1.10\n40.874001\n1\n14\n0.40874\n3.5\n\n\n\n\n\n\n\n\nwell_model = bmb.Model(\n    \"switch ~ dist100 + arsenic + educ4\",\n    data,\n    family=\"bernoulli\"\n)\n\nwell_idata = well_model.fit(\n    draws=1000, \n    target_accept=0.95, \n    random_seed=1234, \n    chains=4\n)\n\nModeling the probability that switch==0\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 2 jobs)\nNUTS: [Intercept, dist100, arsenic, educ4]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 10 seconds.\n\n\n\nUser provided values\nFirst, an example of scenario 1 (user provided values) is given below. In both plot_slopes and slopes, \\(w\\) and \\(c\\) are represented by wrt (with respect to) and conditional, respectively. The modeler has the ability to pass their own values for wrt and conditional by using a dictionary where the key-value pairs are the covariate and value(s) of interest.\nFor example, if we wanted to compute the slope of the probability of switching wells for a typical arsenic value of \\(1.3\\) conditional on a range of dist and educ values, we would pass the following dictionary in the code block below. By default, for \\(w\\), Bambi compares \\(w^\\text{value}\\) to \\(w^{\\text{value} + \\epsilon}\\) where \\(\\epsilon =\\) 1e-4. However, the value for \\(\\epsilon\\) can be changed by passing a value to the argument eps.\nThus, in this example, \\(w^\\text{value} = 1.3\\) and \\(w^{\\text{value} + \\epsilon} = 1.3001\\). The user is not limited to passing a list for the values. A np.array can also be used. Furthermore, Bambi by default, maps the order of the dict keys to the main, group, and panel of the matplotlib figure. Below, since dist100 is the first key, this is used for the x-axis, and educ4 is used for the group (color). If a third key was passed, it would be used for the panel (facet).\n\nfig, ax = bmb.interpret.plot_slopes(\n    well_model,\n    well_idata,\n    wrt={\"arsenic\": 1.3},\n    conditional={\"dist100\": [0.20, 0.50, 0.80], \"educ4\": [1.00, 1.20, 2.00]},\n)\nfig.set_size_inches(7, 3)\nfig.axes[0].set_ylabel(\"Slope of Well Switching Probability\");\n\n\n\n\n\n\n\n\nThe plot above shows that, for example, conditional on dist100 \\(= 0.2\\) and educ4 \\(= 1.0\\) a unit increase in arsenic is associated with households being \\(11\\)% less likely to switch wells. Notice that even though we fit a logistic regression model where the coefficients are on the log-odds scale, the slopes function returns the slope on the probability scale. Thus, we can interpret the y-axis (slope) as the expected change in the probability of switching wells for a unit increase in arsenic conditional on the specified covariates.\nslopes can be called directly to view a summary dataframe that includes the term name, estimate type (discussed in detail in the interpreting coefficients as an elasticity section), values \\(w\\) used to compute the estimate, the specified conditional covariates \\(c\\), and the expected slope of the outcome with the uncertainty interval (by default the \\(94\\)% highest density interval is computed).\n\nbmb.interpret.slopes(\n    well_model,\n    well_idata,\n    wrt={\"arsenic\": 1.5},\n    conditional={\n        \"dist100\": [0.20, 0.50, 0.80], \n        \"educ4\": [1.00, 1.20, 2.00]\n        }\n)\n\n\n\n\n\n\n\n\nterm\nestimate_type\nvalue\ndist100\neduc4\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\narsenic\ndydx\n(1.5, 1.5001)\n0.2\n1.0\n-0.110797\n-0.128775\n-0.092806\n\n\n1\narsenic\ndydx\n(1.5, 1.5001)\n0.2\n1.2\n-0.109867\n-0.126725\n-0.091065\n\n\n2\narsenic\ndydx\n(1.5, 1.5001)\n0.2\n2.0\n-0.105618\n-0.122685\n-0.088383\n\n\n3\narsenic\ndydx\n(1.5, 1.5001)\n0.5\n1.0\n-0.116087\n-0.134965\n-0.096843\n\n\n4\narsenic\ndydx\n(1.5, 1.5001)\n0.5\n1.2\n-0.115632\n-0.134562\n-0.096543\n\n\n5\narsenic\ndydx\n(1.5, 1.5001)\n0.5\n2.0\n-0.113140\n-0.130448\n-0.093209\n\n\n6\narsenic\ndydx\n(1.5, 1.5001)\n0.8\n1.0\n-0.117262\n-0.136850\n-0.098549\n\n\n7\narsenic\ndydx\n(1.5, 1.5001)\n0.8\n1.2\n-0.117347\n-0.136475\n-0.098044\n\n\n8\narsenic\ndydx\n(1.5, 1.5001)\n0.8\n2.0\n-0.116957\n-0.135079\n-0.096476\n\n\n\n\n\n\n\nSince all covariates used to fit the model were also specified to compute the slopes, no default value is used for unspecified covariates. A default value is computed for the unspecified covariates because in order to peform predictions, Bambi is expecting a value for each covariate used to fit the model. Additionally, with GLM models, average predictive slopes are conditional in the sense that the estimate depends on the values of all the covariates in the model. Thus, for unspecified covariates, slopes and plot_slopes computes a default value (mean or mode based on the data type of the covariate). Each row in the summary dataframe is read as “the slope (or rate of change) of the probability of switching wells with respect to a small change in \\(w\\) conditional on \\(c\\) is \\(y\\)”.\n\n\nMultiple slope values\nUsers can also compute slopes on multiple values for wrt. For example, if we want to compute the slope of \\(y\\) with respect to arsenic \\(= 1.5\\), \\(2.0\\), and \\(2.5\\), simply pass a list or numpy array as the dictionary values for wrt. Keeping the conditional covariate and values the same, the following slope estimates are computed below.\n\nmultiple_values = bmb.interpret.slopes(\n    well_model,\n    well_idata,\n    wrt={\"arsenic\": [1.5, 2.0, 2.5]},\n    conditional={\n        \"dist100\": [0.20, 0.50, 0.80], \n        \"educ4\": [1.00, 1.20, 2.00]\n        }\n)\n\nmultiple_values.head(6)\n\n\n\n\n\n\n\n\nterm\nestimate_type\nvalue\ndist100\neduc4\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\narsenic\ndydx\n(1.5, 1.5001)\n0.2\n1.0\n-0.110797\n-0.128775\n-0.092806\n\n\n1\narsenic\ndydx\n(2.0, 2.0001)\n0.2\n1.0\n-0.109867\n-0.126725\n-0.091065\n\n\n2\narsenic\ndydx\n(2.5, 2.5001)\n0.2\n1.0\n-0.105618\n-0.122685\n-0.088383\n\n\n3\narsenic\ndydx\n(1.5, 1.5001)\n0.2\n1.2\n-0.116087\n-0.134965\n-0.096843\n\n\n4\narsenic\ndydx\n(2.0, 2.0001)\n0.2\n1.2\n-0.115632\n-0.134562\n-0.096543\n\n\n5\narsenic\ndydx\n(2.5, 2.5001)\n0.2\n1.2\n-0.113140\n-0.130448\n-0.093209\n\n\n\n\n\n\n\nThe output above is essentially the same as the summary dataframe when we only passed one value to wrt. However, now each element (value) in the list gets a small amount \\(\\epsilon\\) added to it, and the slope is calculated for each of these values.\n\n\nConditional slopes\nAs stated in the interpreting interaction effects section, interpreting coefficients of multiple interaction terms can be difficult and cumbersome. Thus, plot_slopes provides an effective way to visualize the conditional slopes of the interaction effects. Below, we will use the same well switching dataset, but with interaction terms. Specifically, one interaction is added between dist100 and educ4, and another between arsenic and educ4.\n\nwell_model_interact = bmb.Model(\n    \"switch ~ dist100 + arsenic + educ4 + dist100:educ4 + arsenic:educ4\",\n    data=data,\n    family=\"bernoulli\"\n)\n\nwell_idata_interact = well_model_interact.fit(\n    draws=500, \n    tune=500,\n    target_accept=0.95, \n    random_seed=1234, \n    chains=4\n)\n\nModeling the probability that switch==0\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 2 jobs)\nNUTS: [Intercept, dist100, arsenic, educ4, dist100:educ4, arsenic:educ4]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 500 tune and 500 draw iterations (2_000 + 2_000 draws total) took 13 seconds.\n\n\n\n# summary of coefficients\naz.summary(well_idata_interact)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-0.100\n0.126\n-0.308\n0.155\n0.004\n0.003\n1249.0\n1350.0\n1.0\n\n\narsenic\n-0.396\n0.064\n-0.505\n-0.267\n0.002\n0.001\n1051.0\n938.0\n1.0\n\n\narsenic:educ4\n-0.079\n0.045\n-0.162\n0.006\n0.001\n0.001\n1072.0\n1160.0\n1.0\n\n\ndist100\n1.321\n0.181\n1.011\n1.681\n0.005\n0.004\n1105.0\n1101.0\n1.0\n\n\ndist100:educ4\n-0.331\n0.109\n-0.539\n-0.133\n0.003\n0.002\n1072.0\n1056.0\n1.0\n\n\neduc4\n0.101\n0.082\n-0.054\n0.251\n0.003\n0.002\n1049.0\n1062.0\n1.0\n\n\n\n\n\n\n\nThe coefficients of the linear model are shown in the table above. The interaction coefficents indicate the slope varies in a continuous fashion with the continuous variable.\nA negative value for arsenic:dist100 indicates that the “effect” of arsenic on the outcome is less negative as distance from the well increases. Similarly, a negative value for arsenic:educ4 indicates that the “effect” of arsenic on the outcome is more negative as education increases. Remember, these coefficients are still on the logit scale. Furthermore, as more variables and interaction terms are added to the model, interpreting these coefficients becomes more difficult.\nThus, lets use plot_slopes to visually see how the slope changes with respect to arsenic conditional on dist100 and educ4 changing. Notice in the code block below how parameters are passed to the subplot_kwargs and fig_kwargs arguments. At times, it can be useful to pass specific group and panel arguments to aid in the interpretation of the plot. Therefore, subplot_kwargs allows the user to manipulate the plotting by passing a dictionary where the keys are {\"main\": ..., \"group\": ..., \"panel\": ...} and the values are the names of the covariates to be plotted. fig_kwargs are figure level key word arguments such as figsize and sharey.\n\nfig, ax = bmb.interpret.plot_slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    conditional={\n        \"dist100\": np.linspace(0, 4, 50),\n        \"educ4\": np.arange(0, 5, 1)\n    },\n    subplot_kwargs={\"main\": \"dist100\", \"group\": \"educ4\", \"panel\": \"educ4\"},\n    fig_kwargs={\"figsize\": (16, 6), \"sharey\": True, \"tight_layout\": True},\n    legend=False\n)\n\nDefault computed for wrt variable: arsenic\n\n\n\n\n\n\n\n\n\nBefore we talk about the plot, you will notice that some messages have been logged to the console. By default interpret is verbose and logs a message to the console if a default value is computed for covariates in conditional and wrt. This is useful because unless the documentation is read, it can be difficult to tell which covariates are having default values computed for. Thus, Bambi has a config file bmb.config[\"INTERPRET_VERBOSE\"] where we can specify whether or not to log messages. By default, this is set to true. To turn off logging, set bmb.config[\"INTERPRET_VERBOSE\"] = False. From here on, we will turn off logging.\nWith interaction terms now defined, it can be seen how the slope of the outcome with respect to arsenic differ depending on the value of educ4. Especially in the case of educ4 \\(= 4.25\\), the slope is more “constant”, but with greater uncertainty. Lets compare this with the model that does not include any interaction terms.\n\nbmb.config[\"INTERPRET_VERBOSE\"] = False\n\n\nfig, ax = bmb.interpret.plot_slopes(\n    well_model,\n    well_idata,\n    wrt=\"arsenic\",\n    conditional={\n        \"dist100\": np.linspace(0, 4, 50),\n        \"educ4\": np.arange(0, 5, 1)\n    },\n    subplot_kwargs={\"main\": \"dist100\", \"group\": \"educ4\", \"panel\": \"educ4\"},\n    fig_kwargs={\"figsize\": (16, 6), \"sharey\": True, \"tight_layout\": True},\n    legend=False\n)\n\n\n\n\n\n\n\n\nFor the non-interaction model, conditional on a range of values for educ4 and dist100, the slopes of the outcome are nearly identical.\n\n\nUnit level slopes\nEvaluating average predictive slopes at central values for the conditional covariates \\(c\\) can be problematic when the inputs have a large variance since no single central value (mean, median, etc.) is representative of the covariate. This is especially true when \\(c\\) exhibits bi or multimodality. Thus, it may be desireable to use the empirical distribution of \\(c\\) to compute the predictive slopes, and then average over a specific or set of covariates to obtain average slopes. To achieve unit level slopes, do not pass a parameter into conditional and or specify None.\n\nunit_level = bmb.interpret.slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    conditional=None\n)\n\n# empirical distribution\nprint(unit_level.shape[0] == well_model_interact.data.shape[0])\nunit_level.head(10)\n\nTrue\n\n\n\n\n\n\n\n\n\nterm\nestimate_type\nvalue\ndist100\neduc4\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\narsenic\ndydx\n(2.36, 2.3601)\n0.16826\n0.00\n-0.083830\n-0.103303\n-0.059619\n\n\n1\narsenic\ndydx\n(0.71, 0.7101)\n0.47322\n0.00\n-0.097236\n-0.125494\n-0.069691\n\n\n2\narsenic\ndydx\n(2.07, 2.0701)\n0.20967\n2.50\n-0.117659\n-0.141282\n-0.093521\n\n\n3\narsenic\ndydx\n(1.15, 1.1501)\n0.21486\n3.00\n-0.150092\n-0.188730\n-0.101029\n\n\n4\narsenic\ndydx\n(1.1, 1.1001)\n0.40874\n3.50\n-0.160705\n-0.211825\n-0.101781\n\n\n5\narsenic\ndydx\n(3.9, 3.9001)\n0.69518\n2.25\n-0.073752\n-0.080340\n-0.067324\n\n\n6\narsenic\ndydx\n(2.97, 2.9701000000000004)\n0.80711\n1.00\n-0.108058\n-0.123407\n-0.092499\n\n\n7\narsenic\ndydx\n(3.24, 3.2401000000000004)\n0.55146\n2.50\n-0.087782\n-0.097920\n-0.077981\n\n\n8\narsenic\ndydx\n(3.28, 3.2801)\n0.52647\n0.00\n-0.086990\n-0.106773\n-0.065548\n\n\n9\narsenic\ndydx\n(2.52, 2.5201000000000002)\n0.75072\n0.00\n-0.098481\n-0.125366\n-0.066855\n\n\n\n\n\n\n\n\nwell_model_interact.data.head(10)\n\n\n\n\n\n\n\n\nswitch\narsenic\ndist\nassoc\neduc\ndist100\neduc4\n\n\n\n\n1\n1\n2.36\n16.826000\n0\n0\n0.16826\n0.00\n\n\n2\n1\n0.71\n47.321999\n0\n0\n0.47322\n0.00\n\n\n3\n0\n2.07\n20.966999\n0\n10\n0.20967\n2.50\n\n\n4\n1\n1.15\n21.486000\n0\n12\n0.21486\n3.00\n\n\n5\n1\n1.10\n40.874001\n1\n14\n0.40874\n3.50\n\n\n6\n1\n3.90\n69.517998\n1\n9\n0.69518\n2.25\n\n\n7\n1\n2.97\n80.710999\n1\n4\n0.80711\n1.00\n\n\n8\n1\n3.24\n55.146000\n0\n10\n0.55146\n2.50\n\n\n9\n1\n3.28\n52.646999\n1\n0\n0.52647\n0.00\n\n\n10\n1\n2.52\n75.071999\n1\n0\n0.75072\n0.00\n\n\n\n\n\n\n\nAbove, unit_level is the slopes summary dataframe and well_model_interact.data is the empirical data used to fit the model. Notice how the values for \\(c\\) are identical in both dataframes. However, for \\(w\\), the values are the original \\(w\\) value plus \\(\\epsilon\\). Thus, the estimate value represents the instantaneous rate of change for that unit of observation. However, these unit level slopes are difficult to interpret since each row may have a different slope estimate. Therefore, it is useful to average over (marginalize) the estimates to summarize the unit level predictive slopes.\n\nMarginalizing over covariates\nSince the empirical distrubution is used for computing the average predictive slopes, the same number of rows (\\(3020\\)) is returned as the data used to fit the model. To average over a covariate, use the average_by argument. If True is passed, then slopes averages over all covariates. Else, if a single or list of covariates are passed, then slopes averages by the covariates passed.\n\nbmb.interpret.slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    conditional=None,\n    average_by=True\n)\n\n\n\n\n\n\n\n\nterm\nestimate_type\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\narsenic\ndydx\n-0.110844\n-0.134169\n-0.086302\n\n\n\n\n\n\n\nThe code block above is equivalent to taking the mean of the estimate and uncertainty columns. For example:\n\nunit_level[[\"estimate\", \"lower_3.0%\", \"upper_97.0%\"]].mean()\n\nestimate      -0.110844\nlower_3.0%    -0.134169\nupper_97.0%   -0.086302\ndtype: float64\n\n\n\n\nAverage by subgroups\nAveraging over all covariates may not be desired, and you would rather average by a group or specific covariate. To perform averaging by subgroups, users can pass a single or list of covariates to average_by to average over specific covariates. For example, if we wanted to average by educ4:\n\n# average by educ4\nbmb.interpret.slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    conditional=None,\n    average_by=\"educ4\"\n)\n\n\n\n\n\n\n\n\nterm\nestimate_type\neduc4\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\narsenic\ndydx\n0.00\n-0.091847\n-0.116890\n-0.064127\n\n\n1\narsenic\ndydx\n0.25\n-0.101129\n-0.125250\n-0.075227\n\n\n2\narsenic\ndydx\n0.50\n-0.101583\n-0.121680\n-0.081013\n\n\n3\narsenic\ndydx\n0.75\n-0.105501\n-0.123085\n-0.086949\n\n\n4\narsenic\ndydx\n1.00\n-0.110082\n-0.127725\n-0.092328\n\n\n5\narsenic\ndydx\n1.25\n-0.111864\n-0.128894\n-0.094192\n\n\n6\narsenic\ndydx\n1.50\n-0.114416\n-0.132123\n-0.095338\n\n\n7\narsenic\ndydx\n1.75\n-0.122075\n-0.143268\n-0.100941\n\n\n8\narsenic\ndydx\n2.00\n-0.124711\n-0.149062\n-0.101160\n\n\n9\narsenic\ndydx\n2.25\n-0.124916\n-0.150870\n-0.099147\n\n\n10\narsenic\ndydx\n2.50\n-0.130269\n-0.160280\n-0.100108\n\n\n11\narsenic\ndydx\n2.75\n-0.136928\n-0.169772\n-0.100540\n\n\n12\narsenic\ndydx\n3.00\n-0.135619\n-0.171182\n-0.096698\n\n\n13\narsenic\ndydx\n3.25\n-0.156415\n-0.203887\n-0.105919\n\n\n14\narsenic\ndydx\n3.50\n-0.142054\n-0.186528\n-0.095787\n\n\n15\narsenic\ndydx\n3.75\n-0.137817\n-0.183458\n-0.092731\n\n\n16\narsenic\ndydx\n4.00\n-0.137608\n-0.187025\n-0.087608\n\n\n17\narsenic\ndydx\n4.25\n-0.176076\n-0.249957\n-0.106476\n\n\n\n\n\n\n\n\n# average by both educ4 and dist100\nbmb.interpret.slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    conditional=None,\n    average_by=[\"educ4\", \"dist100\"]\n)\n\n\n\n\n\n\n\n\nterm\nestimate_type\neduc4\ndist100\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\narsenic\ndydx\n0.00\n0.00591\n-0.085353\n-0.106906\n-0.058374\n\n\n1\narsenic\ndydx\n0.00\n0.02409\n-0.095671\n-0.122071\n-0.063162\n\n\n2\narsenic\ndydx\n0.00\n0.02454\n-0.056419\n-0.065869\n-0.046909\n\n\n3\narsenic\ndydx\n0.00\n0.02791\n-0.097036\n-0.124305\n-0.064259\n\n\n4\narsenic\ndydx\n0.00\n0.03252\n-0.075905\n-0.094201\n-0.055535\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2992\narsenic\ndydx\n4.00\n1.13727\n-0.069666\n-0.095900\n-0.047386\n\n\n2993\narsenic\ndydx\n4.00\n1.14418\n-0.124765\n-0.177566\n-0.078547\n\n\n2994\narsenic\ndydx\n4.00\n1.25308\n-0.155919\n-0.225351\n-0.091734\n\n\n2995\narsenic\ndydx\n4.00\n1.67025\n-0.160505\n-0.230657\n-0.084599\n\n\n2996\narsenic\ndydx\n4.25\n0.29633\n-0.176076\n-0.249957\n-0.106476\n\n\n\n\n2997 rows × 7 columns\n\n\n\nIt is still possible to use plot_slopes when passing an argument to average_by. In the plot below, the empirical distribution is used to compute unit level slopes with respect to arsenic and then averaged over educ4 to obtain the average predictive slopes.\n\nfig, ax = bmb.interpret.plot_slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    conditional=None,\n    average_by=\"educ4\"\n)\nfig.set_size_inches(7, 3)\n\n\n\n\n\n\n\n\n\n\n\nInterpreting coefficients as an elasticity\nIn some fields, such as economics, it is useful to interpret the results of a regression model in terms of an elasticity (a percent change in \\(x\\) is associated with a percent change in \\(y\\)) or semi-elasticity (a unit change in \\(x\\) is associated with a percent change in \\(y\\), or vice versa). Typically, this is achieved by fitting a model where either the outcome and or the covariates are log-transformed. However, since the log transformation is performed by the modeler, to compute elasticities for slopes and plot_slopes, Bambi “post-processes” the predictions to compute the elasticities. Below, it is shown the possible elasticity arguments and how they are computed for slopes and plot_slopes:\n\neyex: a percentage point increase in \\(x_1\\) is associated with an \\(n\\) percentage point increase in \\(y\\)\n\n\\[\\frac{\\partial \\hat{y}}{\\partial x_1} * \\frac{x_1}{\\hat{y}}\\]\n\neydx: a unit increase in \\(x_1\\) is associated with an \\(n\\) percentage point increase in \\(y\\)\n\n\\[\\frac{\\partial \\hat{y}}{\\partial x_1} * \\frac{1}{\\hat{y}}\\]\n\ndyex: a percentage point increase in \\(x_1\\) is associated with an \\(n\\) unit increase in \\(y\\)\n\n\\[\\frac{\\partial \\hat{y}}{\\partial x_1} * x_1\\]\nBelow, each code cell shows the same model, and wrt and conditional argument, but with a different elasticity (slope) argument. By default, dydx (a derivative with no post-processing) is used.\n\nbmb.interpret.slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    slope=\"eyex\",\n    conditional=None,\n    average_by=True\n)\n\n\n\n\n\n\n\n\nterm\nestimate_type\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\narsenic\neyex\n-0.522681\n-0.653823\n-0.390103\n\n\n\n\n\n\n\n\nbmb.interpret.slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    slope=\"eydx\",\n    conditional=None,\n    average_by=True\n)\n\n\n\n\n\n\n\n\nterm\nestimate_type\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\narsenic\neydx\n-0.285539\n-0.352966\n-0.217926\n\n\n\n\n\n\n\n\nbmb.interpret.slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    slope=\"dyex\",\n    conditional=None,\n    average_by=True\n)\n\n\n\n\n\n\n\n\nterm\nestimate_type\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\narsenic\ndyex\n-0.16691\n-0.200171\n-0.132009\n\n\n\n\n\n\n\nslope is also an argument for plot_slopes. Below, we visualize the elasticity with respect to arsenic conditional on a range of dist100 and educ4 values (notice this is the same plot as in the conditional slopes section).\n\nfig, ax = bmb.interpret.plot_slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"arsenic\",\n    conditional={\n        \"dist100\": np.linspace(0, 4, 50),\n        \"educ4\": np.arange(0, 5, 1)\n    },\n    slope=\"eyex\",\n    subplot_kwargs={\"main\": \"dist100\", \"group\": \"educ4\", \"panel\": \"educ4\"},\n    fig_kwargs={\"figsize\": (16, 6), \"sharey\": True, \"tight_layout\": True},\n    legend=False\n)\n\n\n\n\n\n\n\n\n\n\nCategorical covariates\nAs mentioned in the computing slopes section, if you pass a variable with a string or categorical data type, the comparisons function will be called to compute the expected difference in group means. Here, we fit the same interaction model as above, albeit, by specifying educ4 as an ordinal data type.\n\ndata = pd.read_csv(\"http://www.stat.columbia.edu/~gelman/arm/examples/arsenic/wells.dat\", sep=\" \")\ndata[\"switch\"] = pd.Categorical(data[\"switch\"])\ndata[\"dist100\"] = data[\"dist\"] / 100\ndata[\"educ4\"] = pd.Categorical(data[\"educ\"] / 4, ordered=True)\n\n\nwell_model_interact = bmb.Model(\n    \"switch ~ dist100 + arsenic + educ4 + dist100:educ4 + arsenic:educ4\",\n    data,\n    family=\"bernoulli\"\n)\n\nwell_idata_interact = well_model_interact.fit(\n    draws=1000, \n    target_accept=0.95, \n    random_seed=1234, \n    chains=4\n)\n\nModeling the probability that switch==0\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 2 jobs)\nNUTS: [Intercept, dist100, arsenic, educ4, dist100:educ4, arsenic:educ4]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 449 seconds.\n\n\n\nfig, ax = bmb.interpret.plot_slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt=\"educ4\",\n    conditional=\"dist100\",\n    average_by=\"dist100\"\n)\nfig.set_size_inches(7, 3)\n\n\n\n\n\n\n\n\nAs the model was fit with educ4 as a categorical data type, Bambi recognized this, and calls comparisons to compute the differences between each level of educ4. As educ4 contains many category levels, a covariate must be passed to average_by in order to perform plotting. Below, we can see this plot is equivalent to plot_comparisons.\n\nfig, ax = bmb.interpret.plot_comparisons(\n    well_model_interact,\n    well_idata_interact,\n    contrast=\"educ4\",\n    conditional=\"dist100\",\n    average_by=\"dist100\"\n)\nfig.set_size_inches(7, 3)\n\n\n\n\n\n\n\n\nHowever, computing the predictive difference between each educ4 level may not be desired. Thus, in plot_slopes, as in plot_comparisons, if wrt is a categorical or string data type, it is possible to specify the wrt values. For example, if we wanted to compute the expected difference in probability of switching wells for when educ4 is \\(4\\) versus \\(1\\) conditional on a range of dist100 and arsenic values, we would pass the following dictionary in the code block below. Please refer to the comparisons documentation for more details.\n\nfig, ax = bmb.interpret.plot_slopes(\n    well_model_interact,\n    well_idata_interact,\n    wrt={\"educ4\": [1, 4]},\n    conditional=\"dist100\",\n    average_by=\"dist100\"\n)\nfig.set_size_inches(7, 3)\n\n\n\n\n\n\n\n\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sat May 25 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\nnumpy : 1.26.4\npandas: 2.2.2\narviz : 0.18.0\nbambi : 0.13.1.dev37+g2a54df76.d20240525\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Tools to interpret model outputs",
      "Plot Slopes"
    ]
  },
  {
    "objectID": "notebooks/predict_new_groups.html",
    "href": "notebooks/predict_new_groups.html",
    "title": "Predict New Groups",
    "section": "",
    "text": "In Bambi, it is possible to perform predictions on new, unseen, groups of data that were not in the observed data used to fit the model with the argument sample_new_groups in the model.predict() method. This is useful in the context of hierarchical modeling, where groups are assumed to be a sample from a larger group.\nBelow, it is first described how predictions at multiple levels and for unseen groups are possible with hierarchical models. Then, it is described how this is performed in Bambi. Lastly, a hierarchical model is developed to show how to use the sample_new_groups argument in the model.predict() method, and within the interpret sub-package. For users coming from brms in R, this is equivalent to the sample_new_levels argument.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Predict New Groups"
    ]
  },
  {
    "objectID": "notebooks/predict_new_groups.html#hierarchical-models-and-predictions-at-multiple-levels",
    "href": "notebooks/predict_new_groups.html#hierarchical-models-and-predictions-at-multiple-levels",
    "title": "Predict New Groups",
    "section": "Hierarchical models and predictions at multiple levels",
    "text": "Hierarchical models and predictions at multiple levels\nA feature of hierarchical models is that they are able to make predictions at multiple levels. For example, if we were to use the penguin dataset to fit a hierchical regression to estimate the body mass of each penguin species given a set of predictors, we could estimate the mass of all penguins and each individual species at the same time. Thus, in this example, there are predictions for two levels: (1) the population level, and (2) the species level.\nAdditionally, a hierarchical model can be used to make predictions for groups (levels) that were never seen before if a hyperprior is defined over the group-specific effect. With a hyperior defined on group-specific effects, the groups do not share one fixed parameter, but rather share a hyperprior distribution which describes the distribution for the parameter of the prior itself. Lets write a hierarchical model (without intercepts) with a hyperprior defined for group-specific effects in statistical notation so this concept becomes more clear:\n\\[\\beta_{\\mu h} \\sim \\mathcal{N}(0, 10)\\] \\[\\beta_{\\sigma h} \\sim \\mathcal{HN}(10)\\] \\[\\beta_{m} \\sim \\mathcal{N}(\\beta_{\\mu h}, \\beta_{\\sigma h})\\] \\[\\sigma_{h} \\sim \\mathcal{HN}(10)\\] \\[\\sigma_{m} \\sim \\mathcal{HN}(\\sigma_{h})\\] \\[Y \\sim \\mathcal{N}(\\beta_{m} * X_{m}, \\sigma_{m})\\]\nThe parameters \\(\\beta_{\\mu h}, \\beta_{\\sigma h}\\) of the group-specific effect prior \\(\\beta_{m}\\) come from hyperprior distributions. Thus, if we would like to make predictions for a new, unseen, group, we can do so by first sampling from these hyperprior distributions to obtain the parameters for the new group, and then sample from the posterior or posterior predictive distribution to obtain the estimates for the new group. For a more in depth explanation of hierarchical models in Bambi, see either: the radon example, or the sleep study example.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Predict New Groups"
    ]
  },
  {
    "objectID": "notebooks/predict_new_groups.html#sampling-new-groups-in-bambi",
    "href": "notebooks/predict_new_groups.html#sampling-new-groups-in-bambi",
    "title": "Predict New Groups",
    "section": "Sampling new groups in Bambi",
    "text": "Sampling new groups in Bambi\nIf data with unseen groups are passed to the new_data argument of the model.predict() method, Bambi first needs to identify if that group exists, and if not, to evaluate the new group with the respective group-specific term. This evaluation updates the design matrix initially used to fit the model with the new group(s). This is achieved with the .evaluate_new_data method in the formulae package.\nOnce the design matrix has been updated, Bambi can perform predictions on the new, unseen, groups by specifying sample_new_groups=True in model.predict(). Each posterior sample for the new groups is drawn from the posterior draws of a randomly selected existing group. Since different groups may be selected at each draw, the end result represents the variation across existing groups.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Predict New Groups"
    ]
  },
  {
    "objectID": "notebooks/predict_new_groups.html#hierarchical-regression",
    "href": "notebooks/predict_new_groups.html#hierarchical-regression",
    "title": "Predict New Groups",
    "section": "Hierarchical regression",
    "text": "Hierarchical regression\nTo demonstrate the sample_new_groups argument, we will develop a hierarchical model on the OSIC Pulmonary Fibrosis Progression dataset. Pulmonary fibrosis is a disorder with no known cause and no known cure, created by scarring of the lungs. Using a hierarchical model, the objective is to predict a patient’s severity of decline in lung function. Lung function is assessed based on output from a spirometer, which measures the forced vital capacity (FVC), i.e. the volume of air exhaled by the patient.\n\nimport arviz as az\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport warnings\n\nimport bambi as bmb\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\n\n\nThe OSIC pulmonary fibrosis progression dataset\nIn the dataset, we were provided with a baseline chest computerized tomography (CT) scan and associated clinical information for a set of patients where the columns represent the following\n\npatient- a unique id for each patient\nweeks- the relative number of weeks pre/post the baseline CT (may be negative)\nfvc - the recorded lung capacity in millilitres (ml)\npercent- a computed field which approximates the patient’s FVC as a percent of the typical FVC for a person of similar characteristics\nsex - male or female\nsmoking_status - ex-smoker, never smoked, currently smokes\nage - age of the patient\n\nA patient has an image acquired at time week = 0 and has numerous follow up visits over the course of approximately 1-2 years, at which time their FVC is measured. Below, we randomly sample three patients and plot their FVC measurements over time.\n\ndata = pd.read_csv(\n    \"https://gist.githubusercontent.com/ucals/\"\n    \"2cf9d101992cb1b78c2cdd6e3bac6a4b/raw/\"\n    \"43034c39052dcf97d4b894d2ec1bc3f90f3623d9/\"\n    \"osic_pulmonary_fibrosis.csv\"\n)\n\ndata.columns = data.columns.str.lower()\ndata.columns = data.columns.str.replace(\"smokingstatus\", \"smoking_status\")\ndata\n\n\n\n\n\n\n\n\npatient\nweeks\nfvc\npercent\nage\nsex\nsmoking_status\n\n\n\n\n0\nID00007637202177411956430\n-4\n2315\n58.253649\n79\nMale\nEx-smoker\n\n\n1\nID00007637202177411956430\n5\n2214\n55.712129\n79\nMale\nEx-smoker\n\n\n2\nID00007637202177411956430\n7\n2061\n51.862104\n79\nMale\nEx-smoker\n\n\n3\nID00007637202177411956430\n9\n2144\n53.950679\n79\nMale\nEx-smoker\n\n\n4\nID00007637202177411956430\n11\n2069\n52.063412\n79\nMale\nEx-smoker\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1544\nID00426637202313170790466\n13\n2712\n66.594637\n73\nMale\nNever smoked\n\n\n1545\nID00426637202313170790466\n19\n2978\n73.126412\n73\nMale\nNever smoked\n\n\n1546\nID00426637202313170790466\n31\n2908\n71.407524\n73\nMale\nNever smoked\n\n\n1547\nID00426637202313170790466\n43\n2975\n73.052745\n73\nMale\nNever smoked\n\n\n1548\nID00426637202313170790466\n59\n2774\n68.117081\n73\nMale\nNever smoked\n\n\n\n\n1549 rows × 7 columns\n\n\n\n\ndef label_encoder(labels):\n    \"\"\"\n    Encode patient IDs as integers.\n    \"\"\"\n    unique_labels = np.unique(labels)\n    label_to_index = {label: index for index, label in enumerate(unique_labels)}\n    encoded_labels = labels.map(label_to_index)\n    return encoded_labels\n\n\npredictors = [\"patient\", \"weeks\", \"fvc\", \"smoking_status\"]\n\ndata[\"patient\"] = label_encoder(data['patient'])\n\ndata[\"weeks\"] = (data[\"weeks\"] - data[\"weeks\"].min()) / (\n    data[\"weeks\"].max() - data[\"weeks\"].min()\n)\ndata[\"fvc\"] = (data[\"fvc\"] - data[\"fvc\"].min()) / (\n    data[\"fvc\"].max() - data[\"fvc\"].min()\n)\n\ndata = data[predictors]\n\n\npatient_id = data.sample(n=3, random_state=42)[\"patient\"].values\n\nfig, ax = plt.subplots(1, 3, figsize=(12, 3), sharey=True)\nfor i, p in enumerate(patient_id):\n    patient_data = data[data[\"patient\"] == p]\n    ax[i].scatter(patient_data[\"weeks\"], patient_data[\"fvc\"])\n    ax[i].set_xlabel(\"weeks\")\n    ax[i].set_ylabel(\"fvc\")\n    ax[i].set_title(f\"patient {p}\")\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\nThe plots show variability in FVC measurements, unequal time intervals between follow up visits, and different number of visits per patient. This is a good scenario to use a hierarchical model, where we can model the FVC measurements for each patient as a function of time, and also model the variability in the FVC measurements across patients.\n\n\nPartial pooling model\nThe hierarchical model we will develop is a partially pooled model using the predictors weeks, smoking_status, and patient to predict the response fvc. We will estimate the following model with common and group-effects:\n\ncommon-effects: weeks and smoking_status\ngroup-effects: the slope of weeks will vary by patient\n\nAdditionally, the global intercept is not included. Since the global intercept is excluded, smoking_status uses cell means encoding (i.e. the coefficient represents the estimate for each smoking_status category of the entire group). This logic also applies for weeks. However, a group-effect is also specified for weeks, which means that the association between weeks and the fvc is allowed to vary by individual patients.\nBelow, the default prior for the group-effect sigma is changed from HalfNormal to a Gamma distribution. Additionally, the model graph shows the model has been reparameterized to be non-centered. This is the default when there are group-effects in Bambi.\n\npriors = {\n    \"weeks|patient\": bmb.Prior(\"Normal\", mu=0, sigma=bmb.Prior(\"Gamma\", alpha=3, beta=3)),\n}\n\nmodel = bmb.Model(\n    \"fvc ~ 0 + weeks + smoking_status + (0 + weeks | patient)\",\n    data, \n    priors=priors,\n    categorical=[\"patient\", \"smoking_status\"],\n)\nmodel.build()\nmodel.graph()\n\n\n\n\n\n\n\n\n\nidata = model.fit(\n    draws=1500,\n    tune=1000,\n    target_accept=0.95,\n    chains=4,\n    random_seed=42,\n)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 2 jobs)\nNUTS: [sigma, weeks, smoking_status, weeks|patient_sigma, weeks|patient_offset]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_500 draw iterations (4_000 + 6_000 draws total) took 79 seconds.\n\n\n\n\nModel criticism\nHierarchical models can induce difficult posterior geometries to sample from. Below, we quickly analyze the traces to ensure sampling went well.\n\naz.plot_trace(idata)\nplt.tight_layout();\n\n\n\n\n\n\n\n\nAnalyzing the marginal posteriors of weeks and weeks|patient, we see that the slope can be very different for some individuals. weeks indicates that as a population, the slope is negative. However, weeks|patients indicates some patients are negative, some are positive, and some are close to zero. Moreover, there are varying levels of uncertainty observed in the coefficients for the three different values of the smoking_status variable.\n\naz.summary(idata, var_names=[\"weeks\", \"smoking_status\", \"sigma\", \"weeks|patient_sigma\"])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nweeks\n-0.116\n0.036\n-0.183\n-0.046\n0.002\n0.001\n416.0\n822.0\n1.00\n\n\nsmoking_status[Currently smokes]\n0.398\n0.017\n0.364\n0.429\n0.000\n0.000\n3305.0\n4116.0\n1.00\n\n\nsmoking_status[Ex-smoker]\n0.382\n0.005\n0.373\n0.392\n0.000\n0.000\n5004.0\n4945.0\n1.00\n\n\nsmoking_status[Never smoked]\n0.291\n0.008\n0.277\n0.305\n0.000\n0.000\n2813.0\n4261.0\n1.00\n\n\nsigma\n0.077\n0.001\n0.074\n0.080\n0.000\n0.000\n9197.0\n4194.0\n1.00\n\n\nweeks|patient_sigma\n0.458\n0.026\n0.413\n0.511\n0.001\n0.001\n697.0\n1411.0\n1.01\n\n\n\n\n\n\n\nThe effective sample size (ESS) is much lower for the weeks and weeks|patient_sigma parameters. This can also be inferred visually by looking at the trace plots for these parameters above. There seems to be some autocorrelation in the samples for these parameters. However, for the sake of this example, we will not worry about this.\n\n\nPredict observed patients\nFirst, we will use the posterior distribution to plot the mean and 95% credible interval for the FVC measurements of the three randomly sampled patients above.\n\npreds = model.predict(idata, kind=\"params\", inplace=False)\nfvc_mean = az.extract(preds[\"posterior\"])[\"mu\"]\n\n\n# plot posterior predictions\nfig, ax = plt.subplots(1, 3, figsize=(12, 3), sharey=True)\nfor i, p in enumerate(patient_id):\n    idx = data.index[data[\"patient\"] == p].tolist()\n    weeks = data.loc[idx, \"weeks\"].values\n    fvc = data.loc[idx, \"fvc\"].values\n\n    ax[i].scatter(weeks, fvc)\n    az.plot_hdi(weeks, fvc_mean[idx].T, color=\"C0\", ax=ax[i])\n    ax[i].plot(weeks, fvc_mean[idx].mean(axis=1), color=\"C0\")\n\n    ax[i].set_xlabel(\"weeks\")\n    ax[i].set_ylabel(\"fvc\")\n    ax[i].set_title(f\"patient {p}\")\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\nThe plots show that the posterior estimates seem to fit the three patients well. Where there are more observations, the credible interval is smaller, and where there are fewer observations, the credible interval is larger. Next, we will predict new, unseen, patients.\n\n\nPredict new patients\nImagine the cost of acquiring a CT scan increases dramatically, and we would like to interopolate the FVC measurement for a new patient with a given set of clinical information smoking_status and weeks. We achieve this by passing this data to the predict method and setting sample_new_groups=True. As outlined in the Sampling new groups in Bambi section, this new data is evaluated by formulae to update the design matrix, and then predictions are made for the new group by sampling from the posterior draws of a randomly selected existing group.\nBelow, we will simulate a new patient and predict their FVC measurements over time. First, we will copy clinical data from patient 39 and use it for patient 176 (the new, unseen, patient). Subsequently, we will construct another new patient, with different clinical data.\n\n# copy patient 39 data to the new patient 176\npatient_39 = data[data[\"patient\"] == 39].reset_index(drop=True)\nnew_data = patient_39.copy()\nnew_data[\"patient\"] = 176\nnew_data = pd.concat([new_data, patient_39]).reset_index(drop=True)[predictors]\nnew_data\n\n\n\n\n\n\n\n\npatient\nweeks\nfvc\nsmoking_status\n\n\n\n\n0\n176\n0.355072\n0.378141\nEx-smoker\n\n\n1\n176\n0.376812\n0.365937\nEx-smoker\n\n\n2\n176\n0.391304\n0.401651\nEx-smoker\n\n\n3\n176\n0.405797\n0.405958\nEx-smoker\n\n\n4\n176\n0.420290\n0.390883\nEx-smoker\n\n\n5\n176\n0.456522\n0.390165\nEx-smoker\n\n\n6\n176\n0.543478\n0.348528\nEx-smoker\n\n\n7\n176\n0.637681\n0.337581\nEx-smoker\n\n\n8\n176\n0.746377\n0.365219\nEx-smoker\n\n\n9\n176\n0.775362\n0.360014\nEx-smoker\n\n\n10\n39\n0.355072\n0.378141\nEx-smoker\n\n\n11\n39\n0.376812\n0.365937\nEx-smoker\n\n\n12\n39\n0.391304\n0.401651\nEx-smoker\n\n\n13\n39\n0.405797\n0.405958\nEx-smoker\n\n\n14\n39\n0.420290\n0.390883\nEx-smoker\n\n\n15\n39\n0.456522\n0.390165\nEx-smoker\n\n\n16\n39\n0.543478\n0.348528\nEx-smoker\n\n\n17\n39\n0.637681\n0.337581\nEx-smoker\n\n\n18\n39\n0.746377\n0.365219\nEx-smoker\n\n\n19\n39\n0.775362\n0.360014\nEx-smoker\n\n\n\n\n\n\n\n\npreds = model.predict(\n    idata, \n    kind=\"params\",\n    data=new_data, \n    sample_new_groups=True,\n    inplace=False\n)\n\n\n# utility func for plotting\ndef plot_new_patient(idata, data, patient_ids):\n    fvc_mean = az.extract(idata[\"posterior\"])[\"mu\"]\n\n    fig, ax = plt.subplots(1, 2, figsize=(10, 3), sharey=True)\n    for i, p in enumerate(patient_ids):\n        idx = data.index[data[\"patient\"] == p].tolist()\n        weeks = data.loc[idx, \"weeks\"].values\n        fvc = data.loc[idx, \"fvc\"].values\n\n        if p == patient_ids[0]:\n            ax[i].scatter(weeks, fvc)\n\n        az.plot_hdi(weeks, fvc_mean[idx].T, color=\"C0\", ax=ax[i])\n        ax[i].plot(weeks, fvc_mean[idx].mean(axis=1), color=\"C0\")\n\n        ax[i].set_xlabel(\"weeks\")\n        ax[i].set_ylabel(\"fvc\")\n        ax[i].set_title(f\"patient {p}\")\n\n\nplot_new_patient(preds, new_data, [39, 176])\n\n\n\n\n\n\n\n\nAlthough identical data was used for both patients, the variability increased consideribly for patient 176. However, the mean predictions for both patients appear to be almost identical. Now, lets construct a new patient with different clinical data and see how the predictions change. We will select 10 time of follow up visits at random, and set the smoking_status = \"Currently smokes\".\n\nnew_data.loc[new_data[\"patient\"] == 176, \"smoking_status\"] = \"Currently smokes\"\nweeks = np.random.choice(sorted(model.data.weeks.unique()), size=10)\nnew_data.loc[new_data[\"patient\"] == 176, \"weeks\"] = weeks \nnew_data\n\n\n\n\n\n\n\n\npatient\nweeks\nfvc\nsmoking_status\n\n\n\n\n0\n176\n0.413043\n0.378141\nCurrently smokes\n\n\n1\n176\n0.181159\n0.365937\nCurrently smokes\n\n\n2\n176\n0.644928\n0.401651\nCurrently smokes\n\n\n3\n176\n0.681159\n0.405958\nCurrently smokes\n\n\n4\n176\n0.028986\n0.390883\nCurrently smokes\n\n\n5\n176\n0.028986\n0.390165\nCurrently smokes\n\n\n6\n176\n0.695652\n0.348528\nCurrently smokes\n\n\n7\n176\n0.456522\n0.337581\nCurrently smokes\n\n\n8\n176\n0.152174\n0.365219\nCurrently smokes\n\n\n9\n176\n0.144928\n0.360014\nCurrently smokes\n\n\n10\n39\n0.355072\n0.378141\nEx-smoker\n\n\n11\n39\n0.376812\n0.365937\nEx-smoker\n\n\n12\n39\n0.391304\n0.401651\nEx-smoker\n\n\n13\n39\n0.405797\n0.405958\nEx-smoker\n\n\n14\n39\n0.420290\n0.390883\nEx-smoker\n\n\n15\n39\n0.456522\n0.390165\nEx-smoker\n\n\n16\n39\n0.543478\n0.348528\nEx-smoker\n\n\n17\n39\n0.637681\n0.337581\nEx-smoker\n\n\n18\n39\n0.746377\n0.365219\nEx-smoker\n\n\n19\n39\n0.775362\n0.360014\nEx-smoker\n\n\n\n\n\n\n\nIf we were to keep the default value of sample_new_groups=False, the following error would be raised: ValueError: There are new groups for the factors ('patient',) and 'sample_new_groups' is False. Thus, we set sample_new_groups=True and obtain predictions for the new patient.\n\npreds = model.predict(\n    idata, \n    kind=\"params\",\n    data=new_data, \n    sample_new_groups=True,\n    inplace=False\n)\n\n\nplot_new_patient(preds, new_data, [39, 176])\n\n\n\n\n\n\n\n\nWith smoking_status = \"Currently smokes\", and the time of follow up visit randomly selected, we can see that the intercept is slightly higher, and it appears that the slope is steeper for this new patient. Again, the variability is much higher for patient 176, and in particular, where there are fewer fvc measurements.\n\nPredict new patients with interpret\nThe interpret sub-package in Bambi allows us to easily interpret the predictions for new patients. In particular, using bmb.interpret.comparisons, we can compare the predictions made for a new patient and an existing similar patient. Below, we will compare the predictions made for patient 176 and patient 39. We will use the same clinical data for both patients as we did in the first exampe above.\n\ntime_of_follow_up = list(new_data.query(\"patient == 39\")[\"weeks\"].values)\ntime_of_follow_up\n\n[0.35507246376811596,\n 0.37681159420289856,\n 0.391304347826087,\n 0.4057971014492754,\n 0.42028985507246375,\n 0.45652173913043476,\n 0.5434782608695652,\n 0.6376811594202898,\n 0.7463768115942029,\n 0.7753623188405797]\n\n\n\nfig, ax = bmb.interpret.plot_comparisons(\n    model,\n    idata,\n    contrast={\"patient\": [39, 176]},\n    conditional={\"weeks\": time_of_follow_up, \"smoking_status\": \"Ex-smoker\"},\n    sample_new_groups=True,\n    fig_kwargs={\"figsize\": (7, 3)}\n)\nplt.title(\"Difference in predictions for patient 176 vs 39\");\n\n\n\n\n\n\n\n\nReferring to the plots where patient 39 and 176 use identical data, the mean fvc predictions “look” about the same. When this comparison is made quantitatively using the comparisons function, we can see that mean fvc measurements are slightly below 0.0, and have a constant slope across weeks indicating there is a slight difference in mean fvc measurements between the two patients.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Predict New Groups"
    ]
  },
  {
    "objectID": "notebooks/predict_new_groups.html#summary",
    "href": "notebooks/predict_new_groups.html#summary",
    "title": "Predict New Groups",
    "section": "Summary",
    "text": "Summary\nIn this notebook, it was shown how predictions at multiple levels and for unseen groups are possible with hierarchical models. To utilize this feature of hierarchical models, Bambi first updates the design matrix to include the new group. Then, predictions are made for the new group by sampling from the posterior draws of a randomly selected existing group.\nTo predict new groups in Bambi, you can either: (1) create a dataset with new groups and pass it to the model.predict() method while specifying sample_new_groups=True, or (2) use the functions comparisons or slopes in the interpret sub-package with sample_new_groups=True to compare predictions or slopes for new groups and existing groups.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sun May 26 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\narviz     : 0.18.0\nnumpy     : 1.26.4\npandas    : 2.2.2\nmatplotlib: 3.8.4\nbambi     : 0.13.1.dev39+gb7d6a6cb\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Predict New Groups"
    ]
  },
  {
    "objectID": "notebooks/radon_example.html",
    "href": "notebooks/radon_example.html",
    "title": "Hierarchical Linear Regression (Radon Contamination dataset)",
    "section": "",
    "text": "In this notebook we want to revisit the classical hierarchical linear regression model based on the dataset of the Radon Contamination by Gelman and Hill. In particular, we want to show how easy is to port the PyMC models, presented in the very complete article A Primer on Bayesian Methods for Multilevel Modeling, to Bambi using the more concise formula specification for the models.\nThis example has been ported from PyMC by Juan Orduz (@juanitorduz) and Bambi developers.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Hierarchical Linear Regression (Radon Contamination dataset)"
    ]
  },
  {
    "objectID": "notebooks/radon_example.html#prepare-notebook",
    "href": "notebooks/radon_example.html#prepare-notebook",
    "title": "Hierarchical Linear Regression (Radon Contamination dataset)",
    "section": "Prepare Notebook",
    "text": "Prepare Notebook\n\nimport arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pymc as pm\nimport seaborn as sns\n\n\naz.style.use(\"arviz-darkgrid\")\nnp.random.default_rng(8924)\n\nGenerator(PCG64) at 0x76AD7DB7DE00",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Hierarchical Linear Regression (Radon Contamination dataset)"
    ]
  },
  {
    "objectID": "notebooks/radon_example.html#read-data",
    "href": "notebooks/radon_example.html#read-data",
    "title": "Hierarchical Linear Regression (Radon Contamination dataset)",
    "section": "Read Data",
    "text": "Read Data\nLet us load the data into a pandas data frame.\n\n# Get radon data\npath = \"https://raw.githubusercontent.com/pymc-devs/pymc-examples/main/examples/data/srrs2.dat\"\nradon_df = pd.read_csv(path)\n\n# Get city data\ncity_df = pd.read_csv(pm.get_data(\"cty.dat\"))\n\n\ndisplay(radon_df.head())\nprint(radon_df.shape[0])\n\n\n\n\n\n\n\n\nidnum\nstate\nstate2\nstfips\nzip\nregion\ntypebldg\nfloor\nroom\nbasement\n...\nstoptm\nstartdt\nstopdt\nactivity\npcterr\nadjwt\ndupflag\nzipflag\ncntyfips\ncounty\n\n\n\n\n0\n1\nAZ\nAZ\n4\n85920\n1\n1\n1\n2\nN\n...\n1100\n112987\n120287\n0.3\n0.0\n136.060971\n0\n0\n1\nAPACHE\n\n\n1\n2\nAZ\nAZ\n4\n85920\n1\n0\n9\n0\n\n...\n700\n70788\n71188\n0.6\n33.3\n128.784975\n0\n0\n1\nAPACHE\n\n\n2\n3\nAZ\nAZ\n4\n85924\n1\n1\n1\n3\nN\n...\n1145\n70788\n70788\n0.5\n0.0\n150.245112\n0\n0\n1\nAPACHE\n\n\n3\n4\nAZ\nAZ\n4\n85925\n1\n1\n1\n3\nN\n...\n1900\n52088\n52288\n0.6\n97.2\n136.060971\n0\n0\n1\nAPACHE\n\n\n4\n5\nAZ\nAZ\n4\n85932\n1\n1\n1\n1\nN\n...\n900\n70788\n70788\n0.3\n0.0\n136.060971\n0\n0\n1\nAPACHE\n\n\n\n\n5 rows × 25 columns\n\n\n\n12777\n\n\n\ndisplay(city_df.head())\nprint(city_df.shape[0])\n\n\n\n\n\n\n\n\nstfips\nctfips\nst\ncty\nlon\nlat\nUppm\n\n\n\n\n0\n1\n1\nAL\nAUTAUGA\n-86.643\n32.534\n1.78331\n\n\n1\n1\n3\nAL\nBALDWIN\n-87.750\n30.661\n1.38323\n\n\n2\n1\n5\nAL\nBARBOUR\n-85.393\n31.870\n2.10105\n\n\n3\n1\n7\nAL\nBIBB\n-87.126\n32.998\n1.67313\n\n\n4\n1\n9\nAL\nBLOUNT\n-86.568\n33.981\n1.88501\n\n\n\n\n\n\n\n3194",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Hierarchical Linear Regression (Radon Contamination dataset)"
    ]
  },
  {
    "objectID": "notebooks/radon_example.html#preprocess-data",
    "href": "notebooks/radon_example.html#preprocess-data",
    "title": "Hierarchical Linear Regression (Radon Contamination dataset)",
    "section": "Preprocess Data",
    "text": "Preprocess Data\nWe are going to preprocess the data as done in the article A Primer on Bayesian Methods for Multilevel Modeling.\n\n# Strip spaces from column names\nradon_df.columns = radon_df.columns.map(str.strip)\n\n# Filter to keep observations for \"MN\" state only\ndf = radon_df[radon_df.state == \"MN\"].copy()\ncity_mn_df = city_df[city_df.st == \"MN\"].copy()\n\n# Compute fips\ndf[\"fips\"] = 1_000 * df.stfips + df.cntyfips\ncity_mn_df[\"fips\"] = 1_000 * city_mn_df.stfips + city_mn_df.ctfips\n\n# Merge data\ndf = df.merge(city_mn_df[[\"fips\", \"Uppm\"]], on=\"fips\")\ndf = df.drop_duplicates(subset=\"idnum\")\n\n# Clean county names\ndf.county = df.county.map(str.strip)\n\n# Compute log(radon + 0.1)\ndf[\"log_radon\"] = np.log(df[\"activity\"] + 0.1)\n\n# Compute log of Uranium\ndf[\"log_u\"] = np.log(df[\"Uppm\"])\n\n# Let's map floor. 0 -&gt; Basement and 1 -&gt; Floor\ndf[\"floor\"] = df[\"floor\"].map({0: \"Basement\", 1: \"Floor\"})\n\n# Sort values by floor\ndf = df.sort_values(by=\"floor\")\n\n# Reset index\ndf = df.reset_index(drop=True)\n\nIn this exercise, we model the logarithm of the Radon measurements. This is because the distribution of the Radon level is approximately log-normal. We also add a small number, 0.1, to prevent us from trying to compute the logarithm of 0.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Hierarchical Linear Regression (Radon Contamination dataset)"
    ]
  },
  {
    "objectID": "notebooks/radon_example.html#eda",
    "href": "notebooks/radon_example.html#eda",
    "title": "Hierarchical Linear Regression (Radon Contamination dataset)",
    "section": "EDA",
    "text": "EDA\nIn order to get a glimpse of the data, we are going to do some exploratory data analysis. First, let’s have a look at the global distribution of the untransformed radon levels.\n\n_, ax = plt.subplots()\nsns.histplot(x=\"activity\", alpha=0.2, stat=\"density\", element=\"step\", common_norm=False, data=df, ax=ax)\nsns.kdeplot(x=\"activity\", data=df, ax=ax, cut=0)\nax.set(title=\"Density of Radon\", xlabel=\"Radon\", ylabel=\"Density\");\n\n\n\n\n\n\n\n\nNext, let us see the global log(radon + 0.1) distribution.\n\n_, ax = plt.subplots()\nsns.histplot(x=\"log_radon\", alpha=0.2, stat=\"density\", element=\"step\", common_norm=False, data=df, ax=ax)\nsns.kdeplot(x=\"log_radon\", data=df, ax=ax)\nax.set(title=\"Density of log(Radon + 0.1)\", xlabel=\"$\\log(Radon + 0.1)$\", ylabel=\"Density\");\n\n\n\n\n\n\n\n\nThere are many a priori reasons to think houses with basement has higher radon levels. From geochemistry to composition of building materials to poor ventilation. We can split the distribution of log(radon + 0.1) per floor to see if we are able to see that difference in our data.\n\n_, ax = plt.subplots()\nsns.histplot(\n    x=\"log_radon\", hue=\"floor\", alpha=0.2, stat=\"density\", element=\"step\", \n    common_norm=False, data=df, ax=ax\n)\nsns.kdeplot(x=\"log_radon\", hue=\"floor\", common_norm=False, data=df, ax=ax)\nax.set(title=\"Density of log(Radon + 0.1)\", xlabel=\"$\\log + 0.1$\", ylabel=\"Density\");\n\n\n\n\n\n\n\n\nThis exploration tell us that, as expected, the average radon level is higher in Basement than Floor.\nNext, we are going to count the number of counties.\n\nn_counties = df[\"county\"].unique().size\nprint(f\"Number of counties: {n_counties}\")\n\nNumber of counties: 85\n\n\nLet us dig deeper into the distribution of radon and number of observations per county and floor level.\n\nlog_radon_county_agg  = (\n    df \n    .groupby([\"county\", \"floor\"], as_index=False)\n    .agg(\n        log_radon_mean=(\"log_radon\", \"mean\"),\n        n_obs=(\"log_radon\", \"count\")\n    )\n)\n\nfig, ax= plt.subplots(nrows=1, ncols=2, figsize=(12, 6), layout=\"constrained\")\nsns.boxplot(x=\"floor\", y=\"log_radon_mean\", data=log_radon_county_agg, ax=ax[0])\nax[0].set(title=\"log(Radon + 0.1) Mean per County\", ylabel=\"$\\log + 0.1$\")\n\nsns.boxplot(x=\"floor\", y=\"n_obs\", data=log_radon_county_agg, ax=ax[1])\nax[1].set(title=\"Number of Observations\", xlabel=\"floor\", ylabel=\"Number of observations\");\n\n\n\n\n\n\n\n\n\nOn the left hand side we can see that the \"Basement\" distribution per county is shifted to higher values with respect to the \"Floor\" distribution. We had seen this above when considering all counties together.\nOn the right hand side we see that the number of observations per county is not the same for the floor levels. In particular, we see that there are some counties with a lot of basement observations. This can create some bias when computing simple statistics to compare across counties. Moreover, not all county and floor combinations are present in the dataset. For example:\n\n\nassert df.query(\"county == 'YELLOW MEDICINE' and floor == 'Floor'\").empty",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Hierarchical Linear Regression (Radon Contamination dataset)"
    ]
  },
  {
    "objectID": "notebooks/radon_example.html#models-conventional-approaches",
    "href": "notebooks/radon_example.html#models-conventional-approaches",
    "title": "Hierarchical Linear Regression (Radon Contamination dataset)",
    "section": "Models: Conventional Approaches",
    "text": "Models: Conventional Approaches\n\nComplete Pooling\n\nModel\nFor this first model we only consider the predictor floor, which represents the floor level. The following equation describes the linear model that we are going to build with Bambi\n\\[\ny = \\beta_{j} + \\varepsilon\n\\]\nwhere\n\\[\n\\begin{aligned}\ny &= \\text{Response for the (log) radon measurement }\\\\\n\\beta_{j} &= \\text{Coefficient for the floor level } j \\\\\n\\varepsilon & = \\text{Residual random error}\n\\end{aligned}\n\\]\nEach \\(j\\) indexes a different floor level. In this case, \\(j=1\\) means \"basement\" and \\(j=2\\) means \"floor\".\n\n\nPriors\n\nCommon effects\nThe only common effect in this model is the floor effect represented by the \\(\\beta_{j}\\) coefficients. We have\n\\[\n\\beta_{j} \\sim \\text{Normal}(0, \\sigma_{\\beta_j})\n\\]\nfor \\(j: 1, 2\\), where \\(\\sigma_{\\beta_j}\\) is a positive constant that we set to 10 for all \\(j\\).\n\n\nResidual error\n\\[\n\\begin{aligned}\n\\varepsilon & \\sim \\text{Normal}(0, \\sigma) \\\\\n\\sigma & \\sim \\text{Exponential}(\\lambda)\n\\end{aligned}\n\\]\nwhere \\(\\lambda\\) is a positive constant that we set to 1.\nLet us now write the Bambi model.\nThe 0 on the right side of ~ in the model formula removes the global intercept that is added by default. This allows Bambi to use one coefficient for each floor level.\n\n# A dictionary with the priors we pass to the model initialization\npooled_priors = {\n    \"floor\": bmb.Prior(\"Normal\", mu=0, sigma=10),\n    \"sigma\": bmb.Prior(\"Exponential\", lam=1),\n}\n\npooled_model = bmb.Model(\"log_radon ~ 0 + floor\", df, priors=pooled_priors)\npooled_model\n\n       Formula: log_radon ~ 0 + floor\n        Family: gaussian\n          Link: mu = identity\n  Observations: 919\n        Priors: \n    target = mu\n        Common-level effects\n            floor ~ Normal(mu: 0.0, sigma: 10.0)\n        \n        Auxiliary parameters\n            sigma ~ Exponential(lam: 1.0)\n\n\nThe Family name: Gaussian indicates the selected family, which defaults to Gaussian. And Link: identity indicates the default value for the link argument in bmb.Model(). Taken together this simply means that we are fitting a normal linear regression model.\nLet’s see the graph representation of the model before fitting. To do so, we first need to call the .build() method. Internally, this builds the underlying PyMC model.\n\npooled_model.build()\npooled_model.graph()\n\n\n\n\n\n\n\n\nLet’s now fit the model.\n\npooled_results = pooled_model.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, floor]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 3 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nNow we can examine the posterior distribution, i.e. the joint distribution of model parameters conditional on the data:\n\naz.plot_trace(data=pooled_results, compact=True, chain_prop={\"ls\": \"-\"})\nplt.suptitle(\"Pooled Model Trace\");\n\n\n\n\n\n\n\n\nWe can also see some posterior summary statistics.\n\npooled_summary = az.summary(data=pooled_results)\npooled_summary\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nfloor[Basement]\n1.362\n0.029\n1.309\n1.416\n0.001\n0.000\n3280.0\n1577.0\n1.0\n\n\nfloor[Floor]\n0.776\n0.066\n0.657\n0.898\n0.001\n0.001\n3035.0\n1397.0\n1.0\n\n\nsigma\n0.791\n0.019\n0.752\n0.824\n0.000\n0.000\n3143.0\n1483.0\n1.0\n\n\n\n\n\n\n\nFrom the posterior plot and the summary, we can see the mean radon level is considerably higher in the Basement than in the Floor level. This reflects what we originally saw in the initial data exploration. In addition, sice we have more measurements in the Basement, the uncertainty in its posterior is smaller than the uncertainty in the posterior for the Floor level.\nWe can compare the mean of the posterior distribution of the floor terms to the sample mean. This is going to be useful to understand the meaning of complete pooling.\n\n_, ax = plt.subplots()\n\n(\n    pooled_summary[\"mean\"]\n    .iloc[:-1]\n    .reset_index()\n    .assign(floor = lambda x: x[\"index\"].str.slice(6, -1).str.strip())\n    .merge(\n        right=df.groupby([\"floor\"])[\"log_radon\"].mean(),\n        left_on=\"floor\",\n        right_index=True\n    )\n    .rename(columns={\n        \"mean\": \"posterior mean\",\n        \"log_radon\": \"sample mean\"\n    })\n    .melt(\n        id_vars=\"floor\",\n        value_vars=[\"posterior mean\", \"sample mean\"]\n    )\n    .pipe((sns.barplot, \"data\"),\n        x=\"floor\",\n        y=\"value\",\n        hue=\"variable\",\n        ax=ax\n    )\n)\nax.set(title=\"log(Radon + 0.1) Mean per Floor - Pooled Model\", ylabel=\"$\\log + 0.1$\");\n\n\n\n\n\n\n\n\nFrom the plot alone it is hard to detect the difference between the posterior mean and the sample mean. This happens because the estimation for any observation in either group is simply the group mean plus the smoothing due to the non-flat priors.\nIn other words, for every observation where floor is \"Basement\" the model predicts the mean radon for all the basement measurements, and for every observation where floor is \"Floor\", the model predicts the mean radon for all the floor measurements.\nWhat does complete pooling exactly mean here?\nIn this example, the pooling refers to how we treat the different counties when computing estimates (i.e. this does not refer to pooling across floor levels for example). Complete pooling means that all measurements for all counties are pooled into a single estimate (“treat all counties the same”), conditional on the floor level (because it is used as a covariate/predictor). For that reason, when computing the prediction for a given observation, we do not discriminate which county it belongs to. We pool all the counties into a single estimate, or in other words, we perform a complete pooling.\nLet’s now compare the posterior predictive distribution for each group with the distribution of the observed data.\nTo do this we need to perform a couple of steps:\n\nObtain samples from the posterior predictive distribution using the .predict() method.\nApply the inverse transform to have the posterior predictive samples in the original scale of the response.\n\n\n# Note we create a new data set. \n# One observation per group is enough to obtain posterior predictive samples for that group\n# The more observations we create, the more posterior predictive samples from the same distribution\n# we obtain.\nnew_data = pd.DataFrame({\"floor\": [\"Basement\", \"Floor\"]})\npooled_model.predict(pooled_results, kind=\"pps\", data=new_data)\n\n# Stack chains and draws and extract posterior predictive samples\npps = az.extract_dataset(pooled_results, group=\"posterior_predictive\")[\"log_radon\"].values\n\n# Inverse transform the posterior predictive samples\npps = np.exp(pps) - 0.1\n\nfig, ax = plt.subplots(nrows=2, ncols=2, figsize=(12, 6), layout=\"constrained\")\nax = ax.flatten()\n\nsns.histplot(x=pps[0].flatten(), stat=\"density\", color=\"C0\", ax=ax[0])\nax[0].set(title=\"Basement (Posterior Predictive Distribution)\", xlabel=\"radon\", ylabel=\"Density\")\nsns.histplot(x=\"activity\", data=df.query(\"floor == 'Basement'\"), stat=\"density\", ax=ax[2])\nax[2].set(title=\"Basement (Sample Distribution)\", xlim=ax[0].get_xlim(), xlabel=\"radon\", ylabel=\"Density\")\n\nsns.histplot(x=pps[1].flatten(), stat=\"density\", color=\"C1\", ax=ax[1])\nax[1].set(title=\"Floor (Posterior Predictive Distribution)\", xlabel=\"radon\", ylabel=\"Density\")\nsns.histplot(x=\"activity\", data=df.query(\"floor == 'Floor'\"), stat=\"density\", color=\"C1\", ax=ax[3])\nax[3].set(title=\"Floor (Sample Distribution)\", xlim=ax[1].get_xlim(), xlabel=\"radon\", ylabel=\"Density\");\n\n/home/tomas/Desktop/OSS/bambinos/bambi/bambi/models.py:845: FutureWarning: 'pps' has been replaced by 'response' and is not going to work in the future\n  warnings.warn(\n/tmp/ipykernel_45847/1213510270.py:9: FutureWarning: extract_dataset has been deprecated, please use extract\n  pps = az.extract_dataset(pooled_results, group=\"posterior_predictive\")[\"log_radon\"].values\n\n\n\n\n\n\n\n\n\nThe distributions look very similar, but we see that we have some extreme values. Hence if we need a number to compare them let us use the median.\n\nnp.median(a=pps, axis=1)\n\narray([3.862334  , 2.07121177])\n\n\n\ndf.groupby([\"floor\"])[\"activity\"].median()\n\nfloor\nBasement    3.9\nFloor       2.1\nName: activity, dtype: float64\n\n\n\n\n\n\nNo Pooling\nThe following model uses both floor and county as predictors. They are represented with an interaction effect. It means the predicted radon level for a given measurement depends both on the floor level as well as the county. This interaction coefficient allows the floor effect to vary across counties. Or said analogously, the county effect can vary across floor levels.\n\nModel\n\\[\ny = \\gamma_{jk} + \\varepsilon\n\\]\nwhere\n\\[\n\\begin{aligned}\ny &= \\text{Response for the (log) radon measurement }\\\\\n\\gamma_{jk} &= \\text{Coefficient for floor level } j \\text{ and county } k\\\\\n\\varepsilon & = \\text{Residual random error}\n\\end{aligned}\n\\]\n\n\nPriors\n\nCommon effects\nThe common effect is the interaction between floor and county. The prior is\n\\[\n\\gamma_{jk} \\sim \\text{Normal}(0, \\sigma_{\\gamma_{jk}})\n\\]\nfor all \\(j: 1, 2\\) and \\(k: 1, \\cdots, 85\\).\n\\(\\sigma_{\\gamma_{jk}}\\) is a positive constant that we set to 10 in all cases.\n\n\nResidual error\n\\[\n\\begin{aligned}\n\\varepsilon_i & \\sim \\text{Normal}(0, \\sigma) \\\\\n\\sigma & \\sim \\text{Exponential}(\\lambda)\n\\end{aligned}\n\\] where \\(\\lambda\\) is a positive constant that we set to 1.\nTo specify this model in Bambi we can use the formula log_radon ~ 0 + county:floor. Again, we remove the global intercept with the 0 on the right hand side. county:floor specifies the multiplicative interaction between county and floor.\n\nunpooled_priors = {\n    \"county:floor\": bmb.Prior(\"Normal\", mu=0, sigma=10),\n    \"sigma\": bmb.Prior(\"Exponential\", lam=1),\n}\n\nunpooled_model = bmb.Model(\"log_radon ~ 0 + county:floor\", df, priors=unpooled_priors)\nunpooled_model\n\n       Formula: log_radon ~ 0 + county:floor\n        Family: gaussian\n          Link: mu = identity\n  Observations: 919\n        Priors: \n    target = mu\n        Common-level effects\n            county:floor ~ Normal(mu: 0.0, sigma: 10.0)\n        \n        Auxiliary parameters\n            sigma ~ Exponential(lam: 1.0)\n\n\n\nunpooled_results = unpooled_model.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, county:floor]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 36 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n\n\n\nunpooled_model.graph()\n\n\n\n\n\n\n\n\nFrom the graph representation of the model we see the model estimates \\(170 = 85 \\times 2\\) parameters for the county:floor interaction. Let us now explore the model fit.\nFirst, we can now see the plot of the marginal posterior distributions along with the sampling traces.\n\naz.plot_trace(data=unpooled_results, compact=True, chain_prop={\"ls\": \"-\"})\nplt.suptitle(\"Un-Pooled Model Trace\");\n\n\n\n\n\n\n\n\nSome posteriors for county:floor are much more spread than others, which makes it harder to compare them. To obtain a better summary visualization we can use a forest plot. This plot also allows us to identify exactly the combination of county and floor level.\n\naz.plot_forest(data=unpooled_results, figsize=(6, 32), r_hat=True, combined=True, textsize=8);\n\n\n\n\n\n\n\n\nNote how for the combination county == 'YELLOW MEDICINE' and floor == 'Floor' where we do not have any observations, the model can still generate predictions which are essentially coming from the prior distributions, which explains the large HDI intervals.\nNext, let’s have a look into the posterior mean for each county and floor combination:\n\nunpooled_summary = az.summary(data=unpooled_results)\n\nWe can now plot the posterior distribution mean of the gamma coefficients against the observed values (sample).\n\n# Get county and floor names from summary table\nvar_mapping = (\n    unpooled_summary\n    .iloc[:-1]\n    .reset_index(drop=False)[\"index\"].str.slice(13, -1).str.split(\",\").apply(pd.Series)\n)\n\nvar_mapping.rename(columns={0: \"county\", 1: \"floor\"}, inplace=True)\nvar_mapping[\"county\"] = var_mapping[\"county\"].str.strip()\nvar_mapping[\"floor\"] = var_mapping[\"floor\"].str.strip()\nvar_mapping.index = unpooled_summary.iloc[:-1].index\n    \n# Merge with observed values\nunpooled_summary_2 = pd.concat([var_mapping, unpooled_summary.iloc[:-1]], axis=1)\n\nfig, ax = plt.subplots(figsize=(7, 6))\n\n(\n    unpooled_summary_2\n    .merge(right=log_radon_county_agg, on=[\"county\", \"floor\"], how=\"left\")\n    .pipe(\n        (sns.scatterplot, \"data\"),\n        x=\"log_radon_mean\",\n        y=\"mean\",\n        hue=\"floor\",\n        ax=ax\n    )\n)\nax.axline(xy1=(1, 1), slope=1, color=\"black\", linestyle=\"--\", label=\"diagonal\")\nax.legend()\nax.set(\n    title=\"log(Radon + 0.1) Mean per County (Unpooled Model)\",\n    xlabel=\"observed (sample)\",\n    ylabel=\"prediction\",\n);\n\n\n\n\n\n\n\n\nAs expected, the values strongly concentrated along the diagonal. In other words, for each county and floor level combination, the model uses their sample mean of radon level as prediction, plus smoothing due to the non-flat priors.\nWhat does no pooling exactly mean here?\nIn the previous example we said complete pooling means the observations are pooled together into single estimates no matter the county they belong to. The situation is completely the opposite in this no pooling scenario. Here, none of the measurements in a given county affect the computation of the coefficient for another county. That’s why, in the end, the estimation for each combination of county and floor level (i.e. \\(\\gamma_{jk}\\)) is the mean of the measurements in that county and floor level (plus prior smoothing) as is reflected in the diagonal scatterplot above.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Hierarchical Linear Regression (Radon Contamination dataset)"
    ]
  },
  {
    "objectID": "notebooks/radon_example.html#multilevel-and-hierarchical-models",
    "href": "notebooks/radon_example.html#multilevel-and-hierarchical-models",
    "title": "Hierarchical Linear Regression (Radon Contamination dataset)",
    "section": "Multilevel and hierarchical models",
    "text": "Multilevel and hierarchical models\nIn this section we are going to explore various types of hierarchical models. If you’re familiar with the PyMC way of using hierarchies, the Bambi way (borrowed from mixed effects models way) may be a bit unfamiliar in the beginning, but as we will see, the notation is very convenient. A good explanation is found in Chapter 16 from Bayes Rules book, specifically section 16.3.2. Moreover, you can also take a look into the Bambi examples section where you can find other use cases.\n\nPartial pooling model\nWe start with a model that considers a global intercept and varying intercepts for each county. The dispersion parameter of the prior for these varying intercepts is an hyperprior that is common to all the counties. As we are going to conclude later, this is what causes the partial pooling in the model estimates.\n\nModel\nLet us use greek letters for common effects and roman letters for varying effects. In this case, \\(\\alpha\\) is a common intercept and \\(u\\) is a group-specific intercept.\n\\[\ny = \\alpha + u_j + \\varepsilon\n\\]\nwhere\n\\[\n\\begin{aligned}\ny &= \\text{Response for the (log) radon measurement } \\\\\n\\alpha &= \\text{Intercept common to all measurements or global intercept} \\\\\nu_j &= \\text{Intercept specific to the county } j \\\\\n\\varepsilon & = \\text{Residual random error}\n\\end{aligned}\n\\]\n\n\nPriors\n\nCommon effects\nThe only common effect in this model is the intercept \\(\\alpha\\). We have\n\\[\n\\alpha \\sim \\text{Normal}(0, \\sigma_\\alpha)\n\\]\nwhere \\(\\sigma_\\alpha\\) is a positive constant that we set to 10.\n\n\nGroup-specific effects\n\\[\nu_j \\sim \\text{Normal}(0, \\sigma_u)\n\\]\nfor all \\(j: 1, \\cdots, 85\\).\nContrary to the common effects case, \\(\\sigma_u\\) is considered a random variable.\nWe assign \\(\\sigma_u\\) the following hyperprior, which is the same to all the counties,\n\\[\n\\sigma_u\\sim \\text{Exponential}(\\tau)\n\\]\nand \\(\\tau\\) is a positive constant that we set to \\(1\\).\n\n\nResidual error\n\\[\n\\begin{aligned}\n\\varepsilon & \\sim \\text{Normal}(0, \\sigma) \\\\\n\\sigma & \\sim \\text{Exponential}(\\lambda)\n\\end{aligned}\n\\]\nwhere \\(\\lambda\\) is a positive constant that we set to 1.\n\n\n\nNotes\nThe common intercept \\(\\alpha\\) represents the mean response across all counties and floor levels.\nOn top of it, the county-specific intercept terms \\(u_j\\) represent county-specific deviations from that global mean. This type of term is also known as a vaying intercept in the statistical literature.\n\n# We can add the hyper-priors inside the prior dictionary parameter of the model constructor\npartial_pooling_priors = {\n    \"Intercept\": bmb.Prior(\"Normal\", mu=0, sigma=10),\n    \"1|county\": bmb.Prior(\"Normal\", mu=0, sigma=bmb.Prior(\"Exponential\", lam=1)),\n    \"sigma\": bmb.Prior(\"Exponential\", lam=1),\n}\n\npartial_pooling_model = bmb.Model(\n    formula=\"log_radon ~ 1 + (1|county)\", \n    data=df, \n    priors=partial_pooling_priors, \n    noncentered=False\n)\npartial_pooling_model\n\n       Formula: log_radon ~ 1 + (1|county)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 919\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 0.0, sigma: 10.0)\n        \n        Group-level effects\n            1|county ~ Normal(mu: 0.0, sigma: Exponential(lam: 1.0))\n        \n        Auxiliary parameters\n            sigma ~ Exponential(lam: 1.0)\n\n\nThe noncentered argument asks Bambi not to use the non centered representation for the varying effects. This makes the graph representation clearer and is closer to the original implementation in the PyMC documentation.\n\npartial_pooling_results = partial_pooling_model.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, 1|county_sigma, 1|county]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 6 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n\n\nWe can inspect the graphical representation of the model:\n\npartial_pooling_model.graph()\n\n\n\n\n\n\n\n\nWe can clearly see a new hierarchical level as compared to the complete pooling model and unpooled model.\nNext, we can plot the posterior distribution of the coefficients in the model:\n\naz.plot_trace(data=partial_pooling_results, compact=True, chain_prop={\"ls\": \"-\"})\nplt.suptitle(\"Partial Pooling Model Trace\");\n\n\n\n\n\n\n\n\n\n1|county is \\(u_j\\), the county-specific intercepts.\n1|county_sigma is \\(\\sigma_u\\), the standard deviation of the county-specific intercepts above.\n\nLet us now compare the posterior predictive mean against the observed data at county level.\n\npartial_pooling_results\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 1MB\nDimensions:             (chain: 2, draw: 1000, county__factor_dim: 85)\nCoordinates:\n  * chain               (chain) int64 16B 0 1\n  * draw                (draw) int64 8kB 0 1 2 3 4 5 ... 994 995 996 997 998 999\n  * county__factor_dim  (county__factor_dim) &lt;U17 6kB 'AITKIN' ... 'YELLOW ME...\nData variables:\n    1|county            (chain, draw, county__factor_dim) float64 1MB 0.1093 ...\n    1|county_sigma      (chain, draw) float64 16kB 0.3421 0.3602 ... 0.2518\n    Intercept           (chain, draw) float64 16kB 1.44 1.4 ... 1.301 1.295\n    sigma               (chain, draw) float64 16kB 0.7651 0.7419 ... 0.7995\nAttributes:\n    created_at:                  2024-05-26T22:50:19.814875+00:00\n    arviz_version:               0.18.0\n    inference_library:           pymc\n    inference_library_version:   5.15.0+23.g19be124e\n    sampling_time:               6.147133111953735\n    tuning_steps:                1000\n    modeling_interface:          bambi\n    modeling_interface_version:  0.13.1.dev39+gb7d6a6cbxarray.DatasetDimensions:chain: 2draw: 1000county__factor_dim: 85Coordinates: (3)chain(chain)int640 1array([0, 1])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])county__factor_dim(county__factor_dim)&lt;U17'AITKIN' ... 'YELLOW MEDICINE'array(['AITKIN', 'ANOKA', 'BECKER', 'BELTRAMI', 'BENTON', 'BIG STONE',\n       'BLUE EARTH', 'BROWN', 'CARLTON', 'CARVER', 'CASS', 'CHIPPEWA',\n       'CHISAGO', 'CLAY', 'CLEARWATER', 'COOK', 'COTTONWOOD', 'CROW WING',\n       'DAKOTA', 'DODGE', 'DOUGLAS', 'FARIBAULT', 'FILLMORE', 'FREEBORN',\n       'GOODHUE', 'HENNEPIN', 'HOUSTON', 'HUBBARD', 'ISANTI', 'ITASCA',\n       'JACKSON', 'KANABEC', 'KANDIYOHI', 'KITTSON', 'KOOCHICHING',\n       'LAC QUI PARLE', 'LAKE', 'LAKE OF THE WOODS', 'LE SUEUR', 'LINCOLN',\n       'LYON', 'MAHNOMEN', 'MARSHALL', 'MARTIN', 'MCLEOD', 'MEEKER',\n       'MILLE LACS', 'MORRISON', 'MOWER', 'MURRAY', 'NICOLLET', 'NOBLES',\n       'NORMAN', 'OLMSTED', 'OTTER TAIL', 'PENNINGTON', 'PINE', 'PIPESTONE',\n       'POLK', 'POPE', 'RAMSEY', 'REDWOOD', 'RENVILLE', 'RICE', 'ROCK',\n       'ROSEAU', 'SCOTT', 'SHERBURNE', 'SIBLEY', 'ST LOUIS', 'STEARNS',\n       'STEELE', 'STEVENS', 'SWIFT', 'TODD', 'TRAVERSE', 'WABASHA', 'WADENA',\n       'WASECA', 'WASHINGTON', 'WATONWAN', 'WILKIN', 'WINONA', 'WRIGHT',\n       'YELLOW MEDICINE'], dtype='&lt;U17')Data variables: (4)1|county(chain, draw, county__factor_dim)float640.1093 -0.5662 ... 0.325 -0.2251array([[[ 0.10925731, -0.566226  , -0.09000699, ..., -0.27306477,\n          0.23927698,  0.20538249],\n        [-0.61860104, -0.54807003, -0.17833427, ..., -0.13802683,\n         -0.29767395, -0.05617042],\n        [-0.02315516, -0.63490798, -0.1897692 , ..., -0.06686441,\n          0.14023241,  0.02202231],\n        ...,\n        [-0.30931644, -0.46458741, -0.37153588, ...,  0.11928815,\n          0.10271827,  0.12858761],\n        [-0.24246309, -0.42452553,  0.10190816, ...,  0.0297322 ,\n          0.31775183,  0.12238267],\n        [-0.11289643, -0.45281249, -0.0720627 , ..., -0.00316119,\n          0.109228  , -0.15858485]],\n\n       [[-0.48851576, -0.45108672,  0.09534777, ...,  0.40064506,\n          0.29706353, -0.5736238 ],\n        [-0.38335947, -0.45444664, -0.04944886, ...,  0.32466663,\n          0.46604097, -0.09875201],\n        [-0.172785  , -0.31658689, -0.02637731, ...,  0.02700598,\n          0.03342428,  0.17974528],\n        ...,\n        [ 0.10934748, -0.39886058,  0.27313887, ...,  0.16720247,\n          0.04149402, -0.07026582],\n        [-0.22966455, -0.24279823, -0.41640239, ...,  0.00669983,\n          0.16205345, -0.23887474],\n        [-0.06651367, -0.42916719,  0.15400986, ...,  0.34961275,\n          0.32496288, -0.22505465]]])1|county_sigma(chain, draw)float640.3421 0.3602 ... 0.2498 0.2518array([[0.34210321, 0.36021532, 0.29334103, ..., 0.28282012, 0.35124886,\n        0.33627169],\n       [0.31875038, 0.35045077, 0.33136916, ..., 0.22967175, 0.24982968,\n        0.25178762]])Intercept(chain, draw)float641.44 1.4 1.372 ... 1.301 1.295array([[1.44017201, 1.40006556, 1.37197719, ..., 1.37240347, 1.31568418,\n        1.36887556],\n       [1.34806946, 1.31749286, 1.31428794, ..., 1.33580165, 1.30139677,\n        1.29451323]])sigma(chain, draw)float640.7651 0.7419 ... 0.7604 0.7995array([[0.76509665, 0.74185114, 0.80634063, ..., 0.76435342, 0.76195412,\n        0.7711739 ],\n       [0.75649317, 0.73755021, 0.7870685 , ..., 0.75311483, 0.76044651,\n        0.79951296]])Indexes: (3)chainPandasIndexPandasIndex(Index([0, 1], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))county__factor_dimPandasIndexPandasIndex(Index(['AITKIN', 'ANOKA', 'BECKER', 'BELTRAMI', 'BENTON', 'BIG STONE',\n       'BLUE EARTH', 'BROWN', 'CARLTON', 'CARVER', 'CASS', 'CHIPPEWA',\n       'CHISAGO', 'CLAY', 'CLEARWATER', 'COOK', 'COTTONWOOD', 'CROW WING',\n       'DAKOTA', 'DODGE', 'DOUGLAS', 'FARIBAULT', 'FILLMORE', 'FREEBORN',\n       'GOODHUE', 'HENNEPIN', 'HOUSTON', 'HUBBARD', 'ISANTI', 'ITASCA',\n       'JACKSON', 'KANABEC', 'KANDIYOHI', 'KITTSON', 'KOOCHICHING',\n       'LAC QUI PARLE', 'LAKE', 'LAKE OF THE WOODS', 'LE SUEUR', 'LINCOLN',\n       'LYON', 'MAHNOMEN', 'MARSHALL', 'MARTIN', 'MCLEOD', 'MEEKER',\n       'MILLE LACS', 'MORRISON', 'MOWER', 'MURRAY', 'NICOLLET', 'NOBLES',\n       'NORMAN', 'OLMSTED', 'OTTER TAIL', 'PENNINGTON', 'PINE', 'PIPESTONE',\n       'POLK', 'POPE', 'RAMSEY', 'REDWOOD', 'RENVILLE', 'RICE', 'ROCK',\n       'ROSEAU', 'SCOTT', 'SHERBURNE', 'SIBLEY', 'ST LOUIS', 'STEARNS',\n       'STEELE', 'STEVENS', 'SWIFT', 'TODD', 'TRAVERSE', 'WABASHA', 'WADENA',\n       'WASECA', 'WASHINGTON', 'WATONWAN', 'WILKIN', 'WINONA', 'WRIGHT',\n       'YELLOW MEDICINE'],\n      dtype='object', name='county__factor_dim'))Attributes: (8)created_at :2024-05-26T22:50:19.814875+00:00arviz_version :0.18.0inference_library :pymcinference_library_version :5.15.0+23.g19be124esampling_time :6.147133111953735tuning_steps :1000modeling_interface :bambimodeling_interface_version :0.13.1.dev39+gb7d6a6cb\n                      \n                  \n            \n            \n            \n                  \n                  sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 252kB\nDimensions:                (chain: 2, draw: 1000)\nCoordinates:\n  * chain                  (chain) int64 16B 0 1\n  * draw                   (draw) int64 8kB 0 1 2 3 4 5 ... 995 996 997 998 999\nData variables: (12/17)\n    acceptance_rate        (chain, draw) float64 16kB 0.9844 0.986 ... 0.8069\n    diverging              (chain, draw) bool 2kB False False ... False False\n    energy                 (chain, draw) float64 16kB 1.133e+03 ... 1.111e+03\n    energy_error           (chain, draw) float64 16kB 0.1159 -0.4477 ... 0.4183\n    index_in_trajectory    (chain, draw) int64 16kB 5 -4 4 -4 -2 ... 6 -2 -4 -4\n    largest_eigval         (chain, draw) float64 16kB nan nan nan ... nan nan\n    ...                     ...\n    process_time_diff      (chain, draw) float64 16kB 0.001789 ... 0.001452\n    reached_max_treedepth  (chain, draw) bool 2kB False False ... False False\n    smallest_eigval        (chain, draw) float64 16kB nan nan nan ... nan nan\n    step_size              (chain, draw) float64 16kB 0.3948 0.3948 ... 0.3688\n    step_size_bar          (chain, draw) float64 16kB 0.467 0.467 ... 0.4521\n    tree_depth             (chain, draw) int64 16kB 3 3 3 3 3 3 ... 3 3 3 3 3 3\nAttributes:\n    created_at:                  2024-05-26T22:50:19.833200+00:00\n    arviz_version:               0.18.0\n    inference_library:           pymc\n    inference_library_version:   5.15.0+23.g19be124e\n    sampling_time:               6.147133111953735\n    tuning_steps:                1000\n    modeling_interface:          bambi\n    modeling_interface_version:  0.13.1.dev39+gb7d6a6cbxarray.DatasetDimensions:chain: 2draw: 1000Coordinates: (2)chain(chain)int640 1array([0, 1])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])Data variables: (17)acceptance_rate(chain, draw)float640.9844 0.986 ... 0.9234 0.8069array([[0.98436784, 0.98601233, 0.96124626, ..., 0.22486349, 0.33767736,\n        0.63248875],\n       [0.97609702, 0.54231738, 0.66807577, ..., 0.90569141, 0.92340586,\n        0.80685305]])diverging(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])energy(chain, draw)float641.133e+03 1.142e+03 ... 1.111e+03array([[1132.54289023, 1141.58447928, 1132.55888828, ..., 1124.70123514,\n        1120.42203721, 1137.91003849],\n       [1126.17947876, 1137.18871967, 1139.57160506, ..., 1132.34943256,\n        1117.88735552, 1110.58936884]])energy_error(chain, draw)float640.1159 -0.4477 ... -0.3531 0.4183array([[ 0.11588806, -0.44768874, -0.21160451, ...,  0.        ,\n         1.03675117,  0.92922675],\n       [-0.57963706,  0.26236369,  0.52248315, ..., -0.62318029,\n        -0.3531464 ,  0.41828798]])index_in_trajectory(chain, draw)int645 -4 4 -4 -2 5 ... -5 6 6 -2 -4 -4array([[ 5, -4,  4, ...,  0,  6, -3],\n       [-4, -2,  6, ..., -2, -4, -4]])largest_eigval(chain, draw)float64nan nan nan nan ... nan nan nan nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]])lp(chain, draw)float64-1.101e+03 ... -1.078e+03array([[-1100.61605617, -1089.20456285, -1085.37306441, ...,\n        -1070.8425698 , -1081.67979406, -1099.51643907],\n       [-1083.87244587, -1091.09546455, -1098.29189477, ...,\n        -1078.38308382, -1070.94143721, -1077.73397692]])max_energy_error(chain, draw)float64-0.8364 -0.4477 ... 0.4791 0.4183array([[-0.83641232, -0.44768874, -0.21160451, ...,  2.57007364,\n         1.75862866,  1.02220945],\n       [-0.90128732,  1.19021079,  0.93406381, ..., -0.94764139,\n         0.47910821,  0.41828798]])n_steps(chain, draw)float647.0 7.0 7.0 7.0 ... 7.0 7.0 7.0 7.0array([[7., 7., 7., ..., 7., 7., 7.],\n       [7., 7., 7., ..., 7., 7., 7.]])perf_counter_diff(chain, draw)float640.001788 0.002915 ... 0.001451array([[0.00178769, 0.00291476, 0.00231155, ..., 0.0017955 , 0.00293924,\n        0.00292779],\n       [0.00228063, 0.00151575, 0.00228206, ..., 0.00143171, 0.00142564,\n        0.00145092]])perf_counter_start(chain, draw)float641.254e+04 1.254e+04 ... 1.254e+04array([[12537.35090269, 12537.35459767, 12537.35781169, ...,\n        12539.52664598, 12539.52994777, 12539.53319831],\n       [12537.46978133, 12537.47228786, 12537.47398005, ...,\n        12539.76039464, 12539.76199041, 12539.76357576]])process_time_diff(chain, draw)float640.001789 0.002916 ... 0.001452array([[0.00178875, 0.00291601, 0.00231246, ..., 0.0017962 , 0.00294044,\n        0.00292832],\n       [0.00228178, 0.00151654, 0.00228368, ..., 0.00143229, 0.00142587,\n        0.00145171]])reached_max_treedepth(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])smallest_eigval(chain, draw)float64nan nan nan nan ... nan nan nan nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]])step_size(chain, draw)float640.3948 0.3948 ... 0.3688 0.3688array([[0.39478295, 0.39478295, 0.39478295, ..., 0.39478295, 0.39478295,\n        0.39478295],\n       [0.36879817, 0.36879817, 0.36879817, ..., 0.36879817, 0.36879817,\n        0.36879817]])step_size_bar(chain, draw)float640.467 0.467 0.467 ... 0.4521 0.4521array([[0.46704576, 0.46704576, 0.46704576, ..., 0.46704576, 0.46704576,\n        0.46704576],\n       [0.45208578, 0.45208578, 0.45208578, ..., 0.45208578, 0.45208578,\n        0.45208578]])tree_depth(chain, draw)int643 3 3 3 3 3 3 4 ... 3 3 3 3 3 3 3 3array([[3, 3, 3, ..., 3, 3, 3],\n       [3, 3, 3, ..., 3, 3, 3]])Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Attributes: (8)created_at :2024-05-26T22:50:19.833200+00:00arviz_version :0.18.0inference_library :pymcinference_library_version :5.15.0+23.g19be124esampling_time :6.147133111953735tuning_steps :1000modeling_interface :bambimodeling_interface_version :0.13.1.dev39+gb7d6a6cb\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 15kB\nDimensions:    (__obs__: 919)\nCoordinates:\n  * __obs__    (__obs__) int64 7kB 0 1 2 3 4 5 6 ... 912 913 914 915 916 917 918\nData variables:\n    log_radon  (__obs__) float64 7kB 1.435 1.03 0.2624 ... 0.0 2.219 0.8329\nAttributes:\n    created_at:                  2024-05-26T22:50:19.839116+00:00\n    arviz_version:               0.18.0\n    inference_library:           pymc\n    inference_library_version:   5.15.0+23.g19be124e\n    modeling_interface:          bambi\n    modeling_interface_version:  0.13.1.dev39+gb7d6a6cbxarray.DatasetDimensions:__obs__: 919Coordinates: (1)__obs__(__obs__)int640 1 2 3 4 5 ... 914 915 916 917 918array([  0,   1,   2, ..., 916, 917, 918])Data variables: (1)log_radon(__obs__)float641.435 1.03 0.2624 ... 2.219 0.8329array([ 1.43508453,  1.02961942,  0.26236426,  1.28093385,  1.7227666 ,\n        1.7227666 ,  0.26236426,  1.60943791,  1.41098697,  1.28093385,\n        0.95551145,  0.26236426,  1.02961942,  0.58778666,  1.16315081,\n       -0.22314355,  0.09531018,  0.69314718,  1.36097655,  2.19722458,\n        2.01490302,  1.80828877,  1.66770682,  1.84054963,  2.16332303,\n        1.45861502,  1.77495235,  1.43508453,  1.06471074,  0.69314718,\n        0.26236426,  0.47000363,  2.2512918 ,  0.58778666,  2.50143595,\n        1.94591015,  0.78845736,  2.27212589,  1.25276297,  1.93152141,\n        1.30833282,  0.83290912,  0.99325177,  0.78845736,  1.96009478,\n        0.26236426,  1.36097655,  1.28093385,  1.36097655,  2.28238239,\n        1.87180218,  1.54756251,  1.19392247,  0.95551145,  1.06471074,\n        1.16315081,  0.53062825,  1.56861592,  1.41098697,  1.62924054,\n        0.47000363,  1.58923521,  0.87546874, -0.10536052,  0.87546874,\n        1.54756251,  2.40694511,  2.7080502 ,  2.16332303,  1.5260563 ,\n        0.47000363,  1.38629436,  0.64185389,  0.53062825,  0.91629073,\n        1.36097655,  1.64865863,  1.70474809,  1.74046617,  2.94968834,\n        1.13140211,  1.64865863,  2.05412373,  2.10413415,  1.56861592,\n        2.14006616,  0.53062825,  2.44234704,  3.2308044 ,  2.34180581,\n        1.30833282,  1.02961942,  1.41098697,  0.74193734,  2.44234704,\n        2.3321439 ,  0.26236426,  1.19392247,  1.48160454,  0.83290912,\n...\n        0.40546511,  0.95551145,  1.06471074,  0.53062825,  1.06471074,\n        0.95551145,  2.32238772,  2.54160199,  0.78845736,  1.13140211,\n       -2.30258509,  1.06471074,  0.33647224,  2.43361336,  0.33647224,\n        0.        ,  1.5260563 ,  1.48160454,  1.09861229,  1.45861502,\n        1.28093385,  1.94591015,  0.47000363, -0.51082562,  0.        ,\n        0.18232156,  0.        , -0.51082562,  1.33500107, -0.10536052,\n        1.06471074,  0.83290912,  1.58923521,  0.18232156,  1.09861229,\n        0.53062825,  3.23867845,  0.40546511,  2.69462718,  3.03495299,\n        0.91629073,  0.58778666, -0.10536052,  0.58778666,  1.06471074,\n        1.98787435,  1.91692261,  0.95551145,  0.09531018,  0.95551145,\n        0.        , -2.30258509,  2.41591378,  1.19392247, -0.22314355,\n        0.83290912,  1.58923521,  1.94591015,  0.18232156,  0.64185389,\n        0.95551145,  1.28093385,  0.        ,  0.09531018,  0.99325177,\n        0.47000363, -2.30258509,  0.        ,  1.77495235,  1.28093385,\n        0.78845736,  2.29253476,  1.94591015,  1.74046617,  0.83290912,\n        1.80828877,  0.18232156,  1.48160454,  1.30833282,  1.25276297,\n        0.26236426,  0.58778666,  1.45861502, -0.10536052,  2.96527307,\n        0.95551145,  0.78845736,  0.33647224,  0.74193734,  1.33500107,\n       -0.51082562,  0.09531018,  0.40546511, -0.69314718, -0.51082562,\n        0.53062825,  0.        ,  2.21920348,  0.83290912])Indexes: (1)__obs__PandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       909, 910, 911, 912, 913, 914, 915, 916, 917, 918],\n      dtype='int64', name='__obs__', length=919))Attributes: (6)created_at :2024-05-26T22:50:19.839116+00:00arviz_version :0.18.0inference_library :pymcinference_library_version :5.15.0+23.g19be124emodeling_interface :bambimodeling_interface_version :0.13.1.dev39+gb7d6a6cb\n                      \n                  \n            \n            \n              \n            \n            \n\n\n\npartial_pooling_model.predict(partial_pooling_results, kind=\"pps\")\n\n# Stack chains and draws. pps stands for posterior predictive samples\npps = az.extract_dataset(partial_pooling_results, group=\"posterior_predictive\")[\"log_radon\"].values\n\npps_df = pd.DataFrame(data=pps).assign(county=df[\"county\"])\ny_pred = pps_df.groupby(\"county\").mean().mean(axis=1)\ny_sample = df.groupby(\"county\")[\"log_radon\"].mean()\n\nfig, ax = plt.subplots(figsize=(8, 7))\nsns.regplot(x=y_sample, y=y_pred, ax=ax)\nax.axline(xy1=(1, 1), slope=1, color=\"black\", linestyle=\"--\", label=\"diagonal\")\nax.axhline(y=y_pred.mean(), color=\"C3\", linestyle=\"--\", label=\"predicted global mean\")\nax.legend(loc=\"lower right\")\nax.set(\n    title=\"log(Radon + 0.1) Mean per County (Partial Pooling Model)\",\n    xlabel=\"observed (sample)\",\n    ylabel=\"prediction\",\n    xlim=(0.3, 2.7),\n    ylim=(0.3, 2.7),\n);\n\n/home/tomas/Desktop/OSS/bambinos/bambi/bambi/models.py:845: FutureWarning: 'pps' has been replaced by 'response' and is not going to work in the future\n  warnings.warn(\n/tmp/ipykernel_45847/3145587883.py:4: FutureWarning: extract_dataset has been deprecated, please use extract\n  pps = az.extract_dataset(partial_pooling_results, group=\"posterior_predictive\")[\"log_radon\"].values\n\n\n\n\n\n\n\n\n\nNote that in this case the points are not concentrated along the diagonal (as it was the case for the unpooled model). The reason is that in the partial pooling model the hyperprior shrinks the predictions towards the global mean, represented by the horizonital dashed line.\nWhat does partial pooling exactly mean here?\nWe said the first model we built performed a complete pooling because estimates pooled observations regardless to which county they belong to. We could see that in the coefficients for the floor variable. The estimate for each level was the sample mean for each level, plus prior smoothing, without making any special distinction to observations from different counties.\nThen, when we built our second model we said it performed no pooling. This was the opposite scenario. Estimates for effects involving a specific county were not informed at all by the information in the other counties.\nNow, we say this model performs partial pooling. But what does it mean? Well, if we had complete pooling and no pooling, this must be some type of compromise in between.\nIn this model, we have a global intercept \\(\\alpha\\), which represents the mean of the response variable across all counties. We also have group-specific intercepts \\(u_j\\) that represent deviations from the global mean specific to each county \\(j\\). Thess group-specific intercepts are assigned a Normal prior centered at 0. The standard deviations of these priors are considered random, instead of fixed. Since they are random, they are assigned a prior distribution, which is a hyperprior in this case because it is a prior on top of a prior. And that hyperprior is the same distribution for all the county-specific intercepts. Because of that, these random deviations from the global mean are not independent. Indeed, the shared hyperprior is what causes the partial pooling in the model estimates. In other words, some information is shared between counties when computing estimates for their effects and it results in a shrinkage towards the global mean.\nConnecting what we’ve just said with the figure above we can see the partial pooling is a compromise between complete pooling (global mean) and no pooling (diagonal).\n\n\n\nCounty-specific intercepts and common predictors\nNext, we add the floor global feature (i.e. does not depend on the county) into the model above. We remove the global intercept so Bambi keeps one coefficient for each floor level.\nIn the original PyMC example, this model is introduced under the Varying intercept model title. We feel that “County-specific intercepts and common predictors” is a more accurate representation of the model we build in Bambi. It is correct to say this is a varying intercept model, because of the county-specific intercepts, but so was the last model we built.\n\nModel\n\\[\ny = \\beta_j + u_k + \\varepsilon\n\\]\nwhere\n\\[\n\\begin{aligned}\ny &= \\text{Response for the (log) radon measurement } \\\\\n\\beta_j &= \\text{Coefficient for the floor level } j \\\\\nu_k &= \\text{Intercept specific to the county } k \\\\\n\\varepsilon & = \\text{Residual random error}\n\\end{aligned}\n\\]\n\n\nPriors\n\nCommon effects\nThe common effect in this model is the floor term \\(\\beta_j\\)\n\\[\n\\beta_j \\sim \\text{Normal}(0, \\sigma_{\\beta_j})\n\\]\nfor all \\(j: 1, 2\\) and \\(\\sigma_{\\beta_j}\\) is a positive constant that we set to \\(10\\).\n\n\nGroup-specific effects\n\\[\nu_k \\sim \\text{Normal}(0, \\sigma_u)\n\\]\nfor all \\(j:1, \\cdots, 85\\). The hyperprior is\n$$\n_u ()\n$$\nand \\(\\tau\\) is a positive constant that we set to \\(1\\).\n\n\nResidual error\n\\[\n\\begin{aligned}\n\\varepsilon & \\sim \\text{Normal}(0, \\sigma) \\\\\n\\sigma & \\sim \\text{Exponential}(\\lambda)\n\\end{aligned}\n\\]\nwhere \\(\\lambda\\) is a positive constant that we set to \\(1\\).\n\n\nNotes\n\\(\\beta_j\\) and \\(u_k\\) may look similar. The difference is that the latter is a hierarchical effect (it has a hyperprior), while the former is not.\n\nvarying_intercept_priors = {\n    \"floor\": bmb.Prior(\"Normal\", mu=0, sigma=10),\n    \"1|county\": bmb.Prior(\"Normal\", mu=0, sigma=bmb.Prior(\"Exponential\", lam=1)),\n    \"sigma\": bmb.Prior(\"Exponential\", lam=1),\n}\n\nvarying_intercept_model = bmb.Model(\n    formula=\"log_radon ~ 0 + floor + (1|county)\",\n    data=df,\n    priors=varying_intercept_priors,\n    noncentered=False\n )\n\nvarying_intercept_model\n\n       Formula: log_radon ~ 0 + floor + (1|county)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 919\n        Priors: \n    target = mu\n        Common-level effects\n            floor ~ Normal(mu: 0.0, sigma: 10.0)\n        \n        Group-level effects\n            1|county ~ Normal(mu: 0.0, sigma: Exponential(lam: 1.0))\n        \n        Auxiliary parameters\n            sigma ~ Exponential(lam: 1.0)\n\n\n\nvarying_intercept_results = varying_intercept_model.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, floor, 1|county_sigma, 1|county]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 7 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n\n\nWhen looking at the graph representation of the model we still see the hierarchical structure for the county varying intercepts, but we do not see it for the floor feature as expected.\n\nvarying_intercept_model.graph()\n\n\n\n\n\n\n\n\nLet us visualize the posterior distributions:\n\naz.plot_trace(data=varying_intercept_results, compact=True, chain_prop={\"ls\": \"-\"});\nplt.suptitle(\"Varying Intercepts Model Trace\");\n\n\n\n\n\n\n\n\n\n\n\n\nVarying intercept and slope model\nNext we want to include a hierarchical structure in the floor effect.\n\nModel\n\\[\ny = \\beta_j + b_{jk} + \\varepsilon\n\\]\nwhere\n\\[\n\\begin{aligned}\ny &= \\text{Response for the (log) radon measurement}\\\\\n\\beta_j &= \\text{Coefficient for the floor level } j \\\\\nb_{jk} &= \\text{Coefficient for the floor level } j \\text{ specific to the county } k\\\\\n\\varepsilon & = \\text{Residual random error}\n\\end{aligned}\n\\]\n\n\nPriors\n\nCommon effects\nThe common effect in this model is the floor term \\(\\beta_j\\)\n\\[\n\\beta_j \\sim \\text{Normal}(0, \\sigma_{\\beta_j})\n\\]\nwhere \\(\\sigma_{\\beta_j}\\) is a positive constant that we set to \\(10\\).\n\n\nGroup-specific effects\nHere, again, we have the floor effects\n\\[\nb_{jk} \\sim \\text{Normal}(0, \\sigma_{b_j})\n\\]\nfor \\(j:1, 2\\) and \\(k: 1, \\cdots, 85\\).\nThe hyperprior is\n\\[\n\\sigma_{b_j} \\sim \\text{Exponential}(\\tau)\n\\]\nfor \\(j:1, 2\\).\n\\(\\tau\\) is a positive constant that we set to \\(1\\).\n\n\nResidual error\n\\[\n\\begin{aligned}\n\\varepsilon & \\sim \\text{Normal}(0, \\sigma) \\\\\n\\sigma & \\sim \\text{Exponential}(\\lambda)\n\\end{aligned}\n\\]\nwhere \\(\\lambda\\) is a positive constant that we set to 1.\n\n\nNotes\nBoth \\(\\beta_j\\) and \\(b_{jk}\\) are floor effects. The difference is that the first one is a common effect, while the second is a group-specific effect. In other words, the second floor effect varies from county to county. These effects represent the county specific deviations from the common floor effect \\(\\beta_j\\). Because of the hyperprior, the \\(b_{jk}\\) effects aren’t independent and result in the partial-pooling effect.\nIn this case the Bambi model specification is quite easy, namely log_radon ~ 0 + floor + (0 + floor|county). This formula represents the following terms:\n\nThe first 0 tells we don’t want a global intercept.\nfloor is \\(\\beta_j\\). It says we want to include an effect for each floor level. Since there’s no global intercept, a coefficient for each level is included.\nThe 0 in (0 + floor|county) means we don’t want county-specific intercept. We need to explicitly turn it off as we did with the regular intercept.\nfloor|county is \\(b_{jk}\\), the county-specific floor coefficients. Again, since there’s no varying intercepot for the counties, this includes coefficients for both floor levels.\n\n\nvarying_intercept_slope_priors = {\n    \"floor\": bmb.Prior(\"Normal\", mu=0, sigma=10),\n    \"floor|county\": bmb.Prior(\"Normal\", mu=0, sigma=bmb.Prior(\"Exponential\", lam=1)),\n    \"sigma\": bmb.Prior(\"Exponential\", lam=1),\n}\n\nvarying_intercept_slope_model = bmb.Model(\n    formula=\"log_radon ~ 0 + floor + (0 + floor|county)\",\n    data=df,\n    priors=varying_intercept_slope_priors,\n    noncentered=True\n )\n\nvarying_intercept_slope_model\n\n       Formula: log_radon ~ 0 + floor + (0 + floor|county)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 919\n        Priors: \n    target = mu\n        Common-level effects\n            floor ~ Normal(mu: 0.0, sigma: 10.0)\n        \n        Group-level effects\n            floor|county ~ Normal(mu: 0.0, sigma: Exponential(lam: 1.0))\n        \n        Auxiliary parameters\n            sigma ~ Exponential(lam: 1.0)\n\n\nNext, we fit the model. Note we increase the default number of draws from the posterior and the tune samples to 2000. In addition, as the structure of the model gets more complex, so does the posterior. That’s why we increase target_accept from the default 0.8 to 0.9, because we want to explore the posterior more cautiously .\n\nvarying_intercept_slope_results = varying_intercept_slope_model.fit(\n    draws=2000, \n    tune=2000,\n    target_accept=0.9\n)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, floor, floor|county_sigma, floor|county_offset]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 2_000 tune and 2_000 draw iterations (4_000 + 4_000 draws total) took 27 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\nIn the graph representation of the model we can now see hierarchical structures both in the intercepts and the slopes. The terms that end with _offset appeared because we are using a non-centered parametrization. This parametrization is an algebraic trick that helps computation but leaves the model unchanged.\n\nvarying_intercept_slope_model.graph()\n\n\n\n\n\n\n\n\nLet’s have a look at the marginal posterior for the coefficients in the model.\n\nvar_names = [\"floor\", \"floor|county\", \"floor|county_sigma\", \"sigma\"]\naz.plot_trace(\n    data=varying_intercept_slope_results,\n    var_names=var_names, \n    compact=True, \n    chain_prop={\"ls\": \"-\"}\n);\n\n\n\n\n\n\n\n\n\n\n\n\nAdding group-level predictors\nWe now want to consider a county-level predictor, namely the (log) uranium level. This is not a county-level predictor in the sense that we use a county-specific coefficient, but in the sense that all the uranium concentrations were measured per county. Thus all the houses in the same county have the same uranium level.\n\nModel\n\\[\ny = \\beta_j + \\xi x + b_{jk} + \\varepsilon\n\\]\nwhere\n\\[\n\\begin{aligned}\ny &= \\text{Response for the (log) radon measurement} \\\\\nx &= \\text{Log uranium concentration} \\\\\n\\beta_j &= \\text{Coefficient for the floor level } j \\\\\n\\xi &= \\text{Coefficient for the slope of the log uranium concentration}\\\\\nb_{jk} &= \\text{Coefficient for the floor level } j \\text{ specific to the county } k\\\\\n\\varepsilon & = \\text{Residual random error}\n\\end{aligned}\n\\]\n\n\nPriors\n\nCommon effects\nThis model has two common effects:\n\\[\n\\begin{aligned}\n\\beta_j \\sim \\text{Normal}(0, \\sigma_{\\beta_j}) \\\\\n\\xi \\sim \\text{Normal}(0, \\sigma_\\xi)\n\\end{aligned}\n\\]\nwhere \\(j:1, 2\\) and all \\(\\sigma_{\\beta_j}\\) and \\(\\sigma_{\\xi}\\) are set to \\(10\\).\n\n\nGroup-specific effects\nHere, again, we have the floor effects\n\\[\nb_{jk} \\sim \\text{Normal}(0, \\sigma_{b_j})\n\\]\nfor \\(j:1, 2\\) and \\(k: 1, \\cdots, 85\\).\nThe hyperprior is\n\\[\n\\sigma_{b_j} \\sim \\text{Exponential}(\\tau)\n\\]\nfor \\(j:1, 2\\).\n\\(\\tau\\) is a positive constant that we set to \\(1\\).\n\n\nResidual error\n\\[\n\\begin{aligned}\n\\varepsilon & \\sim \\text{Normal}(0, \\sigma) \\\\\n\\sigma & \\sim \\text{Exponential}(\\lambda)\n\\end{aligned}\n\\]\nwhere \\(\\lambda\\) is a positive constant that we set to \\(1\\).\n\ncovariate_priors = {\n    \"floor\": bmb.Prior(\"Normal\", mu=0, sigma=10),\n    \"log_u\": bmb.Prior(\"Normal\", mu=0, sigma=10),\n    \"floor|county\": bmb.Prior(\"Normal\", mu=0, sigma=bmb.Prior(\"Exponential\", lam=1)),\n    \"sigma\": bmb.Prior(\"Exponential\", lam=1),\n}\n\ncovariate_model = bmb.Model(\n    formula=\"log_radon ~ 0 + floor + log_u + (0 + floor|county)\",\n    data=df,\n    priors=covariate_priors,\n    noncentered=True\n )\n\ncovariate_model\n\n       Formula: log_radon ~ 0 + floor + log_u + (0 + floor|county)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 919\n        Priors: \n    target = mu\n        Common-level effects\n            floor ~ Normal(mu: 0.0, sigma: 10.0)\n            log_u ~ Normal(mu: 0.0, sigma: 10.0)\n        \n        Group-level effects\n            floor|county ~ Normal(mu: 0.0, sigma: Exponential(lam: 1.0))\n        \n        Auxiliary parameters\n            sigma ~ Exponential(lam: 1.0)\n\n\n\ncovariate_results = covariate_model.fit(\n    draws=2000, \n    tune=2000,\n    target_accept=0.9,\n    chains=2\n)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, floor, log_u, floor|county_sigma, floor|county_offset]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 2_000 tune and 2_000 draw iterations (4_000 + 4_000 draws total) took 39 seconds.\nThere were 3 divergences after tuning. Increase `target_accept` or reparameterize.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\ncovariate_model.graph()\n\n\n\n\n\n\n\n\n\nvar_names = [\"floor\", \"log_u\", \"floor|county\", \"floor|county_sigma\", \"sigma\"]\naz.plot_trace(\n    data=covariate_results,\n    var_names=var_names, \n    compact=True, \n    chain_prop={\"ls\": \"-\"}\n);\n\n\n\n\n\n\n\n\nLet us now visualize the posterior distributions of the intercepts:\n\n# get log_u values per county\nlog_u_sample = df.groupby([\"county\"])[\"log_u\"].mean().values\n\n# compute the slope posterior samples\nlog_u_slope = covariate_results.posterior[\"log_u\"].values[..., None] * log_u_sample\n\n# Compute the posterior for the floor coefficient when it is Basement\nintercepts = (\n    covariate_results.posterior.sel(floor_dim=\"Basement\")[\"floor\"]\n    + covariate_results.posterior.sel(floor__expr_dim=\"Basement\")[\"floor|county\"] \n).values\n\ny_predicted = (intercepts + log_u_slope).reshape(4000, n_counties).T\n\n# reduce the intercepts posterior samples to the mean per county\nmean_intercept = intercepts.mean(axis=2)[..., None] + log_u_slope\n\n\nfig, ax = plt.subplots()\n\ny_predicted_bounds = np.quantile(y_predicted, q=[0.03, 0.96], axis=1)\n\nsns.scatterplot(\n    x=log_u_sample,\n    y=y_predicted.mean(axis=1),\n    alpha=0.8,\n    color=\"C0\",\n    s=50,\n    label=\"Mean county-intercept\",\n    ax=ax\n)\nax.vlines(log_u_sample, y_predicted_bounds[0], y_predicted_bounds[1], color=\"C1\", alpha=0.5)\n\naz.plot_hdi(\n    x=log_u_sample,\n    y=mean_intercept,\n    color=\"black\",\n    fill_kwargs={\"alpha\": 0.1, \"label\": \"Mean intercept HPD\"},\n    ax=ax\n)\n\nsns.lineplot(\n    x=log_u_sample,\n    y=mean_intercept.reshape(4000, n_counties).mean(axis=0),\n    color=\"black\",\n    alpha=0.6,\n    label=\"Mean intercept\",\n    ax=ax\n)\n\nax.legend(loc=\"upper left\")\nax.set(\n    title=\"County Intercepts (Covariance Model)\",\n    xlabel=\"County-level log uranium\",\n    ylabel=\"Intercept estimate\"\n);",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Hierarchical Linear Regression (Radon Contamination dataset)"
    ]
  },
  {
    "objectID": "notebooks/radon_example.html#summary",
    "href": "notebooks/radon_example.html#summary",
    "title": "Hierarchical Linear Regression (Radon Contamination dataset)",
    "section": "Summary",
    "text": "Summary\nLet us dig deeper into the model comparison for the pooled, unpooled, and partial pooling models. To do so we are generate predictions for each model ad county level, where we aggregate by taking the mean, and plot them against the observed values.\n\n# generate posterior predictive samples\npooled_model.predict(pooled_results, kind=\"response\")\nunpooled_model.predict(unpooled_results, kind=\"response\")\npartial_pooling_model.predict(partial_pooling_results, kind=\"response\")\n\n# stack chain and draw values\npooled_pps = az.extract_dataset(pooled_results, group=\"posterior_predictive\")[\"log_radon\"].values\nunpooled_pps = az.extract_dataset(unpooled_results, group=\"posterior_predictive\")[\"log_radon\"].values\npartial_pooling_pps = az.extract_dataset(partial_pooling_results, group=\"posterior_predictive\")[\"log_radon\"].values\n\n# Generate predictions per county\npooled_pps_df = pd.DataFrame(data=pooled_pps).assign(county=df[\"county\"])\ny_pred_pooled = pooled_pps_df.groupby(\"county\").mean().mean(axis=1)\n\nunpooled_pps_df = pd.DataFrame(data=unpooled_pps).assign(county=df[\"county\"])\ny_pred_unpooled = unpooled_pps_df.groupby(\"county\").mean().mean(axis=1)\n\npartial_pooling_pps_df = pd.DataFrame(data=partial_pooling_pps).assign(county=df[\"county\"])\ny_pred_partial_pooling = partial_pooling_pps_df.groupby(\"county\").mean().mean(axis=1)\n\n# observed values\ny_sample = df.groupby(\"county\")[\"log_radon\"].mean()\n\n/tmp/ipykernel_45847/1610299561.py:7: FutureWarning: extract_dataset has been deprecated, please use extract\n  pooled_pps = az.extract_dataset(pooled_results, group=\"posterior_predictive\")[\"log_radon\"].values\n/tmp/ipykernel_45847/1610299561.py:8: FutureWarning: extract_dataset has been deprecated, please use extract\n  unpooled_pps = az.extract_dataset(unpooled_results, group=\"posterior_predictive\")[\"log_radon\"].values\n/tmp/ipykernel_45847/1610299561.py:9: FutureWarning: extract_dataset has been deprecated, please use extract\n  partial_pooling_pps = az.extract_dataset(partial_pooling_results, group=\"posterior_predictive\")[\"log_radon\"].values\n\n\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\nsns.regplot(x=y_sample, y=y_pred_pooled, label=\"pooled\", color=\"C0\", ax=ax)\nsns.regplot(x=y_sample, y=y_pred_unpooled, label=\"unpooled\", color=\"C1\", ax=ax)\nsns.regplot(x=y_sample, y=y_pred_partial_pooling, label=\"partial pooling\", color=\"C2\", ax=ax)\nax.axhline(y=df[\"log_radon\"].mean(), color=\"C0\", linestyle=\"--\", label=\"sample mean\")\nax.axline(xy1=(1, 1), slope=1, color=\"black\", linestyle=\"--\", label=\"diagonal\")\nax.axhline(\n    y=y_pred_partial_pooling.mean(), color=\"C3\",\n    linestyle=\"--\", label=\"predicted global mean (partial pooling)\"\n)\nax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.1), ncol=2)\nax.set(\n    title=\"log(Radon + 0.1) Mean per County - Model Comparison\",\n    xlabel=\"observed (sample)\",\n    ylabel=\"prediction\",\n    xlim=(0.2, 2.8),\n    ylim=(0.2, 2.8),\n);\n\n\n\n\n\n\n\n\n\nThe pooled model consider all the counties together, this explains why the predictions do not vary at county level. This is represented by the almost-flat line in the plot above (blue).\nOn the other hand, the unpooled model considers each county separately, so the prediction is very close to the observation mean. This is represented by the line very close to the diagonal (orange).\nThe partial pooling model is mixing global and information at county level. This is clearly seen by how corresponding (green) line is in between the pooling and unpooling lines.\n\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sun May 26 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\nseaborn   : 0.13.2\nmatplotlib: 3.8.4\npymc      : 5.15.0+23.g19be124e\nbambi     : 0.13.1.dev39+gb7d6a6cb\nnumpy     : 1.26.4\npandas    : 2.2.2\narviz     : 0.18.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Hierarchical Linear Regression (Radon Contamination dataset)"
    ]
  },
  {
    "objectID": "notebooks/sleepstudy.html",
    "href": "notebooks/sleepstudy.html",
    "title": "Hierarchical Linear Regression (Sleepstudy example)",
    "section": "",
    "text": "import arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\naz.style.use(\"arviz-darkgrid\")\nSEED = 7355608\nIn this example we are going to use sleepstudy dataset. It is derived from the study described in Belenky et al. (2003) and popularized in the lme4 R package. This dataset contains the average reaction time per day (in milliseconds) on a series of tests for the most sleep-deprived group in a sleep deprivation study. The first two days of the study are considered as adaptation and training, the third day is a baseline, and sleep deprivation started after day 3. The subjects in this group were restricted to 3 hours of sleep per night.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Hierarchical Linear Regression (Sleepstudy example)"
    ]
  },
  {
    "objectID": "notebooks/sleepstudy.html#load-data",
    "href": "notebooks/sleepstudy.html#load-data",
    "title": "Hierarchical Linear Regression (Sleepstudy example)",
    "section": "Load data",
    "text": "Load data\nThe sleepstudy dataset can be loaded using the load_data() function:\n\ndata = bmb.load_data(\"sleepstudy\")\ndata\n\n\n\n\n\n\n\n\nReaction\nDays\nSubject\n\n\n\n\n0\n249.5600\n0\n308\n\n\n1\n258.7047\n1\n308\n\n\n2\n250.8006\n2\n308\n\n\n3\n321.4398\n3\n308\n\n\n4\n356.8519\n4\n308\n\n\n...\n...\n...\n...\n\n\n175\n329.6076\n5\n372\n\n\n176\n334.4818\n6\n372\n\n\n177\n343.2199\n7\n372\n\n\n178\n369.1417\n8\n372\n\n\n179\n364.1236\n9\n372\n\n\n\n\n180 rows × 3 columns\n\n\n\nThe response variable is Reaction, the average of the reaction time measurements on a given subject for a given day. The two covariates are Days, the number of days of sleep deprivation, and Subject, the identifier of the subject on which the observation was made.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Hierarchical Linear Regression (Sleepstudy example)"
    ]
  },
  {
    "objectID": "notebooks/sleepstudy.html#explore-data",
    "href": "notebooks/sleepstudy.html#explore-data",
    "title": "Hierarchical Linear Regression (Sleepstudy example)",
    "section": "Explore data",
    "text": "Explore data\nLet’s get started by displaying the data in a multi-panel layout. There’s a panel for each subject in the study. This allows us to observe and compare the association of Days and Reaction between subjects.\n\ndef plot_data(data):\n    fig, axes = plt.subplots(2, 9, figsize=(16, 7.5), sharey=True, sharex=True, dpi=300, constrained_layout=False)\n    fig.subplots_adjust(left=0.075, right=0.975, bottom=0.075, top=0.925, wspace=0.03)\n\n    axes_flat = axes.ravel()\n\n    for i, subject in enumerate(data[\"Subject\"].unique()):\n        ax = axes_flat[i]\n        idx = data.index[data[\"Subject\"] == subject].tolist()\n        days = data.loc[idx, \"Days\"].values\n        reaction = data.loc[idx, \"Reaction\"].values\n\n        # Plot observed data points\n        ax.scatter(days, reaction, color=\"C0\", ec=\"black\", alpha=0.7)\n\n        # Add a title\n        ax.set_title(f\"Subject: {subject}\", fontsize=14)\n\n    ax.xaxis.set_ticks([0, 2, 4, 6, 8])\n    fig.text(0.5, 0.02, \"Days\", fontsize=14)\n    fig.text(0.03, 0.5, \"Reaction time (ms)\", rotation=90, fontsize=14, va=\"center\")\n\n    return axes\n\n\nplot_data(data);\n\n\n\n\n\n\n\n\nFor most of the subjects, there’s a clear positive association between Days and Reaction time. Reaction times increase as people accumulate more days of sleep deprivation. Participants differ in the initial reaction times as well as in the association between sleep deprivation and reaction time. Reaction times increase faster for some subjects and slower for others. Finally, the relationship between Days and Reaction time presents some deviations from linearity within the panels, but these are neither substantial nor systematic.",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Hierarchical Linear Regression (Sleepstudy example)"
    ]
  },
  {
    "objectID": "notebooks/sleepstudy.html#the-model",
    "href": "notebooks/sleepstudy.html#the-model",
    "title": "Hierarchical Linear Regression (Sleepstudy example)",
    "section": "The model",
    "text": "The model\nOur main goal is to measure the association between Days and Reaction times. We are interested both in the common effect across all subjects, as well as the effects associated with each individual. To do this, we’re going to use a hierarchical linear regression model that includes the effect of a common intercept and slope, as well as intercepts and slopes specific to each subject. These types of effects are also known as fixed and random effects in the statistical literature.\nThe model can be written as follows:\n\\[\n\\begin{aligned}\n\\text{Reaction}_i & \\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i & = \\beta_{\\text{Intercept}[i]} + \\beta_{\\text{Days}[i]}\\text{Days}_i \\\\\n\\beta_{\\text{Intercept}[i]} & = \\beta_{\\text{Intercept}} + \\alpha_{\\text{Intercept}_i}\\\\\n\\beta_{\\text{Days}[i]} & = \\beta_{\\text{Days}} + \\alpha_{\\text{Days}_i}\\\\\n\\end{aligned}\n\\]\nwhere \\(\\beta_{\\text{Intercept}}\\) and \\(\\beta_{\\text{Days}}\\) are the intercept and day slope effects common to all subjects in the study, and \\(\\alpha_{\\text{Intercept}_i}\\) and \\(\\alpha_{\\text{Days}_i}\\) are the subject-specific intercept and slope effects. These group-specific effects represent the deviation of each subject from the average behavior.\nNote we’re not describing the prior distributions for \\(\\beta_{\\text{Intercept}}\\), \\(\\beta_{\\text{Days}}\\), \\(\\alpha_{\\text{Intercept}_i}\\), \\(\\alpha_{\\text{Days}_i}\\), and \\(\\sigma\\) because we’re going to use default priors in Bambi.\nNext, let’s create the Bambi model. Here we use the formula syntax to specify the model in a clear and concise manner. The term on the left side of ~ tells Reaction is the response variable. The Days term on the right-hand side tells we want to include a slope effect for the Days variable common to all subjects. (Days | Subject) indicates the Days slope for a given subject is going to consist of the common slope plus a deviation specific to that subject. The common and subject-specific intercepts are added implicitly. We could suppress them by adding a 0 on the common or the group-specific part of the formula (e.g. 0 + Days + (0 + Days|Subject)).\nIf we wanted subject-specific intercepts, but not subjec-specific slopes we would have written Reaction ~ Days + (1 | Subject) and if we wanted slopes specific to each Subject without including a Subject specific intercept, we would write Reaction ~ Days + (0 + Days | Subject).\nThat’s been quite a long introduction for the model. Let’s write it down in code now:\n\nmodel = bmb.Model(\"Reaction ~ 1 + Days + (Days | Subject)\", data, categorical=\"Subject\")\n\nA description of the model and the priors can be obtained by simply printing the model object\n\nmodel\n\n       Formula: Reaction ~ 1 + Days + (Days | Subject)\n        Family: gaussian\n          Link: mu = identity\n  Observations: 180\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 298.5079, sigma: 261.0092)\n            Days ~ Normal(mu: 0.0, sigma: 48.8915)\n        \n        Group-level effects\n            1|Subject ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 261.0092))\n            Days|Subject ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 48.8915))\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 56.1721)\n\n\nThere we see the formula used to specify the model, the name of the response distribution (Gaussian), the link function (identity), together with the number of observations (180). Below, we have a description of the prior distributions for the different terms in the model. This tells Bambi is using Normal priors for both common and group-specific terms, and a HalfStudentT distribution for the residual error term of the linear regression.\nNow it’s time to hit the inference button. In Bambi, it is as simple as using the .fit() method. This returns an InferenceData object from the ArviZ library. The draws=2000 argument asks the sampler to obtain 2000 draws from the posterior for each chain.\n\nidata = model.fit(draws=2000, random_seed=SEED)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, Days, 1|Subject_sigma, 1|Subject_offset, Days|Subject_sigma, Days|Subject_offset]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 2_000 draw iterations (2_000 + 4_000 draws total) took 27 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Hierarchical Linear Regression (Sleepstudy example)"
    ]
  },
  {
    "objectID": "notebooks/sleepstudy.html#analyze-results",
    "href": "notebooks/sleepstudy.html#analyze-results",
    "title": "Hierarchical Linear Regression (Sleepstudy example)",
    "section": "Analyze results",
    "text": "Analyze results\nFirst of all, let’s obtain a summary of the posterior distribution of the Intercept and Days effects.\n\naz.summary(idata, var_names=[\"Intercept\", \"Days\"], kind=\"stats\")\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\nIntercept\n251.617\n7.472\n237.991\n266.122\n\n\nDays\n10.471\n1.708\n7.373\n13.710\n\n\n\n\n\n\n\nOn average, people’s average reaction time at the beginning of the study is between 235 and 265 milliseconds. With every extra day of sleep deprivation, the mean reaction times increase, on average, between 7.2 and 13.9 milliseconds.\nSo far so good with the interpretation of the common effects. It’s quite straightforward and simple. But this analysis would be incomplete and misleading if we don’t evaluate the subject-specific terms we added to the model. These terms are telling us how much subjects differ from each other in terms of the initial reaction time and the association between days of sleep deprivation and reaction times.\nBelow we use ArviZ to obtain a traceplot of the subject-specific intercepts 1|Subject and slopes Days|Subject. This traceplot contains two columns. On the left, we have the posterior distributions that we analyze below, and on the right, we have the draws from the posterior in the order the sampler draw them for us. The stationary random pattern, or white noise appearence, tells us the sampler converged and the chains mixed well.\nFrom the range of the posteriors of the subject-specific intercepts we can see the initial mean reaction time for a given subject can differ substantially from the general mean we see in the table above. There’s also a large difference in the slopes. Some subjects see their reaction times increase quite rapidly as they’re deprived from sleep, while others have a better tolerance and get worse more slowly. Finally, from the pink posterior centered at ~ -11, there seems to be one person who gets better at reaction times. Looks like they took this as a serious challenge!\nIn summary, the model is capturing the behavior we saw in the data exploration stage. People differ both in the initial reaction times as well as in how these reaction times are affected by the successive days of sleep deprivation.\n\naz.plot_trace(idata, var_names=[\"1|Subject\", \"Days|Subject\"]);\n\n\n\n\n\n\n\n\nSo far, we’ve made the following conclusions\n\nPeople’s mean reaction time increase as they are deprived from sleep.\nPeople have different reaction times in the beginning of the study.\nSome people are more affected by sleep deprivation than others.\n\nBut there’s another question we haven’t answered yet: Are the initial reaction times associated with how much the sleep deprivation affects the evolution of reaction times? Let’s create a scatterplot to visualize the joint posterior of the subject-specific intercepts and slopes. This chart uses different colors for the individuals.\n\n#  extract a subsample from the posterior and stack the chain and draw dims \nposterior = az.extract(idata, num_samples=500)\n\n_, ax = plt.subplots()\n\nidata.posterior.plot.scatter(\n    x=\"1|Subject\", y=\"Days|Subject\",\n    hue=\"Subject__factor_dim\",\n    add_colorbar=False,\n    add_legend=False,\n    cmap=\"tab20\",\n    edgecolors=None,\n)                      \n\nax.axhline(c=\"0.25\", ls=\"--\")\nax.axvline(c=\"0.25\", ls=\"--\")\nax.set_xlabel(\"Subject-specific intercept\")\nax.set_ylabel(\"Subject-specific slope\");\n\n\n\n\n\n\n\n\nIf we look at the bigger picture, i.e omitting the groups, we can conclude there’s no association between the intercept and slope. In other words, having lower or higher intial reaction times does not say anything about how much sleep deprivation affects the average reaction time on a given subject.\nOn the other hand, if we look at the joint posterior for a given individual, we can see a negative correlation between the intercept and the slope. This is telling that, conditional on a given subject, the intercept and slope posteriors are not independent. However, it doesn’t imply anything about the overall relationship between the intercept and the slope, which is what we need if we want to know whether the initial time is associated with how much sleep deprivation affects the reaction time.\nTo conclude with this example, we’re going create the same plot we created in the beginning with the mean regression lines and a credible bands for them.\n\n# Obtain the posterior of the mean\nmodel.predict(idata)\n\n# Plot the data\naxes = plot_data(data)\n\n# Take the posterior of the mean reaction time\nreaction_mean = az.extract(idata)[\"mu\"].values\n\nfor subject, ax in zip(data[\"Subject\"].unique(), axes.ravel()):\n\n    idx = data.index[data[\"Subject\"]== subject].tolist()\n    days = data.loc[idx, \"Days\"].values\n    \n    # Plot highest density interval / credibility interval\n    az.plot_hdi(days, reaction_mean[idx].T[np.newaxis], color=\"C0\", ax=ax)\n    \n    # Plot mean regression line\n    ax.plot(days, reaction_mean[idx].mean(axis=1), color=\"C0\")\n\n\n\n\n\n\n\n\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sun May 26 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\nnumpy     : 1.26.4\nmatplotlib: 3.8.4\narviz     : 0.18.0\npandas    : 2.2.2\nbambi     : 0.13.1.dev39+gb7d6a6cb\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Hierarchical Linear Regression (Sleepstudy example)"
    ]
  },
  {
    "objectID": "notebooks/survival_model.html",
    "href": "notebooks/survival_model.html",
    "title": "Survival Models",
    "section": "",
    "text": "Survival models, also known as time-to-event models, are specialized statistical methods designed to analyze the time until the occurrence of an event of interest. In this notebook, a review of survival analysis (using non-parametric and parametric methods) and censored data is provided, followed by a survival model implementation in Bambi.",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Survival Models"
    ]
  },
  {
    "objectID": "notebooks/survival_model.html#survival-and-censoring-times",
    "href": "notebooks/survival_model.html#survival-and-censoring-times",
    "title": "Survival Models",
    "section": "Survival and censoring times",
    "text": "Survival and censoring times\nSometimes the right way to model discrete, countable events is to model not the counts themselves but rather the time between events. This gives us information regarding the rate of an event. Survival models are models for countable things, but the outcomes we want to predict are durations. Durations are continuous deviations from some point of reference (so they are all positive values).\nThe tricky part with survival models is not the probability distribution assigned to the durations, but dealing with censoring. Censoring occurs when the event of interest does not occur in the window of observation. In a simple scenario, this can happen because the observation period ends before the event occurred. Censored individuals (or units) can not just be dropped from the sample. As an example, we use Richard McElreath’s cat adoption example from chapter 11.4 of Statistical Rethinking: Imagine a cohort of 100 cats who start waiting for adoption at the same time. After one month, half of them have been adopted. Now what is the rate of adoption? You can’t compute it using only the cats who have been adopted. You need to also account for the cats who haven’t yet been adopted. The cats who haven’t been adopted yet, but eventually will be adopted, clearly have longer waiting times than the cats who have already been adopted. So the average rate among those who are already adopted is biased upwards—it is confounded by conditioning on adoption.\nIncluding censored observations requires a new type of model. The key idea is that the same distribution assumption for the outcome tells us both the probability of any observed duration that end in the event as well as the probability that we would wait the observed duration without seeing the event. For each unit, we assume there is a true survival time \\(T\\) as well as a true censoring time \\(C\\). The survival time represents the time at which the event of interest occurs. The censoring time is the time at which censoring occurs. We observe either: the survival, or the censoring time:\n\\[Y = \\text{min}(T, C)\\]\nIf the event occurs, then we observe the survival time, else we observe the censoring time. In order to analyze survival data, we first need to understand the two types of censoring: left and right censoring, and how to estimate the survival function.",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Survival Models"
    ]
  },
  {
    "objectID": "notebooks/survival_model.html#left-and-right-censoring",
    "href": "notebooks/survival_model.html#left-and-right-censoring",
    "title": "Survival Models",
    "section": "Left and right censoring",
    "text": "Left and right censoring\nThere are two main “types” of censoring: right and left. Right censoring occurs when \\(T \\ge Y\\), i.e. the true event time \\(T\\) is at least as large as the observed time \\(Y\\). This is a consequence of \\(Y = \\text{min}(T, C)\\). Right censoring derives its name from the notion that time is typically read and displayed from left to right. Left sensoring occurs when the true event time \\(T\\) is less than or equal to the observed time \\(Y\\). An example of left censoring could be in a study of pregnancy duration. Suppose that patients are surveyed 250 days (8.2 months) after conception. Some patients may have already had their babies. For these patients, pregnancy duration is less than 250 days.",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Survival Models"
    ]
  },
  {
    "objectID": "notebooks/survival_model.html#estimating-the-survival-function",
    "href": "notebooks/survival_model.html#estimating-the-survival-function",
    "title": "Survival Models",
    "section": "Estimating the survival function",
    "text": "Estimating the survival function\nSurvival analysis is concerned with estimating the survival function \\(S(t)\\)\n\\[S(t) = Pr(T &gt; t) = 1 - F(t)\\]\nwhich is a decreasing function that quantifies the probability of surviving past time \\(t\\). Alternatively, \\(S(t)\\) can be expressed as one minus the cumulative distribution function (CDF) \\(F\\) of the event time \\(T\\)—referred to as the complementary cumulative distribution function (CCDF). The focus on the survival function is important because for censored observations, we only know that the time-to-event exceeds the observed time \\(Y\\).\nHere, continuing with the cat adoption example, we consider the task of estimating the survival function for cat adoptions. To estimate \\(S(30) = Pr(T &gt; 30)\\), the probability that a cat is not adopted after 30 days, it is tempting to compute the proportion of cats who were adopted before 30 days and subtract this from 1. However, this would be incorrect because it ignores the cats who were not adopted before 30 days but who will be adopted later—these cats clearly have longer adoption rates. Thus, if we continued with the naive approach, the average rate of adoption would be biased upwards—it is confounded by conditioning on adoption.\nHowever, it is possible to overcome this challenge by using the Kaplan-Meier estimator. The Kaplan-Meier estimator is a non-parametric estimator of the survival function that accounts for censoring. Let \\(d_1 &lt; d_2 &lt; . . . &lt; d_K\\) denote the \\(K\\) unique adoption times among the non-censored cats, and \\(q_k\\) denote the number of cats adopted at time \\(d_k\\). For \\(k = 1,...,K\\), let \\(r_k\\) denote the number of cats not adopted at time \\(d_k\\). By the law of total probability\n\\[Pr(T &gt; d_k) = Pr(T &gt; d_k | T &gt; d_{k-1}) Pr(T &gt; d_{k-1}) + Pr(T &gt; d_k | T \\leq d_{k-1}) Pr(T \\leq d_{k-1})\\]\nThe fact that \\(d_{k-1} &lt; d_k\\) implies that \\(Pr(T &gt; d_k | T \\leq d_{k-1}) = 0\\) (as it is impossible for a cat to be adopted past time \\(d_k\\) if the cat was adopted before time \\(d_{k-1}\\)). Thus, if we simplify the above equation and plug into the survival function, we obtain\n\\[S(d_k) = Pr(T &gt; d_k | T &gt; d_{k-1})S(d_{k-1})\\]\nNow we must estimate the terms on the right-hand side. It is common to use the following estimator\n\\[\\hat{Pr}(T &gt; d_j | T &gt; d_{j-1}) = \\frac{r_j - q_j}{r_j}\\]\nwhich leads us to the Kaplan-Meier estimator of the survival function\n\\[\\hat{S}(d_k) = \\prod_{j=1}^k \\frac{r_j - q_j}{r_j}\\]\nwhere \\(\\hat{S}(d_k)\\) represents the estimated survival probability up to time \\(d_k\\). The product is taken over all time points up to \\(k\\), where an event occurred. The variables \\(r_j\\) and \\(q_j\\) denote the number of subjects at risk and the number of events at time \\(d_j\\), respectively. The term \\(\\frac{r_j - q_j}{r_j}\\) is the conditional probability of surviving the \\(j\\)-th time point given that an individual has survived just before \\(d_j\\). Specifically, \\(r_j - q_j\\) are the number of individuals who survived just before \\(d_j\\) and \\(r_j\\) is the number of individuals who survived just after \\(d_j\\), and \\(r_j\\) are those who were at risk \\(d_j\\).\n\nCat adoption survival function\nBelow we use the KaplanMeierFitter class of the lifelines package to compute and visualize the survival curve for cat adoptions from an animal shelter in Austin, Texas beginning October 1st, 2013 until May 30th, 2018 (the last day the shelter rescued a cat). The dataset comes from the City of Austin Open Data Portal and contains columns such as animal name, date of birth, species, and many more. However, for the purpose of this notebook we are interested in the following columns: - days_to_event - number of days until the cat was adopted (date_in - date_out) - out_event - the reason for the cat leaving this particular shelter, e.g. adopted or transfered. - color - the color of the cat, e.g. white, blue, brown tabby, black.\n\nimport arviz as az\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport scipy\n\nfrom lifelines import KaplanMeierFitter\n\nimport bambi as bmb\n\n\nurl = \"https://raw.githubusercontent.com/rmcelreath/rethinking/master/data/AustinCats.csv\"\ncats_df = pd.read_csv(url, sep=\";\")\n\n\nplt.figure(figsize=(7, 3))\nplt.hist(cats_df[\"days_to_event\"], bins=250, label=\"Uncensored data\")\nplt.xlim(0, 186) # limit to 6 months for visibility\nplt.title(\"Days Until Adoption\")\nplt.ylabel(\"Count\")\nplt.xlabel(\"Days\")\nplt.legend();\n\n\n\n\n\n\n\n\nThe distribution of days until adoption exhibits a long tail with most cats (if we observe the adopt event) being adopted within the first month of inception. Note that the plot has been truncated to six months for better visibility. Below, we estimate the survival function using the KaplanMeierFitter class from the lifelines package.\n\nkm = KaplanMeierFitter()\nkm_adoptions = km.fit(\n    cats_df[\"days_to_event\"], \n    cats_df[\"out_event\"].apply(lambda x: 1 if x == \"Adoption\" else 0)\n)\n\n\nfig, ax = plt.subplots(figsize=(7, 3))\nkm_adoptions.plot(label=\"Kaplan-Meier Estimator\", ax=ax)\nax.set_ylabel(\"Probability of Adoption\")\nax.set_xlabel(\"Days\")\nax.set_xlim(0, 365)\nax.grid(True)\nax.set_title(\"Cat Adoption Survival Curve\");\n\n\n\n\n\n\n\n\nThe Kaplan-Meier estimator shows that by 100 days, the probability of a cat not being adopted is about \\(0.15\\) percent. After 100 days, the probability of cat not being adopted decreases, albeit at a much slower rate. Thus, if a cat hasn’t been adopted by the 100th day, it is more likely the cat will continue to wait for adoption. In the next section, we discuss pm.Censored, a PyMC distrbution that allows us to model censored data.",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Survival Models"
    ]
  },
  {
    "objectID": "notebooks/survival_model.html#the-pm.censored-distribution",
    "href": "notebooks/survival_model.html#the-pm.censored-distribution",
    "title": "Survival Models",
    "section": "The pm.Censored distribution",
    "text": "The pm.Censored distribution\nThe censored distribution from PyMC allows us to make use of a sequential construction, similar to the Kaplan-Meier estimator outlined above, to model censored data. To understand the pm.Censored distribution, lets reason how a distribution may be used to model censored data. For observed adoptions, the probability of observed waiting time can be distributed according to an exponential with some rate \\(\\lambda\\) \\[D_i \\sim \\text{Exponential}(\\lambda_i)\\] or \\[f(D_i | \\lambda_i) = \\lambda_i \\text{exp}(-\\lambda_i D_i)\\] It’s the censored cats that are tricky. If something else happened before a cat could be adopted, or it simply hasn’t been adopted yet, then we need the probability of not being adopted, conditional on the observation time so far. One way to motivate this is to image a cohort of 100 cats, all joining the shelter on the same day. - If half have been adopted after 30 days, then the probability of waiting 30 days and still not being adopted is 0.5. - If after 60 days, only 25 remain, then the probability of waiting 60 days and not yet being adopted is 0.25.\nThus, any given rate of adoption implies a proportion of the cohort of 100 cats that will remain after any given number of days. This probability comes from the cumulative probability distribution. A cumulative distribution gives the proportion of cats adopted before or at a certain number of days. So \\(1 - \\text{CDF}\\), which is the CCDF, gives the probability a cat is not adopted by the same number of days. Remember from the Estimating the survival function section, this is equivalent to the survival function. If the exponential distribution is used, the CDF is\n\\[F(D_i | \\lambda_i) = 1 - \\text{exp}(-\\lambda_i D_i)\\]\nwhere the complement is (here we use \\(S\\) to denote the equivalence of the survival function and CCDF)\n\\[S(D_i|\\lambda) = \\text{exp}(-\\lambda_i D_i)\\]\nWhich is what we need in our model since it is the probability of waiting \\(D_i\\) days without being adopted yet. The pm.Censored from PyMC offers a convenient way to model censored data and the probability density function (PDF) is defined as\n\\[\\begin{cases}\n0 & \\text{for } x &lt; \\text{lower}, \\\\\n\\text{CDF}(\\text{lower}, \\text{dist}) & \\text{for } x = \\text{lower}, \\\\\n\\text{PDF}(x, \\text{dist}) & \\text{for } \\text{lower} &lt; x &lt; \\text{upper}, \\\\\n1 - \\text{CDF}(\\text{upper}, \\text{dist}) & \\text{for } x = \\text{upper}, \\\\\n0 & \\text{for } x &gt; \\text{upper}.\n\\end{cases}\\]\nwhere lower is left-censored and upper is right-censored. Our cat adoption dataset is right-censored. Therefore, lower can be None, and upper is the observed times when an event occurs. The pm.Censored uses the CCDF to answer the question we are interested in: what is the probability of not being adopted yet, given the observation time so far?\n\nImplementation in Bambi\nTo understand how this is used, lets use Bambi to recover the parameters of the censored distribution with no predictors. Before the model is fit, days_to_event is scaled to represent months as the raw values contain very large values. This scaling ensures a smoother sampling process.\nAdditionally, modeling censored data in Bambi requires a new formula syntax censored(time, event) on the response term. censored indicates we want to model censored data and gets parsed where time and event are passed into a Bambi transformation function censored. This function takes two arguments: the first being the observed value \\(Y\\) (in this example time), and the second being the type of censoring of the event. In Bambi, it is possible to have left, none, right, and interval censoring. event needs to be encoded as one of the censoring types. In our cat adoption example, we will encode the adoption event as right.\nLastly, the exponential distribution is used to model the cat adoption rate parameter. But why not enter censored as the likelihood like we normally do in Bambi? The pm.Censored is indeed eventually used as the likelihood. However, there also needs to be a distribution that models the rate parameter. In this example it is the exponential distribution. This distribution is then used as input into the pm.Censored distribution. For more information on how to use the pm.Censored distribution, see the following PyMC documentation: Bayesian regression models with truncated and censored data and Censored data models.\n\ncats = cats_df.copy()\ncats[\"adopt\"] = np.where(cats[\"out_event\"] == \"Adoption\", \"right\", \"none\")\ncats[\"color_id\"] = np.where(cats[\"color\"] == \"Black\", 1, 0)\ncats = cats[[\"days_to_event\", \"adopt\", \"color_id\"]]\n\n\nmodel_1 = bmb.Model(\n    \"censored(days_to_event / 31, adopt) ~ 1\", \n    data=cats,\n    family=\"exponential\",\n    link=\"log\"\n)\nmodel_1.build()\nmodel_1.graph()\n\n\n\n\n\n\n\n\n\nidata_1 = model_1.fit(\n    tune=500,\n    draws=500,\n    random_seed=42, \n    chains=4, \n)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 2 jobs)\nNUTS: [Intercept]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 500 tune and 500 draw iterations (2_000 + 2_000 draws total) took 27 seconds.\n\n\n\naz.plot_trace(idata_1);\n\n\n\n\n\n\n\n\n\nsummary = az.summary(idata_1)\nsummary\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n0.501\n0.01\n0.483\n0.52\n0.0\n0.0\n801.0\n1099.0\n1.0\n\n\n\n\n\n\n\nInterpreting the intercept (the cat adoption rate parameter) alone is of not much value. Therefore, lets use the survival function to compute the probability of not being adopted after a range of months, given the learned rate parameter \\(\\lambda\\). We could dervive the survival function and pass the intercept parameter to it, but SciPy already implements it as scipy.stats.expon.sf, so we will just use this implementation.\n\n\nCat adoption plots\nThe plot below shows the estimated survival function and CCDF for cat adoptions. First, we compute the \\(0.95\\) credible interval (CI) and median value for the intercept. Then, since a log-link was used, the values are exponentiated.\n\nlambda_preds = np.quantile(\n    idata_1[\"posterior\"][\"Intercept\"], \n    [0.025, 0.5, 0.975]\n)\n\nlambda_lower = 1 / np.exp(lambda_preds[0])\nlambda_median = 1 / np.exp(lambda_preds[1])\nlambda_upper = 1 / np.exp(lambda_preds[2])\n\n\nt = np.linspace(0, max(cats[\"days_to_event\"] / 31), 100)\nS0 = scipy.stats.expon.sf\ncdf = scipy.stats.expon.cdf\n\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 3), sharey=True)\n\nax[0].plot(t, S0(lambda_median * t))\nax[0].fill_between(t, S0(lambda_lower * t), S0(lambda_upper * t), alpha=0.25)\nax[0].grid(True)\nax[0].set_xlim(0, 12)\nax[0].set_xlabel(\"Months\")\nax[0].set_ylabel(\"Probability\")\nax[0].set_title(\"Probability Not Being Adopted by Time $d_k$\")\n\nax[1].plot(t, cdf(lambda_median * t))\nax[1].fill_between(t, cdf(lambda_lower * t), cdf(lambda_upper * t), alpha=0.25)\nax[1].grid(True)\nax[1].vlines(1, 1, 1, linestyles=\"dashed\")\nax[1].set_xlabel(\"Months\")\nax[1].set_ylabel(\"Probability\")\nax[1].set_title(\"Probability of Being Adopted by Time $d_k$\");\n\n\n\n\n\n\n\n\nAnalyzing the CCDF (the left plot), the probability of a cat waiting one month without being adopted is about \\(0.60\\), whereas the probability of a cat being adopted by the first month is about \\(0.40\\). Analyzing the CDF (right plot), the majority of cats, about \\(0.97\\), are adopted by the sixth month. Now that we have an intuition on how pm.Censored is used for modeling censored data, in the next section, we will discuss how to model censored data with predictors.",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Survival Models"
    ]
  },
  {
    "objectID": "notebooks/survival_model.html#regression-models-with-a-survival-response",
    "href": "notebooks/survival_model.html#regression-models-with-a-survival-response",
    "title": "Survival Models",
    "section": "Regression models with a survival response",
    "text": "Regression models with a survival response\nIt is often the case that we would like to understand how various predictors are associated with the survival function. For example, we may want to know if the survival function for cats of different colors or species is different. As outlined above, we cannot simply run a regression on the observed times \\(Y\\) given some predictors \\(X\\). What we are actually interested in is predicting the survival time \\(T\\) given the predictors \\(X\\). To achieve this, we first need to understand the Hazard function and the Cox proportional hazards model.\n\nThe hazard function\nIn survival analysis, it is often more convenient to express the survival function in terms of the hazards rate, which is closely related to the survival function \\(S(t)\\), and is the instantaneous rate of an event occuring at time \\(t\\) given that the event has not yet occured.\n\\[\\begin{split}\\begin{align*}\n\\lambda(t)\n    & = \\lim_{\\Delta t \\to 0} \\frac{P(t &lt; T &lt; t + \\Delta t\\ |\\ T &gt; t) / \\Delta t}{Pr(T &gt; t)} \\\\\n    & = \\lim_{{\\Delta t \\to 0}} \\frac{Pr(t &lt; T \\leq t + \\Delta t) / \\Delta t}{Pr(T &gt; t)} \\\\\n    & = \\frac{f(t)}{S(t)}\n\\end{align*}\\end{split}\\]\nwhere\n\\[f(t) = \\lim_{{\\Delta t \\to 0}} \\frac{Pr(t &lt; T \\leq t + \\Delta t)}{\\Delta t}\\]\nwhere \\(T\\) is the (unobserved) survival time and \\(f(t)\\) is the PDF associated with \\(T\\). The relationship between the hazard function and the survival function can be described in terms of the likelihood \\(L\\)\n\\[\\begin{equation}\nL_i =\n\\begin{cases}\nf(y_i) & \\text{if the } i\\text{th observation is not censored} \\\\\nS(y_i) & \\text{if the } i\\text{th observation is censored}\n\\end{cases}\n\\end{equation}\\]\nIf \\(Y = y_i\\) and the \\(i\\text{th}\\) observation is not censored, then the likelihood is the probability of the event in a tiny interval around time \\(y_i\\). If the \\(i\\text{th}\\) observation is censored, then the likelihood is the probability of surviving at least until time \\(y_i\\). We have now seen two ways to model the survival times: (1) a non-parametric estimator such as Kaplan-Meier, and (2) a parametric model using the PDF \\(f(t)\\) to estimate the hazard rate. However, what we would really like to do is to model the survival time as a function of the predictors. Thus, instead of working with the PDF \\(f(t)\\), we work directly with the hazard function to model the survival time as a function of predictors.\n\n\nThe Cox proportional hazards model\nAbove, we developed a model with no predictors to recover the parameters of the cat adoption rate, and used this as input into the pm.Censored distribution. Since we would now like to add predictor(s), we need to reformulate our modeling task into a risk regression model as it allows us to model the hazard rate as a function of our predictors. Specifically, the Cox proportional hazards model. With predictors \\(x_j\\) and regression coefficients \\(\\beta\\), the hazard rate is modeled as\n\\[\\lambda(t|x_i) = \\lambda_0(t)\\text{exp}(\\sum_{j=1}^p x_{ij}\\beta_j)\\]\nwhere \\(\\lambda_{0}t\\) is the baseline hazard rate independent of the predictors. This baseline hazard rate is unspecified (or unidentified) and means that we allow the instantaneous probability of an event at time \\(t\\), given that a subject has survived at least until time \\(t\\), to take any form. Practically speaking, this means that the hazard function is very flexible and can model a wide range of relationships between the covariates and survival time. One can interpret the Cox proportional hazards model as a one-unit increase in \\(x_{ij}\\) corresponds to an increase in \\(\\lambda(t, x_i)\\) by a factor of \\(\\text{exp}(\\beta_j)\\). In the next section, it is discussed how to develop a regression model with survival responses and predictors.",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Survival Models"
    ]
  },
  {
    "objectID": "notebooks/survival_model.html#implementation-in-bambi-1",
    "href": "notebooks/survival_model.html#implementation-in-bambi-1",
    "title": "Survival Models",
    "section": "Implementation in Bambi",
    "text": "Implementation in Bambi\nAdding predictors to model the hazard rate as a function of our predictors is trivial in Bambi. We simply continue to use the formula syntax. In the backend, the rate is modeled as a function of the specified predictors in the Bambi model. For example, if in the Bambi model, we specified censored(y, event) ~ 1 + x with an exponential likelihood, then the latent rate \\(\\lambda\\) is modeled as an exponential distribution according to\n\\[\\alpha \\sim \\mathcal{N}(0, 1)\\] \\[\\beta \\sim \\mathcal{N}(0, 1)\\] \\[\\mu = \\text{exp}(\\alpha + \\beta X)\\] \\[\\lambda = 1 / \\mu\\] \\[Y \\sim \\text{Exponential}(\\lambda)\\]\nwhere \\(Y\\) is then passed to the dist argument of the pm.Censored distribution.\n\nCat adoption rates by color\nHowever, thanks to Bambi’s formula syntax, we can just include the predictors of interest. Below, color_id is added to model the survival probability of black and other colored cats.\n\ncat_model = bmb.Model(\n    \"censored(days_to_event / 31, adopt) ~ 0 + color_id\", \n    data=cats,\n    center_predictors=False,\n    priors={\"color_id\": bmb.Prior(\"Normal\", mu=0, sigma=1)},\n    categorical=[\"color_id\"],\n    family=\"exponential\",\n    link=\"log\"\n)\ncat_model.build()\ncat_model.graph()\n\n\n\n\n\n\n\n\n\ncat_model\n\n       Formula: censored(days_to_event / 31, adopt) ~ 0 + color_id\n        Family: exponential\n          Link: mu = log\n  Observations: 22356\n        Priors: \n    target = mu\n        Common-level effects\n            color_id ~ Normal(mu: 0.0, sigma: 1.0)\n\n\n\nidata = cat_model.fit(\n    tune=500,\n    draws=500,\n    random_seed=42, \n    chains=4,\n)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 2 jobs)\nNUTS: [color_id]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 500 tune and 500 draw iterations (2_000 + 2_000 draws total) took 42 seconds.\n\n\n\naz.summary(idata)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ncolor_id[0]\n0.490\n0.010\n0.472\n0.510\n0.000\n0.0\n2069.0\n1548.0\n1.0\n\n\ncolor_id[1]\n0.568\n0.026\n0.521\n0.618\n0.001\n0.0\n2188.0\n1443.0\n1.0\n\n\n\n\n\n\n\nThe summary output informs us that, on average, the rate parameter for other cats color_id[0] is lower than the rate for black cats color_id[1]. As performed above, lets plot the survival curves and CDFs for black and other colored cats to get a better understanding of the rate parameters.\n\n\nCat adoption plots\nIn the inference data, we have posterior draws for color_id (with corresponding coordinates for other and black cats) where the values represent the sampled rates. However, it is also possible to obtain \\(Y\\), in this example, months to event (as our data has been scaled) by calling model.predict() on the observed or new data. This will add a new data variable mu to the posterior group of the inference data.\n\nnew_data = pd.DataFrame({\"color_id\": [0, 1]})\ncat_model.predict(idata, data=new_data, kind=\"params\")\n\n\nother_cats = (\n    idata[\"posterior\"][\"mu\"]\n    .sel({\"__obs__\": 0})\n    .values\n    .flatten()\n)\nother_cats_preds = np.quantile(other_cats, [0.025, 0.5, 0.975])\n\nblack_cats = (\n    idata[\"posterior\"][\"mu\"]\n    .sel({\"__obs__\": 1})\n    .values.\n    flatten()\n)\n\nblack_cats_preds = np.quantile(black_cats, [0.025, 0.5, 0.975])\n\nlambdas = {\n    \"Other cats\": 1 / other_cats_preds,\n    \"Black cats\": 1 / black_cats_preds\n}\n\n\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 3), sharey=True)\n\nfor key, value in lambdas.items():\n    lower, median, upper = value\n    ax[0].plot(t, S0(median * t), label=f\"{key}\")\n    ax[0].fill_between(t, S0(lower * t), S0(upper * t), alpha=0.25)\n\nax[0].grid(True)\nax[0].set_xlim(0, 10)\nax[0].legend()\nax[0].set_title(\"Probability Not Being Adopted by Time $d_k$\")\n\nfor key, value in lambdas.items():\n    lower, median, upper = value\n    ax[1].plot(t, cdf(median * t), label=f\"{key}\")\n    ax[1].fill_between(t, cdf(lower * t), cdf(upper * t), alpha=0.25)\n\nax[1].grid(True)\nax[1].set_xlim(0, 10)\nax[1].legend()\nax[1].set_title(\"Probability of Being Adopted by Time $d_k$\");\n\n\n\n\n\n\n\n\nAnalyzing the CCDF (left plot), we can see that black cats have a slightly higher probability of not being adopted throughout the whole range of \\(k\\). Furthermore, analyzing the CDF (right plot), we can see it also takes a longer time for the majority of black cats to be adopted compared to other colored cats. Below, we plot the distribution of days until adoption for the two groups.\n\nplt.figure(figsize=(7, 3))\nplt.hist(\n    other_cats * 31, \n    bins=50, \n    density=True,\n    label=\"Other cats\"\n)\nplt.hist(\n    black_cats * 31, \n    bins=50,\n    density=True,\n    label=\"Black cats\"\n)\nplt.legend()\nplt.xlabel(\"Days\")\nplt.ylabel(\"Density\")\nplt.title(\"Distribution of Adoption Times\");\n\n\n\n\n\n\n\n\nScaling adoption times back to days (multiplying by 31), we can see that black cats have longer and a wider range of time until adoptions (about 55 days) than cats that are not black (about 51 days).",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Survival Models"
    ]
  },
  {
    "objectID": "notebooks/survival_model.html#summary",
    "href": "notebooks/survival_model.html#summary",
    "title": "Survival Models",
    "section": "Summary",
    "text": "Summary\nIn this notebook, we introduced censored data, left and right censoring, and why such data lends itself to specialized statistical methods and models. First, the non-parametric Kaplan-Meier estimator to estimate the survival curve of censored data was introduced. Subsequently, motivated by modeling the survival function as a function of predictors, the hazards rate and Cox proportional hazards model was introduced. Modeling censored data in Bambi requires defining the response as censored(y, event) where event is left or right censoring. To add predictors to the model, simply include them in the formula. Bambi leverages the pm.Censored distribution from PyMC as the likelihood for censored data.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sun May 26 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\npandas    : 2.2.2\nbambi     : 0.13.1.dev39+gb7d6a6cb\nnumpy     : 1.26.4\nscipy     : 1.13.0\narviz     : 0.18.0\nmatplotlib: 3.8.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "More advanced models",
      "Survival Models"
    ]
  },
  {
    "objectID": "notebooks/t_regression.html",
    "href": "notebooks/t_regression.html",
    "title": "Robust Linear Regression",
    "section": "",
    "text": "This example has been lifted from the PyMC Docs, and adapted to for Bambi by Tyler James Burch (@tjburch on GitHub).\nMany toy datasets circumvent problems that practitioners run into with real data. Specifically, the assumption of normality can be easily violated by outliers, which can cause havoc in traditional linear regression. One way to navigate this is through robust linear regression, outlined in this example.\nFirst load modules and set the RNG for reproducibility.\n\nimport arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\naz.style.use(\"arviz-darkgrid\")\nnp.random.seed(1111)\n\nNext, generate pseudodata. The bulk of the data will be linear with noise distributed normally, but additionally several outliers will be interjected.\n\nsize = 100\ntrue_intercept = 1\ntrue_slope = 2\n\nx = np.linspace(0, 1, size)\n# y = a + b*x\ntrue_regression_line = true_intercept + true_slope * x\n# add noise\ny = true_regression_line + np.random.normal(scale=0.5, size=size)\n\n# Add outliers\nx_out = np.append(x, [0.1, 0.15, 0.2])\ny_out = np.append(y, [8, 6, 9])\n\ndata = pd.DataFrame({\n    \"x\": x_out, \n    \"y\": y_out\n})\n\nPlot this data. The three data points in the top left are the interjected data.\n\nfig = plt.figure(figsize=(7, 7))\nax = fig.add_subplot(111, xlabel=\"x\", ylabel=\"y\", title=\"Generated data and underlying model\")\nax.plot(x_out, y_out, \"x\", label=\"sampled data\")\nax.plot(x, true_regression_line, label=\"true regression line\", lw=2.0)\nplt.legend(loc=0);\n\n\n\n\n\n\n\n\nTo highlight the problem, first fit a standard normally-distributed linear regression.\n\n# Note, \"gaussian\" is the default argument for family. Added to be explicit. \ngauss_model = bmb.Model(\"y ~ x\", data, family=\"gaussian\")\ngauss_fitted = gauss_model.fit(draws=2000, idata_kwargs={\"log_likelihood\": True})\ngauss_model.predict(gauss_fitted, kind=\"pps\")\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, Intercept, x]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 2_000 draw iterations (2_000 + 4_000 draws total) took 3 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n/home/tomas/Desktop/OSS/bambinos/bambi/bambi/models.py:846: FutureWarning: 'pps' has been replaced by 'response' and is not going to work in the future\n  warnings.warn(\n\n\n\naz.summary(gauss_fitted)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n1.532\n0.230\n1.103\n1.972\n0.003\n0.002\n5262.0\n2988.0\n1.0\n\n\nsigma\n1.186\n0.085\n1.023\n1.345\n0.001\n0.001\n5676.0\n2953.0\n1.0\n\n\nx\n1.203\n0.399\n0.423\n1.913\n0.005\n0.004\n5501.0\n3207.0\n1.0\n\n\nmu[0]\n1.532\n0.230\n1.103\n1.972\n0.003\n0.002\n5262.0\n2988.0\n1.0\n\n\nmu[1]\n1.544\n0.226\n1.124\n1.982\n0.003\n0.002\n5263.0\n2988.0\n1.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nmu[98]\n2.722\n0.230\n2.317\n3.178\n0.003\n0.002\n6078.0\n2990.0\n1.0\n\n\nmu[99]\n2.735\n0.233\n2.310\n3.185\n0.003\n0.002\n6071.0\n2979.0\n1.0\n\n\nmu[100]\n1.652\n0.196\n1.290\n2.029\n0.003\n0.002\n5287.0\n3085.0\n1.0\n\n\nmu[101]\n1.712\n0.181\n1.383\n2.059\n0.002\n0.002\n5309.0\n3236.0\n1.0\n\n\nmu[102]\n1.772\n0.166\n1.467\n2.090\n0.002\n0.002\n5357.0\n3234.0\n1.0\n\n\n\n\n106 rows × 9 columns\n\n\n\nRemember, the true intercept was 1, the true slope was 2. The recovered intercept is much higher, and the slope is much lower, so the influence of the outliers is apparent.\nVisually, looking at the recovered regression line and posterior predictive HDI highlights the problem further.\n\nplt.figure(figsize=(7, 5))\n# Plot Data\nplt.plot(x_out, y_out, \"x\", label=\"data\")\n# Plot recovered linear regression\nx_range = np.linspace(min(x_out), max(x_out), 2000)\ny_pred = gauss_fitted.posterior.x.mean().item() * x_range + gauss_fitted.posterior.Intercept.mean().item()\nplt.plot(x_range, y_pred, \n         color=\"black\",linestyle=\"--\",\n         label=\"Recovered regression line\"\n        )\n# Plot HDIs\nfor interval in [0.38, 0.68]:\n    az.plot_hdi(x_out, gauss_fitted.posterior_predictive.y, \n                hdi_prob=interval, color=\"firebrick\")\n# Plot true regression line\nplt.plot(x, true_regression_line, \n        label=\"True regression line\", lw=2.0, color=\"black\")\nplt.legend(loc=0);\n\n\n\n\n\n\n\n\nThe recovered regression line, as well as the \\(0.5\\sigma\\) and \\(1\\sigma\\) bands are shown.\nClearly there is skew in the fit. At lower \\(x\\) values, the regression line is far higher than the true line. This is a result of the outliers, which cause the model to assume a higher value in that regime.\nAdditionally the uncertainty bands are too wide (remember, the \\(1\\sigma\\) band ought to cover 68% of the data, while here it covers most of the points). Due to the small probability mass in the tails of a normal distribution, the outliers have an large effect, causing the uncertainty bands to be oversized.\nClearly, assuming the data are distributed normally is inducing problems here. Bayesian robust linear regression forgoes the normality assumption by instead using a Student T distribution to describe the distribution of the data. The Student T distribution has thicker tails, and by allocating more probability mass to the tails, outliers have a less strong effect.\nComparing the two distributions,\n\nnormal_data = np.random.normal(loc=0, scale=1, size=100_000)\nt_data = np.random.standard_t(df=1, size=100_000)\n\nbins = np.arange(-8,8,0.15)\nplt.hist(normal_data, \n         bins=bins, density=True,\n         alpha=0.6,\n         label=\"Normal\"\n        )\nplt.hist(t_data, \n         bins=bins,density=True,\n         alpha=0.6,\n         label=\"Student T\"\n        )\nplt.xlabel(\"x\")\nplt.ylabel(\"Probability density\")\nplt.xlim(-8,8)\nplt.legend();\n\n\n\n\n\n\n\n\nAs we can see, the tails of the Student T are much larger, which means values far from the mean are more likely when compared to the normal distribution.\nThe T distribution is specified by a number of degrees of freedom (\\(\\nu\\)). In numpy.random.standard_t this is the parameter df, in the pymc T distribution, it’s nu. It is constrained to real numbers greater than 0. As the degrees of freedom increase, the probability in the tails Student T distribution decrease. In the limit of \\(\\nu \\rightarrow + \\infty\\), the Student T distribution is a normal distribution. Below, the T distribution is plotted for various \\(\\nu\\).\n\nbins = np.arange(-8,8,0.15)\nfor ndof in [0.1, 1, 10]:\n\n    t_data = np.random.standard_t(df=ndof, size=100_000)\n\n    plt.hist(t_data, \n             bins=bins,density=True,\n             label=f\"$\\\\nu = {ndof}$\",\n             histtype=\"step\"\n            )\nplt.hist(normal_data, \n         bins=bins, density=True,\n         histtype=\"step\",\n         label=\"Normal\"\n        )    \n    \nplt.xlabel(\"x\")\nplt.ylabel(\"Probability density\")\nplt.xlim(-6,6)\nplt.legend();\n\n\n\n\n\n\n\n\nIn Bambi, the way to specify a regression with Student T distributed data is by passing \"t\" to the family parameter of a Model.\n\nt_model = bmb.Model(\"y ~ x\", data, family=\"t\")\nt_fitted = t_model.fit(draws=2000, idata_kwargs={\"log_likelihood\": True})\nt_model.predict(t_fitted, kind=\"pps\")\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [nu, sigma, Intercept, x]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 1_000 tune and 2_000 draw iterations (2_000 + 4_000 draws total) took 4 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n/home/tomas/Desktop/OSS/bambinos/bambi/bambi/models.py:846: FutureWarning: 'pps' has been replaced by 'response' and is not going to work in the future\n  warnings.warn(\n\n\n\naz.summary(t_fitted)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n0.993\n0.109\n0.793\n1.193\n0.002\n0.001\n5305.0\n3502.0\n1.0\n\n\nnu\n2.610\n0.610\n1.533\n3.721\n0.009\n0.007\n4246.0\n3662.0\n1.0\n\n\nsigma\n0.406\n0.045\n0.326\n0.489\n0.001\n0.001\n3669.0\n3243.0\n1.0\n\n\nx\n1.900\n0.189\n1.533\n2.242\n0.002\n0.002\n6136.0\n3533.0\n1.0\n\n\nmu[0]\n0.993\n0.109\n0.793\n1.193\n0.002\n0.001\n5305.0\n3502.0\n1.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nmu[98]\n2.875\n0.105\n2.683\n3.077\n0.001\n0.001\n6187.0\n3392.0\n1.0\n\n\nmu[99]\n2.894\n0.107\n2.700\n3.100\n0.001\n0.001\n6199.0\n3308.0\n1.0\n\n\nmu[100]\n1.183\n0.093\n1.018\n1.359\n0.001\n0.001\n5178.0\n3469.0\n1.0\n\n\nmu[101]\n1.278\n0.085\n1.126\n1.440\n0.001\n0.001\n5108.0\n3472.0\n1.0\n\n\nmu[102]\n1.373\n0.078\n1.226\n1.516\n0.001\n0.001\n5016.0\n3384.0\n1.0\n\n\n\n\n107 rows × 9 columns\n\n\n\nNote the new parameter in the model, y_nu. This is the aforementioned degrees of freedom. If this number were very high, we would expect it to be well described by a normal distribution. However, the HDI of this spans from 1.5 to 3.7, meaning that the tails are much heavier than a normal distribution. As a result of the heavier tails, y_sigma has also dropped precipitously from the normal model, meaning the oversized uncertainty bands from above have shrunk.\nComparing the extracted values of the two models,\n\ndef get_slope_intercept(mod):\n    return (\n        mod.posterior.x.mean().item(),\n        mod.posterior.Intercept.mean().item()\n    )\ngauss_slope, gauss_int = get_slope_intercept(gauss_fitted)\nt_slope, t_int = get_slope_intercept(t_fitted)\n\npd.DataFrame({\n    \"Model\":[\"True\",\"Normal\",\"T\"],\n    \"Slope\":[2, gauss_slope, t_slope],\n    \"Intercept\": [1, gauss_int, t_int]\n}).set_index(\"Model\").T.round(decimals=2)\n\n\n\n\n\n\n\nModel\nTrue\nNormal\nT\n\n\n\n\nSlope\n2.0\n1.20\n1.90\n\n\nIntercept\n1.0\n1.53\n0.99\n\n\n\n\n\n\n\nHere we can see the mean recovered values of both the slope and intercept are far closer to the true values using the robust regression model compared to the normally distributed one.\nVisually comparing the robust regression line,\n\nplt.figure(figsize=(7, 5))\n# Plot Data\nplt.plot(x_out, y_out, \"x\", label=\"data\")\n# Plot recovered robust linear regression\nx_range = np.linspace(min(x_out), max(x_out), 2000)\ny_pred = t_fitted.posterior.x.mean().item() * x_range + t_fitted.posterior.Intercept.mean().item()\nplt.plot(x_range, y_pred, \n         color=\"black\",linestyle=\"--\",\n         label=\"Recovered regression line\"\n        )\n# Plot HDIs\nfor interval in [0.05, 0.38, 0.68]:\n    az.plot_hdi(x_out, t_fitted.posterior_predictive.y, \n                hdi_prob=interval, color=\"firebrick\")\n# Plot true regression line\nplt.plot(x, true_regression_line, \n        label=\"true regression line\", lw=2.0, color=\"black\")\nplt.legend(loc=0);\n\n\n\n\n\n\n\n\nThis is much better. The true and recovered regression lines are much closer, and the uncertainty bands are appropriate sized. The effect of the outliers is not entirely gone, the recovered line still slightly differs from the true line, but the effect is far smaller, which is a result of the Student T likelihood function ascribing a higher probability to outliers than the normal distribution. Additionally, this inference is based on sampling methods, so it is expected to have small differences (especially given a relatively small number of samples).\nLast, another way to evaluate the models is to compare based on Leave-one-out Cross-validation (LOO), which provides an estimate of accuracy on out-of-sample predictions.\n\nmodels = {\n    \"gaussian\": gauss_fitted,\n    \"Student T\": t_fitted\n}\ndf_compare = az.compare(models)\ndf_compare\n\n/home/tomas/anaconda3/envs/bambi-dev/lib/python3.11/site-packages/arviz/stats/stats.py:789: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nStudent T\n0\n-101.645151\n5.484467\n0.000000\n1.0\n14.932301\n0.000000\nFalse\nlog\n\n\ngaussian\n1\n-172.368370\n14.605692\n70.723218\n0.0\n29.836317\n18.037873\nTrue\nlog\n\n\n\n\n\n\n\n\naz.plot_compare(df_compare, insample_dev=False);\n\n\n\n\n\n\n\n\nHere it is quite obvious that the Student T model is much better, due to having a clearly larger value of LOO.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sat May 25 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\npandas    : 2.2.2\nmatplotlib: 3.8.4\nbambi     : 0.13.1.dev37+g2a54df76.d20240525\nnumpy     : 1.26.4\narviz     : 0.18.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Linear regression models",
      "Robust Linear Regression"
    ]
  },
  {
    "objectID": "notebooks/wald_gamma_glm.html",
    "href": "notebooks/wald_gamma_glm.html",
    "title": "Wald and Gamma Regression (Australian insurance claims 2004-2005)",
    "section": "",
    "text": "import arviz as az\nimport bambi as bmb\nimport matplotlib.pyplot as plt\nimport numpy as np\naz.style.use(\"arviz-darkgrid\")\nnp.random.seed(1234)",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Wald and Gamma Regression (Australian insurance claims 2004-2005)"
    ]
  },
  {
    "objectID": "notebooks/wald_gamma_glm.html#load-and-examine-vehicle-insurance-data",
    "href": "notebooks/wald_gamma_glm.html#load-and-examine-vehicle-insurance-data",
    "title": "Wald and Gamma Regression (Australian insurance claims 2004-2005)",
    "section": "Load and examine Vehicle insurance data",
    "text": "Load and examine Vehicle insurance data\nIn this notebook we use a data set consisting of 67856 insurance policies and 4624 (6.8%) claims in Australia between 2004 and 2005. The original source of this dataset is the book Generalized Linear Models for Insurance Data by Piet de Jong and Gillian Z. Heller.\n\ndata = bmb.load_data(\"carclaims\")\ndata.head()\n\n\n\n\n\n\n\n\nveh_value\nexposure\nclm\nnumclaims\nclaimcst0\nveh_body\nveh_age\ngender\narea\nagecat\n\n\n\n\n0\n1.06\n0.303901\n0\n0\n0.0\nHBACK\n3\nF\nC\n2\n\n\n1\n1.03\n0.648871\n0\n0\n0.0\nHBACK\n2\nF\nA\n4\n\n\n2\n3.26\n0.569473\n0\n0\n0.0\nUTE\n2\nF\nE\n2\n\n\n3\n4.14\n0.317591\n0\n0\n0.0\nSTNWG\n2\nF\nD\n2\n\n\n4\n0.72\n0.648871\n0\n0\n0.0\nHBACK\n4\nF\nC\n2\n\n\n\n\n\n\n\nLet’s see the meaning of the variables before creating any plot or fitting any model.\n\nveh_value: Vehicle value, ranges from \\$0 to \\$350,000.\nexposure: Proportion of the year where the policy was exposed. In practice each policy is not exposed for the full year. Some policies come into force partly into the year while others are canceled before the year’s end.\nclm: Claim occurrence. 0 (no), 1 (yes).\nnumclaims: Number of claims.\nclaimcst0: Claim amount. 0 if no claim. Ranges from \\$200 to \\$55922.\nveh_body: Vehicle body type. Can be one of bus, convertible, coupe, hatchback, hardtop, motorized caravan/combi, minibus, panel van, roadster, sedan, station wagon, truck, and utility.\nveh_age: Vehicle age. 1 (new), 2, 3, and 4.\ngender: Gender of the driver. M (Male) and F (Female).\narea: Driver’s area of residence. Can be one of A, B, C, D, E, and F.\nagecat: Driver’s age category. 1 (youngest), 2, 3, 4, 5, and 6.\n\nThe variable of interest is the claim amount, given by \"claimcst0\". We keep the records where there is a claim, so claim amount is greater than 0.\n\ndata = data[data[\"claimcst0\"] &gt; 0]\n\nFor clarity, we only show those claims amounts below \\$15,000, since there are only 65 records above that threshold.\n\ndata[data[\"claimcst0\"] &gt; 15000].shape[0]\n\n65\n\n\n\nplt.hist(data[data[\"claimcst0\"] &lt;= 15000][\"claimcst0\"], bins=30)\nplt.title(\"Distribution of claim amount\")\nplt.xlabel(\"Claim amount ($)\");\n\n\n\n\n\n\n\n\nAnd this is when you say: “Oh, there really are ugly right-skewed distributions out there!”. Well, yes, we’ve all been there :)\nIn this case we are going to fit GLMs with a right-skewed distribution for the random component. This time we will be using Wald and Gamma distributions. One of their differences is that the variance is proportional to the cubic mean in the case of the Wald distribution, and proportional to the squared mean in the case of the Gamma distribution.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Wald and Gamma Regression (Australian insurance claims 2004-2005)"
    ]
  },
  {
    "objectID": "notebooks/wald_gamma_glm.html#wald-family",
    "href": "notebooks/wald_gamma_glm.html#wald-family",
    "title": "Wald and Gamma Regression (Australian insurance claims 2004-2005)",
    "section": "Wald family",
    "text": "Wald family\nThe Wald family (a.k.a inverse Gaussian model) states that\n\\[\n\\begin{array}{cc}\ny_i \\sim \\text{Wald}(\\mu_i, \\lambda) & g(\\mu_i) = \\mathbf{x}_i^T\\beta\n\\end{array}\n\\]\nwhere the pdf of a Wald distribution is given by\n\\[\nf(x|\\mu, \\lambda) =\n\\left(\\frac{\\lambda}{2\\pi}\\right)^{1/2}x^{-3/2}\\exp\\left\\{ -\\frac{\\lambda}{2x} \\left(\\frac{x - \\mu}{\\mu} \\right)^2 \\right\\}\n\\]\nfor \\(x &gt; 0\\), mean \\(\\mu &gt; 0\\) and \\(\\lambda &gt; 0\\) is the shape parameter. The variance is given by \\(\\sigma^2 = \\mu^3/\\lambda\\). The canonical link is \\(g(\\mu_i) = \\mu_i^{-2}\\), but \\(g(\\mu_i) = \\log(\\mu_i)\\) is usually preferred, and it is what we use here.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Wald and Gamma Regression (Australian insurance claims 2004-2005)"
    ]
  },
  {
    "objectID": "notebooks/wald_gamma_glm.html#gamma-family",
    "href": "notebooks/wald_gamma_glm.html#gamma-family",
    "title": "Wald and Gamma Regression (Australian insurance claims 2004-2005)",
    "section": "Gamma family",
    "text": "Gamma family\nThe default parametrization of the Gamma density function is\n\\[\n\\displaystyle f(x | \\alpha, \\beta) = \\frac{\\beta^\\alpha x^{\\alpha -1} e^{-\\beta x}}{\\Gamma(\\alpha)}\n\\]\nwhere \\(x &gt; 0\\), and \\(\\alpha &gt; 0\\) and \\(\\beta &gt; 0\\) are the shape and rate parameters, respectively.\nBut GLMs model the mean of the function, so we need to use an alternative parametrization where\n\\[\n\\begin{array}{ccc}\n\\displaystyle \\mu = \\frac{\\alpha}{\\beta} & \\text{and} & \\displaystyle \\sigma^2 = \\frac{\\alpha}{\\beta^2}\n\\end{array}\n\\]\nand thus we have\n\\[\n\\begin{array}{cccc}\ny_i \\sim \\text{Gamma}(\\mu_i, \\sigma_i), & g(\\mu_i) = \\mathbf{x}_i^T\\beta, & \\text{and} & \\sigma_i = \\mu_i^2/\\alpha\n\\end{array}\n\\]\nwhere \\(\\alpha\\) is the shape parameter in the original parametrization of the gamma pdf. The canonical link is \\(g(\\mu_i) = \\mu_i^{-1}\\), but here we use \\(g(\\mu_i) = \\log(\\mu_i)\\) again.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Wald and Gamma Regression (Australian insurance claims 2004-2005)"
    ]
  },
  {
    "objectID": "notebooks/wald_gamma_glm.html#model-fit",
    "href": "notebooks/wald_gamma_glm.html#model-fit",
    "title": "Wald and Gamma Regression (Australian insurance claims 2004-2005)",
    "section": "Model fit",
    "text": "Model fit\nIn this example we are going to use the binned age, the gender, and the area of residence to predict the amount of the claim, conditional on the existence of the claim because we are only working with observations where there is a claim.\n\"agecat\" is interpreted as a numeric variable in our data frame, but we know it is categorical, and we wouldn’t be happy if our model takes it as if it was numeric, would we?\nWe have two alternatives to tell Bambi that this numeric variable must be treated as categorical. The first one is to wrap the name of the variable with C(), and the other is to pass the same name to the categorical argument when we create the model. We are going to use the first approach with the Wald family and the second with the Gamma.\nThe C() notation is taken from Patsy and is encouraged when you want to explicitly pass the order of the levels of the variables. If you are happy with the default order, better pass the name to categorical so tables and plots have prettier labels :)\n\nWald\n\nmodel_wald = bmb.Model(\"claimcst0 ~ C(agecat) + gender + area\", data, family = \"wald\", link = \"log\")\nfitted_wald = model_wald.fit(tune=2000, target_accept=0.9, idata_kwargs={\"log_likelihood\": True})\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [lam, Intercept, C(agecat), gender, area]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 2_000 tune and 1_000 draw iterations (4_000 + 2_000 draws total) took 23 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\naz.plot_trace(fitted_wald);\n\n\n\n\n\n\n\n\n\naz.summary(fitted_wald)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nC(agecat)[2]\n-0.164\n0.102\n-0.345\n0.030\n0.004\n0.003\n765.0\n822.0\n1.01\n\n\nC(agecat)[3]\n-0.258\n0.102\n-0.446\n-0.061\n0.004\n0.003\n775.0\n838.0\n1.01\n\n\nC(agecat)[4]\n-0.263\n0.101\n-0.442\n-0.063\n0.004\n0.003\n803.0\n899.0\n1.01\n\n\nC(agecat)[5]\n-0.377\n0.109\n-0.575\n-0.166\n0.004\n0.003\n797.0\n776.0\n1.01\n\n\nC(agecat)[6]\n-0.320\n0.122\n-0.550\n-0.086\n0.004\n0.003\n888.0\n1005.0\n1.01\n\n\nIntercept\n7.724\n0.099\n7.529\n7.895\n0.004\n0.003\n539.0\n614.0\n1.01\n\n\narea[B]\n-0.030\n0.073\n-0.170\n0.103\n0.002\n0.002\n1056.0\n1032.0\n1.00\n\n\narea[C]\n0.070\n0.067\n-0.052\n0.194\n0.002\n0.001\n1244.0\n1324.0\n1.00\n\n\narea[D]\n-0.022\n0.089\n-0.189\n0.148\n0.002\n0.002\n1305.0\n1630.0\n1.00\n\n\narea[E]\n0.147\n0.103\n-0.056\n0.330\n0.003\n0.002\n1347.0\n1370.0\n1.00\n\n\narea[F]\n0.368\n0.137\n0.124\n0.641\n0.003\n0.003\n1621.0\n1347.0\n1.00\n\n\ngender[M]\n0.154\n0.050\n0.053\n0.244\n0.001\n0.001\n2273.0\n1414.0\n1.00\n\n\nlam\n722.857\n14.623\n694.186\n750.000\n0.337\n0.238\n1890.0\n1335.0\n1.00\n\n\n\n\n\n\n\nIf we look at the agecat variable, we can see the log mean of the claim amount tends to decrease when the age of the person increases, with the exception of the last category where we can see a slight increase in the mean of the coefficient (-0.307 vs -0.365 of the previous category). However, these differences only represent a slight tendency because of the large overlap between the marginal posteriors for these coefficients (see overlaid density plots for C(agecat).\nThe posterior for gender tells us that the claim amount tends to be larger for males than for females, with the mean being 0.153 and the credible interval ranging from 0.054 to 0.246.\nFinally, from the marginal posteriors for the areas, we can see that F is the only area that clearly stands out, with a higher mean claim amount than in the rest. Area E may also have a higher claim amount, but this difference with the other areas is not as evident as it happens with F.\n\n\nGamma\n\nmodel_gamma = bmb.Model(\n    \"claimcst0 ~ agecat + gender + area\",\n    data,\n    family=\"gamma\",\n    link=\"log\",\n    categorical=\"agecat\",\n)\nfitted_gamma = model_gamma.fit(tune=2000, target_accept=0.9, idata_kwargs={\"log_likelihood\": True})\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [alpha, Intercept, agecat, gender, area]\n\n\n\n\n\n\n\n\n\n\n\nSampling 2 chains for 2_000 tune and 1_000 draw iterations (4_000 + 2_000 draws total) took 29 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\n\n\n\naz.plot_trace(fitted_gamma);\n\n\n\n\n\n\n\n\n\naz.summary(fitted_gamma)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n7.718\n0.062\n7.588\n7.823\n0.002\n0.001\n959.0\n1220.0\n1.0\n\n\nagecat[2]\n-0.182\n0.063\n-0.299\n-0.060\n0.002\n0.002\n829.0\n1106.0\n1.0\n\n\nagecat[3]\n-0.276\n0.062\n-0.389\n-0.156\n0.002\n0.002\n803.0\n1207.0\n1.0\n\n\nagecat[4]\n-0.268\n0.062\n-0.385\n-0.152\n0.002\n0.001\n874.0\n1177.0\n1.0\n\n\nagecat[5]\n-0.388\n0.070\n-0.510\n-0.245\n0.002\n0.002\n999.0\n1434.0\n1.0\n\n\nagecat[6]\n-0.314\n0.078\n-0.461\n-0.171\n0.002\n0.002\n1125.0\n1223.0\n1.0\n\n\nalpha\n0.762\n0.014\n0.737\n0.788\n0.000\n0.000\n2389.0\n1185.0\n1.0\n\n\narea[B]\n-0.025\n0.051\n-0.120\n0.069\n0.001\n0.001\n1706.0\n1278.0\n1.0\n\n\narea[C]\n0.070\n0.046\n-0.022\n0.152\n0.001\n0.001\n1498.0\n1300.0\n1.0\n\n\narea[D]\n-0.017\n0.062\n-0.125\n0.100\n0.002\n0.001\n1358.0\n1220.0\n1.0\n\n\narea[E]\n0.150\n0.068\n0.031\n0.286\n0.002\n0.001\n2016.0\n1432.0\n1.0\n\n\narea[F]\n0.369\n0.075\n0.229\n0.508\n0.002\n0.001\n1984.0\n1538.0\n1.0\n\n\ngender[M]\n0.166\n0.034\n0.105\n0.229\n0.001\n0.000\n2309.0\n1276.0\n1.0\n\n\n\n\n\n\n\nThe interpretation of the parameter posteriors is very similar to what we’ve done for the Wald family. The only difference is that some differences, such as the ones for the area posteriors, are a little more exacerbated here.",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Wald and Gamma Regression (Australian insurance claims 2004-2005)"
    ]
  },
  {
    "objectID": "notebooks/wald_gamma_glm.html#model-comparison",
    "href": "notebooks/wald_gamma_glm.html#model-comparison",
    "title": "Wald and Gamma Regression (Australian insurance claims 2004-2005)",
    "section": "Model comparison",
    "text": "Model comparison\nWe can perform a Bayesian model comparison very easily with az.compare(). Here we pass a dictionary with the InferenceData objects that Model.fit() returned and az.compare() returns a data frame that is ordered from best to worst according to the criteria used.\n\nmodels = {\"wald\": fitted_wald, \"gamma\": fitted_gamma}\ndf_compare = az.compare(models)\ndf_compare\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nwald\n0\n-38581.390685\n12.850506\n0.000000\n1.0\n106.056885\n0.000000\nFalse\nlog\n\n\ngamma\n1\n-39628.917221\n26.536036\n1047.526536\n0.0\n104.988496\n35.778307\nFalse\nlog\n\n\n\n\n\n\n\n\naz.plot_compare(df_compare, insample_dev=False);\n\n\n\n\n\n\n\n\nBy default, ArviZ uses loo, which is an estimation of leave one out cross-validation. Another option is the widely applicable information criterion (WAIC). Since the results are in the log scale, the better out-of-sample predictive fit is given by the model with the highest value, which is the Wald model.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sun May 26 2024\n\nPython implementation: CPython\nPython version       : 3.11.9\nIPython version      : 8.24.0\n\nbambi     : 0.13.1.dev39+gb7d6a6cb\nmatplotlib: 3.8.4\nnumpy     : 1.26.4\narviz     : 0.18.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Examples",
      "Generalized linear models",
      "Wald and Gamma Regression (Australian insurance claims 2004-2005)"
    ]
  },
  {
    "objectID": "api/Family.html",
    "href": "api/Family.html",
    "title": "Family",
    "section": "",
    "text": "families.Family(self, name, likelihood, link)\nA specification of model family\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nname\nstr\nThe name of the family. It can be any string.\nrequired\n\n\nlikelihood\nLikelihood\nA bambi.families.Likelihood instance specifying the model likelihood function.\nrequired\n\n\nlink\nUnion[str, Dict[str, Union[str, Link]]]\nThe link function that’s used for every parameter in the likelihood function. Keys are the names of the parameters and values are the link functions. These can be a str with a name or a bambi.families.Link instance. The link function transforms the linear predictors.\nrequired\n\n\n\n\n\n\n&gt;&gt;&gt; import bambi as bmb\nReplicate the Gaussian built-in family.\n&gt;&gt;&gt; sigma_prior = bmb.Prior(\"HalfNormal\", sigma=1)\n&gt;&gt;&gt; likelihood = bmb.Likelihood(\"Gaussian\", params=[\"mu\", \"sigma\"], parent=\"mu\")\n&gt;&gt;&gt; family = bmb.Family(\"gaussian\", likelihood, \"identity\")\n&gt;&gt;&gt; bmb.Model(\"y ~ x\", data, family=family, priors={\"sigma\": sigma_prior})\nReplicate the Bernoulli built-in family.\n&gt;&gt;&gt; likelihood = bmb.Likelihood(\"Bernoulli\", parent=\"p\")\n&gt;&gt;&gt; family = bmb.Family(\"bernoulli\", likelihood, \"logit\")\n&gt;&gt;&gt; bmb.Model(\"y ~ x\", data, family=family)\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nauxiliary_parameters\nGet names of auxiliary parameters\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nlog_likelihood\nEvaluate the model log-likelihood\n\n\nposterior_predictive\nGet draws from the posterior predictive distribution\n\n\nset_default_priors\nSet default priors for non-parent parameters\n\n\n\n\n\nFamily.log_likelihood(self, model, posterior, data, **kwargs)\nEvaluate the model log-likelihood\nThis method uses pm.logp().\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\nbambi.Model\nThe model\nrequired\n\n\nposterior\nxr.Dataset\nThe xarray dataset that contains the draws for all the parameters in the posterior. It must contain the parameters that are needed in the distribution of the response, or the parameters that allow to derive them.\nrequired\n\n\nkwargs\n\nParameters that are used to get draws but do not appear in the posterior object or other configuration parameters. For instance, the ‘n’ in binomial models and multinomial models.\n{}\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nxr.DataArray\nA data array with the value of the log-likelihood for each chain, draw, and value of the response variable.\n\n\n\n\n\n\n\nFamily.posterior_predictive(self, model, posterior, random_seed, **kwargs)\nGet draws from the posterior predictive distribution\nThis function works for almost all the families. It grabs the draws for the parameters needed in the response distribution, and then gets samples from the posterior predictive distribution using pm.draw(). It won’t work when the response distribution requires parameters that are not available in posterior.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\nbambi.Model\nThe model\nrequired\n\n\nposterior\nxr.Dataset\nThe xarray dataset that contains the draws for all the parameters in the posterior. It must contain the parameters that are needed in the distribution of the response, or the parameters that allow to derive them.\nrequired\n\n\nrandom_seed\n(int, RandomState or Generator)\nSeed for the random number generator.\nrequired\n\n\nkwargs\n\nParameters that are used to get draws but do not appear in the posterior object or other configuration parameters. For instance, the ‘n’ in binomial models and multinomial models.\n{}\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nxr.DataArray\nA data array with the draws from the posterior predictive distribution.\n\n\n\n\n\n\n\nFamily.set_default_priors(self, priors)\nSet default priors for non-parent parameters\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npriors\ndict\nThe keys are the names of non-parent parameters and the values are their default priors.\nrequired",
    "crumbs": [
      "API Reference",
      "Custom families",
      "Family"
    ]
  },
  {
    "objectID": "api/Family.html#parameters",
    "href": "api/Family.html#parameters",
    "title": "Family",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nname\nstr\nThe name of the family. It can be any string.\nrequired\n\n\nlikelihood\nLikelihood\nA bambi.families.Likelihood instance specifying the model likelihood function.\nrequired\n\n\nlink\nUnion[str, Dict[str, Union[str, Link]]]\nThe link function that’s used for every parameter in the likelihood function. Keys are the names of the parameters and values are the link functions. These can be a str with a name or a bambi.families.Link instance. The link function transforms the linear predictors.\nrequired",
    "crumbs": [
      "API Reference",
      "Custom families",
      "Family"
    ]
  },
  {
    "objectID": "api/Family.html#examples",
    "href": "api/Family.html#examples",
    "title": "Family",
    "section": "",
    "text": "&gt;&gt;&gt; import bambi as bmb\nReplicate the Gaussian built-in family.\n&gt;&gt;&gt; sigma_prior = bmb.Prior(\"HalfNormal\", sigma=1)\n&gt;&gt;&gt; likelihood = bmb.Likelihood(\"Gaussian\", params=[\"mu\", \"sigma\"], parent=\"mu\")\n&gt;&gt;&gt; family = bmb.Family(\"gaussian\", likelihood, \"identity\")\n&gt;&gt;&gt; bmb.Model(\"y ~ x\", data, family=family, priors={\"sigma\": sigma_prior})\nReplicate the Bernoulli built-in family.\n&gt;&gt;&gt; likelihood = bmb.Likelihood(\"Bernoulli\", parent=\"p\")\n&gt;&gt;&gt; family = bmb.Family(\"bernoulli\", likelihood, \"logit\")\n&gt;&gt;&gt; bmb.Model(\"y ~ x\", data, family=family)",
    "crumbs": [
      "API Reference",
      "Custom families",
      "Family"
    ]
  },
  {
    "objectID": "api/Family.html#attributes",
    "href": "api/Family.html#attributes",
    "title": "Family",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nauxiliary_parameters\nGet names of auxiliary parameters",
    "crumbs": [
      "API Reference",
      "Custom families",
      "Family"
    ]
  },
  {
    "objectID": "api/Family.html#methods",
    "href": "api/Family.html#methods",
    "title": "Family",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nlog_likelihood\nEvaluate the model log-likelihood\n\n\nposterior_predictive\nGet draws from the posterior predictive distribution\n\n\nset_default_priors\nSet default priors for non-parent parameters\n\n\n\n\n\nFamily.log_likelihood(self, model, posterior, data, **kwargs)\nEvaluate the model log-likelihood\nThis method uses pm.logp().\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\nbambi.Model\nThe model\nrequired\n\n\nposterior\nxr.Dataset\nThe xarray dataset that contains the draws for all the parameters in the posterior. It must contain the parameters that are needed in the distribution of the response, or the parameters that allow to derive them.\nrequired\n\n\nkwargs\n\nParameters that are used to get draws but do not appear in the posterior object or other configuration parameters. For instance, the ‘n’ in binomial models and multinomial models.\n{}\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nxr.DataArray\nA data array with the value of the log-likelihood for each chain, draw, and value of the response variable.\n\n\n\n\n\n\n\nFamily.posterior_predictive(self, model, posterior, random_seed, **kwargs)\nGet draws from the posterior predictive distribution\nThis function works for almost all the families. It grabs the draws for the parameters needed in the response distribution, and then gets samples from the posterior predictive distribution using pm.draw(). It won’t work when the response distribution requires parameters that are not available in posterior.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\nbambi.Model\nThe model\nrequired\n\n\nposterior\nxr.Dataset\nThe xarray dataset that contains the draws for all the parameters in the posterior. It must contain the parameters that are needed in the distribution of the response, or the parameters that allow to derive them.\nrequired\n\n\nrandom_seed\n(int, RandomState or Generator)\nSeed for the random number generator.\nrequired\n\n\nkwargs\n\nParameters that are used to get draws but do not appear in the posterior object or other configuration parameters. For instance, the ‘n’ in binomial models and multinomial models.\n{}\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nxr.DataArray\nA data array with the draws from the posterior predictive distribution.\n\n\n\n\n\n\n\nFamily.set_default_priors(self, priors)\nSet default priors for non-parent parameters\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npriors\ndict\nThe keys are the names of non-parent parameters and the values are their default priors.\nrequired",
    "crumbs": [
      "API Reference",
      "Custom families",
      "Family"
    ]
  },
  {
    "objectID": "api/Likelihood.html",
    "href": "api/Likelihood.html",
    "title": "Likelihood",
    "section": "",
    "text": "families.Likelihood(self, name, params=None, parent=None, dist=None)\nRepresentation of a Likelihood function for a Bambi model\nNotes: * parent must be in params * parent is inferred from the name if it is a known name\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nname\nstr\nName of the likelihood function. Must be a valid PyMC distribution name.\nrequired\n\n\nparams\nSequence[str]\nThe name of the parameters the likelihood function accepts.\nNone\n\n\nparent\nstr\nOptional specification of the name of the mean parameter in the likelihood. This is the parameter whose transformation is modeled by the linear predictor.\nNone\n\n\ndist\npymc.distributions.distribution.DistributionMeta or callable\nOptional custom PyMC distribution that will be used to compute the likelihood.\nNone",
    "crumbs": [
      "API Reference",
      "Custom families",
      "Likelihood"
    ]
  },
  {
    "objectID": "api/Likelihood.html#parameters",
    "href": "api/Likelihood.html#parameters",
    "title": "Likelihood",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nname\nstr\nName of the likelihood function. Must be a valid PyMC distribution name.\nrequired\n\n\nparams\nSequence[str]\nThe name of the parameters the likelihood function accepts.\nNone\n\n\nparent\nstr\nOptional specification of the name of the mean parameter in the likelihood. This is the parameter whose transformation is modeled by the linear predictor.\nNone\n\n\ndist\npymc.distributions.distribution.DistributionMeta or callable\nOptional custom PyMC distribution that will be used to compute the likelihood.\nNone",
    "crumbs": [
      "API Reference",
      "Custom families",
      "Likelihood"
    ]
  },
  {
    "objectID": "api/Model.html",
    "href": "api/Model.html",
    "title": "Model",
    "section": "",
    "text": "Model(self, formula, data, family='gaussian', priors=None, link=None, categorical=None, potentials=None, dropna=False, auto_scale=True, noncentered=True, center_predictors=True, extra_namespace=None)\nSpecification of model class\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nformula\nstr or bambi.formula.Formula\nA model description written using the formula syntax from the formulae library.\nrequired\n\n\ndata\npandas.DataFrame\nA pandas dataframe containing the data on which the model will be fit, with column names matching variables defined in the formula.\nrequired\n\n\nfamily\nstr or bambi.families.Family\nA specification of the model family (analogous to the family object in R). Either a string, or an instance of class bambi.families.Family. If a string is passed, a family with the corresponding name must be defined in the defaults loaded at Model initialization. Valid pre-defined families are \"bernoulli\", \"beta\", \"binomial\", \"categorical\", \"gamma\", \"gaussian\", \"negativebinomial\", \"poisson\", \"t\", and \"wald\". Defaults to \"gaussian\".\n'gaussian'\n\n\npriors\ndict\nOptional specification of priors for one or more terms. A dictionary where the keys are the names of terms in the model, “common,” or “group_specific” and the values are instances of class Prior. If priors are unset, uses automatic priors inspired by the R rstanarm library.\nNone\n\n\nlink\nstr or Dict[str, str]\nThe name of the link function to use. Valid names are \"cloglog\", \"identity\", \"inverse_squared\", \"inverse\", \"log\", \"logit\", \"probit\", and \"softmax\". Not all the link functions can be used with all the families. If a dictionary, keys are the names of the target parameters and the values are the names of the link functions.\nNone\n\n\ncategorical\nstr or list\nThe names of any variables to treat as categorical. Can be either a single variable name, or a list of names. If categorical is None, the data type of the columns in the data will be used to infer handling. In cases where numeric columns are to be treated as categorical (e.g., group specific factors coded as numerical IDs), explicitly passing variable names via this argument is recommended.\nNone\n\n\npotentials\nA list of 2-tuples.\nOptional specification of potentials. A potential is an arbitrary expression added to the likelihood, this is generally useful to add constrains to models, that are difficult to express otherwise. The first term of a 2-tuple is the name of a variable in the model, the second a lambda function expressing the desired constraint. If a constraint involves n variables, you can pass n 2-tuples or pass a tuple which first element is a n-tuple and second element is a lambda function with n arguments. The number and order of the lambda function has to match the number and order of the variables names.\nNone\n\n\ndropna\nbool\nWhen True, rows with any missing values in either the predictors or outcome are automatically dropped from the dataset in a listwise manner.\nFalse\n\n\nauto_scale\nbool\nIf True (default), priors are automatically rescaled to the data (to be weakly informative) any time default priors are used. Note that any priors explicitly set by the user will always take precedence over default priors.\nTrue\n\n\nnoncentered\nbool\nIf True (default), uses a non-centered parameterization for normal hyperpriors on grouped parameters. If False, naive (centered) parameterization is used.\nTrue\n\n\ncenter_predictors\nbool\nIf True (default), and if there is an intercept in the common terms, the data is centered by subtracting the mean. The centering is undone after sampling to provide the actual intercept in all distributional components that have an intercept. Note that this changes the interpretation of the prior on the intercept because it refers to the intercept of the centered data.\nTrue\n\n\nextra_namespace\ndict\nAdditional user supplied variables with transformations or data to include in the environment where the formula is evaluated. Defaults to None.\nNone\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nbuild\nSet up the model for sampling/fitting\n\n\ncompute_log_likelihood\nCompute the model’s log-likelihood\n\n\nfit\nFit the model using PyMC\n\n\ngraph\nProduce a graphviz Digraph from a built Bambi model.\n\n\nplot_priors\nSamples from the prior distribution and plots its marginals.\n\n\npredict\nPredict method for Bambi models\n\n\nprior_predictive\nGenerate samples from the prior predictive distribution.\n\n\nr2_score\nR² for Bayesian regression models.\n\n\nset_alias\nSet aliases for the terms and auxiliary parameters in the model\n\n\nset_priors\nSet priors for one or more existing terms\n\n\n\n\n\nModel.build(self)\nSet up the model for sampling/fitting\nCreates an instance of the underlying PyMC model and adds all the necessary terms to it.\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone.\n\n\n\n\n\n\n\n\nModel.compute_log_likelihood(self, idata, data=None, inplace=True)\nCompute the model’s log-likelihood\nNOTE: This is a new feature and it may not work in all cases.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nidata\nInferenceData\nThe InferenceData instance returned by .fit().\nrequired\n\n\ndata\npandas.DataFrame or None\nAn optional data frame with values for the predictors and the response on which the model’s log-likelihood function is evaluated. If omitted, the original dataset is used.\nNone\n\n\ninplace\nbool\nIf Trueit will modifyidatain-place. Otherwise, it will return a copy ofidatawith thelog_likelihoodgroup added.                                                |True`\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInferenceData or None\n\n\n\n\n\n\n\n\nModel.fit(self, draws=1000, tune=1000, discard_tuned_samples=True, omit_offsets=True, include_mean=None, include_response_params=False, inference_method='mcmc', init='auto', n_init=50000, chains=None, cores=None, random_seed=None, **kwargs)\nFit the model using PyMC\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndraws\n\nThe number of samples to draw from the posterior distribution. Defaults to 1000.\n1000\n\n\ntune\nint\nNumber of iterations to tune. Defaults to 1000. Samplers adjust the step sizes, scalings or similar during tuning. These tuning samples are be drawn in addition to the number specified in the draws argument, and will be discarded unless discard_tuned_samples is set to False.\n1000\n\n\ndiscard_tuned_samples\nbool\nWhether to discard posterior samples of the tune interval. Defaults to True.\nTrue\n\n\nomit_offsets\nbool\nOmits offset terms in the InferenceData object returned when the model includes group specific effects. Defaults to True.\nTrue\n\n\ninclude_mean\nbool\nDeprecated. Use include_response_params.\nNone\n\n\ninclude_response_params\nbool\nInclude parameters of the response distribution in the output. These usually take more space than other parameters as there’s one of them per observation. Defaults to False.\nFalse\n\n\ninference_method\nstr\nThe method to use for fitting the model. By default, \"mcmc\". This automatically assigns a MCMC method best suited for each kind of variables, like NUTS for continuous variables and Metropolis for non-binary discrete ones. Alternatively, \"vi\", in which case the model will be fitted using variational inference as implemented in PyMC using the fit function. Finally, \"laplace\", in which case a Laplace approximation is used and is not recommended other than for pedagogical use. To get a list of JAX based inference methods, call bmb.inference_methods.names['bayeux']. This will return a dictionary of the available methods such as blackjax_nuts, numpyro_nuts, among others.\n'mcmc'\n\n\ninit\nstr\nInitialization method. Defaults to \"auto\". The available methods are: * auto: Use \"jitter+adapt_diag\" and if this method fails it uses \"adapt_diag\". * adapt_diag: Start with a identity mass matrix and then adapt a diagonal based on the variance of the tuning samples. All chains use the test value (usually the prior mean) as starting point. * jitter+adapt_diag: Same as \"adapt_diag\", but use test value plus a uniform jitter in [-1, 1] as starting point in each chain. * advi+adapt_diag: Run ADVI and then adapt the resulting diagonal mass matrix based on the sample variance of the tuning samples. * advi+adapt_diag_grad: Run ADVI and then adapt the resulting diagonal mass matrix based on the variance of the gradients during tuning. This is experimental and might be removed in a future release. * advi: Run ADVI to estimate posterior mean and diagonal mass matrix. * advi_map: Initialize ADVI with MAP and use MAP as starting point. * map: Use the MAP as starting point. This is strongly discouraged. * adapt_full: Adapt a dense mass matrix using the sample covariances. All chains use the test value (usually the prior mean) as starting point. * jitter+adapt_full: Same as \"adapt_full\", but use test value plus a uniform jitter in [-1, 1] as starting point in each chain.\n'auto'\n\n\nn_init\nint\nNumber of initialization iterations. Only works for \"advi\" init methods.\n50000\n\n\nchains\nint\nThe number of chains to sample. Running independent chains is important for some convergence statistics and can also reveal multiple modes in the posterior. If None, then set to either cores or 2, whichever is larger.\nNone\n\n\ncores\nint\nThe number of chains to run in parallel. If None, it is equal to the number of CPUs in the system unless there are more than 4 CPUs, in which case it is set to 4.\nNone\n\n\nrandom_seed\nint or list of ints\nA list is accepted if cores is greater than one.\nNone\n\n\n**kwargs\n\nFor other kwargs see the documentation for PyMC.sample().\n{}\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAn ArviZ InferenceData instance if inference_method is \"mcmc\" (default),\n\n\n\n“laplace”, or one of the MCMC methods in\n\n\n\nbmb.inference_methods.names\\['bayeux'\\]\\['mcmc\\].\n\n\n\nAn Approximation object if \"vi\".\n\n\n\n\n\n\n\n\nModel.graph(self, formatting='plain', name=None, figsize=None, dpi=300, fmt='png')\nProduce a graphviz Digraph from a built Bambi model.\nRequires graphviz, which may be installed most easily with conda install -c conda-forge python-graphviz\nAlternatively, you may install the graphviz binaries yourself, and then pip install graphviz to get the python bindings. See http://graphviz.readthedocs.io/en/stable/manual.html for more information.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nformatting\nstr\nOne of \"plain\" or \"plain_with_params\". Defaults to \"plain\".\n'plain'\n\n\nname\nstr\nName of the figure to save. Defaults to None, no figure is saved.\nNone\n\n\nfigsize\ntuple\nMaximum width and height of figure in inches. Defaults to None, the figure size is set automatically. If defined and the drawing is larger than the given size, the drawing is uniformly scaled down so that it fits within the given size. Only works if name is not None.\nNone\n\n\ndpi\nint\nPoint per inch of the figure to save. Defaults to 300. Only works if name is not None.\n300\n\n\nfmt\nstr\nFormat of the figure to save. Defaults to \"png\". Only works if name is not None.\n'png'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ngraphviz.Digraph\nThe graph\n\n\n\n\n\n\n\n\n\nmodel = Model(“y ~ x + (1|z)”) model.build() model.graph()\n\n\n\n\n\n\nmodel = Model(“y ~ x + (1|z)”) model.fit() model.graph()\n\n\n\n\n\n\n\nModel.plot_priors(self, draws=5000, var_names=None, random_seed=None, figsize=None, textsize=None, hdi_prob=None, round_to=2, point_estimate='mean', kind='kde', bins=None, omit_offsets=True, omit_group_specific=True, ax=None, **kwargs)\nSamples from the prior distribution and plots its marginals.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndraws\nint\nNumber of draws to sample from the prior predictive distribution. Defaults to 5000.\n5000\n\n\nvar_names\nstr or list\nA list of names of variables for which to compute the prior predictive distribution. Defaults to None which means to include both observed and unobserved RVs.\nNone\n\n\nrandom_seed\nint\nSeed for the random number generator.\nNone\n\n\nfigsize\ntuple\nFigure size. If None it will be defined automatically.\nNone\n\n\ntextsize\nfloat\nText size scaling factor for labels, titles and lines. If None it will be autoscaled based on figsize.\nNone\n\n\nhdi_prob\nfloat or str\nPlots highest density interval for chosen percentage of density. Use \"hide\" to hide the highest density interval. Defaults to 0.94.\nNone\n\n\nround_to\nint\nControls formatting of floats. Defaults to 2 or the integer part, whichever is bigger.\n2\n\n\npoint_estimate\nstr\nPlot point estimate per variable. Values should be \"mean\", \"median\", \"mode\" or None. Defaults to \"auto\" i.e. it falls back to default set in ArviZ’s rcParams.\n'mean'\n\n\nkind\nstr\nType of plot to display (\"kde\" or \"hist\") For discrete variables this argument is ignored and a histogram is always used.\n'kde'\n\n\nbins\ninteger or sequence or auto\nControls the number of bins, accepts the same keywords matplotlib.pyplot.hist() does. Only works if kind == \"hist\". If None (default) it will use \"auto\" for continuous variables and range(xmin, xmax + 1) for discrete variables.\nNone\n\n\nomit_offsets\nbool\nWhether to omit offset terms in the plot. Defaults to True.\nTrue\n\n\nomit_group_specific\nbool\nWhether to omit group specific effects in the plot. Defaults to True.\nTrue\n\n\nax\nnumpy array-like of matplotlib axes or bokeh figures\nA 2D array of locations into which to plot the densities. If not supplied, ArviZ will create its own array of plot areas (and return it).\nNone\n\n\n**kwargs\n\nPassed as-is to matplotlib.pyplot.hist() or matplotlib.pyplot.plot() function depending on the value of kind.\n{}\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmatplotlib axes.\n\n\n\n\n\n\n\n\nModel.predict(self, idata, kind='response_params', data=None, inplace=True, include_group_specific=True, sample_new_groups=False, random_seed=None)\nPredict method for Bambi models\nObtains in-sample and out-of-sample predictions from a fitted Bambi model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nidata\nInferenceData\nThe InferenceData instance returned by .fit().\nrequired\n\n\nkind\nstr\nIndicates the type of prediction required. Can be \"response_params\" or \"response\". The first returns draws from the posterior distribution of the likelihood parameters, while the latter returns the draws from the posterior predictive distribution (i.e. the posterior probability distribution for a new observation) in addition to the posterior distribution. Defaults to \"response_params\".\n'response_params'\n\n\ndata\npandas.DataFrame or None\nAn optional data frame with values for the predictors that are used to obtain out-of-sample predictions. If omitted, the original dataset is used.\nNone\n\n\ninplace\nbool\nIf True it will modify idata in-place. Otherwise, it will return a copy of idata with the predictions added. If kind=\"response_params\", a new variable with the name of the parent parameter, e.g. \"mu\" and \"sigma\" for a Gaussian likelihood, or“p”for a Bernoulli likelihood, is added to theposteriorgroup. Ifkind=“response”, it appends aposterior_predictivegroup toidata. If any of these already exist, it will be overwritten. |True| |include_group_specific| bool                            | Determines if predictions incorporate group-specific effects. IfFalse, predictions are made with common effects only (i.e. group specific are set to zero). Defaults toTrue.                                                                                                                                                                                                                                                                                   |True| |sample_new_groups| bool                            | Specifies if it is allowed to obtain predictions for new groups of group-specific terms. WhenTrue, each posterior sample for the new groups is drawn from the posterior draws of a randomly selected existing group. Since different groups may be selected at each draw, the end result represents the variation across existing groups. The method implemented is equivalent tosample_new_levels=“uncertainty”in brms.                                      |False| |random_seed| (int, RandomState or Generator) | Seed for the random number generator.                                                                                                                                                                                                                                                                                                                                                                                                                                |None`\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInferenceData or None\n\n\n\n\n\n\n\n\nModel.prior_predictive(self, draws=500, var_names=None, omit_offsets=True, random_seed=None)\nGenerate samples from the prior predictive distribution.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndraws\nint\nNumber of draws to sample from the prior predictive distribution. Defaults to 500.\n500\n\n\nvar_names\nstr or list\nA list of names of variables for which to compute the prior predictive distribution. Defaults to None which means both observed and unobserved RVs.\nNone\n\n\nomit_offsets\nbool\nWhether to omit offset terms in the plot. Defaults to True.\nTrue\n\n\nrandom_seed\nint\nSeed for the random number generator.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInferenceData\nInferenceData object with the groups prior, prior_predictive and observed_data.\n\n\n\n\n\n\n\nModel.r2_score(self, idata, summary=True)\nR² for Bayesian regression models.\nThe R², or coefficient of determination, is defined as the proportion of variance in the data that is explained by the model. It is computed as the variance of the predicted values divided by the variance of the predicted values plus the variance of the residuals. For details of the Bayesian R² see [1]_.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nidata\nInferenceData\nThe InferenceData instance returned by .fit(). It should contain the posterior_predictive group, otherwise it will be computed and added to idata.\nrequired\n\n\nsummary\nbool\nIf True, it returns a summary of the Bayesian R². Otherwise, it returns the posterior samples of the Bayesian R².\nTrue\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPandas Series with the following indices:\n\n\n\nmean value for the Bayesian R²\n\n\n\nstandard deviation of the Bayesian R².\n\n\n\n\n\n\n\n.. [1] Gelman et al. R-squared for Bayesian regression models. The American Statistician. 73(3) (2019). https://doi.org/10.1080/00031305.2018.1549100 preprint http://www.stat.columbia.edu/~gelman/research/published/bayes_R2_v3.pdf.\n\n\n\n\nModel.set_alias(self, aliases)\nSet aliases for the terms and auxiliary parameters in the model\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naliases\ndict\nA dictionary where key represents the original term name and the value is the alias.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone.\n\n\n\n\n\n\n\n\nModel.set_priors(self, priors=None, common=None, group_specific=None)\nSet priors for one or more existing terms\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npriors\ndict\nDictionary of priors to update. Keys are names of terms to update; values are the new priors (either a Prior instance, or an int or float that scales the default priors).\nNone\n\n\ncommon\nPrior, int, or float\nA prior specification to apply to all common terms included in the model.\nNone\n\n\ngroup_specific\nPrior, int, or float\nA prior specification to apply to all group specific terms included in the model.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone.",
    "crumbs": [
      "API Reference",
      "Model",
      "Model"
    ]
  },
  {
    "objectID": "api/Model.html#parameters",
    "href": "api/Model.html#parameters",
    "title": "Model",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nformula\nstr or bambi.formula.Formula\nA model description written using the formula syntax from the formulae library.\nrequired\n\n\ndata\npandas.DataFrame\nA pandas dataframe containing the data on which the model will be fit, with column names matching variables defined in the formula.\nrequired\n\n\nfamily\nstr or bambi.families.Family\nA specification of the model family (analogous to the family object in R). Either a string, or an instance of class bambi.families.Family. If a string is passed, a family with the corresponding name must be defined in the defaults loaded at Model initialization. Valid pre-defined families are \"bernoulli\", \"beta\", \"binomial\", \"categorical\", \"gamma\", \"gaussian\", \"negativebinomial\", \"poisson\", \"t\", and \"wald\". Defaults to \"gaussian\".\n'gaussian'\n\n\npriors\ndict\nOptional specification of priors for one or more terms. A dictionary where the keys are the names of terms in the model, “common,” or “group_specific” and the values are instances of class Prior. If priors are unset, uses automatic priors inspired by the R rstanarm library.\nNone\n\n\nlink\nstr or Dict[str, str]\nThe name of the link function to use. Valid names are \"cloglog\", \"identity\", \"inverse_squared\", \"inverse\", \"log\", \"logit\", \"probit\", and \"softmax\". Not all the link functions can be used with all the families. If a dictionary, keys are the names of the target parameters and the values are the names of the link functions.\nNone\n\n\ncategorical\nstr or list\nThe names of any variables to treat as categorical. Can be either a single variable name, or a list of names. If categorical is None, the data type of the columns in the data will be used to infer handling. In cases where numeric columns are to be treated as categorical (e.g., group specific factors coded as numerical IDs), explicitly passing variable names via this argument is recommended.\nNone\n\n\npotentials\nA list of 2-tuples.\nOptional specification of potentials. A potential is an arbitrary expression added to the likelihood, this is generally useful to add constrains to models, that are difficult to express otherwise. The first term of a 2-tuple is the name of a variable in the model, the second a lambda function expressing the desired constraint. If a constraint involves n variables, you can pass n 2-tuples or pass a tuple which first element is a n-tuple and second element is a lambda function with n arguments. The number and order of the lambda function has to match the number and order of the variables names.\nNone\n\n\ndropna\nbool\nWhen True, rows with any missing values in either the predictors or outcome are automatically dropped from the dataset in a listwise manner.\nFalse\n\n\nauto_scale\nbool\nIf True (default), priors are automatically rescaled to the data (to be weakly informative) any time default priors are used. Note that any priors explicitly set by the user will always take precedence over default priors.\nTrue\n\n\nnoncentered\nbool\nIf True (default), uses a non-centered parameterization for normal hyperpriors on grouped parameters. If False, naive (centered) parameterization is used.\nTrue\n\n\ncenter_predictors\nbool\nIf True (default), and if there is an intercept in the common terms, the data is centered by subtracting the mean. The centering is undone after sampling to provide the actual intercept in all distributional components that have an intercept. Note that this changes the interpretation of the prior on the intercept because it refers to the intercept of the centered data.\nTrue\n\n\nextra_namespace\ndict\nAdditional user supplied variables with transformations or data to include in the environment where the formula is evaluated. Defaults to None.\nNone",
    "crumbs": [
      "API Reference",
      "Model",
      "Model"
    ]
  },
  {
    "objectID": "api/Model.html#methods",
    "href": "api/Model.html#methods",
    "title": "Model",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nbuild\nSet up the model for sampling/fitting\n\n\ncompute_log_likelihood\nCompute the model’s log-likelihood\n\n\nfit\nFit the model using PyMC\n\n\ngraph\nProduce a graphviz Digraph from a built Bambi model.\n\n\nplot_priors\nSamples from the prior distribution and plots its marginals.\n\n\npredict\nPredict method for Bambi models\n\n\nprior_predictive\nGenerate samples from the prior predictive distribution.\n\n\nr2_score\nR² for Bayesian regression models.\n\n\nset_alias\nSet aliases for the terms and auxiliary parameters in the model\n\n\nset_priors\nSet priors for one or more existing terms\n\n\n\n\n\nModel.build(self)\nSet up the model for sampling/fitting\nCreates an instance of the underlying PyMC model and adds all the necessary terms to it.\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone.\n\n\n\n\n\n\n\n\nModel.compute_log_likelihood(self, idata, data=None, inplace=True)\nCompute the model’s log-likelihood\nNOTE: This is a new feature and it may not work in all cases.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nidata\nInferenceData\nThe InferenceData instance returned by .fit().\nrequired\n\n\ndata\npandas.DataFrame or None\nAn optional data frame with values for the predictors and the response on which the model’s log-likelihood function is evaluated. If omitted, the original dataset is used.\nNone\n\n\ninplace\nbool\nIf Trueit will modifyidatain-place. Otherwise, it will return a copy ofidatawith thelog_likelihoodgroup added.                                                |True`\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInferenceData or None\n\n\n\n\n\n\n\n\nModel.fit(self, draws=1000, tune=1000, discard_tuned_samples=True, omit_offsets=True, include_mean=None, include_response_params=False, inference_method='mcmc', init='auto', n_init=50000, chains=None, cores=None, random_seed=None, **kwargs)\nFit the model using PyMC\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndraws\n\nThe number of samples to draw from the posterior distribution. Defaults to 1000.\n1000\n\n\ntune\nint\nNumber of iterations to tune. Defaults to 1000. Samplers adjust the step sizes, scalings or similar during tuning. These tuning samples are be drawn in addition to the number specified in the draws argument, and will be discarded unless discard_tuned_samples is set to False.\n1000\n\n\ndiscard_tuned_samples\nbool\nWhether to discard posterior samples of the tune interval. Defaults to True.\nTrue\n\n\nomit_offsets\nbool\nOmits offset terms in the InferenceData object returned when the model includes group specific effects. Defaults to True.\nTrue\n\n\ninclude_mean\nbool\nDeprecated. Use include_response_params.\nNone\n\n\ninclude_response_params\nbool\nInclude parameters of the response distribution in the output. These usually take more space than other parameters as there’s one of them per observation. Defaults to False.\nFalse\n\n\ninference_method\nstr\nThe method to use for fitting the model. By default, \"mcmc\". This automatically assigns a MCMC method best suited for each kind of variables, like NUTS for continuous variables and Metropolis for non-binary discrete ones. Alternatively, \"vi\", in which case the model will be fitted using variational inference as implemented in PyMC using the fit function. Finally, \"laplace\", in which case a Laplace approximation is used and is not recommended other than for pedagogical use. To get a list of JAX based inference methods, call bmb.inference_methods.names['bayeux']. This will return a dictionary of the available methods such as blackjax_nuts, numpyro_nuts, among others.\n'mcmc'\n\n\ninit\nstr\nInitialization method. Defaults to \"auto\". The available methods are: * auto: Use \"jitter+adapt_diag\" and if this method fails it uses \"adapt_diag\". * adapt_diag: Start with a identity mass matrix and then adapt a diagonal based on the variance of the tuning samples. All chains use the test value (usually the prior mean) as starting point. * jitter+adapt_diag: Same as \"adapt_diag\", but use test value plus a uniform jitter in [-1, 1] as starting point in each chain. * advi+adapt_diag: Run ADVI and then adapt the resulting diagonal mass matrix based on the sample variance of the tuning samples. * advi+adapt_diag_grad: Run ADVI and then adapt the resulting diagonal mass matrix based on the variance of the gradients during tuning. This is experimental and might be removed in a future release. * advi: Run ADVI to estimate posterior mean and diagonal mass matrix. * advi_map: Initialize ADVI with MAP and use MAP as starting point. * map: Use the MAP as starting point. This is strongly discouraged. * adapt_full: Adapt a dense mass matrix using the sample covariances. All chains use the test value (usually the prior mean) as starting point. * jitter+adapt_full: Same as \"adapt_full\", but use test value plus a uniform jitter in [-1, 1] as starting point in each chain.\n'auto'\n\n\nn_init\nint\nNumber of initialization iterations. Only works for \"advi\" init methods.\n50000\n\n\nchains\nint\nThe number of chains to sample. Running independent chains is important for some convergence statistics and can also reveal multiple modes in the posterior. If None, then set to either cores or 2, whichever is larger.\nNone\n\n\ncores\nint\nThe number of chains to run in parallel. If None, it is equal to the number of CPUs in the system unless there are more than 4 CPUs, in which case it is set to 4.\nNone\n\n\nrandom_seed\nint or list of ints\nA list is accepted if cores is greater than one.\nNone\n\n\n**kwargs\n\nFor other kwargs see the documentation for PyMC.sample().\n{}\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAn ArviZ InferenceData instance if inference_method is \"mcmc\" (default),\n\n\n\n“laplace”, or one of the MCMC methods in\n\n\n\nbmb.inference_methods.names\\['bayeux'\\]\\['mcmc\\].\n\n\n\nAn Approximation object if \"vi\".\n\n\n\n\n\n\n\n\nModel.graph(self, formatting='plain', name=None, figsize=None, dpi=300, fmt='png')\nProduce a graphviz Digraph from a built Bambi model.\nRequires graphviz, which may be installed most easily with conda install -c conda-forge python-graphviz\nAlternatively, you may install the graphviz binaries yourself, and then pip install graphviz to get the python bindings. See http://graphviz.readthedocs.io/en/stable/manual.html for more information.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nformatting\nstr\nOne of \"plain\" or \"plain_with_params\". Defaults to \"plain\".\n'plain'\n\n\nname\nstr\nName of the figure to save. Defaults to None, no figure is saved.\nNone\n\n\nfigsize\ntuple\nMaximum width and height of figure in inches. Defaults to None, the figure size is set automatically. If defined and the drawing is larger than the given size, the drawing is uniformly scaled down so that it fits within the given size. Only works if name is not None.\nNone\n\n\ndpi\nint\nPoint per inch of the figure to save. Defaults to 300. Only works if name is not None.\n300\n\n\nfmt\nstr\nFormat of the figure to save. Defaults to \"png\". Only works if name is not None.\n'png'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ngraphviz.Digraph\nThe graph\n\n\n\n\n\n\n\n\n\nmodel = Model(“y ~ x + (1|z)”) model.build() model.graph()\n\n\n\n\n\n\nmodel = Model(“y ~ x + (1|z)”) model.fit() model.graph()\n\n\n\n\n\n\n\nModel.plot_priors(self, draws=5000, var_names=None, random_seed=None, figsize=None, textsize=None, hdi_prob=None, round_to=2, point_estimate='mean', kind='kde', bins=None, omit_offsets=True, omit_group_specific=True, ax=None, **kwargs)\nSamples from the prior distribution and plots its marginals.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndraws\nint\nNumber of draws to sample from the prior predictive distribution. Defaults to 5000.\n5000\n\n\nvar_names\nstr or list\nA list of names of variables for which to compute the prior predictive distribution. Defaults to None which means to include both observed and unobserved RVs.\nNone\n\n\nrandom_seed\nint\nSeed for the random number generator.\nNone\n\n\nfigsize\ntuple\nFigure size. If None it will be defined automatically.\nNone\n\n\ntextsize\nfloat\nText size scaling factor for labels, titles and lines. If None it will be autoscaled based on figsize.\nNone\n\n\nhdi_prob\nfloat or str\nPlots highest density interval for chosen percentage of density. Use \"hide\" to hide the highest density interval. Defaults to 0.94.\nNone\n\n\nround_to\nint\nControls formatting of floats. Defaults to 2 or the integer part, whichever is bigger.\n2\n\n\npoint_estimate\nstr\nPlot point estimate per variable. Values should be \"mean\", \"median\", \"mode\" or None. Defaults to \"auto\" i.e. it falls back to default set in ArviZ’s rcParams.\n'mean'\n\n\nkind\nstr\nType of plot to display (\"kde\" or \"hist\") For discrete variables this argument is ignored and a histogram is always used.\n'kde'\n\n\nbins\ninteger or sequence or auto\nControls the number of bins, accepts the same keywords matplotlib.pyplot.hist() does. Only works if kind == \"hist\". If None (default) it will use \"auto\" for continuous variables and range(xmin, xmax + 1) for discrete variables.\nNone\n\n\nomit_offsets\nbool\nWhether to omit offset terms in the plot. Defaults to True.\nTrue\n\n\nomit_group_specific\nbool\nWhether to omit group specific effects in the plot. Defaults to True.\nTrue\n\n\nax\nnumpy array-like of matplotlib axes or bokeh figures\nA 2D array of locations into which to plot the densities. If not supplied, ArviZ will create its own array of plot areas (and return it).\nNone\n\n\n**kwargs\n\nPassed as-is to matplotlib.pyplot.hist() or matplotlib.pyplot.plot() function depending on the value of kind.\n{}\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmatplotlib axes.\n\n\n\n\n\n\n\n\nModel.predict(self, idata, kind='response_params', data=None, inplace=True, include_group_specific=True, sample_new_groups=False, random_seed=None)\nPredict method for Bambi models\nObtains in-sample and out-of-sample predictions from a fitted Bambi model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nidata\nInferenceData\nThe InferenceData instance returned by .fit().\nrequired\n\n\nkind\nstr\nIndicates the type of prediction required. Can be \"response_params\" or \"response\". The first returns draws from the posterior distribution of the likelihood parameters, while the latter returns the draws from the posterior predictive distribution (i.e. the posterior probability distribution for a new observation) in addition to the posterior distribution. Defaults to \"response_params\".\n'response_params'\n\n\ndata\npandas.DataFrame or None\nAn optional data frame with values for the predictors that are used to obtain out-of-sample predictions. If omitted, the original dataset is used.\nNone\n\n\ninplace\nbool\nIf True it will modify idata in-place. Otherwise, it will return a copy of idata with the predictions added. If kind=\"response_params\", a new variable with the name of the parent parameter, e.g. \"mu\" and \"sigma\" for a Gaussian likelihood, or“p”for a Bernoulli likelihood, is added to theposteriorgroup. Ifkind=“response”, it appends aposterior_predictivegroup toidata. If any of these already exist, it will be overwritten. |True| |include_group_specific| bool                            | Determines if predictions incorporate group-specific effects. IfFalse, predictions are made with common effects only (i.e. group specific are set to zero). Defaults toTrue.                                                                                                                                                                                                                                                                                   |True| |sample_new_groups| bool                            | Specifies if it is allowed to obtain predictions for new groups of group-specific terms. WhenTrue, each posterior sample for the new groups is drawn from the posterior draws of a randomly selected existing group. Since different groups may be selected at each draw, the end result represents the variation across existing groups. The method implemented is equivalent tosample_new_levels=“uncertainty”in brms.                                      |False| |random_seed| (int, RandomState or Generator) | Seed for the random number generator.                                                                                                                                                                                                                                                                                                                                                                                                                                |None`\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInferenceData or None\n\n\n\n\n\n\n\n\nModel.prior_predictive(self, draws=500, var_names=None, omit_offsets=True, random_seed=None)\nGenerate samples from the prior predictive distribution.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndraws\nint\nNumber of draws to sample from the prior predictive distribution. Defaults to 500.\n500\n\n\nvar_names\nstr or list\nA list of names of variables for which to compute the prior predictive distribution. Defaults to None which means both observed and unobserved RVs.\nNone\n\n\nomit_offsets\nbool\nWhether to omit offset terms in the plot. Defaults to True.\nTrue\n\n\nrandom_seed\nint\nSeed for the random number generator.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInferenceData\nInferenceData object with the groups prior, prior_predictive and observed_data.\n\n\n\n\n\n\n\nModel.r2_score(self, idata, summary=True)\nR² for Bayesian regression models.\nThe R², or coefficient of determination, is defined as the proportion of variance in the data that is explained by the model. It is computed as the variance of the predicted values divided by the variance of the predicted values plus the variance of the residuals. For details of the Bayesian R² see [1]_.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nidata\nInferenceData\nThe InferenceData instance returned by .fit(). It should contain the posterior_predictive group, otherwise it will be computed and added to idata.\nrequired\n\n\nsummary\nbool\nIf True, it returns a summary of the Bayesian R². Otherwise, it returns the posterior samples of the Bayesian R².\nTrue\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPandas Series with the following indices:\n\n\n\nmean value for the Bayesian R²\n\n\n\nstandard deviation of the Bayesian R².\n\n\n\n\n\n\n\n.. [1] Gelman et al. R-squared for Bayesian regression models. The American Statistician. 73(3) (2019). https://doi.org/10.1080/00031305.2018.1549100 preprint http://www.stat.columbia.edu/~gelman/research/published/bayes_R2_v3.pdf.\n\n\n\n\nModel.set_alias(self, aliases)\nSet aliases for the terms and auxiliary parameters in the model\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naliases\ndict\nA dictionary where key represents the original term name and the value is the alias.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone.\n\n\n\n\n\n\n\n\nModel.set_priors(self, priors=None, common=None, group_specific=None)\nSet priors for one or more existing terms\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npriors\ndict\nDictionary of priors to update. Keys are names of terms to update; values are the new priors (either a Prior instance, or an int or float that scales the default priors).\nNone\n\n\ncommon\nPrior, int, or float\nA prior specification to apply to all common terms included in the model.\nNone\n\n\ngroup_specific\nPrior, int, or float\nA prior specification to apply to all group specific terms included in the model.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone.",
    "crumbs": [
      "API Reference",
      "Model",
      "Model"
    ]
  },
  {
    "objectID": "api/clear_data_home.html",
    "href": "api/clear_data_home.html",
    "title": "clear_data_home",
    "section": "",
    "text": "data.clear_data_home(data_home=None)\nDelete all the content of the data home cache.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata_home\n\nThe path to Bambi data dir. By default a folder named \"bambi_data\" in the user home folder.\nNone",
    "crumbs": [
      "API Reference",
      "Data",
      "clear_data_home"
    ]
  },
  {
    "objectID": "api/clear_data_home.html#parameters",
    "href": "api/clear_data_home.html#parameters",
    "title": "clear_data_home",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndata_home\n\nThe path to Bambi data dir. By default a folder named \"bambi_data\" in the user home folder.\nNone",
    "crumbs": [
      "API Reference",
      "Data",
      "clear_data_home"
    ]
  },
  {
    "objectID": "api/interpret.comparisons.html",
    "href": "api/interpret.comparisons.html",
    "title": "interpret.comparisons",
    "section": "",
    "text": "interpret.comparisons(model, idata, contrast, conditional=None, average_by=None, comparison_type='diff', use_hdi=True, prob=None, transforms=None, sample_new_groups=False)\nCompute Conditional Adjusted Comparisons\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\nbambi.Model\nThe model for which we want to plot the predictions.\nrequired\n\n\nidata\narviz.InferenceData\nThe InferenceData object that contains the samples from the posterior distribution of the model.\nrequired\n\n\ncontrast\n(str, dict)\nThe predictor name whose contrast we would like to compare.\nrequired\n\n\nconditional\n(str, list, dict)\nThe covariates we would like to condition on. If dict, keys are the covariate names and values are the values to condition on.\nNone\n\n\naverage_by\nUnion[str, list, bool, None]\nThe covariates we would like to average by. The passed covariate(s) will marginalize over the other covariates in the model. If True, it averages over all covariates in the model to obtain the average estimate. Defaults to None.\nNone\n\n\ncomparison_type\nstr\nThe type of comparison to plot. Defaults to ‘diff’.\n'diff'\n\n\nuse_hdi\nbool\nWhether to compute the highest density interval (defaults to True) or the quantiles.\nTrue\n\n\nprob\nfloat\nThe probability for the credibility intervals. Must be between 0 and 1. Defaults to 0.94. Changing the global variable az.rcParams[\"stats.hdi_prob\"] affects this default.\nNone\n\n\ntransforms\ndict\nTransformations that are applied to each of the variables being plotted. The keys are the name of the variables, and the values are functions to be applied. Defaults to None.\nNone\n\n\nsample_new_groups\nbool\nIf the model contains group-level effects, and data is passed for unseen groups, whether to sample from the new groups. Defaults to False.\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nA dataframe with the comparison values, highest density interval, contrast name, contrast value, and conditional values.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nIf wrt is a dict and length of contrast is greater than 1. If wrt is a dict and length of contrast is greater than 2 and conditional is None. If conditional is None and contrast is categorical with &gt; 2 values. If conditional is a list and the length is greater than 3. If comparison_type is not ‘diff’ or ‘ratio’. If prob is not &gt; 0 and &lt; 1.",
    "crumbs": [
      "API Reference",
      "Interpretations",
      "interpret.comparisons"
    ]
  },
  {
    "objectID": "api/interpret.comparisons.html#parameters",
    "href": "api/interpret.comparisons.html#parameters",
    "title": "interpret.comparisons",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nmodel\nbambi.Model\nThe model for which we want to plot the predictions.\nrequired\n\n\nidata\narviz.InferenceData\nThe InferenceData object that contains the samples from the posterior distribution of the model.\nrequired\n\n\ncontrast\n(str, dict)\nThe predictor name whose contrast we would like to compare.\nrequired\n\n\nconditional\n(str, list, dict)\nThe covariates we would like to condition on. If dict, keys are the covariate names and values are the values to condition on.\nNone\n\n\naverage_by\nUnion[str, list, bool, None]\nThe covariates we would like to average by. The passed covariate(s) will marginalize over the other covariates in the model. If True, it averages over all covariates in the model to obtain the average estimate. Defaults to None.\nNone\n\n\ncomparison_type\nstr\nThe type of comparison to plot. Defaults to ‘diff’.\n'diff'\n\n\nuse_hdi\nbool\nWhether to compute the highest density interval (defaults to True) or the quantiles.\nTrue\n\n\nprob\nfloat\nThe probability for the credibility intervals. Must be between 0 and 1. Defaults to 0.94. Changing the global variable az.rcParams[\"stats.hdi_prob\"] affects this default.\nNone\n\n\ntransforms\ndict\nTransformations that are applied to each of the variables being plotted. The keys are the name of the variables, and the values are functions to be applied. Defaults to None.\nNone\n\n\nsample_new_groups\nbool\nIf the model contains group-level effects, and data is passed for unseen groups, whether to sample from the new groups. Defaults to False.\nFalse",
    "crumbs": [
      "API Reference",
      "Interpretations",
      "interpret.comparisons"
    ]
  },
  {
    "objectID": "api/interpret.comparisons.html#returns",
    "href": "api/interpret.comparisons.html#returns",
    "title": "interpret.comparisons",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\npandas.DataFrame\nA dataframe with the comparison values, highest density interval, contrast name, contrast value, and conditional values.",
    "crumbs": [
      "API Reference",
      "Interpretations",
      "interpret.comparisons"
    ]
  },
  {
    "objectID": "api/interpret.comparisons.html#raises",
    "href": "api/interpret.comparisons.html#raises",
    "title": "interpret.comparisons",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nValueError\nIf wrt is a dict and length of contrast is greater than 1. If wrt is a dict and length of contrast is greater than 2 and conditional is None. If conditional is None and contrast is categorical with &gt; 2 values. If conditional is a list and the length is greater than 3. If comparison_type is not ‘diff’ or ‘ratio’. If prob is not &gt; 0 and &lt; 1.",
    "crumbs": [
      "API Reference",
      "Interpretations",
      "interpret.comparisons"
    ]
  },
  {
    "objectID": "api/interpret.plot_predictions.html",
    "href": "api/interpret.plot_predictions.html",
    "title": "interpret.plot_predictions",
    "section": "",
    "text": "interpret.plot_predictions(model, idata, conditional=None, average_by=None, target='mean', sample_new_groups=False, pps=False, use_hdi=True, prob=None, transforms=None, legend=True, ax=None, fig_kwargs=None, subplot_kwargs=None)\nPlot Conditional Adjusted Predictions\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\nbambi.Model\nThe model for which we want to plot the predictions.\nrequired\n\n\nidata\narviz.InferenceData\nThe InferenceData object that contains the samples from the posterior distribution of the model.\nrequired\n\n\nconditional\n(str, list, dict)\nThe covariates we would like to condition on. If dict, keys are the covariate names and values are the values to condition on.\nNone\n\n\naverage_by\nUnion[str, list, None]\nThe covariates we would like to average by. The passed covariate(s) will marginalize over the other covariates in the model. If True, it averages over all covariates in the model to obtain the average estimate. Defaults to None.\nNone\n\n\ntarget\nstr\nWhich model parameter to plot. Defaults to ‘mean’. Passing a parameter into target only works when pps is False as the target may not be available in the posterior predictive distribution.\n'mean'\n\n\nsample_new_groups\nbool\nIf the model contains group-level effects, and data is passed for unseen groups, whether to sample from the new groups. Defaults to False.\nFalse\n\n\npps\nbool\nWhether to plot the posterior predictive samples. Defaults to False.\nFalse\n\n\nuse_hdi\nbool\nWhether to compute the highest density interval (defaults to True) or the quantiles.\nTrue\n\n\nprob\nfloat\nThe probability for the credibility intervals. Must be between 0 and 1. Defaults to 0.94. Changing the global variable az.rcParam[\"stats.hdi_prob\"] affects this default.\nNone\n\n\nlegend\nbool\nWhether to automatically include a legend in the plot. Defaults to True.\nTrue\n\n\ntransforms\ndict\nTransformations that are applied to each of the variables being plotted. The keys are the name of the variables, and the values are functions to be applied. Defaults to None.\nNone\n\n\nax\nmatplotlib.axes._subplots.AxesSubplot\nA matplotlib axes object or a sequence of them. If None, this function instantiates a new axes object. Defaults to None.\nNone\n\n\nfig_kwargs\noptional\nKeyword arguments passed to the matplotlib figure function as a dict. For example, fig_kwargs=dict(figsize=(11, 8)), sharey=True would make the figure 11 inches wide by 8 inches high and would share the y-axis values.\nNone\n\n\nsubplot_kwargs\noptional\nKeyword arguments used to determine the covariates used for the horizontal, group, and panel axes. For example, subplot_kwargs=dict(main=\"x\", group=\"y\", panel=\"z\") would plot the horizontal axis as x, the color (hue) as y, and the panel axis as z.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n(matplotlib.figure.Figure, matplotlib.axes._subplots.AxesSubplot)\nA tuple with the figure and the axes.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nIf conditional and average_by are both None. If length of conditional is greater than 3 and average_by is None. If main covariate is not numeric or categoric.",
    "crumbs": [
      "API Reference",
      "Plots",
      "interpret.plot_predictions"
    ]
  },
  {
    "objectID": "api/interpret.plot_predictions.html#parameters",
    "href": "api/interpret.plot_predictions.html#parameters",
    "title": "interpret.plot_predictions",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nmodel\nbambi.Model\nThe model for which we want to plot the predictions.\nrequired\n\n\nidata\narviz.InferenceData\nThe InferenceData object that contains the samples from the posterior distribution of the model.\nrequired\n\n\nconditional\n(str, list, dict)\nThe covariates we would like to condition on. If dict, keys are the covariate names and values are the values to condition on.\nNone\n\n\naverage_by\nUnion[str, list, None]\nThe covariates we would like to average by. The passed covariate(s) will marginalize over the other covariates in the model. If True, it averages over all covariates in the model to obtain the average estimate. Defaults to None.\nNone\n\n\ntarget\nstr\nWhich model parameter to plot. Defaults to ‘mean’. Passing a parameter into target only works when pps is False as the target may not be available in the posterior predictive distribution.\n'mean'\n\n\nsample_new_groups\nbool\nIf the model contains group-level effects, and data is passed for unseen groups, whether to sample from the new groups. Defaults to False.\nFalse\n\n\npps\nbool\nWhether to plot the posterior predictive samples. Defaults to False.\nFalse\n\n\nuse_hdi\nbool\nWhether to compute the highest density interval (defaults to True) or the quantiles.\nTrue\n\n\nprob\nfloat\nThe probability for the credibility intervals. Must be between 0 and 1. Defaults to 0.94. Changing the global variable az.rcParam[\"stats.hdi_prob\"] affects this default.\nNone\n\n\nlegend\nbool\nWhether to automatically include a legend in the plot. Defaults to True.\nTrue\n\n\ntransforms\ndict\nTransformations that are applied to each of the variables being plotted. The keys are the name of the variables, and the values are functions to be applied. Defaults to None.\nNone\n\n\nax\nmatplotlib.axes._subplots.AxesSubplot\nA matplotlib axes object or a sequence of them. If None, this function instantiates a new axes object. Defaults to None.\nNone\n\n\nfig_kwargs\noptional\nKeyword arguments passed to the matplotlib figure function as a dict. For example, fig_kwargs=dict(figsize=(11, 8)), sharey=True would make the figure 11 inches wide by 8 inches high and would share the y-axis values.\nNone\n\n\nsubplot_kwargs\noptional\nKeyword arguments used to determine the covariates used for the horizontal, group, and panel axes. For example, subplot_kwargs=dict(main=\"x\", group=\"y\", panel=\"z\") would plot the horizontal axis as x, the color (hue) as y, and the panel axis as z.\nNone",
    "crumbs": [
      "API Reference",
      "Plots",
      "interpret.plot_predictions"
    ]
  },
  {
    "objectID": "api/interpret.plot_predictions.html#returns",
    "href": "api/interpret.plot_predictions.html#returns",
    "title": "interpret.plot_predictions",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\n(matplotlib.figure.Figure, matplotlib.axes._subplots.AxesSubplot)\nA tuple with the figure and the axes.",
    "crumbs": [
      "API Reference",
      "Plots",
      "interpret.plot_predictions"
    ]
  },
  {
    "objectID": "api/interpret.plot_predictions.html#raises",
    "href": "api/interpret.plot_predictions.html#raises",
    "title": "interpret.plot_predictions",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nValueError\nIf conditional and average_by are both None. If length of conditional is greater than 3 and average_by is None. If main covariate is not numeric or categoric.",
    "crumbs": [
      "API Reference",
      "Plots",
      "interpret.plot_predictions"
    ]
  },
  {
    "objectID": "api/interpret.predictions.html",
    "href": "api/interpret.predictions.html",
    "title": "interpret.predictions",
    "section": "",
    "text": "interpret.predictions(model, idata, conditional=None, average_by=None, target='mean', pps=False, use_hdi=True, prob=None, transforms=None, sample_new_groups=False)\nCompute Conditional Adjusted Predictions\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\nbambi.Model\nThe model for which we want to plot the predictions.\nrequired\n\n\nidata\narviz.InferenceData\nThe InferenceData object that contains the samples from the posterior distribution of the model.\nrequired\n\n\nconditional\n(str, list, dict)\nThe covariates we would like to condition on. If dict, keys are the covariate names and values are the values to condition on.\nNone\n\n\naverage_by\nUnion[str, list, bool, None]\nThe covariates we would like to average by. The passed covariate(s) will marginalize over the other covariates in the model. If True, it averages over all covariates in the model to obtain the average estimate. Defaults to None.\nNone\n\n\ntarget\nstr\nWhich model parameter to plot. Defaults to ‘mean’. Passing a parameter into target only works when pps is False as the target may not be available in the posterior predictive distribution.\n'mean'\n\n\npps\nbool\nWhether to plot the posterior predictive samples. Defaults to False.\nFalse\n\n\nuse_hdi\nbool\nWhether to compute the highest density interval (defaults to True) or the quantiles.\nTrue\n\n\nprob\nfloat\nThe probability for the credibility intervals. Must be between 0 and 1. Defaults to 0.94. Changing the global variable az.rcParam[\"stats.hdi_prob\"] affects this default.\nNone\n\n\ntransforms\ndict\nTransformations that are applied to each of the variables being plotted. The keys are the name of the variables, and the values are functions to be applied. Defaults to None.\nNone\n\n\nsample_new_groups\nbool\nIf the model contains group-level effects, and data is passed for unseen groups, whether to sample from the new groups. Defaults to False.\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nA DataFrame with the create_cap_data and model predictions.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nIf pps is True and target is not \"mean\". If conditional is a list and the length is greater than 3. If prob is not &gt; 0 and &lt; 1.",
    "crumbs": [
      "API Reference",
      "Interpretations",
      "interpret.predictions"
    ]
  },
  {
    "objectID": "api/interpret.predictions.html#parameters",
    "href": "api/interpret.predictions.html#parameters",
    "title": "interpret.predictions",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nmodel\nbambi.Model\nThe model for which we want to plot the predictions.\nrequired\n\n\nidata\narviz.InferenceData\nThe InferenceData object that contains the samples from the posterior distribution of the model.\nrequired\n\n\nconditional\n(str, list, dict)\nThe covariates we would like to condition on. If dict, keys are the covariate names and values are the values to condition on.\nNone\n\n\naverage_by\nUnion[str, list, bool, None]\nThe covariates we would like to average by. The passed covariate(s) will marginalize over the other covariates in the model. If True, it averages over all covariates in the model to obtain the average estimate. Defaults to None.\nNone\n\n\ntarget\nstr\nWhich model parameter to plot. Defaults to ‘mean’. Passing a parameter into target only works when pps is False as the target may not be available in the posterior predictive distribution.\n'mean'\n\n\npps\nbool\nWhether to plot the posterior predictive samples. Defaults to False.\nFalse\n\n\nuse_hdi\nbool\nWhether to compute the highest density interval (defaults to True) or the quantiles.\nTrue\n\n\nprob\nfloat\nThe probability for the credibility intervals. Must be between 0 and 1. Defaults to 0.94. Changing the global variable az.rcParam[\"stats.hdi_prob\"] affects this default.\nNone\n\n\ntransforms\ndict\nTransformations that are applied to each of the variables being plotted. The keys are the name of the variables, and the values are functions to be applied. Defaults to None.\nNone\n\n\nsample_new_groups\nbool\nIf the model contains group-level effects, and data is passed for unseen groups, whether to sample from the new groups. Defaults to False.\nFalse",
    "crumbs": [
      "API Reference",
      "Interpretations",
      "interpret.predictions"
    ]
  },
  {
    "objectID": "api/interpret.predictions.html#returns",
    "href": "api/interpret.predictions.html#returns",
    "title": "interpret.predictions",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\npandas.DataFrame\nA DataFrame with the create_cap_data and model predictions.",
    "crumbs": [
      "API Reference",
      "Interpretations",
      "interpret.predictions"
    ]
  },
  {
    "objectID": "api/interpret.predictions.html#raises",
    "href": "api/interpret.predictions.html#raises",
    "title": "interpret.predictions",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nValueError\nIf pps is True and target is not \"mean\". If conditional is a list and the length is greater than 3. If prob is not &gt; 0 and &lt; 1.",
    "crumbs": [
      "API Reference",
      "Interpretations",
      "interpret.predictions"
    ]
  },
  {
    "objectID": "api/load_data.html",
    "href": "api/load_data.html",
    "title": "load_data",
    "section": "",
    "text": "data.load_data(dataset=None, data_home=None)\nLoad a dataset.\nRun with no parameters to get a list of all available data sets.\nThe directory to save can also be set with the environment variable BAMBI_HOME. The checksum of the dataset is checked against a hardcoded value to watch for data corruption. Run bmb.clear_data_home() to clear the data directory.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndataset\n\nName of dataset to load.\nNone\n\n\ndata_home\n\nWhere to save remote datasets\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame",
    "crumbs": [
      "API Reference",
      "Data",
      "load_data"
    ]
  },
  {
    "objectID": "api/load_data.html#parameters",
    "href": "api/load_data.html#parameters",
    "title": "load_data",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndataset\n\nName of dataset to load.\nNone\n\n\ndata_home\n\nWhere to save remote datasets\nNone",
    "crumbs": [
      "API Reference",
      "Data",
      "load_data"
    ]
  },
  {
    "objectID": "api/load_data.html#returns",
    "href": "api/load_data.html#returns",
    "title": "load_data",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\npandas.DataFrame",
    "crumbs": [
      "API Reference",
      "Data",
      "load_data"
    ]
  },
  {
    "objectID": "faq.html",
    "href": "faq.html",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "Bambi is a regression library built on top of PyMC. It provides a simple interface for specifying Bayesian models, and allows for easy inference using MCMC or variational inference.\nPyMC is a library for Bayesian modelling, and is the backend used by Bambi. It is a very powerful library, but can be challenging to use for beginners. Bambi provides a simple interface for specifying models, and allows for easy inference via MCMC or variational inference using PyMC."
  },
  {
    "objectID": "faq.html#general-questions",
    "href": "faq.html#general-questions",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "Bambi is a regression library built on top of PyMC. It provides a simple interface for specifying Bayesian models, and allows for easy inference using MCMC or variational inference.\nPyMC is a library for Bayesian modelling, and is the backend used by Bambi. It is a very powerful library, but can be challenging to use for beginners. Bambi provides a simple interface for specifying models, and allows for easy inference via MCMC or variational inference using PyMC."
  },
  {
    "objectID": "faq.html#inference-questions",
    "href": "faq.html#inference-questions",
    "title": "Frequently Asked Questions",
    "section": "Inference Questions",
    "text": "Inference Questions\n\nWhat sampling methods are available?\nThe sampler used is automatically selected given the type of variables used in the model. For inference, Bambi supports both MCMC and variational inference. MCMC is the default, but you can specify variational inference by passing inference_method='vi' to Model.fit(). Bambi also supports multiple backends for MCMC, including NumPyro, and BlackJax. See API for “fit” method for more details here.\n\n\nCan inference in Bambi be sped up using GPUs/TPUs?\nYes, Bambi supports inference on GPUs and TPUs using the numpyro and blackjax backends. See the API for “fit” method for more details here."
  },
  {
    "objectID": "faq.html#model-specification-questions",
    "href": "faq.html#model-specification-questions",
    "title": "Frequently Asked Questions",
    "section": "Model Specification Questions",
    "text": "Model Specification Questions\n\nMy data has a non-normal distributions, can I still use Bambi?\nYes, Bambi supports a wide range of distributions which can be specified using the “family” argument to the “Model”. You can find examples of how to specify these distributions in the Bambi examples.\n\n\nHow do I find out what priors are available?\nYou can use any valid PyMC distribution as a prior. You can find a list of all the distributions available in PyMC here. You can also find examples of how to specify priors in the Bambi examples, and in the Getting Started Guide.\n\n\nDoes bambi come with pre-specified regression models?\nTo allow building of bespoke models, Bambi does not come with pre-specified regression models. However, you can find examples of how to specify models in the Bambi examples."
  }
]